b'\n\nfrom __future__ import division, absolute_import, print_function\n\nimport os\n\nfrom numpy.distutils.cpuinfo import cpu\nfrom numpy.distutils.fcompiler import FCompiler, dummy_fortran_file\nfrom numpy.distutils.misc_util import cyg2win32\n\ncompilers = [\'AbsoftFCompiler\']\n\nclass AbsoftFCompiler(FCompiler):\n\n    compiler_type = \'absoft\'\n    description = \'Absoft Corp Fortran Compiler\'\n        version_pattern = r\'(f90:.*?(Absoft Pro FORTRAN Version|FORTRAN 77 Compiler|Absoft Fortran Compiler Version|Copyright Absoft Corporation.*?Version))\'+\\\n                       r\' (?P<version>[^\\s*,]*)(.*?Absoft Corp|)\'\n\n        \n            \n    executables = {\n        \'version_cmd\'  : None,                  \'compiler_f77\' : ["f77"],\n        \'compiler_fix\' : ["f90"],\n        \'compiler_f90\' : ["f90"],\n        \'linker_so\'    : ["<F90>"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    if os.name==\'nt\':\n        library_switch = \'/out:\'      \n    module_dir_switch = None\n    module_include_switch = \'-p\'\n\n    def update_executables(self):\n        f = cyg2win32(dummy_fortran_file())\n        self.executables[\'version_cmd\'] = [\'<F90>\', \'-V\', \'-c\',\n                                           f+\'.f\', \'-o\', f+\'.o\']\n\n    def get_flags_linker_so(self):\n        if os.name==\'nt\':\n            opt = [\'/dll\']\n                                        elif self.get_version() >= \'9.0\':\n            opt = [\'-shared\']\n        else:\n            opt = ["-K", "shared"]\n        return opt\n\n    def library_dir_option(self, dir):\n        if os.name==\'nt\':\n            return [\'-link\', \'/PATH:"%s"\' % (dir)]\n        return "-L" + dir\n\n    def library_option(self, lib):\n        if os.name==\'nt\':\n            return \'%s.lib\' % (lib)\n        return "-l" + lib\n\n    def get_library_dirs(self):\n        opt = FCompiler.get_library_dirs(self)\n        d = os.environ.get(\'ABSOFT\')\n        if d:\n            if self.get_version() >= \'10.0\':\n                                prefix = \'sh\'\n            else:\n                prefix = \'\'\n            if cpu.is_64bit():\n                suffix = \'64\'\n            else:\n                suffix = \'\'\n            opt.append(os.path.join(d, \'%slib%s\' % (prefix, suffix)))\n        return opt\n\n    def get_libraries(self):\n        opt = FCompiler.get_libraries(self)\n        if self.get_version() >= \'11.0\':\n            opt.extend([\'af90math\', \'afio\', \'af77math\', \'amisc\'])\n        elif self.get_version() >= \'10.0\':\n            opt.extend([\'af90math\', \'afio\', \'af77math\', \'U77\'])\n        elif self.get_version() >= \'8.0\':\n            opt.extend([\'f90math\', \'fio\', \'f77math\', \'U77\'])\n        else:\n            opt.extend([\'fio\', \'f90math\', \'fmath\', \'U77\'])\n        if os.name ==\'nt\':\n            opt.append(\'COMDLG32\')\n        return opt\n\n    def get_flags(self):\n        opt = FCompiler.get_flags(self)\n        if os.name != \'nt\':\n            opt.extend([\'-s\'])\n            if self.get_version():\n                if self.get_version()>=\'8.2\':\n                    opt.append(\'-fpic\')\n        return opt\n\n    def get_flags_f77(self):\n        opt = FCompiler.get_flags_f77(self)\n        opt.extend([\'-N22\', \'-N90\', \'-N110\'])\n        v = self.get_version()\n        if os.name == \'nt\':\n            if v and v>=\'8.0\':\n                opt.extend([\'-f\', \'-N15\'])\n        else:\n            opt.append(\'-f\')\n            if v:\n                if v<=\'4.6\':\n                    opt.append(\'-B108\')\n                else:\n                                                            opt.append(\'-N15\')\n        return opt\n\n    def get_flags_f90(self):\n        opt = FCompiler.get_flags_f90(self)\n        opt.extend(["-YCFRL=1", "-YCOM_NAMES=LCS", "-YCOM_PFX", "-YEXT_PFX",\n                    "-YCOM_SFX=_", "-YEXT_SFX=_", "-YEXT_NAMES=LCS"])\n        if self.get_version():\n            if self.get_version()>\'4.6\':\n                opt.extend(["-YDEALLOC=ALL"])\n        return opt\n\n    def get_flags_fix(self):\n        opt = FCompiler.get_flags_fix(self)\n        opt.extend(["-YCFRL=1", "-YCOM_NAMES=LCS", "-YCOM_PFX", "-YEXT_PFX",\n                    "-YCOM_SFX=_", "-YEXT_SFX=_", "-YEXT_NAMES=LCS"])\n        opt.extend(["-f", "fixed"])\n        return opt\n\n    def get_flags_opt(self):\n        opt = [\'-O\']\n        return opt\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'absoft\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.lib import add_newdoc\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\',\n    )\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\', (\'base\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\', (\'coords\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\', (\'index\',\n    ))\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\', (\'__array__\',\n    ))\n\n\nadd_newdoc(\'numpy.core\', \'flatiter\', (\'copy\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core\', \'nditer\',\n    )\n\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'copy\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'debug_print\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'enable_external_loop\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'iternext\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'remove_axis\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'remove_multi_index\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'nditer\', (\'reset\',\n    ))\n\n\n\n\nadd_newdoc(\'numpy.core\', \'broadcast\',\n    )\n\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'index\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'iters\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'nd\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'numiter\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'shape\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'size\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'broadcast\', (\'reset\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'array\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'empty\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'empty_like\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'scalar\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'zeros\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'count_nonzero\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'set_typeDict\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'fromstring\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'fromiter\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'fromfile\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'frombuffer\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'concatenate\',\n    )\n\nadd_newdoc(\'numpy.core\', \'inner\',\n    )\n\nadd_newdoc(\'numpy.core\', \'fastCopyAndTranspose\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'correlate\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'arange\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'_get_ndarray_c_version\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'_reconstruct\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'set_string_function\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'set_numeric_ops\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'where\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'lexsort\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'can_cast\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'promote_types\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'min_scalar_type\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'result_type\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'newbuffer\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'getbuffer\',\n    )\n\nadd_newdoc(\'numpy.core\', \'dot\',\n    )\n\nadd_newdoc(\'numpy.core\', \'matmul\',\n    )\n\n\nadd_newdoc(\'numpy.core\', \'einsum\',\n    )\n\nadd_newdoc(\'numpy.core\', \'vdot\',\n    )\n\n\n\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\',\n    )\n\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_interface__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_finalize__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_priority__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_struct__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'_as_parameter_\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'base\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'ctypes\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'data\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'dtype\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'imag\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'itemsize\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'flags\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'flat\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'nbytes\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'ndim\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'real\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'shape\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'size\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'strides\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'T\',\n    ))\n\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_prepare__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__array_wrap__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__copy__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__deepcopy__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__reduce__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'__setstate__\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'all\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'any\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'argmax\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'argmin\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'argsort\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'argpartition\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'astype\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'byteswap\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'choose\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'clip\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'compress\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'conj\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'conjugate\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'copy\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'cumprod\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'cumsum\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'diagonal\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'dot\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'dump\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'dumps\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'fill\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'flatten\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'getfield\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'item\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'itemset\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'max\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'mean\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'min\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'shares_memory\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'newbyteorder\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'nonzero\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'prod\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'ptp\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'put\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'copyto\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'putmask\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'ravel\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'repeat\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'reshape\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'resize\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'round\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'searchsorted\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'setfield\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'setflags\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'sort\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'partition\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'squeeze\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'std\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'sum\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'swapaxes\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'take\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'tofile\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'tolist\',\n    ))\n\n\ntobytesdoc = \n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\',\n           (\'tostring\', tobytesdoc.format(name=\'tostring\',\n                                          deprecated=\n                                          \'This function is a compatibility \'\n                                          \'alias for tobytes. Despite its \'\n                                          \'name it returns bytes not \'\n                                          \'strings.\')))\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\',\n           (\'tobytes\', tobytesdoc.format(name=\'tobytes\',\n                                         deprecated=\'.. versionadded:: 1.9.0\')))\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'trace\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'transpose\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'var\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'ndarray\', (\'view\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core.umath\', \'frompyfunc\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'geterrobj\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'seterrobj\',\n    )\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'digitize\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'bincount\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'ravel_multi_index\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'unravel_index\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'add_docstring\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'_add_newdoc_ufunc\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'packbits\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'unpackbits\',\n    )\n\n\n\n\n\nadd_newdoc(\'numpy.core\', \'ufunc\',\n    )\n\n\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'identity\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'nargs\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'nin\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'nout\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'ntypes\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'types\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'reduce\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'accumulate\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'reduceat\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'outer\',\n    ))\n\nadd_newdoc(\'numpy.core\', \'ufunc\', (\'at\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\',\n    )\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'alignment\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'byteorder\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'char\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'descr\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'fields\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'flags\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'hasobject\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'isbuiltin\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'isnative\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'isalignedstruct\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'itemsize\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'kind\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'name\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'names\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'num\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'shape\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'str\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'subdtype\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'type\',\n    ))\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'dtype\', (\'newbyteorder\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core.multiarray\', \'busdaycalendar\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'busdaycalendar\', (\'weekmask\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'busdaycalendar\', (\'holidays\',\n    ))\n\nadd_newdoc(\'numpy.core.multiarray\', \'is_busday\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'busday_offset\',\n    )\n\nadd_newdoc(\'numpy.core.multiarray\', \'busday_count\',\n    )\n\n\nadd_newdoc(\'numpy.lib.index_tricks\', \'mgrid\',\n    )\n\nadd_newdoc(\'numpy.lib.index_tricks\', \'ogrid\',\n    )\n\n\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\',\n    )\n\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'T\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'base\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'data\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'dtype\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'flags\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'flat\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'imag\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'itemsize\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'nbytes\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'ndim\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'real\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'shape\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'size\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'strides\',\n    ))\n\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'all\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'any\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'argmax\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'argmin\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'argsort\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'astype\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'byteswap\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'choose\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'clip\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'compress\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'conjugate\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'copy\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'cumprod\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'cumsum\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'diagonal\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'dump\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'dumps\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'fill\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'flatten\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'getfield\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'item\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'itemset\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'max\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'mean\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'min\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'newbyteorder\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'nonzero\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'prod\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'ptp\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'put\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'ravel\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'repeat\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'reshape\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'resize\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'round\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'searchsorted\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'setfield\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'setflags\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'sort\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'squeeze\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'std\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'sum\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'swapaxes\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'take\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'tofile\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'tolist\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'tostring\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'trace\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'transpose\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'var\',\n    ))\n\nadd_newdoc(\'numpy.core.numerictypes\', \'generic\', (\'view\',\n    ))\n\n\n\nadd_newdoc(\'numpy.core.numerictypes\', \'bool_\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'complex64\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'complex128\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'complex256\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'float32\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'float64\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'float96\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'float128\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'int8\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'int16\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'int32\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'int64\',\n    )\n\nadd_newdoc(\'numpy.core.numerictypes\', \'object_\',\n    )\nimport os\nimport sys\nimport re\n\n__all__ = [\'uses_accelerate_framework\', \'get_sgemv_fix\']\n\ndef uses_accelerate_framework(info):\n    \n    if sys.platform != "darwin":\n        return False\n    r_accelerate = re.compile("Accelerate")\n    extra_link_args = info.get(\'extra_link_args\', \'\')\n    for arg in extra_link_args:\n        if r_accelerate.search(arg):\n            return True\n    return False\n\ndef get_sgemv_fix():\n    \n    path = os.path.abspath(os.path.dirname(__file__))\n    return [os.path.join(path, \'src\', \'apple_sgemv_fix.c\')]\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\n\n__all__ = [\'pad\']\n\n\n\n\ndef _arange_ndarray(arr, shape, axis, reverse=False):\n    \n    initshape = tuple(1 if i != axis else shape[axis]\n                      for (i, x) in enumerate(arr.shape))\n    if not reverse:\n        padarr = np.arange(1, shape[axis] + 1)\n    else:\n        padarr = np.arange(shape[axis], 0, -1)\n    padarr = padarr.reshape(initshape)\n    for i, dim in enumerate(shape):\n        if padarr.shape[i] != dim:\n            padarr = padarr.repeat(dim, axis=i)\n    return padarr\n\n\ndef _round_ifneeded(arr, dtype):\n    \n    if np.issubdtype(dtype, np.integer):\n        arr.round(out=arr)\n\n\ndef _prepend_const(arr, pad_amt, val, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n    padshape = tuple(x if i != axis else pad_amt\n                     for (i, x) in enumerate(arr.shape))\n    if val == 0:\n        return np.concatenate((np.zeros(padshape, dtype=arr.dtype), arr),\n                              axis=axis)\n    else:\n        return np.concatenate(((np.zeros(padshape) + val).astype(arr.dtype),\n                               arr), axis=axis)\n\n\ndef _append_const(arr, pad_amt, val, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n    padshape = tuple(x if i != axis else pad_amt\n                     for (i, x) in enumerate(arr.shape))\n    if val == 0:\n        return np.concatenate((arr, np.zeros(padshape, dtype=arr.dtype)),\n                              axis=axis)\n    else:\n        return np.concatenate(\n            (arr, (np.zeros(padshape) + val).astype(arr.dtype)), axis=axis)\n\n\ndef _prepend_edge(arr, pad_amt, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n    edge_slice = tuple(slice(None) if i != axis else 0\n                       for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n    edge_arr = arr[edge_slice].reshape(pad_singleton)\n    return np.concatenate((edge_arr.repeat(pad_amt, axis=axis), arr),\n                          axis=axis)\n\n\ndef _append_edge(arr, pad_amt, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n    edge_slice = tuple(slice(None) if i != axis else arr.shape[axis] - 1\n                       for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n    edge_arr = arr[edge_slice].reshape(pad_singleton)\n    return np.concatenate((arr, edge_arr.repeat(pad_amt, axis=axis)),\n                          axis=axis)\n\n\ndef _prepend_ramp(arr, pad_amt, end, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        padshape = tuple(x if i != axis else pad_amt\n                     for (i, x) in enumerate(arr.shape))\n\n        ramp_arr = _arange_ndarray(arr, padshape, axis,\n                               reverse=True).astype(np.float64)\n\n        edge_slice = tuple(slice(None) if i != axis else 0\n                       for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        edge_pad = arr[edge_slice].reshape(pad_singleton).repeat(pad_amt, axis)\n\n        slope = (end - edge_pad) / float(pad_amt)\n    ramp_arr = ramp_arr * slope\n    ramp_arr += edge_pad\n    _round_ifneeded(ramp_arr, arr.dtype)\n\n        return np.concatenate((ramp_arr.astype(arr.dtype), arr), axis=axis)\n\n\ndef _append_ramp(arr, pad_amt, end, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        padshape = tuple(x if i != axis else pad_amt\n                     for (i, x) in enumerate(arr.shape))\n\n        ramp_arr = _arange_ndarray(arr, padshape, axis,\n                               reverse=False).astype(np.float64)\n\n        edge_slice = tuple(slice(None) if i != axis else -1\n                       for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        edge_pad = arr[edge_slice].reshape(pad_singleton).repeat(pad_amt, axis)\n\n        slope = (end - edge_pad) / float(pad_amt)\n    ramp_arr = ramp_arr * slope\n    ramp_arr += edge_pad\n    _round_ifneeded(ramp_arr, arr.dtype)\n\n        return np.concatenate((arr, ramp_arr.astype(arr.dtype)), axis=axis)\n\n\ndef _prepend_max(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _prepend_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        max_slice = tuple(slice(None) if i != axis else slice(num)\n                      for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        max_chunk = arr[max_slice].max(axis=axis).reshape(pad_singleton)\n\n        return np.concatenate((max_chunk.repeat(pad_amt, axis=axis), arr),\n                          axis=axis)\n\n\ndef _append_max(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _append_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        end = arr.shape[axis] - 1\n    if num is not None:\n        max_slice = tuple(\n            slice(None) if i != axis else slice(end, end - num, -1)\n            for (i, x) in enumerate(arr.shape))\n    else:\n        max_slice = tuple(slice(None) for x in arr.shape)\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        max_chunk = arr[max_slice].max(axis=axis).reshape(pad_singleton)\n\n        return np.concatenate((arr, max_chunk.repeat(pad_amt, axis=axis)),\n                          axis=axis)\n\n\ndef _prepend_mean(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _prepend_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        mean_slice = tuple(slice(None) if i != axis else slice(num)\n                       for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        mean_chunk = arr[mean_slice].mean(axis).reshape(pad_singleton)\n    _round_ifneeded(mean_chunk, arr.dtype)\n\n        return np.concatenate((mean_chunk.repeat(pad_amt, axis).astype(arr.dtype),\n                           arr), axis=axis)\n\n\ndef _append_mean(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _append_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        end = arr.shape[axis] - 1\n    if num is not None:\n        mean_slice = tuple(\n            slice(None) if i != axis else slice(end, end - num, -1)\n            for (i, x) in enumerate(arr.shape))\n    else:\n        mean_slice = tuple(slice(None) for x in arr.shape)\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        mean_chunk = arr[mean_slice].mean(axis=axis).reshape(pad_singleton)\n    _round_ifneeded(mean_chunk, arr.dtype)\n\n        return np.concatenate(\n        (arr, mean_chunk.repeat(pad_amt, axis).astype(arr.dtype)), axis=axis)\n\n\ndef _prepend_med(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _prepend_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        med_slice = tuple(slice(None) if i != axis else slice(num)\n                      for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        med_chunk = np.median(arr[med_slice], axis=axis).reshape(pad_singleton)\n    _round_ifneeded(med_chunk, arr.dtype)\n\n        return np.concatenate(\n        (med_chunk.repeat(pad_amt, axis).astype(arr.dtype), arr), axis=axis)\n\n\ndef _append_med(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _append_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        end = arr.shape[axis] - 1\n    if num is not None:\n        med_slice = tuple(\n            slice(None) if i != axis else slice(end, end - num, -1)\n            for (i, x) in enumerate(arr.shape))\n    else:\n        med_slice = tuple(slice(None) for x in arr.shape)\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        med_chunk = np.median(arr[med_slice], axis=axis).reshape(pad_singleton)\n    _round_ifneeded(med_chunk, arr.dtype)\n\n        return np.concatenate(\n        (arr, med_chunk.repeat(pad_amt, axis).astype(arr.dtype)), axis=axis)\n\n\ndef _prepend_min(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _prepend_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        min_slice = tuple(slice(None) if i != axis else slice(num)\n                      for (i, x) in enumerate(arr.shape))\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        min_chunk = arr[min_slice].min(axis=axis).reshape(pad_singleton)\n\n        return np.concatenate((min_chunk.repeat(pad_amt, axis=axis), arr),\n                          axis=axis)\n\n\ndef _append_min(arr, pad_amt, num, axis=-1):\n    \n    if pad_amt == 0:\n        return arr\n\n        if num == 1:\n        return _append_edge(arr, pad_amt, axis)\n\n        if num is not None:\n        if num >= arr.shape[axis]:\n            num = None\n\n        end = arr.shape[axis] - 1\n    if num is not None:\n        min_slice = tuple(\n            slice(None) if i != axis else slice(end, end - num, -1)\n            for (i, x) in enumerate(arr.shape))\n    else:\n        min_slice = tuple(slice(None) for x in arr.shape)\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n\n        min_chunk = arr[min_slice].min(axis=axis).reshape(pad_singleton)\n\n        return np.concatenate((arr, min_chunk.repeat(pad_amt, axis=axis)),\n                          axis=axis)\n\n\ndef _pad_ref(arr, pad_amt, method, axis=-1):\n    \n        if pad_amt[0] == 0 and pad_amt[1] == 0:\n        return arr\n\n        \n        ref_slice = tuple(slice(None) if i != axis else slice(pad_amt[0], 0, -1)\n                      for (i, x) in enumerate(arr.shape))\n\n    ref_chunk1 = arr[ref_slice]\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n    if pad_amt[0] == 1:\n        ref_chunk1 = ref_chunk1.reshape(pad_singleton)\n\n        if \'odd\' in method and pad_amt[0] > 0:\n        edge_slice1 = tuple(slice(None) if i != axis else 0\n                            for (i, x) in enumerate(arr.shape))\n        edge_chunk = arr[edge_slice1].reshape(pad_singleton)\n        ref_chunk1 = 2 * edge_chunk - ref_chunk1\n        del edge_chunk\n\n        \n        start = arr.shape[axis] - pad_amt[1] - 1\n    end = arr.shape[axis] - 1\n    ref_slice = tuple(slice(None) if i != axis else slice(start, end)\n                      for (i, x) in enumerate(arr.shape))\n    rev_idx = tuple(slice(None) if i != axis else slice(None, None, -1)\n                    for (i, x) in enumerate(arr.shape))\n    ref_chunk2 = arr[ref_slice][rev_idx]\n\n    if pad_amt[1] == 1:\n        ref_chunk2 = ref_chunk2.reshape(pad_singleton)\n\n    if \'odd\' in method:\n        edge_slice2 = tuple(slice(None) if i != axis else -1\n                            for (i, x) in enumerate(arr.shape))\n        edge_chunk = arr[edge_slice2].reshape(pad_singleton)\n        ref_chunk2 = 2 * edge_chunk - ref_chunk2\n        del edge_chunk\n\n        return np.concatenate((ref_chunk1, arr, ref_chunk2), axis=axis)\n\n\ndef _pad_sym(arr, pad_amt, method, axis=-1):\n    \n        if pad_amt[0] == 0 and pad_amt[1] == 0:\n        return arr\n\n        \n        sym_slice = tuple(slice(None) if i != axis else slice(0, pad_amt[0])\n                      for (i, x) in enumerate(arr.shape))\n    rev_idx = tuple(slice(None) if i != axis else slice(None, None, -1)\n                    for (i, x) in enumerate(arr.shape))\n    sym_chunk1 = arr[sym_slice][rev_idx]\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n    if pad_amt[0] == 1:\n        sym_chunk1 = sym_chunk1.reshape(pad_singleton)\n\n        if \'odd\' in method and pad_amt[0] > 0:\n        edge_slice1 = tuple(slice(None) if i != axis else 0\n                            for (i, x) in enumerate(arr.shape))\n        edge_chunk = arr[edge_slice1].reshape(pad_singleton)\n        sym_chunk1 = 2 * edge_chunk - sym_chunk1\n        del edge_chunk\n\n        \n        start = arr.shape[axis] - pad_amt[1]\n    end = arr.shape[axis]\n    sym_slice = tuple(slice(None) if i != axis else slice(start, end)\n                      for (i, x) in enumerate(arr.shape))\n    sym_chunk2 = arr[sym_slice][rev_idx]\n\n    if pad_amt[1] == 1:\n        sym_chunk2 = sym_chunk2.reshape(pad_singleton)\n\n    if \'odd\' in method:\n        edge_slice2 = tuple(slice(None) if i != axis else -1\n                            for (i, x) in enumerate(arr.shape))\n        edge_chunk = arr[edge_slice2].reshape(pad_singleton)\n        sym_chunk2 = 2 * edge_chunk - sym_chunk2\n        del edge_chunk\n\n        return np.concatenate((sym_chunk1, arr, sym_chunk2), axis=axis)\n\n\ndef _pad_wrap(arr, pad_amt, axis=-1):\n    \n        if pad_amt[0] == 0 and pad_amt[1] == 0:\n        return arr\n\n        \n        start = arr.shape[axis] - pad_amt[0]\n    end = arr.shape[axis]\n    wrap_slice = tuple(slice(None) if i != axis else slice(start, end)\n                       for (i, x) in enumerate(arr.shape))\n    wrap_chunk1 = arr[wrap_slice]\n\n        pad_singleton = tuple(x if i != axis else 1\n                          for (i, x) in enumerate(arr.shape))\n    if pad_amt[0] == 1:\n        wrap_chunk1 = wrap_chunk1.reshape(pad_singleton)\n\n        \n        wrap_slice = tuple(slice(None) if i != axis else slice(0, pad_amt[1])\n                       for (i, x) in enumerate(arr.shape))\n    wrap_chunk2 = arr[wrap_slice]\n\n    if pad_amt[1] == 1:\n        wrap_chunk2 = wrap_chunk2.reshape(pad_singleton)\n\n        return np.concatenate((wrap_chunk1, arr, wrap_chunk2), axis=axis)\n\n\ndef _normalize_shape(ndarray, shape, cast_to_int=True):\n    \n    ndims = ndarray.ndim\n\n        if shape is None:\n        return ((None, None), ) * ndims\n\n        arr = np.asarray(shape)\n\n        if arr.ndim <= 1:\n        if arr.shape == () or arr.shape == (1,):\n                                    arr = np.ones((ndims, 2), dtype=ndarray.dtype) * arr\n        elif arr.shape == (2,):\n                                    arr = arr[np.newaxis, :].repeat(ndims, axis=0)\n        else:\n            fmt = "Unable to create correctly shaped tuple from %s"\n            raise ValueError(fmt % (shape,))\n\n    elif arr.ndim == 2:\n        if arr.shape[1] == 1 and arr.shape[0] == ndims:\n                        arr = arr.repeat(2, axis=1)\n        elif arr.shape[0] == ndims:\n                        arr = shape\n        else:\n            fmt = "Unable to create correctly shaped tuple from %s"\n            raise ValueError(fmt % (shape,))\n\n    else:\n        fmt = "Unable to create correctly shaped tuple from %s"\n        raise ValueError(fmt % (shape,))\n\n        if cast_to_int is True:\n        arr = np.round(arr).astype(int)\n\n        return tuple(tuple(axis) for axis in arr.tolist())\n\n\ndef _validate_lengths(narray, number_elements):\n    \n    normshp = _normalize_shape(narray, number_elements)\n    for i in normshp:\n        chk = [1 if x is None else x for x in i]\n        chk = [1 if x >= 0 else -1 for x in chk]\n        if (chk[0] < 0) or (chk[1] < 0):\n            fmt = "%s cannot contain negative values."\n            raise ValueError(fmt % (number_elements,))\n    return normshp\n\n\n\n\ndef pad(array, pad_width, mode, **kwargs):\n    \n    if not np.asarray(pad_width).dtype.kind == \'i\':\n        raise TypeError(\'`pad_width` must be of integral type.\')\n\n    narray = np.array(array)\n    pad_width = _validate_lengths(narray, pad_width)\n\n    allowedkwargs = {\n        \'constant\': [\'constant_values\'],\n        \'edge\': [],\n        \'linear_ramp\': [\'end_values\'],\n        \'maximum\': [\'stat_length\'],\n        \'mean\': [\'stat_length\'],\n        \'median\': [\'stat_length\'],\n        \'minimum\': [\'stat_length\'],\n        \'reflect\': [\'reflect_type\'],\n        \'symmetric\': [\'reflect_type\'],\n        \'wrap\': [],\n        }\n\n    kwdefaults = {\n        \'stat_length\': None,\n        \'constant_values\': 0,\n        \'end_values\': 0,\n        \'reflect_type\': \'even\',\n        }\n\n    if isinstance(mode, str):\n                for key in kwargs:\n            if key not in allowedkwargs[mode]:\n                raise ValueError(\'%s keyword not in allowed keywords %s\' %\n                                 (key, allowedkwargs[mode]))\n\n                for kw in allowedkwargs[mode]:\n            kwargs.setdefault(kw, kwdefaults[kw])\n\n                for i in kwargs:\n            if i == \'stat_length\':\n                kwargs[i] = _validate_lengths(narray, kwargs[i])\n            if i in [\'end_values\', \'constant_values\']:\n                kwargs[i] = _normalize_shape(narray, kwargs[i],\n                                             cast_to_int=False)\n    else:\n                        function = mode\n\n                rank = list(range(len(narray.shape)))\n        total_dim_increase = [np.sum(pad_width[i]) for i in rank]\n        offset_slices = [slice(pad_width[i][0],\n                               pad_width[i][0] + narray.shape[i])\n                         for i in rank]\n        new_shape = np.array(narray.shape) + total_dim_increase\n        newmat = np.zeros(new_shape, narray.dtype)\n\n                newmat[offset_slices] = narray\n\n                for iaxis in rank:\n            np.apply_along_axis(function,\n                                iaxis,\n                                newmat,\n                                pad_width[iaxis],\n                                iaxis,\n                                kwargs)\n        return newmat\n\n        newmat = narray.copy()\n\n            if mode == \'constant\':\n        for axis, ((pad_before, pad_after), (before_val, after_val)) \\\n                in enumerate(zip(pad_width, kwargs[\'constant_values\'])):\n            newmat = _prepend_const(newmat, pad_before, before_val, axis)\n            newmat = _append_const(newmat, pad_after, after_val, axis)\n\n    elif mode == \'edge\':\n        for axis, (pad_before, pad_after) in enumerate(pad_width):\n            newmat = _prepend_edge(newmat, pad_before, axis)\n            newmat = _append_edge(newmat, pad_after, axis)\n\n    elif mode == \'linear_ramp\':\n        for axis, ((pad_before, pad_after), (before_val, after_val)) \\\n                in enumerate(zip(pad_width, kwargs[\'end_values\'])):\n            newmat = _prepend_ramp(newmat, pad_before, before_val, axis)\n            newmat = _append_ramp(newmat, pad_after, after_val, axis)\n\n    elif mode == \'maximum\':\n        for axis, ((pad_before, pad_after), (chunk_before, chunk_after)) \\\n                in enumerate(zip(pad_width, kwargs[\'stat_length\'])):\n            newmat = _prepend_max(newmat, pad_before, chunk_before, axis)\n            newmat = _append_max(newmat, pad_after, chunk_after, axis)\n\n    elif mode == \'mean\':\n        for axis, ((pad_before, pad_after), (chunk_before, chunk_after)) \\\n                in enumerate(zip(pad_width, kwargs[\'stat_length\'])):\n            newmat = _prepend_mean(newmat, pad_before, chunk_before, axis)\n            newmat = _append_mean(newmat, pad_after, chunk_after, axis)\n\n    elif mode == \'median\':\n        for axis, ((pad_before, pad_after), (chunk_before, chunk_after)) \\\n                in enumerate(zip(pad_width, kwargs[\'stat_length\'])):\n            newmat = _prepend_med(newmat, pad_before, chunk_before, axis)\n            newmat = _append_med(newmat, pad_after, chunk_after, axis)\n\n    elif mode == \'minimum\':\n        for axis, ((pad_before, pad_after), (chunk_before, chunk_after)) \\\n                in enumerate(zip(pad_width, kwargs[\'stat_length\'])):\n            newmat = _prepend_min(newmat, pad_before, chunk_before, axis)\n            newmat = _append_min(newmat, pad_after, chunk_after, axis)\n\n    elif mode == \'reflect\':\n        for axis, (pad_before, pad_after) in enumerate(pad_width):\n                                                if ((pad_before > 0) or\n                    (pad_after > 0)) and newmat.shape[axis] == 1:\n                                                newmat = _prepend_edge(newmat, pad_before, axis)\n                newmat = _append_edge(newmat, pad_after, axis)\n                continue\n\n            method = kwargs[\'reflect_type\']\n            safe_pad = newmat.shape[axis] - 1\n            while ((pad_before > safe_pad) or (pad_after > safe_pad)):\n                pad_iter_b = min(safe_pad,\n                                 safe_pad * (pad_before // safe_pad))\n                pad_iter_a = min(safe_pad, safe_pad * (pad_after // safe_pad))\n                newmat = _pad_ref(newmat, (pad_iter_b,\n                                           pad_iter_a), method, axis)\n                pad_before -= pad_iter_b\n                pad_after -= pad_iter_a\n                safe_pad += pad_iter_b + pad_iter_a\n            newmat = _pad_ref(newmat, (pad_before, pad_after), method, axis)\n\n    elif mode == \'symmetric\':\n        for axis, (pad_before, pad_after) in enumerate(pad_width):\n                                                method = kwargs[\'reflect_type\']\n            safe_pad = newmat.shape[axis]\n            while ((pad_before > safe_pad) or\n                   (pad_after > safe_pad)):\n                pad_iter_b = min(safe_pad,\n                                 safe_pad * (pad_before // safe_pad))\n                pad_iter_a = min(safe_pad, safe_pad * (pad_after // safe_pad))\n                newmat = _pad_sym(newmat, (pad_iter_b,\n                                           pad_iter_a), method, axis)\n                pad_before -= pad_iter_b\n                pad_after -= pad_iter_a\n                safe_pad += pad_iter_b + pad_iter_a\n            newmat = _pad_sym(newmat, (pad_before, pad_after), method, axis)\n\n    elif mode == \'wrap\':\n        for axis, (pad_before, pad_after) in enumerate(pad_width):\n                                                safe_pad = newmat.shape[axis]\n            while ((pad_before > safe_pad) or\n                   (pad_after > safe_pad)):\n                pad_iter_b = min(safe_pad,\n                                 safe_pad * (pad_before // safe_pad))\n                pad_iter_a = min(safe_pad, safe_pad * (pad_after // safe_pad))\n                newmat = _pad_wrap(newmat, (pad_iter_b, pad_iter_a), axis)\n\n                pad_before -= pad_iter_b\n                pad_after -= pad_iter_a\n                safe_pad += pad_iter_b + pad_iter_a\n            newmat = _pad_wrap(newmat, (pad_before, pad_after), axis)\n\n    return newmat\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = ["array2string", "set_printoptions", "get_printoptions"]\n__docformat__ = \'restructuredtext\'\n\n\nimport sys\nfrom functools import reduce\nfrom . import numerictypes as _nt\nfrom .umath import maximum, minimum, absolute, not_equal, isnan, isinf\nfrom .multiarray import (array, format_longfloat, datetime_as_string,\n                         datetime_data)\nfrom .fromnumeric import ravel\nfrom .numeric import asarray\n\nif sys.version_info[0] >= 3:\n    _MAXINT = sys.maxsize\n    _MININT = -sys.maxsize - 1\nelse:\n    _MAXINT = sys.maxint\n    _MININT = -sys.maxint - 1\n\ndef product(x, y):\n    return x*y\n\n_summaryEdgeItems = 3     _summaryThreshold = 1000  \n_float_output_precision = 8\n_float_output_suppress_small = False\n_line_width = 75\n_nan_str = \'nan\'\n_inf_str = \'inf\'\n_formatter = None  \n\ndef set_printoptions(precision=None, threshold=None, edgeitems=None,\n                     linewidth=None, suppress=None,\n                     nanstr=None, infstr=None,\n                     formatter=None):\n    \n\n    global _summaryThreshold, _summaryEdgeItems, _float_output_precision\n    global _line_width, _float_output_suppress_small, _nan_str, _inf_str\n    global _formatter\n\n    if linewidth is not None:\n        _line_width = linewidth\n    if threshold is not None:\n        _summaryThreshold = threshold\n    if edgeitems is not None:\n        _summaryEdgeItems = edgeitems\n    if precision is not None:\n        _float_output_precision = precision\n    if suppress is not None:\n        _float_output_suppress_small = not not suppress\n    if nanstr is not None:\n        _nan_str = nanstr\n    if infstr is not None:\n        _inf_str = infstr\n    _formatter = formatter\n\ndef get_printoptions():\n    \n    d = dict(precision=_float_output_precision,\n             threshold=_summaryThreshold,\n             edgeitems=_summaryEdgeItems,\n             linewidth=_line_width,\n             suppress=_float_output_suppress_small,\n             nanstr=_nan_str,\n             infstr=_inf_str,\n             formatter=_formatter)\n    return d\n\ndef _leading_trailing(a):\n    from . import numeric as _nc\n    if a.ndim == 1:\n        if len(a) > 2*_summaryEdgeItems:\n            b = _nc.concatenate((a[:_summaryEdgeItems],\n                                     a[-_summaryEdgeItems:]))\n        else:\n            b = a\n    else:\n        if len(a) > 2*_summaryEdgeItems:\n            l = [_leading_trailing(a[i]) for i in range(\n                min(len(a), _summaryEdgeItems))]\n            l.extend([_leading_trailing(a[-i]) for i in range(\n                min(len(a), _summaryEdgeItems), 0, -1)])\n        else:\n            l = [_leading_trailing(a[i]) for i in range(0, len(a))]\n        b = _nc.concatenate(tuple(l))\n    return b\n\ndef _boolFormatter(x):\n    if x:\n        return \' True\'\n    else:\n        return \'False\'\n\n\ndef repr_format(x):\n    return repr(x)\n\ndef _array2string(a, max_line_width, precision, suppress_small, separator=\' \',\n                  prefix="", formatter=None):\n\n    if max_line_width is None:\n        max_line_width = _line_width\n\n    if precision is None:\n        precision = _float_output_precision\n\n    if suppress_small is None:\n        suppress_small = _float_output_suppress_small\n\n    if formatter is None:\n        formatter = _formatter\n\n    if a.size > _summaryThreshold:\n        summary_insert = "..., "\n        data = _leading_trailing(a)\n    else:\n        summary_insert = ""\n        data = ravel(asarray(a))\n\n    formatdict = {\'bool\': _boolFormatter,\n                  \'int\': IntegerFormat(data),\n                  \'float\': FloatFormat(data, precision, suppress_small),\n                  \'longfloat\': LongFloatFormat(precision),\n                  \'complexfloat\': ComplexFormat(data, precision,\n                                                 suppress_small),\n                  \'longcomplexfloat\': LongComplexFormat(precision),\n                  \'datetime\': DatetimeFormat(data),\n                  \'timedelta\': TimedeltaFormat(data),\n                  \'numpystr\': repr_format,\n                  \'str\': str}\n\n    if formatter is not None:\n        fkeys = [k for k in formatter.keys() if formatter[k] is not None]\n        if \'all\' in fkeys:\n            for key in formatdict.keys():\n                formatdict[key] = formatter[\'all\']\n        if \'int_kind\' in fkeys:\n            for key in [\'int\']:\n                formatdict[key] = formatter[\'int_kind\']\n        if \'float_kind\' in fkeys:\n            for key in [\'float\', \'longfloat\']:\n                formatdict[key] = formatter[\'float_kind\']\n        if \'complex_kind\' in fkeys:\n            for key in [\'complexfloat\', \'longcomplexfloat\']:\n                formatdict[key] = formatter[\'complex_kind\']\n        if \'str_kind\' in fkeys:\n            for key in [\'numpystr\', \'str\']:\n                formatdict[key] = formatter[\'str_kind\']\n        for key in formatdict.keys():\n            if key in fkeys:\n                formatdict[key] = formatter[key]\n\n        dtypeobj = a.dtype.type\n    if issubclass(dtypeobj, _nt.bool_):\n        format_function = formatdict[\'bool\']\n    elif issubclass(dtypeobj, _nt.integer):\n        if issubclass(dtypeobj, _nt.timedelta64):\n            format_function = formatdict[\'timedelta\']\n        else:\n            format_function = formatdict[\'int\']\n    elif issubclass(dtypeobj, _nt.floating):\n        if issubclass(dtypeobj, _nt.longfloat):\n            format_function = formatdict[\'longfloat\']\n        else:\n            format_function = formatdict[\'float\']\n    elif issubclass(dtypeobj, _nt.complexfloating):\n        if issubclass(dtypeobj, _nt.clongfloat):\n            format_function = formatdict[\'longcomplexfloat\']\n        else:\n            format_function = formatdict[\'complexfloat\']\n    elif issubclass(dtypeobj, (_nt.unicode_, _nt.string_)):\n        format_function = formatdict[\'numpystr\']\n    elif issubclass(dtypeobj, _nt.datetime64):\n        format_function = formatdict[\'datetime\']\n    else:\n        format_function = formatdict[\'numpystr\']\n\n        next_line_prefix = " "\n        next_line_prefix += " "*len(prefix)\n\n    lst = _formatArray(a, format_function, len(a.shape), max_line_width,\n                       next_line_prefix, separator,\n                       _summaryEdgeItems, summary_insert)[:-1]\n    return lst\n\ndef _convert_arrays(obj):\n    from . import numeric as _nc\n    newtup = []\n    for k in obj:\n        if isinstance(k, _nc.ndarray):\n            k = k.tolist()\n        elif isinstance(k, tuple):\n            k = _convert_arrays(k)\n        newtup.append(k)\n    return tuple(newtup)\n\n\ndef array2string(a, max_line_width=None, precision=None,\n                 suppress_small=None, separator=\' \', prefix="",\n                 style=repr, formatter=None):\n    \n\n    if a.shape == ():\n        x = a.item()\n        if isinstance(x, tuple):\n            x = _convert_arrays(x)\n        lst = style(x)\n    elif reduce(product, a.shape) == 0:\n                lst = "[]"\n    else:\n        lst = _array2string(a, max_line_width, precision, suppress_small,\n                            separator, prefix, formatter=formatter)\n    return lst\n\ndef _extendLine(s, line, word, max_line_len, next_line_prefix):\n    if len(line.rstrip()) + len(word.rstrip()) >= max_line_len:\n        s += line.rstrip() + "\\n"\n        line = next_line_prefix\n    line += word\n    return s, line\n\n\ndef _formatArray(a, format_function, rank, max_line_len,\n                 next_line_prefix, separator, edge_items, summary_insert):\n    \n    if rank == 0:\n        obj = a.item()\n        if isinstance(obj, tuple):\n            obj = _convert_arrays(obj)\n        return str(obj)\n\n    if summary_insert and 2*edge_items < len(a):\n        leading_items = edge_items\n        trailing_items = edge_items\n        summary_insert1 = summary_insert\n    else:\n        leading_items = 0\n        trailing_items = len(a)\n        summary_insert1 = ""\n\n    if rank == 1:\n        s = ""\n        line = next_line_prefix\n        for i in range(leading_items):\n            word = format_function(a[i]) + separator\n            s, line = _extendLine(s, line, word, max_line_len, next_line_prefix)\n\n        if summary_insert1:\n            s, line = _extendLine(s, line, summary_insert1, max_line_len, next_line_prefix)\n\n        for i in range(trailing_items, 1, -1):\n            word = format_function(a[-i]) + separator\n            s, line = _extendLine(s, line, word, max_line_len, next_line_prefix)\n\n        word = format_function(a[-1])\n        s, line = _extendLine(s, line, word, max_line_len, next_line_prefix)\n        s += line + "]\\n"\n        s = \'[\' + s[len(next_line_prefix):]\n    else:\n        s = \'[\'\n        sep = separator.rstrip()\n        for i in range(leading_items):\n            if i > 0:\n                s += next_line_prefix\n            s += _formatArray(a[i], format_function, rank-1, max_line_len,\n                              " " + next_line_prefix, separator, edge_items,\n                              summary_insert)\n            s = s.rstrip() + sep.rstrip() + \'\\n\'*max(rank-1, 1)\n\n        if summary_insert1:\n            s += next_line_prefix + summary_insert1 + "\\n"\n\n        for i in range(trailing_items, 1, -1):\n            if leading_items or i != trailing_items:\n                s += next_line_prefix\n            s += _formatArray(a[-i], format_function, rank-1, max_line_len,\n                              " " + next_line_prefix, separator, edge_items,\n                              summary_insert)\n            s = s.rstrip() + sep.rstrip() + \'\\n\'*max(rank-1, 1)\n        if leading_items or trailing_items > 1:\n            s += next_line_prefix\n        s += _formatArray(a[-1], format_function, rank-1, max_line_len,\n                          " " + next_line_prefix, separator, edge_items,\n                          summary_insert).rstrip()+\']\\n\'\n    return s\n\nclass FloatFormat(object):\n    def __init__(self, data, precision, suppress_small, sign=False):\n        self.precision = precision\n        self.suppress_small = suppress_small\n        self.sign = sign\n        self.exp_format = False\n        self.large_exponent = False\n        self.max_str_len = 0\n        try:\n            self.fillFormat(data)\n        except (TypeError, NotImplementedError):\n                                    pass\n\n    def fillFormat(self, data):\n        from . import numeric as _nc\n\n        with _nc.errstate(all=\'ignore\'):\n            special = isnan(data) | isinf(data)\n            valid = not_equal(data, 0) & ~special\n            non_zero = absolute(data.compress(valid))\n            if len(non_zero) == 0:\n                max_val = 0.\n                min_val = 0.\n            else:\n                max_val = maximum.reduce(non_zero)\n                min_val = minimum.reduce(non_zero)\n                if max_val >= 1.e8:\n                    self.exp_format = True\n                if not self.suppress_small and (min_val < 0.0001\n                                           or max_val/min_val > 1000.):\n                    self.exp_format = True\n\n        if self.exp_format:\n            self.large_exponent = 0 < min_val < 1e-99 or max_val >= 1e100\n            self.max_str_len = 8 + self.precision\n            if self.large_exponent:\n                self.max_str_len += 1\n            if self.sign:\n                format = \'%+\'\n            else:\n                format = \'%\'\n            format = format + \'%d.%de\' % (self.max_str_len, self.precision)\n        else:\n            format = \'%%.%df\' % (self.precision,)\n            if len(non_zero):\n                precision = max([_digits(x, self.precision, format)\n                                 for x in non_zero])\n            else:\n                precision = 0\n            precision = min(self.precision, precision)\n            self.max_str_len = len(str(int(max_val))) + precision + 2\n            if _nc.any(special):\n                self.max_str_len = max(self.max_str_len,\n                                       len(_nan_str),\n                                       len(_inf_str)+1)\n            if self.sign:\n                format = \'%            else:\n                format = \'%            format = format + \'%d.%df\' % (self.max_str_len, precision)\n\n        self.special_fmt = \'%%%ds\' % (self.max_str_len,)\n        self.format = format\n\n    def __call__(self, x, strip_zeros=True):\n        from . import numeric as _nc\n\n        with _nc.errstate(invalid=\'ignore\'):\n            if isnan(x):\n                if self.sign:\n                    return self.special_fmt % (\'+\' + _nan_str,)\n                else:\n                    return self.special_fmt % (_nan_str,)\n            elif isinf(x):\n                if x > 0:\n                    if self.sign:\n                        return self.special_fmt % (\'+\' + _inf_str,)\n                    else:\n                        return self.special_fmt % (_inf_str,)\n                else:\n                    return self.special_fmt % (\'-\' + _inf_str,)\n\n        s = self.format % x\n        if self.large_exponent:\n                        expsign = s[-3]\n            if expsign == \'+\' or expsign == \'-\':\n                s = s[1:-2] + \'0\' + s[-2:]\n        elif self.exp_format:\n                        if s[-3] == \'0\':\n                s = \' \' + s[:-3] + s[-2:]\n        elif strip_zeros:\n            z = s.rstrip(\'0\')\n            s = z + \' \'*(len(s)-len(z))\n        return s\n\n\ndef _digits(x, precision, format):\n    s = format % x\n    z = s.rstrip(\'0\')\n    return precision - len(s) + len(z)\n\n\nclass IntegerFormat(object):\n    def __init__(self, data):\n        try:\n            max_str_len = max(len(str(maximum.reduce(data))),\n                              len(str(minimum.reduce(data))))\n            self.format = \'%\' + str(max_str_len) + \'d\'\n        except (TypeError, NotImplementedError):\n                                    pass\n        except ValueError:\n                        pass\n\n    def __call__(self, x):\n        if _MININT < x < _MAXINT:\n            return self.format % x\n        else:\n            return "%s" % x\n\nclass LongFloatFormat(object):\n            def __init__(self, precision, sign=False):\n        self.precision = precision\n        self.sign = sign\n\n    def __call__(self, x):\n        if isnan(x):\n            if self.sign:\n                return \'+\' + _nan_str\n            else:\n                return \' \' + _nan_str\n        elif isinf(x):\n            if x > 0:\n                if self.sign:\n                    return \'+\' + _inf_str\n                else:\n                    return \' \' + _inf_str\n            else:\n                return \'-\' + _inf_str\n        elif x >= 0:\n            if self.sign:\n                return \'+\' + format_longfloat(x, self.precision)\n            else:\n                return \' \' + format_longfloat(x, self.precision)\n        else:\n            return format_longfloat(x, self.precision)\n\n\nclass LongComplexFormat(object):\n    def __init__(self, precision):\n        self.real_format = LongFloatFormat(precision)\n        self.imag_format = LongFloatFormat(precision, sign=True)\n\n    def __call__(self, x):\n        r = self.real_format(x.real)\n        i = self.imag_format(x.imag)\n        return r + i + \'j\'\n\n\nclass ComplexFormat(object):\n    def __init__(self, x, precision, suppress_small):\n        self.real_format = FloatFormat(x.real, precision, suppress_small)\n        self.imag_format = FloatFormat(x.imag, precision, suppress_small,\n                                       sign=True)\n\n    def __call__(self, x):\n        r = self.real_format(x.real, strip_zeros=False)\n        i = self.imag_format(x.imag, strip_zeros=False)\n        if not self.imag_format.exp_format:\n            z = i.rstrip(\'0\')\n            i = z + \'j\' + \' \'*(len(i)-len(z))\n        else:\n            i = i + \'j\'\n        return r + i\n\nclass DatetimeFormat(object):\n    def __init__(self, x, unit=None,\n                timezone=None, casting=\'same_kind\'):\n                if unit is None:\n            if x.dtype.kind == \'M\':\n                unit = datetime_data(x.dtype)[0]\n            else:\n                unit = \'s\'\n\n                if timezone is None:\n                        if unit in (\'Y\', \'M\', \'W\', \'D\'):\n                self.timezone = \'UTC\'\n            else:\n                self.timezone = \'local\'\n        else:\n            self.timezone = timezone\n        self.unit = unit\n        self.casting = casting\n\n    def __call__(self, x):\n        return "\'%s\'" % datetime_as_string(x,\n                                    unit=self.unit,\n                                    timezone=self.timezone,\n                                    casting=self.casting)\n\nclass TimedeltaFormat(object):\n    def __init__(self, data):\n        if data.dtype.kind == \'m\':\n            nat_value = array([\'NaT\'], dtype=data.dtype)[0]\n            v = data[not_equal(data, nat_value)].view(\'i8\')\n            if len(v) > 0:\n                                max_str_len = max(len(str(maximum.reduce(v))),\n                                  len(str(minimum.reduce(v))))\n            else:\n                max_str_len = 0\n            if len(v) < len(data):\n                                max_str_len = max(max_str_len, 5)\n            self.format = \'%\' + str(max_str_len) + \'d\'\n            self._nat = "\'NaT\'".rjust(max_str_len)\n\n    def __call__(self, x):\n        if x + 1 == x:\n            return self._nat\n        else:\n            return self.format % x.astype(\'i8\')\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\n\n__all__ = [\n    \'ediff1d\', \'intersect1d\', \'setxor1d\', \'union1d\', \'setdiff1d\', \'unique\',\n    \'in1d\'\n    ]\n\n\ndef ediff1d(ary, to_end=None, to_begin=None):\n    \n    ary = np.asanyarray(ary).flat\n    ed = ary[1:] - ary[:-1]\n    arrays = [ed]\n    if to_begin is not None:\n        arrays.insert(0, to_begin)\n    if to_end is not None:\n        arrays.append(to_end)\n\n    if len(arrays) != 1:\n                        ed = np.hstack(arrays)\n\n    return ed\n\ndef unique(ar, return_index=False, return_inverse=False, return_counts=False):\n    \n    ar = np.asanyarray(ar).flatten()\n\n    optional_indices = return_index or return_inverse\n    optional_returns = optional_indices or return_counts\n\n    if ar.size == 0:\n        if not optional_returns:\n            ret = ar\n        else:\n            ret = (ar,)\n            if return_index:\n                ret += (np.empty(0, np.bool),)\n            if return_inverse:\n                ret += (np.empty(0, np.bool),)\n            if return_counts:\n                ret += (np.empty(0, np.intp),)\n        return ret\n\n    if optional_indices:\n        perm = ar.argsort(kind=\'mergesort\' if return_index else \'quicksort\')\n        aux = ar[perm]\n    else:\n        ar.sort()\n        aux = ar\n    flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n\n    if not optional_returns:\n        ret = aux[flag]\n    else:\n        ret = (aux[flag],)\n        if return_index:\n            ret += (perm[flag],)\n        if return_inverse:\n            iflag = np.cumsum(flag) - 1\n            inv_idx = np.empty(ar.shape, dtype=np.intp)\n            inv_idx[perm] = iflag\n            ret += (inv_idx,)\n        if return_counts:\n            idx = np.concatenate(np.nonzero(flag) + ([ar.size],))\n            ret += (np.diff(idx),)\n    return ret\n\ndef intersect1d(ar1, ar2, assume_unique=False):\n    \n    if not assume_unique:\n                ar1 = unique(ar1)\n        ar2 = unique(ar2)\n    aux = np.concatenate((ar1, ar2))\n    aux.sort()\n    return aux[:-1][aux[1:] == aux[:-1]]\n\ndef setxor1d(ar1, ar2, assume_unique=False):\n    \n    if not assume_unique:\n        ar1 = unique(ar1)\n        ar2 = unique(ar2)\n\n    aux = np.concatenate((ar1, ar2))\n    if aux.size == 0:\n        return aux\n\n    aux.sort()\n    flag = np.concatenate(([True], aux[1:] != aux[:-1], [True]))\n    flag2 = flag[1:] == flag[:-1]\n    return aux[flag2]\n\ndef in1d(ar1, ar2, assume_unique=False, invert=False):\n    \n        ar1 = np.asarray(ar1).ravel()\n    ar2 = np.asarray(ar2).ravel()\n\n        if len(ar2) < 10 * len(ar1) ** 0.145:\n        if invert:\n            mask = np.ones(len(ar1), dtype=np.bool)\n            for a in ar2:\n                mask &= (ar1 != a)\n        else:\n            mask = np.zeros(len(ar1), dtype=np.bool)\n            for a in ar2:\n                mask |= (ar1 == a)\n        return mask\n\n        if not assume_unique:\n        ar1, rev_idx = np.unique(ar1, return_inverse=True)\n        ar2 = np.unique(ar2)\n\n    ar = np.concatenate((ar1, ar2))\n                order = ar.argsort(kind=\'mergesort\')\n    sar = ar[order]\n    if invert:\n        bool_ar = (sar[1:] != sar[:-1])\n    else:\n        bool_ar = (sar[1:] == sar[:-1])\n    flag = np.concatenate((bool_ar, [invert]))\n    ret = np.empty(ar.shape, dtype=bool)\n    ret[order] = flag\n\n    if assume_unique:\n        return ret[:len(ar1)]\n    else:\n        return ret[rev_idx]\n\ndef union1d(ar1, ar2):\n    \n    return unique(np.concatenate((ar1, ar2)))\n\ndef setdiff1d(ar1, ar2, assume_unique=False):\n    \n    if assume_unique:\n        ar1 = np.asarray(ar1).ravel()\n    else:\n        ar1 = unique(ar1)\n        ar2 = unique(ar2)\n    return ar1[in1d(ar1, ar2, assume_unique=True, invert=True)]\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom operator import mul\nfrom functools import reduce\n\nfrom numpy.compat import long\n\n__all__ = [\'Arrayterator\']\n\n\nclass Arrayterator(object):\n    \n\n    def __init__(self, var, buf_size=None):\n        self.var = var\n        self.buf_size = buf_size\n\n        self.start = [0 for dim in var.shape]\n        self.stop = [dim for dim in var.shape]\n        self.step = [1 for dim in var.shape]\n\n    def __getattr__(self, attr):\n        return getattr(self.var, attr)\n\n    def __getitem__(self, index):\n        \n                if not isinstance(index, tuple):\n            index = (index,)\n        fixed = []\n        length, dims = len(index), len(self.shape)\n        for slice_ in index:\n            if slice_ is Ellipsis:\n                fixed.extend([slice(None)] * (dims-length+1))\n                length = len(fixed)\n            elif isinstance(slice_, (int, long)):\n                fixed.append(slice(slice_, slice_+1, 1))\n            else:\n                fixed.append(slice_)\n        index = tuple(fixed)\n        if len(index) < dims:\n            index += (slice(None),) * (dims-len(index))\n\n                out = self.__class__(self.var, self.buf_size)\n        for i, (start, stop, step, slice_) in enumerate(\n                zip(self.start, self.stop, self.step, index)):\n            out.start[i] = start + (slice_.start or 0)\n            out.step[i] = step * (slice_.step or 1)\n            out.stop[i] = start + (slice_.stop or stop-start)\n            out.stop[i] = min(stop, out.stop[i])\n        return out\n\n    def __array__(self):\n        \n        slice_ = tuple(slice(*t) for t in zip(\n                self.start, self.stop, self.step))\n        return self.var[slice_]\n\n    @property\n    def flat(self):\n        \n        for block in self:\n            for value in block.flat:\n                yield value\n\n    @property\n    def shape(self):\n        \n        return tuple(((stop-start-1)//step+1) for start, stop, step in\n                zip(self.start, self.stop, self.step))\n\n    def __iter__(self):\n                if [dim for dim in self.shape if dim <= 0]:\n            return\n\n        start = self.start[:]\n        stop = self.stop[:]\n        step = self.step[:]\n        ndims = len(self.var.shape)\n\n        while True:\n            count = self.buf_size or reduce(mul, self.shape)\n\n                                                rundim = 0\n            for i in range(ndims-1, -1, -1):\n                                                if count == 0:\n                    stop[i] = start[i]+1\n                elif count <= self.shape[i]:\n                                        stop[i] = start[i] + count*step[i]\n                    rundim = i\n                else:\n                                        stop[i] = self.stop[i]\n                stop[i] = min(self.stop[i], stop[i])\n                count = count//self.shape[i]\n\n                        slice_ = tuple(slice(*t) for t in zip(start, stop, step))\n            yield self.var[slice_]\n\n                                    start[rundim] = stop[rundim]              for i in range(ndims-1, 0, -1):\n                if start[i] >= self.stop[i]:\n                    start[i] = self.start[i]\n                    start[i-1] += self.step[i-1]\n            if start[0] >= self.stop[0]:\n                return\n\nfrom __future__ import division, absolute_import, print_function\n\n\n\ndef check_inline(cmd):\n    \n    cmd._check_compiler()\n    body = \n\n    for kw in [\'inline\', \'__inline__\', \'__inline\']:\n        st = cmd.try_compile(body % {\'inline\': kw}, None, None)\n        if st:\n            return kw\n\n    return \'\'\n\ndef check_restrict(cmd):\n    \n    cmd._check_compiler()\n    body = \n\n    for kw in [\'restrict\', \'__restrict__\', \'__restrict\']:\n        st = cmd.try_compile(body % {\'restrict\': kw}, None, None)\n        if st:\n            return kw\n\n    return \'\'\n\ndef check_compiler_gcc4(cmd):\n    \n    cmd._check_compiler()\n    body = \n    return cmd.try_compile(body, None, None)\n\n\ndef check_gcc_function_attribute(cmd, attribute, name):\n    \n    cmd._check_compiler()\n    body =  % (attribute, name)\n    return cmd.try_compile(body, None, None) != 0\n\ndef check_gcc_variable_attribute(cmd, attribute):\n    \n    cmd._check_compiler()\n    body =  % (attribute, )\n    return cmd.try_compile(body, None, None) != 0\n\nfrom __future__ import division, absolute_import, print_function\n\nimport pprint\nimport sys\nimport types\nfrom functools import reduce\n\nfrom . import __version__\nfrom . import cfuncs\n\n__all__ = [\n    \'applyrules\', \'debugcapi\', \'dictappend\', \'errmess\', \'gentitle\',\n    \'getargs2\', \'getcallprotoargument\', \'getcallstatement\',\n    \'getfortranname\', \'getpymethoddef\', \'getrestdoc\', \'getusercode\',\n    \'getusercode1\', \'hasbody\', \'hascallstatement\', \'hascommon\',\n    \'hasexternals\', \'hasinitvalue\', \'hasnote\', \'hasresultnote\',\n    \'isallocatable\', \'isarray\', \'isarrayofstrings\', \'iscomplex\',\n    \'iscomplexarray\', \'iscomplexfunction\', \'iscomplexfunction_warn\',\n    \'isdouble\', \'isdummyroutine\', \'isexternal\', \'isfunction\',\n    \'isfunction_wrap\', \'isint1array\', \'isinteger\', \'isintent_aux\',\n    \'isintent_c\', \'isintent_callback\', \'isintent_copy\', \'isintent_dict\',\n    \'isintent_hide\', \'isintent_in\', \'isintent_inout\', \'isintent_inplace\',\n    \'isintent_nothide\', \'isintent_out\', \'isintent_overwrite\', \'islogical\',\n    \'islogicalfunction\', \'islong_complex\', \'islong_double\',\n    \'islong_doublefunction\', \'islong_long\', \'islong_longfunction\',\n    \'ismodule\', \'ismoduleroutine\', \'isoptional\', \'isprivate\', \'isrequired\',\n    \'isroutine\', \'isscalar\', \'issigned_long_longarray\', \'isstring\',\n    \'isstringarray\', \'isstringfunction\', \'issubroutine\',\n    \'issubroutine_wrap\', \'isthreadsafe\', \'isunsigned\', \'isunsigned_char\',\n    \'isunsigned_chararray\', \'isunsigned_long_long\',\n    \'isunsigned_long_longarray\', \'isunsigned_short\',\n    \'isunsigned_shortarray\', \'l_and\', \'l_not\', \'l_or\', \'outmess\',\n    \'replace\', \'show\', \'stripcomma\', \'throw_error\',\n]\n\n\nf2py_version = __version__.version\n\n\nerrmess = sys.stderr.write\nshow = pprint.pprint\n\noptions = {}\ndebugoptions = []\nwrapfuncs = 1\n\n\ndef outmess(t):\n    if options.get(\'verbose\', 1):\n        sys.stdout.write(t)\n\n\ndef debugcapi(var):\n    return \'capi\' in debugoptions\n\n\ndef _isstring(var):\n    return \'typespec\' in var and var[\'typespec\'] == \'character\' and \\\n           not isexternal(var)\n\n\ndef isstring(var):\n    return _isstring(var) and not isarray(var)\n\n\ndef ischaracter(var):\n    return isstring(var) and \'charselector\' not in var\n\n\ndef isstringarray(var):\n    return isarray(var) and _isstring(var)\n\n\ndef isarrayofstrings(var):\n            return isstringarray(var) and var[\'dimension\'][-1] == \'(*)\'\n\n\ndef isarray(var):\n    return \'dimension\' in var and not isexternal(var)\n\n\ndef isscalar(var):\n    return not (isarray(var) or isstring(var) or isexternal(var))\n\n\ndef iscomplex(var):\n    return isscalar(var) and \\\n           var.get(\'typespec\') in [\'complex\', \'double complex\']\n\n\ndef islogical(var):\n    return isscalar(var) and var.get(\'typespec\') == \'logical\'\n\n\ndef isinteger(var):\n    return isscalar(var) and var.get(\'typespec\') == \'integer\'\n\n\ndef isreal(var):\n    return isscalar(var) and var.get(\'typespec\') == \'real\'\n\n\ndef get_kind(var):\n    try:\n        return var[\'kindselector\'][\'*\']\n    except KeyError:\n        try:\n            return var[\'kindselector\'][\'kind\']\n        except KeyError:\n            pass\n\n\ndef islong_long(var):\n    if not isscalar(var):\n        return 0\n    if var.get(\'typespec\') not in [\'integer\', \'logical\']:\n        return 0\n    return get_kind(var) == \'8\'\n\n\ndef isunsigned_char(var):\n    if not isscalar(var):\n        return 0\n    if var.get(\'typespec\') != \'integer\':\n        return 0\n    return get_kind(var) == \'-1\'\n\n\ndef isunsigned_short(var):\n    if not isscalar(var):\n        return 0\n    if var.get(\'typespec\') != \'integer\':\n        return 0\n    return get_kind(var) == \'-2\'\n\n\ndef isunsigned(var):\n    if not isscalar(var):\n        return 0\n    if var.get(\'typespec\') != \'integer\':\n        return 0\n    return get_kind(var) == \'-4\'\n\n\ndef isunsigned_long_long(var):\n    if not isscalar(var):\n        return 0\n    if var.get(\'typespec\') != \'integer\':\n        return 0\n    return get_kind(var) == \'-8\'\n\n\ndef isdouble(var):\n    if not isscalar(var):\n        return 0\n    if not var.get(\'typespec\') == \'real\':\n        return 0\n    return get_kind(var) == \'8\'\n\n\ndef islong_double(var):\n    if not isscalar(var):\n        return 0\n    if not var.get(\'typespec\') == \'real\':\n        return 0\n    return get_kind(var) == \'16\'\n\n\ndef islong_complex(var):\n    if not iscomplex(var):\n        return 0\n    return get_kind(var) == \'32\'\n\n\ndef iscomplexarray(var):\n    return isarray(var) and \\\n           var.get(\'typespec\') in [\'complex\', \'double complex\']\n\n\ndef isint1array(var):\n    return isarray(var) and var.get(\'typespec\') == \'integer\' \\\n        and get_kind(var) == \'1\'\n\n\ndef isunsigned_chararray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'-1\'\n\n\ndef isunsigned_shortarray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'-2\'\n\n\ndef isunsignedarray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'-4\'\n\n\ndef isunsigned_long_longarray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'-8\'\n\n\ndef issigned_chararray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'1\'\n\n\ndef issigned_shortarray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'2\'\n\n\ndef issigned_array(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'4\'\n\n\ndef issigned_long_longarray(var):\n    return isarray(var) and var.get(\'typespec\') in [\'integer\', \'logical\']\\\n        and get_kind(var) == \'8\'\n\n\ndef isallocatable(var):\n    return \'attrspec\' in var and \'allocatable\' in var[\'attrspec\']\n\n\ndef ismutable(var):\n    return not (\'dimension\' not in var or isstring(var))\n\n\ndef ismoduleroutine(rout):\n    return \'modulename\' in rout\n\n\ndef ismodule(rout):\n    return \'block\' in rout and \'module\' == rout[\'block\']\n\n\ndef isfunction(rout):\n    return \'block\' in rout and \'function\' == rout[\'block\']\n\ndef isfunction_wrap(rout):\n    if isintent_c(rout):\n        return 0\n    return wrapfuncs and isfunction(rout) and (not isexternal(rout))\n\n\ndef issubroutine(rout):\n    return \'block\' in rout and \'subroutine\' == rout[\'block\']\n\n\ndef issubroutine_wrap(rout):\n    if isintent_c(rout):\n        return 0\n    return issubroutine(rout) and hasassumedshape(rout)\n\n\ndef hasassumedshape(rout):\n    if rout.get(\'hasassumedshape\'):\n        return True\n    for a in rout[\'args\']:\n        for d in rout[\'vars\'].get(a, {}).get(\'dimension\', []):\n            if d == \':\':\n                rout[\'hasassumedshape\'] = True\n                return True\n    return False\n\n\ndef isroutine(rout):\n    return isfunction(rout) or issubroutine(rout)\n\n\ndef islogicalfunction(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return islogical(rout[\'vars\'][a])\n    return 0\n\n\ndef islong_longfunction(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return islong_long(rout[\'vars\'][a])\n    return 0\n\n\ndef islong_doublefunction(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return islong_double(rout[\'vars\'][a])\n    return 0\n\n\ndef iscomplexfunction(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return iscomplex(rout[\'vars\'][a])\n    return 0\n\n\ndef iscomplexfunction_warn(rout):\n    if iscomplexfunction(rout):\n        outmess()\n        return 1\n    return 0\n\n\ndef isstringfunction(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return isstring(rout[\'vars\'][a])\n    return 0\n\n\ndef hasexternals(rout):\n    return \'externals\' in rout and rout[\'externals\']\n\n\ndef isthreadsafe(rout):\n    return \'f2pyenhancements\' in rout and \\\n           \'threadsafe\' in rout[\'f2pyenhancements\']\n\n\ndef hasvariables(rout):\n    return \'vars\' in rout and rout[\'vars\']\n\n\ndef isoptional(var):\n    return (\'attrspec\' in var and \'optional\' in var[\'attrspec\'] and\n            \'required\' not in var[\'attrspec\']) and isintent_nothide(var)\n\n\ndef isexternal(var):\n    return \'attrspec\' in var and \'external\' in var[\'attrspec\']\n\n\ndef isrequired(var):\n    return not isoptional(var) and isintent_nothide(var)\n\n\ndef isintent_in(var):\n    if \'intent\' not in var:\n        return 1\n    if \'hide\' in var[\'intent\']:\n        return 0\n    if \'inplace\' in var[\'intent\']:\n        return 0\n    if \'in\' in var[\'intent\']:\n        return 1\n    if \'out\' in var[\'intent\']:\n        return 0\n    if \'inout\' in var[\'intent\']:\n        return 0\n    if \'outin\' in var[\'intent\']:\n        return 0\n    return 1\n\n\ndef isintent_inout(var):\n    return (\'intent\' in var and (\'inout\' in var[\'intent\'] or\n            \'outin\' in var[\'intent\']) and \'in\' not in var[\'intent\'] and\n            \'hide\' not in var[\'intent\'] and \'inplace\' not in var[\'intent\'])\n\n\ndef isintent_out(var):\n    return \'out\' in var.get(\'intent\', [])\n\n\ndef isintent_hide(var):\n    return (\'intent\' in var and (\'hide\' in var[\'intent\'] or\n            (\'out\' in var[\'intent\'] and \'in\' not in var[\'intent\'] and\n                (not l_or(isintent_inout, isintent_inplace)(var)))))\n\ndef isintent_nothide(var):\n    return not isintent_hide(var)\n\n\ndef isintent_c(var):\n    return \'c\' in var.get(\'intent\', [])\n\n\n\ndef isintent_cache(var):\n    return \'cache\' in var.get(\'intent\', [])\n\n\ndef isintent_copy(var):\n    return \'copy\' in var.get(\'intent\', [])\n\n\ndef isintent_overwrite(var):\n    return \'overwrite\' in var.get(\'intent\', [])\n\n\ndef isintent_callback(var):\n    return \'callback\' in var.get(\'intent\', [])\n\n\ndef isintent_inplace(var):\n    return \'inplace\' in var.get(\'intent\', [])\n\n\ndef isintent_aux(var):\n    return \'aux\' in var.get(\'intent\', [])\n\n\ndef isintent_aligned4(var):\n    return \'aligned4\' in var.get(\'intent\', [])\n\n\ndef isintent_aligned8(var):\n    return \'aligned8\' in var.get(\'intent\', [])\n\n\ndef isintent_aligned16(var):\n    return \'aligned16\' in var.get(\'intent\', [])\n\nisintent_dict = {isintent_in: \'INTENT_IN\', isintent_inout: \'INTENT_INOUT\',\n                 isintent_out: \'INTENT_OUT\', isintent_hide: \'INTENT_HIDE\',\n                 isintent_cache: \'INTENT_CACHE\',\n                 isintent_c: \'INTENT_C\', isoptional: \'OPTIONAL\',\n                 isintent_inplace: \'INTENT_INPLACE\',\n                 isintent_aligned4: \'INTENT_ALIGNED4\',\n                 isintent_aligned8: \'INTENT_ALIGNED8\',\n                 isintent_aligned16: \'INTENT_ALIGNED16\',\n                 }\n\n\ndef isprivate(var):\n    return \'attrspec\' in var and \'private\' in var[\'attrspec\']\n\n\ndef hasinitvalue(var):\n    return \'=\' in var\n\n\ndef hasinitvalueasstring(var):\n    if not hasinitvalue(var):\n        return 0\n    return var[\'=\'][0] in [\'"\', "\'"]\n\n\ndef hasnote(var):\n    return \'note\' in var\n\n\ndef hasresultnote(rout):\n    if not isfunction(rout):\n        return 0\n    if \'result\' in rout:\n        a = rout[\'result\']\n    else:\n        a = rout[\'name\']\n    if a in rout[\'vars\']:\n        return hasnote(rout[\'vars\'][a])\n    return 0\n\n\ndef hascommon(rout):\n    return \'common\' in rout\n\n\ndef containscommon(rout):\n    if hascommon(rout):\n        return 1\n    if hasbody(rout):\n        for b in rout[\'body\']:\n            if containscommon(b):\n                return 1\n    return 0\n\n\ndef containsmodule(block):\n    if ismodule(block):\n        return 1\n    if not hasbody(block):\n        return 0\n    for b in block[\'body\']:\n        if containsmodule(b):\n            return 1\n    return 0\n\n\ndef hasbody(rout):\n    return \'body\' in rout\n\n\ndef hascallstatement(rout):\n    return getcallstatement(rout) is not None\n\n\ndef istrue(var):\n    return 1\n\n\ndef isfalse(var):\n    return 0\n\n\nclass F2PYError(Exception):\n    pass\n\n\nclass throw_error:\n\n    def __init__(self, mess):\n        self.mess = mess\n\n    def __call__(self, var):\n        mess = \'\\n\\n  var = %s\\n  Message: %s\\n\' % (var, self.mess)\n        raise F2PYError(mess)\n\n\ndef l_and(*f):\n    l, l2 = \'lambda v\', []\n    for i in range(len(f)):\n        l = \'%s,f%d=f[%d]\' % (l, i, i)\n        l2.append(\'f%d(v)\' % (i))\n    return eval(\'%s:%s\' % (l, \' and \'.join(l2)))\n\n\ndef l_or(*f):\n    l, l2 = \'lambda v\', []\n    for i in range(len(f)):\n        l = \'%s,f%d=f[%d]\' % (l, i, i)\n        l2.append(\'f%d(v)\' % (i))\n    return eval(\'%s:%s\' % (l, \' or \'.join(l2)))\n\n\ndef l_not(f):\n    return eval(\'lambda v,f=f:not f(v)\')\n\n\ndef isdummyroutine(rout):\n    try:\n        return rout[\'f2pyenhancements\'][\'fortranname\'] == \'\'\n    except KeyError:\n        return 0\n\n\ndef getfortranname(rout):\n    try:\n        name = rout[\'f2pyenhancements\'][\'fortranname\']\n        if name == \'\':\n            raise KeyError\n        if not name:\n            errmess(\'Failed to use fortranname from %s\\n\' %\n                    (rout[\'f2pyenhancements\']))\n            raise KeyError\n    except KeyError:\n        name = rout[\'name\']\n    return name\n\n\ndef getmultilineblock(rout, blockname, comment=1, counter=0):\n    try:\n        r = rout[\'f2pyenhancements\'].get(blockname)\n    except KeyError:\n        return\n    if not r:\n        return\n    if counter > 0 and isinstance(r, str):\n        return\n    if isinstance(r, list):\n        if counter >= len(r):\n            return\n        r = r[counter]\n    if r[:3] == "":\n            if comment:\n                r = r[:-3] + \'\\n\\t/* end multiline (\' + repr(counter) + \')*/\'\n            else:\n                r = r[:-3]\n        else:\n            errmess("%s multiline block should end with `    if istop:\n        dowithline(\'\', -1)\n    ll, l1 = \'\', \'\'\n    spacedigits = [\' \'] + [str(_m) for _m in range(10)]\n    filepositiontext = \'\'\n    fin = fileinput.FileInput(ffile)\n    while True:\n        l = fin.readline()\n        if not l:\n            break\n        if fin.isfirstline():\n            filepositiontext = \'\'\n            currentfilename = fin.filename()\n            gotnextfile = 1\n            l1 = l\n            strictf77 = 0\n            sourcecodeform = \'fix\'\n            ext = os.path.splitext(currentfilename)[1]\n            if is_f_file(currentfilename) and \\\n                    not (_has_f90_header(l) or _has_fix_header(l)):\n                strictf77 = 1\n            elif is_free_format(currentfilename) and not _has_fix_header(l):\n                sourcecodeform = \'free\'\n            if strictf77:\n                beginpattern = beginpattern77\n            else:\n                beginpattern = beginpattern90\n            outmess(\'\\tReading file %s (format:%s%s)\\n\'\n                    % (repr(currentfilename), sourcecodeform,\n                       strictf77 and \',strict\' or \'\'))\n\n        l = l.expandtabs().replace(\'\\xa0\', \' \')\n                while not l == \'\':\n            if l[-1] not in "\\n\\r\\f":\n                break\n            l = l[:-1]\n        if not strictf77:\n            r = commentline.match(l)\n            if r:\n                l = r.group(\'line\') + \' \'                  rl = r.group(\'rest\')\n                if rl[:4].lower() == \'f2py\':                      l = l + 4 * \' \'\n                    r = commentline.match(rl[4:])\n                    if r:\n                        l = l + r.group(\'line\')\n                    else:\n                        l = l + rl[4:]\n        if l.strip() == \'\':              cont = 0\n            continue\n        if sourcecodeform == \'fix\':\n            if l[0] in [\'*\', \'c\', \'!\', \'C\', \'                if l[1:5].lower() == \'f2py\':                      l = \'     \' + l[5:]\n                else:                      cont = 0\n                    continue\n            elif strictf77:\n                if len(l) > 72:\n                    l = l[:72]\n            if not (l[0] in spacedigits):\n                raise Exception(\'readfortrancode: Found non-(space,digit) char \'\n                                \'in the first column.\\n\\tAre you sure that \'\n                                \'this code is in fix form?\\n\\tline=%s\' % repr(l))\n\n            if (not cont or strictf77) and (len(l) > 5 and not l[5] == \' \'):\n                                ll = ll + l[6:]\n                finalline = \'\'\n                origfinalline = \'\'\n            else:\n                if not strictf77:\n                                        r = cont1.match(l)\n                    if r:\n                        l = r.group(\'line\')                      if cont:\n                        ll = ll + cont2.match(l).group(\'line\')\n                        finalline = \'\'\n                        origfinalline = \'\'\n                    else:\n                                                l = \'     \' + l[5:]\n                        if localdolowercase:\n                            finalline = ll.lower()\n                        else:\n                            finalline = ll\n                        origfinalline = ll\n                        ll = l\n                    cont = (r is not None)\n                else:\n                                        l = \'     \' + l[5:]\n                    if localdolowercase:\n                        finalline = ll.lower()\n                    else:\n                        finalline = ll\n                    origfinalline = ll\n                    ll = l\n\n        elif sourcecodeform == \'free\':\n            if not cont and ext == \'.pyf\' and mline_mark.match(l):\n                l = l + \'\\n\'\n                while True:\n                    lc = fin.readline()\n                    if not lc:\n                        errmess(\n                            \'Unexpected end of file when reading multiline\\n\')\n                        break\n                    l = l + lc\n                    if mline_mark.match(lc):\n                        break\n                l = l.rstrip()\n            r = cont1.match(l)\n            if r:\n                l = r.group(\'line\')              if cont:\n                ll = ll + cont2.match(l).group(\'line\')\n                finalline = \'\'\n                origfinalline = \'\'\n            else:\n                if localdolowercase:\n                    finalline = ll.lower()\n                else:\n                    finalline = ll\n                origfinalline = ll\n                ll = l\n            cont = (r is not None)\n        else:\n            raise ValueError(\n                "Flag sourcecodeform must be either \'fix\' or \'free\': %s" % repr(sourcecodeform))\n        filepositiontext = \'Line             fin.filelineno() - 1, currentfilename, l1)\n        m = includeline.match(origfinalline)\n        if m:\n            fn = m.group(\'name\')\n            if os.path.isfile(fn):\n                readfortrancode(fn, dowithline=dowithline, istop=0)\n            else:\n                include_dirs = [\n                    os.path.dirname(currentfilename)] + include_paths\n                foundfile = 0\n                for inc_dir in include_dirs:\n                    fn1 = os.path.join(inc_dir, fn)\n                    if os.path.isfile(fn1):\n                        foundfile = 1\n                        readfortrancode(fn1, dowithline=dowithline, istop=0)\n                        break\n                if not foundfile:\n                    outmess(\'readfortrancode: could not find include file %s in %s. Ignoring.\\n\' % (\n                        repr(fn), os.pathsep.join(include_dirs)))\n        else:\n            dowithline(finalline)\n        l1 = ll\n    if localdolowercase:\n        finalline = ll.lower()\n    else:\n        finalline = ll\n    origfinalline = ll\n    filepositiontext = \'Line         fin.filelineno() - 1, currentfilename, l1)\n    m = includeline.match(origfinalline)\n    if m:\n        fn = m.group(\'name\')\n        if os.path.isfile(fn):\n            readfortrancode(fn, dowithline=dowithline, istop=0)\n        else:\n            include_dirs = [os.path.dirname(currentfilename)] + include_paths\n            foundfile = 0\n            for inc_dir in include_dirs:\n                fn1 = os.path.join(inc_dir, fn)\n                if os.path.isfile(fn1):\n                    foundfile = 1\n                    readfortrancode(fn1, dowithline=dowithline, istop=0)\n                    break\n            if not foundfile:\n                outmess(\'readfortrancode: could not find include file %s in %s. Ignoring.\\n\' % (\n                    repr(fn), os.pathsep.join(include_dirs)))\n    else:\n        dowithline(finalline)\n    filepositiontext = \'\'\n    fin.close()\n    if istop:\n        dowithline(\'\', 1)\n    else:\n        gotnextfile, filepositiontext, currentfilename, sourcecodeform, strictf77,\\\n            beginpattern, quiet, verbose, dolowercase = saveglobals\n\nbeforethisafter = r\'\\s*(?P<before>%s(?=\\s*(\\b(%s)\\b)))\' + \\\n    r\'\\s*(?P<this>(\\b(%s)\\b))\' + \\\n    r\'\\s*(?P<after>%s)\\s*\\Z\'\nfortrantypes = \'character|logical|integer|real|complex|double\\s*(precision\\s*(complex|)|complex)|type(?=\\s*\\([\\w\\s,=(*)]*\\))|byte\'\ntypespattern = re.compile(\n    beforethisafter % (\'\', fortrantypes, fortrantypes, \'.*\'), re.I), \'type\'\ntypespattern4implicit = re.compile(beforethisafter % (\n    \'\', fortrantypes + \'|static|automatic|undefined\', fortrantypes + \'|static|automatic|undefined\', \'.*\'), re.I)\nfunctionpattern = re.compile(beforethisafter % (\n    \'([a-z]+[\\w\\s(=*+-/)]*?|)\', \'function\', \'function\', \'.*\'), re.I), \'begin\'\nsubroutinepattern = re.compile(beforethisafter % (\n    \'[a-z\\s]*?\', \'subroutine\', \'subroutine\', \'.*\'), re.I), \'begin\'\ngroupbegins77 = r\'program|block\\s*data\'\nbeginpattern77 = re.compile(\n    beforethisafter % (\'\', groupbegins77, groupbegins77, \'.*\'), re.I), \'begin\'\ngroupbegins90 = groupbegins77 + \\\n    r\'|module(?!\\s*procedure)|python\\s*module|interface|type(?!\\s*\\()\'\nbeginpattern90 = re.compile(\n    beforethisafter % (\'\', groupbegins90, groupbegins90, \'.*\'), re.I), \'begin\'\ngroupends = r\'end|endprogram|endblockdata|endmodule|endpythonmodule|endinterface\'\nendpattern = re.compile(\n    beforethisafter % (\'\', groupends, groupends, \'[\\w\\s]*\'), re.I), \'end\'\nendifs = \'(end\\s*(if|do|where|select|while|forall))|(module\\s*procedure)\'\nendifpattern = re.compile(\n    beforethisafter % (\'[\\w]*?\', endifs, endifs, \'[\\w\\s]*\'), re.I), \'endif\'\nimplicitpattern = re.compile(\n    beforethisafter % (\'\', \'implicit\', \'implicit\', \'.*\'), re.I), \'implicit\'\ndimensionpattern = re.compile(beforethisafter % (\n    \'\', \'dimension|virtual\', \'dimension|virtual\', \'.*\'), re.I), \'dimension\'\nexternalpattern = re.compile(\n    beforethisafter % (\'\', \'external\', \'external\', \'.*\'), re.I), \'external\'\noptionalpattern = re.compile(\n    beforethisafter % (\'\', \'optional\', \'optional\', \'.*\'), re.I), \'optional\'\nrequiredpattern = re.compile(\n    beforethisafter % (\'\', \'required\', \'required\', \'.*\'), re.I), \'required\'\npublicpattern = re.compile(\n    beforethisafter % (\'\', \'public\', \'public\', \'.*\'), re.I), \'public\'\nprivatepattern = re.compile(\n    beforethisafter % (\'\', \'private\', \'private\', \'.*\'), re.I), \'private\'\nintrisicpattern = re.compile(\n    beforethisafter % (\'\', \'intrisic\', \'intrisic\', \'.*\'), re.I), \'intrisic\'\nintentpattern = re.compile(beforethisafter % (\n    \'\', \'intent|depend|note|check\', \'intent|depend|note|check\', \'\\s*\\(.*?\\).*\'), re.I), \'intent\'\nparameterpattern = re.compile(\n    beforethisafter % (\'\', \'parameter\', \'parameter\', \'\\s*\\(.*\'), re.I), \'parameter\'\ndatapattern = re.compile(\n    beforethisafter % (\'\', \'data\', \'data\', \'.*\'), re.I), \'data\'\ncallpattern = re.compile(\n    beforethisafter % (\'\', \'call\', \'call\', \'.*\'), re.I), \'call\'\nentrypattern = re.compile(\n    beforethisafter % (\'\', \'entry\', \'entry\', \'.*\'), re.I), \'entry\'\ncallfunpattern = re.compile(\n    beforethisafter % (\'\', \'callfun\', \'callfun\', \'.*\'), re.I), \'callfun\'\ncommonpattern = re.compile(\n    beforethisafter % (\'\', \'common\', \'common\', \'.*\'), re.I), \'common\'\nusepattern = re.compile(\n    beforethisafter % (\'\', \'use\', \'use\', \'.*\'), re.I), \'use\'\ncontainspattern = re.compile(\n    beforethisafter % (\'\', \'contains\', \'contains\', \'\'), re.I), \'contains\'\nformatpattern = re.compile(\n    beforethisafter % (\'\', \'format\', \'format\', \'.*\'), re.I), \'format\'\nf2pyenhancementspattern = re.compile(beforethisafter % (\'\', \'threadsafe|fortranname|callstatement|callprotoargument|usercode|pymethoddef\',\n                                                        \'threadsafe|fortranname|callstatement|callprotoargument|usercode|pymethoddef\', \'.*\'), re.I | re.S), \'f2pyenhancements\'\nmultilinepattern = re.compile(\n    r"\\s*(?P<before>)\\s*\\Z", re.S), \'multiline\'\n\n\ndef _simplifyargs(argsline):\n    a = []\n    for n in markoutercomma(argsline).split(\'@,@\'):\n        for r in \'(),\':\n            n = n.replace(r, \'_\')\n        a.append(n)\n    return \',\'.join(a)\n\ncrackline_re_1 = re.compile(r\'\\s*(?P<result>\\b[a-z]+[\\w]*\\b)\\s*[=].*\', re.I)\n\n\ndef crackline(line, reset=0):\n    \n    global beginpattern, groupcounter, groupname, groupcache, grouplist\n    global filepositiontext, currentfilename, neededmodule, expectbegin\n    global skipblocksuntil, skipemptyends, previous_context, gotnextfile\n\n    if \';\' in line and not (f2pyenhancementspattern[0].match(line) or\n                            multilinepattern[0].match(line)):\n        for l in line.split(\';\'):\n                        assert reset == 0, repr(reset)\n            crackline(l, reset)\n        return\n    if reset < 0:\n        groupcounter = 0\n        groupname = {groupcounter: \'\'}\n        groupcache = {groupcounter: {}}\n        grouplist = {groupcounter: []}\n        groupcache[groupcounter][\'body\'] = []\n        groupcache[groupcounter][\'vars\'] = {}\n        groupcache[groupcounter][\'block\'] = \'\'\n        groupcache[groupcounter][\'name\'] = \'\'\n        neededmodule = -1\n        skipblocksuntil = -1\n        return\n    if reset > 0:\n        fl = 0\n        if f77modulename and neededmodule == groupcounter:\n            fl = 2\n        while groupcounter > fl:\n            outmess(\'crackline: groupcounter=%s groupname=%s\\n\' %\n                    (repr(groupcounter), repr(groupname)))\n            outmess(\n                \'crackline: Mismatch of blocks encountered. Trying to fix it by assuming "end" statement.\\n\')\n            grouplist[groupcounter - 1].append(groupcache[groupcounter])\n            grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n            del grouplist[groupcounter]\n            groupcounter = groupcounter - 1\n        if f77modulename and neededmodule == groupcounter:\n            grouplist[groupcounter - 1].append(groupcache[groupcounter])\n            grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n            del grouplist[groupcounter]\n            groupcounter = groupcounter - 1              grouplist[groupcounter - 1].append(groupcache[groupcounter])\n            grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n            del grouplist[groupcounter]\n            groupcounter = groupcounter - 1              neededmodule = -1\n        return\n    if line == \'\':\n        return\n    flag = 0\n    for pat in [dimensionpattern, externalpattern, intentpattern, optionalpattern,\n                requiredpattern,\n                parameterpattern, datapattern, publicpattern, privatepattern,\n                intrisicpattern,\n                endifpattern, endpattern,\n                formatpattern,\n                beginpattern, functionpattern, subroutinepattern,\n                implicitpattern, typespattern, commonpattern,\n                callpattern, usepattern, containspattern,\n                entrypattern,\n                f2pyenhancementspattern,\n                multilinepattern\n                ]:\n        m = pat[0].match(line)\n        if m:\n            break\n        flag = flag + 1\n    if not m:\n        re_1 = crackline_re_1\n        if 0 <= skipblocksuntil <= groupcounter:\n            return\n        if \'externals\' in groupcache[groupcounter]:\n            for name in groupcache[groupcounter][\'externals\']:\n                if name in invbadnames:\n                    name = invbadnames[name]\n                if \'interfaced\' in groupcache[groupcounter] and name in groupcache[groupcounter][\'interfaced\']:\n                    continue\n                m1 = re.match(\n                    r\'(?P<before>[^"]*)\\b%s\\b\\s*@\\(@(?P<args>[^@]*)@\\)@.*\\Z\' % name, markouterparen(line), re.I)\n                if m1:\n                    m2 = re_1.match(m1.group(\'before\'))\n                    a = _simplifyargs(m1.group(\'args\'))\n                    if m2:\n                        line = \'callfun %s(%s) result (%s)\' % (\n                            name, a, m2.group(\'result\'))\n                    else:\n                        line = \'callfun %s(%s)\' % (name, a)\n                    m = callfunpattern[0].match(line)\n                    if not m:\n                        outmess(\n                            \'crackline: could not resolve function call for line=%s.\\n\' % repr(line))\n                        return\n                    analyzeline(m, \'callfun\', line)\n                    return\n        if verbose > 1 or (verbose == 1 and currentfilename.lower().endswith(\'.pyf\')):\n            previous_context = None\n            outmess(\'crackline:%d: No pattern for line\\n\' % (groupcounter))\n        return\n    elif pat[1] == \'end\':\n        if 0 <= skipblocksuntil < groupcounter:\n            groupcounter = groupcounter - 1\n            if skipblocksuntil <= groupcounter:\n                return\n        if groupcounter <= 0:\n            raise Exception(\'crackline: groupcounter(=%s) is nonpositive. \'\n                            \'Check the blocks.\'\n                            % (groupcounter))\n        m1 = beginpattern[0].match((line))\n        if (m1) and (not m1.group(\'this\') == groupname[groupcounter]):\n            raise Exception(\'crackline: End group %s does not match with \'\n                            \'previous Begin group %s\\n\\t%s\' %\n                            (repr(m1.group(\'this\')), repr(groupname[groupcounter]),\n                             filepositiontext)\n                            )\n        if skipblocksuntil == groupcounter:\n            skipblocksuntil = -1\n        grouplist[groupcounter - 1].append(groupcache[groupcounter])\n        grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n        del grouplist[groupcounter]\n        groupcounter = groupcounter - 1\n        if not skipemptyends:\n            expectbegin = 1\n    elif pat[1] == \'begin\':\n        if 0 <= skipblocksuntil <= groupcounter:\n            groupcounter = groupcounter + 1\n            return\n        gotnextfile = 0\n        analyzeline(m, pat[1], line)\n        expectbegin = 0\n    elif pat[1] == \'endif\':\n        pass\n    elif pat[1] == \'contains\':\n        if ignorecontains:\n            return\n        if 0 <= skipblocksuntil <= groupcounter:\n            return\n        skipblocksuntil = groupcounter\n    else:\n        if 0 <= skipblocksuntil <= groupcounter:\n            return\n        analyzeline(m, pat[1], line)\n\n\ndef markouterparen(line):\n    l = \'\'\n    f = 0\n    for c in line:\n        if c == \'(\':\n            f = f + 1\n            if f == 1:\n                l = l + \'@(@\'\n                continue\n        elif c == \')\':\n            f = f - 1\n            if f == 0:\n                l = l + \'@)@\'\n                continue\n        l = l + c\n    return l\n\n\ndef markoutercomma(line, comma=\',\'):\n    l = \'\'\n    f = 0\n    cc = \'\'\n    for c in line:\n        if (not cc or cc == \')\') and c == \'(\':\n            f = f + 1\n            cc = \')\'\n        elif not cc and c == \'\\\'\' and (not l or l[-1] != \'\\\\\'):\n            f = f + 1\n            cc = \'\\\'\'\n        elif c == cc:\n            f = f - 1\n            if f == 0:\n                cc = \'\'\n        elif c == comma and f == 0:\n            l = l + \'@\' + comma + \'@\'\n            continue\n        l = l + c\n    assert not f, repr((f, line, l, cc))\n    return l\n\n\ndef unmarkouterparen(line):\n    r = line.replace(\'@(@\', \'(\').replace(\'@)@\', \')\')\n    return r\n\n\ndef appenddecl(decl, decl2, force=1):\n    if not decl:\n        decl = {}\n    if not decl2:\n        return decl\n    if decl is decl2:\n        return decl\n    for k in list(decl2.keys()):\n        if k == \'typespec\':\n            if force or k not in decl:\n                decl[k] = decl2[k]\n        elif k == \'attrspec\':\n            for l in decl2[k]:\n                decl = setattrspec(decl, l, force)\n        elif k == \'kindselector\':\n            decl = setkindselector(decl, decl2[k], force)\n        elif k == \'charselector\':\n            decl = setcharselector(decl, decl2[k], force)\n        elif k in [\'=\', \'typename\']:\n            if force or k not in decl:\n                decl[k] = decl2[k]\n        elif k == \'note\':\n            pass\n        elif k in [\'intent\', \'check\', \'dimension\', \'optional\', \'required\']:\n            errmess(\'appenddecl: "%s" not implemented.\\n\' % k)\n        else:\n            raise Exception(\'appenddecl: Unknown variable definition key:\' +\n                            str(k))\n    return decl\n\nselectpattern = re.compile(\n    r\'\\s*(?P<this>(@\\(@.*?@\\)@|[*][\\d*]+|[*]\\s*@\\(@.*?@\\)@|))(?P<after>.*)\\Z\', re.I)\nnameargspattern = re.compile(\n    r\'\\s*(?P<name>\\b[\\w$]+\\b)\\s*(@\\(@\\s*(?P<args>[\\w\\s,]*)\\s*@\\)@|)\\s*((result(\\s*@\\(@\\s*(?P<result>\\b[\\w$]+\\b)\\s*@\\)@|))|(bind\\s*@\\(@\\s*(?P<bind>.*)\\s*@\\)@))*\\s*\\Z\', re.I)\ncallnameargspattern = re.compile(\n    r\'\\s*(?P<name>\\b[\\w$]+\\b)\\s*@\\(@\\s*(?P<args>.*)\\s*@\\)@\\s*\\Z\', re.I)\nreal16pattern = re.compile(\n    r\'([-+]?(?:\\d+(?:\\.\\d*)?|\\d*\\.\\d+))[dD]((?:[-+]?\\d+)?)\')\nreal8pattern = re.compile(\n    r\'([-+]?((?:\\d+(?:\\.\\d*)?|\\d*\\.\\d+))[eE]((?:[-+]?\\d+)?)|(\\d+\\.\\d*))\')\n\n_intentcallbackpattern = re.compile(r\'intent\\s*\\(.*?\\bcallback\\b\', re.I)\n\n\ndef _is_intent_callback(vdecl):\n    for a in vdecl.get(\'attrspec\', []):\n        if _intentcallbackpattern.match(a):\n            return 1\n    return 0\n\n\ndef _resolvenameargspattern(line):\n    line = markouterparen(line)\n    m1 = nameargspattern.match(line)\n    if m1:\n        return m1.group(\'name\'), m1.group(\'args\'), m1.group(\'result\'), m1.group(\'bind\')\n    m1 = callnameargspattern.match(line)\n    if m1:\n        return m1.group(\'name\'), m1.group(\'args\'), None, None\n    return None, [], None, None\n\n\ndef analyzeline(m, case, line):\n    global groupcounter, groupname, groupcache, grouplist, filepositiontext\n    global currentfilename, f77modulename, neededinterface, neededmodule\n    global expectbegin, gotnextfile, previous_context\n\n    block = m.group(\'this\')\n    if case != \'multiline\':\n        previous_context = None\n    if expectbegin and case not in [\'begin\', \'call\', \'callfun\', \'type\'] \\\n       and not skipemptyends and groupcounter < 1:\n        newname = os.path.basename(currentfilename).split(\'.\')[0]\n        outmess(\n            \'analyzeline: no group yet. Creating program group with name "%s".\\n\' % newname)\n        gotnextfile = 0\n        groupcounter = groupcounter + 1\n        groupname[groupcounter] = \'program\'\n        groupcache[groupcounter] = {}\n        grouplist[groupcounter] = []\n        groupcache[groupcounter][\'body\'] = []\n        groupcache[groupcounter][\'vars\'] = {}\n        groupcache[groupcounter][\'block\'] = \'program\'\n        groupcache[groupcounter][\'name\'] = newname\n        groupcache[groupcounter][\'from\'] = \'fromsky\'\n        expectbegin = 0\n    if case in [\'begin\', \'call\', \'callfun\']:\n                block = block.lower()\n        if re.match(r\'block\\s*data\', block, re.I):\n            block = \'block data\'\n        if re.match(r\'python\\s*module\', block, re.I):\n            block = \'python module\'\n        name, args, result, bind = _resolvenameargspattern(m.group(\'after\'))\n        if name is None:\n            if block == \'block data\':\n                name = \'_BLOCK_DATA_\'\n            else:\n                name = \'\'\n            if block not in [\'interface\', \'block data\']:\n                outmess(\'analyzeline: No name/args pattern found for line.\\n\')\n\n        previous_context = (block, name, groupcounter)\n        if args:\n            args = rmbadname([x.strip()\n                              for x in markoutercomma(args).split(\'@,@\')])\n        else:\n            args = []\n        if \'\' in args:\n            while \'\' in args:\n                args.remove(\'\')\n            outmess(\n                \'analyzeline: argument list is malformed (missing argument).\\n\')\n\n                needmodule = 0\n        needinterface = 0\n\n        if case in [\'call\', \'callfun\']:\n            needinterface = 1\n            if \'args\' not in groupcache[groupcounter]:\n                return\n            if name not in groupcache[groupcounter][\'args\']:\n                return\n            for it in grouplist[groupcounter]:\n                if it[\'name\'] == name:\n                    return\n            if name in groupcache[groupcounter][\'interfaced\']:\n                return\n            block = {\'call\': \'subroutine\', \'callfun\': \'function\'}[case]\n        if f77modulename and neededmodule == -1 and groupcounter <= 1:\n            neededmodule = groupcounter + 2\n            needmodule = 1\n            if block != \'interface\':\n                needinterface = 1\n                groupcounter = groupcounter + 1\n        groupcache[groupcounter] = {}\n        grouplist[groupcounter] = []\n        if needmodule:\n            if verbose > 1:\n                outmess(\'analyzeline: Creating module block %s\\n\' %\n                        repr(f77modulename), 0)\n            groupname[groupcounter] = \'module\'\n            groupcache[groupcounter][\'block\'] = \'python module\'\n            groupcache[groupcounter][\'name\'] = f77modulename\n            groupcache[groupcounter][\'from\'] = \'\'\n            groupcache[groupcounter][\'body\'] = []\n            groupcache[groupcounter][\'externals\'] = []\n            groupcache[groupcounter][\'interfaced\'] = []\n            groupcache[groupcounter][\'vars\'] = {}\n            groupcounter = groupcounter + 1\n            groupcache[groupcounter] = {}\n            grouplist[groupcounter] = []\n        if needinterface:\n            if verbose > 1:\n                outmess(\'analyzeline: Creating additional interface block (groupcounter=%s).\\n\' % (\n                    groupcounter), 0)\n            groupname[groupcounter] = \'interface\'\n            groupcache[groupcounter][\'block\'] = \'interface\'\n            groupcache[groupcounter][\'name\'] = \'unknown_interface\'\n            groupcache[groupcounter][\'from\'] = \'%s:%s\' % (\n                groupcache[groupcounter - 1][\'from\'], groupcache[groupcounter - 1][\'name\'])\n            groupcache[groupcounter][\'body\'] = []\n            groupcache[groupcounter][\'externals\'] = []\n            groupcache[groupcounter][\'interfaced\'] = []\n            groupcache[groupcounter][\'vars\'] = {}\n            groupcounter = groupcounter + 1\n            groupcache[groupcounter] = {}\n            grouplist[groupcounter] = []\n        groupname[groupcounter] = block\n        groupcache[groupcounter][\'block\'] = block\n        if not name:\n            name = \'unknown_\' + block\n        groupcache[groupcounter][\'prefix\'] = m.group(\'before\')\n        groupcache[groupcounter][\'name\'] = rmbadname1(name)\n        groupcache[groupcounter][\'result\'] = result\n        if groupcounter == 1:\n            groupcache[groupcounter][\'from\'] = currentfilename\n        else:\n            if f77modulename and groupcounter == 3:\n                groupcache[groupcounter][\'from\'] = \'%s:%s\' % (\n                    groupcache[groupcounter - 1][\'from\'], currentfilename)\n            else:\n                groupcache[groupcounter][\'from\'] = \'%s:%s\' % (\n                    groupcache[groupcounter - 1][\'from\'], groupcache[groupcounter - 1][\'name\'])\n        for k in list(groupcache[groupcounter].keys()):\n            if not groupcache[groupcounter][k]:\n                del groupcache[groupcounter][k]\n\n        groupcache[groupcounter][\'args\'] = args\n        groupcache[groupcounter][\'body\'] = []\n        groupcache[groupcounter][\'externals\'] = []\n        groupcache[groupcounter][\'interfaced\'] = []\n        groupcache[groupcounter][\'vars\'] = {}\n        groupcache[groupcounter][\'entry\'] = {}\n                if block == \'type\':\n            groupcache[groupcounter][\'varnames\'] = []\n\n        if case in [\'call\', \'callfun\']:              if name not in groupcache[groupcounter - 2][\'externals\']:\n                groupcache[groupcounter - 2][\'externals\'].append(name)\n            groupcache[groupcounter][\'vars\'] = copy.deepcopy(\n                groupcache[groupcounter - 2][\'vars\'])\n            try:\n                del groupcache[groupcounter][\'vars\'][name][\n                    groupcache[groupcounter][\'vars\'][name][\'attrspec\'].index(\'external\')]\n            except:\n                pass\n        if block in [\'function\', \'subroutine\']:              try:\n                groupcache[groupcounter][\'vars\'][name] = appenddecl(\n                    groupcache[groupcounter][\'vars\'][name], groupcache[groupcounter - 2][\'vars\'][\'\'])\n            except:\n                pass\n            if case == \'callfun\':                  if result and result in groupcache[groupcounter][\'vars\']:\n                    if not name == result:\n                        groupcache[groupcounter][\'vars\'][name] = appenddecl(\n                            groupcache[groupcounter][\'vars\'][name], groupcache[groupcounter][\'vars\'][result])\n                        try:\n                groupcache[groupcounter - 2][\'interfaced\'].append(name)\n            except:\n                pass\n        if block == \'function\':\n            t = typespattern[0].match(m.group(\'before\') + \' \' + name)\n            if t:\n                typespec, selector, attr, edecl = cracktypespec0(\n                    t.group(\'this\'), t.group(\'after\'))\n                updatevars(typespec, selector, attr, edecl)\n\n        if case in [\'call\', \'callfun\']:\n            grouplist[groupcounter - 1].append(groupcache[groupcounter])\n            grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n            del grouplist[groupcounter]\n            groupcounter = groupcounter - 1              grouplist[groupcounter - 1].append(groupcache[groupcounter])\n            grouplist[groupcounter - 1][-1][\'body\'] = grouplist[groupcounter]\n            del grouplist[groupcounter]\n            groupcounter = groupcounter - 1  \n    elif case == \'entry\':\n        name, args, result, bind = _resolvenameargspattern(m.group(\'after\'))\n        if name is not None:\n            if args:\n                args = rmbadname([x.strip()\n                                  for x in markoutercomma(args).split(\'@,@\')])\n            else:\n                args = []\n            assert result is None, repr(result)\n            groupcache[groupcounter][\'entry\'][name] = args\n            previous_context = (\'entry\', name, groupcounter)\n    elif case == \'type\':\n        typespec, selector, attr, edecl = cracktypespec0(\n            block, m.group(\'after\'))\n        last_name = updatevars(typespec, selector, attr, edecl)\n        if last_name is not None:\n            previous_context = (\'variable\', last_name, groupcounter)\n    elif case in [\'dimension\', \'intent\', \'optional\', \'required\', \'external\', \'public\', \'private\', \'intrisic\']:\n        edecl = groupcache[groupcounter][\'vars\']\n        ll = m.group(\'after\').strip()\n        i = ll.find(\'::\')\n        if i < 0 and case == \'intent\':\n            i = markouterparen(ll).find(\'@)@\') - 2\n            ll = ll[:i + 1] + \'::\' + ll[i + 1:]\n            i = ll.find(\'::\')\n            if ll[i:] == \'::\' and \'args\' in groupcache[groupcounter]:\n                outmess(\'All arguments will have attribute %s%s\\n\' %\n                        (m.group(\'this\'), ll[:i]))\n                ll = ll + \',\'.join(groupcache[groupcounter][\'args\'])\n        if i < 0:\n            i = 0\n            pl = \'\'\n        else:\n            pl = ll[:i].strip()\n            ll = ll[i + 2:]\n        ch = markoutercomma(pl).split(\'@,@\')\n        if len(ch) > 1:\n            pl = ch[0]\n            outmess(\'analyzeline: cannot handle multiple attributes without type specification. Ignoring %r.\\n\' % (\n                \',\'.join(ch[1:])))\n        last_name = None\n\n        for e in [x.strip() for x in markoutercomma(ll).split(\'@,@\')]:\n            m1 = namepattern.match(e)\n            if not m1:\n                if case in [\'public\', \'private\']:\n                    k = \'\'\n                else:\n                    print(m.groupdict())\n                    outmess(\'analyzeline: no name pattern found in %s statement for %s. Skipping.\\n\' % (\n                        case, repr(e)))\n                    continue\n            else:\n                k = rmbadname1(m1.group(\'name\'))\n            if k not in edecl:\n                edecl[k] = {}\n            if case == \'dimension\':\n                ap = case + m1.group(\'after\')\n            if case == \'intent\':\n                ap = m.group(\'this\') + pl\n                if _intentcallbackpattern.match(ap):\n                    if k not in groupcache[groupcounter][\'args\']:\n                        if groupcounter > 1:\n                            if \'__user__\' not in groupcache[groupcounter - 2][\'name\']:\n                                outmess(\n                                    \'analyzeline: missing __user__ module (could be nothing)\\n\')\n                                                        if k != groupcache[groupcounter][\'name\']:\n                                outmess(\'analyzeline: appending intent(callback) %s\'\n                                        \' to %s arguments\\n\' % (k, groupcache[groupcounter][\'name\']))\n                                groupcache[groupcounter][\'args\'].append(k)\n                        else:\n                            errmess(\n                                \'analyzeline: intent(callback) %s is ignored\' % (k))\n                    else:\n                        errmess(\'analyzeline: intent(callback) %s is already\'\n                                \' in argument list\' % (k))\n            if case in [\'optional\', \'required\', \'public\', \'external\', \'private\', \'intrisic\']:\n                ap = case\n            if \'attrspec\' in edecl[k]:\n                edecl[k][\'attrspec\'].append(ap)\n            else:\n                edecl[k][\'attrspec\'] = [ap]\n            if case == \'external\':\n                if groupcache[groupcounter][\'block\'] == \'program\':\n                    outmess(\'analyzeline: ignoring program arguments\\n\')\n                    continue\n                if k not in groupcache[groupcounter][\'args\']:\n                    continue\n                if \'externals\' not in groupcache[groupcounter]:\n                    groupcache[groupcounter][\'externals\'] = []\n                groupcache[groupcounter][\'externals\'].append(k)\n            last_name = k\n        groupcache[groupcounter][\'vars\'] = edecl\n        if last_name is not None:\n            previous_context = (\'variable\', last_name, groupcounter)\n    elif case == \'parameter\':\n        edecl = groupcache[groupcounter][\'vars\']\n        ll = m.group(\'after\').strip()[1:-1]\n        last_name = None\n        for e in markoutercomma(ll).split(\'@,@\'):\n            try:\n                k, initexpr = [x.strip() for x in e.split(\'=\')]\n            except:\n                outmess(\n                    \'analyzeline: could not extract name,expr in parameter statement "%s" of "%s"\\n\' % (e, ll))\n                continue\n            params = get_parameters(edecl)\n            k = rmbadname1(k)\n            if k not in edecl:\n                edecl[k] = {}\n            if \'=\' in edecl[k] and (not edecl[k][\'=\'] == initexpr):\n                outmess(\'analyzeline: Overwriting the value of parameter "%s" ("%s") with "%s".\\n\' % (\n                    k, edecl[k][\'=\'], initexpr))\n            t = determineexprtype(initexpr, params)\n            if t:\n                if t.get(\'typespec\') == \'real\':\n                    tt = list(initexpr)\n                    for m in real16pattern.finditer(initexpr):\n                        tt[m.start():m.end()] = list(\n                            initexpr[m.start():m.end()].lower().replace(\'d\', \'e\'))\n                    initexpr = \'\'.join(tt)\n                elif t.get(\'typespec\') == \'complex\':\n                    initexpr = initexpr[1:].lower().replace(\'d\', \'e\').\\\n                        replace(\',\', \'+1j*(\')\n            try:\n                v = eval(initexpr, {}, params)\n            except (SyntaxError, NameError, TypeError) as msg:\n                errmess(\'analyzeline: Failed to evaluate %r. Ignoring: %s\\n\'\n                        % (initexpr, msg))\n                continue\n            edecl[k][\'=\'] = repr(v)\n            if \'attrspec\' in edecl[k]:\n                edecl[k][\'attrspec\'].append(\'parameter\')\n            else:\n                edecl[k][\'attrspec\'] = [\'parameter\']\n            last_name = k\n        groupcache[groupcounter][\'vars\'] = edecl\n        if last_name is not None:\n            previous_context = (\'variable\', last_name, groupcounter)\n    elif case == \'implicit\':\n        if m.group(\'after\').strip().lower() == \'none\':\n            groupcache[groupcounter][\'implicit\'] = None\n        elif m.group(\'after\'):\n            if \'implicit\' in groupcache[groupcounter]:\n                impl = groupcache[groupcounter][\'implicit\']\n            else:\n                impl = {}\n            if impl is None:\n                outmess(\n                    \'analyzeline: Overwriting earlier "implicit none" statement.\\n\')\n                impl = {}\n            for e in markoutercomma(m.group(\'after\')).split(\'@,@\'):\n                decl = {}\n                m1 = re.match(\n                    r\'\\s*(?P<this>.*?)\\s*(\\(\\s*(?P<after>[a-z-, ]+)\\s*\\)\\s*|)\\Z\', e, re.I)\n                if not m1:\n                    outmess(\n                        \'analyzeline: could not extract info of implicit statement part "%s"\\n\' % (e))\n                    continue\n                m2 = typespattern4implicit.match(m1.group(\'this\'))\n                if not m2:\n                    outmess(\n                        \'analyzeline: could not extract types pattern of implicit statement part "%s"\\n\' % (e))\n                    continue\n                typespec, selector, attr, edecl = cracktypespec0(\n                    m2.group(\'this\'), m2.group(\'after\'))\n                kindselect, charselect, typename = cracktypespec(\n                    typespec, selector)\n                decl[\'typespec\'] = typespec\n                decl[\'kindselector\'] = kindselect\n                decl[\'charselector\'] = charselect\n                decl[\'typename\'] = typename\n                for k in list(decl.keys()):\n                    if not decl[k]:\n                        del decl[k]\n                for r in markoutercomma(m1.group(\'after\')).split(\'@,@\'):\n                    if \'-\' in r:\n                        try:\n                            begc, endc = [x.strip() for x in r.split(\'-\')]\n                        except:\n                            outmess(\n                                \'analyzeline: expected "<char>-<char>" instead of "%s" in range list of implicit statement\\n\' % r)\n                            continue\n                    else:\n                        begc = endc = r.strip()\n                    if not len(begc) == len(endc) == 1:\n                        outmess(\n                            \'analyzeline: expected "<char>-<char>" instead of "%s" in range list of implicit statement (2)\\n\' % r)\n                        continue\n                    for o in range(ord(begc), ord(endc) + 1):\n                        impl[chr(o)] = decl\n            groupcache[groupcounter][\'implicit\'] = impl\n    elif case == \'data\':\n        ll = []\n        dl = \'\'\n        il = \'\'\n        f = 0\n        fc = 1\n        inp = 0\n        for c in m.group(\'after\'):\n            if not inp:\n                if c == "\'":\n                    fc = not fc\n                if c == \'/\' and fc:\n                    f = f + 1\n                    continue\n            if c == \'(\':\n                inp = inp + 1\n            elif c == \')\':\n                inp = inp - 1\n            if f == 0:\n                dl = dl + c\n            elif f == 1:\n                il = il + c\n            elif f == 2:\n                dl = dl.strip()\n                if dl.startswith(\',\'):\n                    dl = dl[1:].strip()\n                ll.append([dl, il])\n                dl = c\n                il = \'\'\n                f = 0\n        if f == 2:\n            dl = dl.strip()\n            if dl.startswith(\',\'):\n                dl = dl[1:].strip()\n            ll.append([dl, il])\n        vars = {}\n        if \'vars\' in groupcache[groupcounter]:\n            vars = groupcache[groupcounter][\'vars\']\n        last_name = None\n        for l in ll:\n            l = [x.strip() for x in l]\n            if l[0][0] == \',\':\n                l[0] = l[0][1:]\n            if l[0][0] == \'(\':\n                outmess(\n                    \'analyzeline: implied-DO list "%s" is not supported. Skipping.\\n\' % l[0])\n                continue\n            i = 0\n            j = 0\n            llen = len(l[1])\n            for v in rmbadname([x.strip() for x in markoutercomma(l[0]).split(\'@,@\')]):\n                if v[0] == \'(\':\n                    outmess(\n                        \'analyzeline: implied-DO list "%s" is not supported. Skipping.\\n\' % v)\n                                                                                continue\n                fc = 0\n                while (i < llen) and (fc or not l[1][i] == \',\'):\n                    if l[1][i] == "\'":\n                        fc = not fc\n                    i = i + 1\n                i = i + 1\n                if v not in vars:\n                    vars[v] = {}\n                if \'=\' in vars[v] and not vars[v][\'=\'] == l[1][j:i - 1]:\n                    outmess(\'analyzeline: changing init expression of "%s" ("%s") to "%s"\\n\' % (\n                        v, vars[v][\'=\'], l[1][j:i - 1]))\n                vars[v][\'=\'] = l[1][j:i - 1]\n                j = i\n                last_name = v\n        groupcache[groupcounter][\'vars\'] = vars\n        if last_name is not None:\n            previous_context = (\'variable\', last_name, groupcounter)\n    elif case == \'common\':\n        line = m.group(\'after\').strip()\n        if not line[0] == \'/\':\n            line = \'//\' + line\n        cl = []\n        f = 0\n        bn = \'\'\n        ol = \'\'\n        for c in line:\n            if c == \'/\':\n                f = f + 1\n                continue\n            if f >= 3:\n                bn = bn.strip()\n                if not bn:\n                    bn = \'_BLNK_\'\n                cl.append([bn, ol])\n                f = f - 2\n                bn = \'\'\n                ol = \'\'\n            if f % 2:\n                bn = bn + c\n            else:\n                ol = ol + c\n        bn = bn.strip()\n        if not bn:\n            bn = \'_BLNK_\'\n        cl.append([bn, ol])\n        commonkey = {}\n        if \'common\' in groupcache[groupcounter]:\n            commonkey = groupcache[groupcounter][\'common\']\n        for c in cl:\n            if c[0] not in commonkey:\n                commonkey[c[0]] = []\n            for i in [x.strip() for x in markoutercomma(c[1]).split(\'@,@\')]:\n                if i:\n                    commonkey[c[0]].append(i)\n        groupcache[groupcounter][\'common\'] = commonkey\n        previous_context = (\'common\', bn, groupcounter)\n    elif case == \'use\':\n        m1 = re.match(\n            r\'\\A\\s*(?P<name>\\b[\\w]+\\b)\\s*((,(\\s*\\bonly\\b\\s*:|(?P<notonly>))\\s*(?P<list>.*))|)\\s*\\Z\', m.group(\'after\'), re.I)\n        if m1:\n            mm = m1.groupdict()\n            if \'use\' not in groupcache[groupcounter]:\n                groupcache[groupcounter][\'use\'] = {}\n            name = m1.group(\'name\')\n            groupcache[groupcounter][\'use\'][name] = {}\n            isonly = 0\n            if \'list\' in mm and mm[\'list\'] is not None:\n                if \'notonly\' in mm and mm[\'notonly\'] is None:\n                    isonly = 1\n                groupcache[groupcounter][\'use\'][name][\'only\'] = isonly\n                ll = [x.strip() for x in mm[\'list\'].split(\',\')]\n                rl = {}\n                for l in ll:\n                    if \'=\' in l:\n                        m2 = re.match(\n                            r\'\\A\\s*(?P<local>\\b[\\w]+\\b)\\s*=\\s*>\\s*(?P<use>\\b[\\w]+\\b)\\s*\\Z\', l, re.I)\n                        if m2:\n                            rl[m2.group(\'local\').strip()] = m2.group(\n                                \'use\').strip()\n                        else:\n                            outmess(\n                                \'analyzeline: Not local=>use pattern found in %s\\n\' % repr(l))\n                    else:\n                        rl[l] = l\n                    groupcache[groupcounter][\'use\'][name][\'map\'] = rl\n            else:\n                pass\n        else:\n            print(m.groupdict())\n            outmess(\'analyzeline: Could not crack the use statement.\\n\')\n    elif case in [\'f2pyenhancements\']:\n        if \'f2pyenhancements\' not in groupcache[groupcounter]:\n            groupcache[groupcounter][\'f2pyenhancements\'] = {}\n        d = groupcache[groupcounter][\'f2pyenhancements\']\n        if m.group(\'this\') == \'usercode\' and \'usercode\' in d:\n            if isinstance(d[\'usercode\'], str):\n                d[\'usercode\'] = [d[\'usercode\']]\n            d[\'usercode\'].append(m.group(\'after\'))\n        else:\n            d[m.group(\'this\')] = m.group(\'after\')\n    elif case == \'multiline\':\n        if previous_context is None:\n            if verbose:\n                outmess(\'analyzeline: No context for multiline block.\\n\')\n            return\n        gc = groupcounter\n        appendmultiline(groupcache[gc],\n                        previous_context[:2],\n                        m.group(\'this\'))\n    else:\n        if verbose > 1:\n            print(m.groupdict())\n            outmess(\'analyzeline: No code implemented for line.\\n\')\n\n\ndef appendmultiline(group, context_name, ml):\n    if \'f2pymultilines\' not in group:\n        group[\'f2pymultilines\'] = {}\n    d = group[\'f2pymultilines\']\n    if context_name not in d:\n        d[context_name] = []\n    d[context_name].append(ml)\n    return\n\n\ndef cracktypespec0(typespec, ll):\n    selector = None\n    attr = None\n    if re.match(r\'double\\s*complex\', typespec, re.I):\n        typespec = \'double complex\'\n    elif re.match(r\'double\\s*precision\', typespec, re.I):\n        typespec = \'double precision\'\n    else:\n        typespec = typespec.strip().lower()\n    m1 = selectpattern.match(markouterparen(ll))\n    if not m1:\n        outmess(\n            \'cracktypespec0: no kind/char_selector pattern found for line.\\n\')\n        return\n    d = m1.groupdict()\n    for k in list(d.keys()):\n        d[k] = unmarkouterparen(d[k])\n    if typespec in [\'complex\', \'integer\', \'logical\', \'real\', \'character\', \'type\']:\n        selector = d[\'this\']\n        ll = d[\'after\']\n    i = ll.find(\'::\')\n    if i >= 0:\n        attr = ll[:i].strip()\n        ll = ll[i + 2:]\n    return typespec, selector, attr, ll\nnamepattern = re.compile(r\'\\s*(?P<name>\\b[\\w]+\\b)\\s*(?P<after>.*)\\s*\\Z\', re.I)\nkindselector = re.compile(\n    r\'\\s*(\\(\\s*(kind\\s*=)?\\s*(?P<kind>.*)\\s*\\)|[*]\\s*(?P<kind2>.*?))\\s*\\Z\', re.I)\ncharselector = re.compile(\n    r\'\\s*(\\((?P<lenkind>.*)\\)|[*]\\s*(?P<charlen>.*))\\s*\\Z\', re.I)\nlenkindpattern = re.compile(\n    r\'\\s*(kind\\s*=\\s*(?P<kind>.*?)\\s*(@,@\\s*len\\s*=\\s*(?P<len>.*)|)|(len\\s*=\\s*|)(?P<len2>.*?)\\s*(@,@\\s*(kind\\s*=\\s*|)(?P<kind2>.*)|))\\s*\\Z\', re.I)\nlenarraypattern = re.compile(\n    r\'\\s*(@\\(@\\s*(?!/)\\s*(?P<array>.*?)\\s*@\\)@\\s*[*]\\s*(?P<len>.*?)|([*]\\s*(?P<len2>.*?)|)\\s*(@\\(@\\s*(?!/)\\s*(?P<array2>.*?)\\s*@\\)@|))\\s*(=\\s*(?P<init>.*?)|(@\\(@|)/\\s*(?P<init2>.*?)\\s*/(@\\)@|)|)\\s*\\Z\', re.I)\n\n\ndef removespaces(expr):\n    expr = expr.strip()\n    if len(expr) <= 1:\n        return expr\n    expr2 = expr[0]\n    for i in range(1, len(expr) - 1):\n        if (expr[i] == \' \' and\n            ((expr[i + 1] in "()[]{}=+-/* ") or\n                (expr[i - 1] in "()[]{}=+-/* "))):\n            continue\n        expr2 = expr2 + expr[i]\n    expr2 = expr2 + expr[-1]\n    return expr2\n\n\ndef markinnerspaces(line):\n    l = \'\'\n    f = 0\n    cc = \'\\\'\'\n    cb = \'\'\n    for c in line:\n        if cb == \'\\\\\' and c in [\'\\\\\', \'\\\'\', \'"\']:\n            l = l + c\n            cb = c\n            continue\n        if f == 0 and c in [\'\\\'\', \'"\']:\n            cc = c\n        if c == cc:\n            f = f + 1\n        elif c == cc:\n            f = f - 1\n        elif c == \' \' and f == 1:\n            l = l + \'@_@\'\n            continue\n        l = l + c\n        cb = c\n    return l\n\n\ndef updatevars(typespec, selector, attrspec, entitydecl):\n    global groupcache, groupcounter\n\n    last_name = None\n    kindselect, charselect, typename = cracktypespec(typespec, selector)\n    if attrspec:\n        attrspec = [x.strip() for x in markoutercomma(attrspec).split(\'@,@\')]\n        l = []\n        c = re.compile(r\'(?P<start>[a-zA-Z]+)\')\n        for a in attrspec:\n            if not a:\n                continue\n            m = c.match(a)\n            if m:\n                s = m.group(\'start\').lower()\n                a = s + a[len(s):]\n            l.append(a)\n        attrspec = l\n    el = [x.strip() for x in markoutercomma(entitydecl).split(\'@,@\')]\n    el1 = []\n    for e in el:\n        for e1 in [x.strip() for x in markoutercomma(removespaces(markinnerspaces(e)), comma=\' \').split(\'@ @\')]:\n            if e1:\n                el1.append(e1.replace(\'@_@\', \' \'))\n    for e in el1:\n        m = namepattern.match(e)\n        if not m:\n            outmess(\n                \'updatevars: no name pattern found for entity=%s. Skipping.\\n\' % (repr(e)))\n            continue\n        ename = rmbadname1(m.group(\'name\'))\n        edecl = {}\n        if ename in groupcache[groupcounter][\'vars\']:\n            edecl = groupcache[groupcounter][\'vars\'][ename].copy()\n            not_has_typespec = \'typespec\' not in edecl\n            if not_has_typespec:\n                edecl[\'typespec\'] = typespec\n            elif typespec and (not typespec == edecl[\'typespec\']):\n                outmess(\'updatevars: attempt to change the type of "%s" ("%s") to "%s". Ignoring.\\n\' % (\n                    ename, edecl[\'typespec\'], typespec))\n            if \'kindselector\' not in edecl:\n                edecl[\'kindselector\'] = copy.copy(kindselect)\n            elif kindselect:\n                for k in list(kindselect.keys()):\n                    if k in edecl[\'kindselector\'] and (not kindselect[k] == edecl[\'kindselector\'][k]):\n                        outmess(\'updatevars: attempt to change the kindselector "%s" of "%s" ("%s") to "%s". Ignoring.\\n\' % (\n                            k, ename, edecl[\'kindselector\'][k], kindselect[k]))\n                    else:\n                        edecl[\'kindselector\'][k] = copy.copy(kindselect[k])\n            if \'charselector\' not in edecl and charselect:\n                if not_has_typespec:\n                    edecl[\'charselector\'] = charselect\n                else:\n                    errmess(\'updatevars:%s: attempt to change empty charselector to %r. Ignoring.\\n\'\n                            % (ename, charselect))\n            elif charselect:\n                for k in list(charselect.keys()):\n                    if k in edecl[\'charselector\'] and (not charselect[k] == edecl[\'charselector\'][k]):\n                        outmess(\'updatevars: attempt to change the charselector "%s" of "%s" ("%s") to "%s". Ignoring.\\n\' % (\n                            k, ename, edecl[\'charselector\'][k], charselect[k]))\n                    else:\n                        edecl[\'charselector\'][k] = copy.copy(charselect[k])\n            if \'typename\' not in edecl:\n                edecl[\'typename\'] = typename\n            elif typename and (not edecl[\'typename\'] == typename):\n                outmess(\'updatevars: attempt to change the typename of "%s" ("%s") to "%s". Ignoring.\\n\' % (\n                    ename, edecl[\'typename\'], typename))\n            if \'attrspec\' not in edecl:\n                edecl[\'attrspec\'] = copy.copy(attrspec)\n            elif attrspec:\n                for a in attrspec:\n                    if a not in edecl[\'attrspec\']:\n                        edecl[\'attrspec\'].append(a)\n        else:\n            edecl[\'typespec\'] = copy.copy(typespec)\n            edecl[\'kindselector\'] = copy.copy(kindselect)\n            edecl[\'charselector\'] = copy.copy(charselect)\n            edecl[\'typename\'] = typename\n            edecl[\'attrspec\'] = copy.copy(attrspec)\n        if m.group(\'after\'):\n            m1 = lenarraypattern.match(markouterparen(m.group(\'after\')))\n            if m1:\n                d1 = m1.groupdict()\n                for lk in [\'len\', \'array\', \'init\']:\n                    if d1[lk + \'2\'] is not None:\n                        d1[lk] = d1[lk + \'2\']\n                        del d1[lk + \'2\']\n                for k in list(d1.keys()):\n                    if d1[k] is not None:\n                        d1[k] = unmarkouterparen(d1[k])\n                    else:\n                        del d1[k]\n                if \'len\' in d1 and \'array\' in d1:\n                    if d1[\'len\'] == \'\':\n                        d1[\'len\'] = d1[\'array\']\n                        del d1[\'array\']\n                    else:\n                        d1[\'array\'] = d1[\'array\'] + \',\' + d1[\'len\']\n                        del d1[\'len\']\n                        errmess(\'updatevars: "%s %s" is mapped to "%s %s(%s)"\\n\' % (\n                            typespec, e, typespec, ename, d1[\'array\']))\n                if \'array\' in d1:\n                    dm = \'dimension(%s)\' % d1[\'array\']\n                    if \'attrspec\' not in edecl or (not edecl[\'attrspec\']):\n                        edecl[\'attrspec\'] = [dm]\n                    else:\n                        edecl[\'attrspec\'].append(dm)\n                        for dm1 in edecl[\'attrspec\']:\n                            if dm1[:9] == \'dimension\' and dm1 != dm:\n                                del edecl[\'attrspec\'][-1]\n                                errmess(\'updatevars:%s: attempt to change %r to %r. Ignoring.\\n\'\n                                        % (ename, dm1, dm))\n                                break\n\n                if \'len\' in d1:\n                    if typespec in [\'complex\', \'integer\', \'logical\', \'real\']:\n                        if (\'kindselector\' not in edecl) or (not edecl[\'kindselector\']):\n                            edecl[\'kindselector\'] = {}\n                        edecl[\'kindselector\'][\'*\'] = d1[\'len\']\n                    elif typespec == \'character\':\n                        if (\'charselector\' not in edecl) or (not edecl[\'charselector\']):\n                            edecl[\'charselector\'] = {}\n                        if \'len\' in edecl[\'charselector\']:\n                            del edecl[\'charselector\'][\'len\']\n                        edecl[\'charselector\'][\'*\'] = d1[\'len\']\n                if \'init\' in d1:\n                    if \'=\' in edecl and (not edecl[\'=\'] == d1[\'init\']):\n                        outmess(\'updatevars: attempt to change the init expression of "%s" ("%s") to "%s". Ignoring.\\n\' % (\n                            ename, edecl[\'=\'], d1[\'init\']))\n                    else:\n                        edecl[\'=\'] = d1[\'init\']\n            else:\n                outmess(\'updatevars: could not crack entity declaration "%s". Ignoring.\\n\' % (\n                    ename + m.group(\'after\')))\n        for k in list(edecl.keys()):\n            if not edecl[k]:\n                del edecl[k]\n        groupcache[groupcounter][\'vars\'][ename] = edecl\n        if \'varnames\' in groupcache[groupcounter]:\n            groupcache[groupcounter][\'varnames\'].append(ename)\n        last_name = ename\n    return last_name\n\n\ndef cracktypespec(typespec, selector):\n    kindselect = None\n    charselect = None\n    typename = None\n    if selector:\n        if typespec in [\'complex\', \'integer\', \'logical\', \'real\']:\n            kindselect = kindselector.match(selector)\n            if not kindselect:\n                outmess(\n                    \'cracktypespec: no kindselector pattern found for %s\\n\' % (repr(selector)))\n                return\n            kindselect = kindselect.groupdict()\n            kindselect[\'*\'] = kindselect[\'kind2\']\n            del kindselect[\'kind2\']\n            for k in list(kindselect.keys()):\n                if not kindselect[k]:\n                    del kindselect[k]\n            for k, i in list(kindselect.items()):\n                kindselect[k] = rmbadname1(i)\n        elif typespec == \'character\':\n            charselect = charselector.match(selector)\n            if not charselect:\n                outmess(\n                    \'cracktypespec: no charselector pattern found for %s\\n\' % (repr(selector)))\n                return\n            charselect = charselect.groupdict()\n            charselect[\'*\'] = charselect[\'charlen\']\n            del charselect[\'charlen\']\n            if charselect[\'lenkind\']:\n                lenkind = lenkindpattern.match(\n                    markoutercomma(charselect[\'lenkind\']))\n                lenkind = lenkind.groupdict()\n                for lk in [\'len\', \'kind\']:\n                    if lenkind[lk + \'2\']:\n                        lenkind[lk] = lenkind[lk + \'2\']\n                    charselect[lk] = lenkind[lk]\n                    del lenkind[lk + \'2\']\n            del charselect[\'lenkind\']\n            for k in list(charselect.keys()):\n                if not charselect[k]:\n                    del charselect[k]\n            for k, i in list(charselect.items()):\n                charselect[k] = rmbadname1(i)\n        elif typespec == \'type\':\n            typename = re.match(r\'\\s*\\(\\s*(?P<name>\\w+)\\s*\\)\', selector, re.I)\n            if typename:\n                typename = typename.group(\'name\')\n            else:\n                outmess(\'cracktypespec: no typename found in %s\\n\' %\n                        (repr(typespec + selector)))\n        else:\n            outmess(\'cracktypespec: no selector used for %s\\n\' %\n                    (repr(selector)))\n    return kindselect, charselect, typename\n\n\ndef setattrspec(decl, attr, force=0):\n    if not decl:\n        decl = {}\n    if not attr:\n        return decl\n    if \'attrspec\' not in decl:\n        decl[\'attrspec\'] = [attr]\n        return decl\n    if force:\n        decl[\'attrspec\'].append(attr)\n    if attr in decl[\'attrspec\']:\n        return decl\n    if attr == \'static\' and \'automatic\' not in decl[\'attrspec\']:\n        decl[\'attrspec\'].append(attr)\n    elif attr == \'automatic\' and \'static\' not in decl[\'attrspec\']:\n        decl[\'attrspec\'].append(attr)\n    elif attr == \'public\' and \'private\' not in decl[\'attrspec\']:\n        decl[\'attrspec\'].append(attr)\n    elif attr == \'private\' and \'public\' not in decl[\'attrspec\']:\n        decl[\'attrspec\'].append(attr)\n    else:\n        decl[\'attrspec\'].append(attr)\n    return decl\n\n\ndef setkindselector(decl, sel, force=0):\n    if not decl:\n        decl = {}\n    if not sel:\n        return decl\n    if \'kindselector\' not in decl:\n        decl[\'kindselector\'] = sel\n        return decl\n    for k in list(sel.keys()):\n        if force or k not in decl[\'kindselector\']:\n            decl[\'kindselector\'][k] = sel[k]\n    return decl\n\n\ndef setcharselector(decl, sel, force=0):\n    if not decl:\n        decl = {}\n    if not sel:\n        return decl\n    if \'charselector\' not in decl:\n        decl[\'charselector\'] = sel\n        return decl\n    for k in list(sel.keys()):\n        if force or k not in decl[\'charselector\']:\n            decl[\'charselector\'][k] = sel[k]\n    return decl\n\n\ndef getblockname(block, unknown=\'unknown\'):\n    if \'name\' in block:\n        return block[\'name\']\n    return unknown\n\n\n\ndef setmesstext(block):\n    global filepositiontext\n\n    try:\n        filepositiontext = \'In: %s:%s\\n\' % (block[\'from\'], block[\'name\'])\n    except:\n        pass\n\n\ndef get_usedict(block):\n    usedict = {}\n    if \'parent_block\' in block:\n        usedict = get_usedict(block[\'parent_block\'])\n    if \'use\' in block:\n        usedict.update(block[\'use\'])\n    return usedict\n\n\ndef get_useparameters(block, param_map=None):\n    global f90modulevars\n\n    if param_map is None:\n        param_map = {}\n    usedict = get_usedict(block)\n    if not usedict:\n        return param_map\n    for usename, mapping in list(usedict.items()):\n        usename = usename.lower()\n        if usename not in f90modulevars:\n            outmess(\'get_useparameters: no module %s info used by %s\\n\' %\n                    (usename, block.get(\'name\')))\n            continue\n        mvars = f90modulevars[usename]\n        params = get_parameters(mvars)\n        if not params:\n            continue\n                if mapping:\n            errmess(\'get_useparameters: mapping for %s not impl.\' % (mapping))\n        for k, v in list(params.items()):\n            if k in param_map:\n                outmess(\'get_useparameters: overriding parameter %s with\'\n                        \' value from module %s\' % (repr(k), repr(usename)))\n            param_map[k] = v\n\n    return param_map\n\n\ndef postcrack2(block, tab=\'\', param_map=None):\n    global f90modulevars\n\n    if not f90modulevars:\n        return block\n    if isinstance(block, list):\n        ret = []\n        for g in block:\n            g = postcrack2(g, tab=tab + \'\\t\', param_map=param_map)\n            ret.append(g)\n        return ret\n    setmesstext(block)\n    outmess(\'%sBlock: %s\\n\' % (tab, block[\'name\']), 0)\n\n    if param_map is None:\n        param_map = get_useparameters(block)\n\n    if param_map is not None and \'vars\' in block:\n        vars = block[\'vars\']\n        for n in list(vars.keys()):\n            var = vars[n]\n            if \'kindselector\' in var:\n                kind = var[\'kindselector\']\n                if \'kind\' in kind:\n                    val = kind[\'kind\']\n                    if val in param_map:\n                        kind[\'kind\'] = param_map[val]\n    new_body = []\n    for b in block[\'body\']:\n        b = postcrack2(b, tab=tab + \'\\t\', param_map=param_map)\n        new_body.append(b)\n    block[\'body\'] = new_body\n\n    return block\n\n\ndef postcrack(block, args=None, tab=\'\'):\n    \n    global usermodules, onlyfunctions\n\n    if isinstance(block, list):\n        gret = []\n        uret = []\n        for g in block:\n            setmesstext(g)\n            g = postcrack(g, tab=tab + \'\\t\')\n                        if \'name\' in g and \'__user__\' in g[\'name\']:\n                uret.append(g)\n            else:\n                gret.append(g)\n        return uret + gret\n    setmesstext(block)\n    if not isinstance(block, dict) and \'block\' not in block:\n        raise Exception(\'postcrack: Expected block dictionary instead of \' +\n                        str(block))\n    if \'name\' in block and not block[\'name\'] == \'unknown_interface\':\n        outmess(\'%sBlock: %s\\n\' % (tab, block[\'name\']), 0)\n    block = analyzeargs(block)\n    block = analyzecommon(block)\n    block[\'vars\'] = analyzevars(block)\n    block[\'sortvars\'] = sortvarnames(block[\'vars\'])\n    if \'args\' in block and block[\'args\']:\n        args = block[\'args\']\n    block[\'body\'] = analyzebody(block, args, tab=tab)\n\n    userisdefined = []\n    if \'use\' in block:\n        useblock = block[\'use\']\n        for k in list(useblock.keys()):\n            if \'__user__\' in k:\n                userisdefined.append(k)\n    else:\n        useblock = {}\n    name = \'\'\n    if \'name\' in block:\n        name = block[\'name\']\n        if \'externals\' in block and block[\'externals\']:\n        interfaced = []\n        if \'interfaced\' in block:\n            interfaced = block[\'interfaced\']\n        mvars = copy.copy(block[\'vars\'])\n        if name:\n            mname = name + \'__user__routines\'\n        else:\n            mname = \'unknown__user__routines\'\n        if mname in userisdefined:\n            i = 1\n            while \'%s_%i\' % (mname, i) in userisdefined:\n                i = i + 1\n            mname = \'%s_%i\' % (mname, i)\n        interface = {\'block\': \'interface\', \'body\': [],\n                     \'vars\': {}, \'name\': name + \'_user_interface\'}\n        for e in block[\'externals\']:\n            if e in interfaced:\n                edef = []\n                j = -1\n                for b in block[\'body\']:\n                    j = j + 1\n                    if b[\'block\'] == \'interface\':\n                        i = -1\n                        for bb in b[\'body\']:\n                            i = i + 1\n                            if \'name\' in bb and bb[\'name\'] == e:\n                                edef = copy.copy(bb)\n                                del b[\'body\'][i]\n                                break\n                        if edef:\n                            if not b[\'body\']:\n                                del block[\'body\'][j]\n                            del interfaced[interfaced.index(e)]\n                            break\n                interface[\'body\'].append(edef)\n            else:\n                if e in mvars and not isexternal(mvars[e]):\n                    interface[\'vars\'][e] = mvars[e]\n        if interface[\'vars\'] or interface[\'body\']:\n            block[\'interfaced\'] = interfaced\n            mblock = {\'block\': \'python module\', \'body\': [\n                interface], \'vars\': {}, \'name\': mname, \'interfaced\': block[\'externals\']}\n            useblock[mname] = {}\n            usermodules.append(mblock)\n    if useblock:\n        block[\'use\'] = useblock\n    return block\n\n\ndef sortvarnames(vars):\n    indep = []\n    dep = []\n    for v in list(vars.keys()):\n        if \'depend\' in vars[v] and vars[v][\'depend\']:\n            dep.append(v)\n        else:\n            indep.append(v)\n    n = len(dep)\n    i = 0\n    while dep:          v = dep[0]\n        fl = 0\n        for w in dep[1:]:\n            if w in vars[v][\'depend\']:\n                fl = 1\n                break\n        if fl:\n            dep = dep[1:] + [v]\n            i = i + 1\n            if i > n:\n                errmess(\'sortvarnames: failed to compute dependencies because\'\n                        \' of cyclic dependencies between \'\n                        + \', \'.join(dep) + \'\\n\')\n                indep = indep + dep\n                break\n        else:\n            indep.append(v)\n            dep = dep[1:]\n            n = len(dep)\n            i = 0\n    return indep\n\n\ndef analyzecommon(block):\n    if not hascommon(block):\n        return block\n    commonvars = []\n    for k in list(block[\'common\'].keys()):\n        comvars = []\n        for e in block[\'common\'][k]:\n            m = re.match(\n                r\'\\A\\s*\\b(?P<name>.*?)\\b\\s*(\\((?P<dims>.*?)\\)|)\\s*\\Z\', e, re.I)\n            if m:\n                dims = []\n                if m.group(\'dims\'):\n                    dims = [x.strip()\n                            for x in markoutercomma(m.group(\'dims\')).split(\'@,@\')]\n                n = m.group(\'name\').strip()\n                if n in block[\'vars\']:\n                    if \'attrspec\' in block[\'vars\'][n]:\n                        block[\'vars\'][n][\'attrspec\'].append(\n                            \'dimension(%s)\' % (\',\'.join(dims)))\n                    else:\n                        block[\'vars\'][n][\'attrspec\'] = [\n                            \'dimension(%s)\' % (\',\'.join(dims))]\n                else:\n                    if dims:\n                        block[\'vars\'][n] = {\n                            \'attrspec\': [\'dimension(%s)\' % (\',\'.join(dims))]}\n                    else:\n                        block[\'vars\'][n] = {}\n                if n not in commonvars:\n                    commonvars.append(n)\n            else:\n                n = e\n                errmess(\n                    \'analyzecommon: failed to extract "<name>[(<dims>)]" from "%s" in common /%s/.\\n\' % (e, k))\n            comvars.append(n)\n        block[\'common\'][k] = comvars\n    if \'commonvars\' not in block:\n        block[\'commonvars\'] = commonvars\n    else:\n        block[\'commonvars\'] = block[\'commonvars\'] + commonvars\n    return block\n\n\ndef analyzebody(block, args, tab=\'\'):\n    global usermodules, skipfuncs, onlyfuncs, f90modulevars\n\n    setmesstext(block)\n    body = []\n    for b in block[\'body\']:\n        b[\'parent_block\'] = block\n        if b[\'block\'] in [\'function\', \'subroutine\']:\n            if args is not None and b[\'name\'] not in args:\n                continue\n            else:\n                as_ = b[\'args\']\n            if b[\'name\'] in skipfuncs:\n                continue\n            if onlyfuncs and b[\'name\'] not in onlyfuncs:\n                continue\n            b[\'saved_interface\'] = crack2fortrangen(\n                b, \'\\n\' + \' \' * 6, as_interface=True)\n\n        else:\n            as_ = args\n        b = postcrack(b, as_, tab=tab + \'\\t\')\n        if b[\'block\'] == \'interface\' and not b[\'body\']:\n            if \'f2pyenhancements\' not in b:\n                continue\n        if b[\'block\'].replace(\' \', \'\') == \'pythonmodule\':\n            usermodules.append(b)\n        else:\n            if b[\'block\'] == \'module\':\n                f90modulevars[b[\'name\']] = b[\'vars\']\n            body.append(b)\n    return body\n\n\ndef buildimplicitrules(block):\n    setmesstext(block)\n    implicitrules = defaultimplicitrules\n    attrrules = {}\n    if \'implicit\' in block:\n        if block[\'implicit\'] is None:\n            implicitrules = None\n            if verbose > 1:\n                outmess(\n                    \'buildimplicitrules: no implicit rules for routine %s.\\n\' % repr(block[\'name\']))\n        else:\n            for k in list(block[\'implicit\'].keys()):\n                if block[\'implicit\'][k].get(\'typespec\') not in [\'static\', \'automatic\']:\n                    implicitrules[k] = block[\'implicit\'][k]\n                else:\n                    attrrules[k] = block[\'implicit\'][k][\'typespec\']\n    return implicitrules, attrrules\n\n\ndef myeval(e, g=None, l=None):\n    r = eval(e, g, l)\n    if type(r) in [type(0), type(0.0)]:\n        return r\n    raise ValueError(\'r=%r\' % (r))\n\ngetlincoef_re_1 = re.compile(r\'\\A\\b\\w+\\b\\Z\', re.I)\n\n\ndef getlincoef(e, xset):      try:\n        c = int(myeval(e, {}, {}))\n        return 0, c, None\n    except:\n        pass\n    if getlincoef_re_1.match(e):\n        return 1, 0, e\n    len_e = len(e)\n    for x in xset:\n        if len(x) > len_e:\n            continue\n        if re.search(r\'\\w\\s*\\([^)]*\\b\' + x + r\'\\b\', e):\n                        continue\n        re_1 = re.compile(r\'(?P<before>.*?)\\b\' + x + r\'\\b(?P<after>.*)\', re.I)\n        m = re_1.match(e)\n        if m:\n            try:\n                m1 = re_1.match(e)\n                while m1:\n                    ee = \'%s(%s)%s\' % (\n                        m1.group(\'before\'), 0, m1.group(\'after\'))\n                    m1 = re_1.match(ee)\n                b = myeval(ee, {}, {})\n                m1 = re_1.match(e)\n                while m1:\n                    ee = \'%s(%s)%s\' % (\n                        m1.group(\'before\'), 1, m1.group(\'after\'))\n                    m1 = re_1.match(ee)\n                a = myeval(ee, {}, {}) - b\n                m1 = re_1.match(e)\n                while m1:\n                    ee = \'%s(%s)%s\' % (\n                        m1.group(\'before\'), 0.5, m1.group(\'after\'))\n                    m1 = re_1.match(ee)\n                c = myeval(ee, {}, {})\n                                m1 = re_1.match(e)\n                while m1:\n                    ee = \'%s(%s)%s\' % (\n                        m1.group(\'before\'), 1.5, m1.group(\'after\'))\n                    m1 = re_1.match(ee)\n                c2 = myeval(ee, {}, {})\n                if (a * 0.5 + b == c and a * 1.5 + b == c2):\n                    return a, b, x\n            except:\n                pass\n            break\n    return None, None, None\n\n_varname_match = re.compile(r\'\\A[a-z]\\w*\\Z\').match\n\n\ndef getarrlen(dl, args, star=\'*\'):\n    edl = []\n    try:\n        edl.append(myeval(dl[0], {}, {}))\n    except:\n        edl.append(dl[0])\n    try:\n        edl.append(myeval(dl[1], {}, {}))\n    except:\n        edl.append(dl[1])\n    if isinstance(edl[0], int):\n        p1 = 1 - edl[0]\n        if p1 == 0:\n            d = str(dl[1])\n        elif p1 < 0:\n            d = \'%s-%s\' % (dl[1], -p1)\n        else:\n            d = \'%s+%s\' % (dl[1], p1)\n    elif isinstance(edl[1], int):\n        p1 = 1 + edl[1]\n        if p1 == 0:\n            d = \'-(%s)\' % (dl[0])\n        else:\n            d = \'%s-(%s)\' % (p1, dl[0])\n    else:\n        d = \'%s-(%s)+1\' % (dl[1], dl[0])\n    try:\n        return repr(myeval(d, {}, {})), None, None\n    except:\n        pass\n    d1, d2 = getlincoef(dl[0], args), getlincoef(dl[1], args)\n    if None not in [d1[0], d2[0]]:\n        if (d1[0], d2[0]) == (0, 0):\n            return repr(d2[1] - d1[1] + 1), None, None\n        b = d2[1] - d1[1] + 1\n        d1 = (d1[0], 0, d1[2])\n        d2 = (d2[0], b, d2[2])\n        if d1[0] == 0 and d2[2] in args:\n            if b < 0:\n                return \'%s * %s - %s\' % (d2[0], d2[2], -b), d2[2], \'+%s)/(%s)\' % (-b, d2[0])\n            elif b:\n                return \'%s * %s + %s\' % (d2[0], d2[2], b), d2[2], \'-%s)/(%s)\' % (b, d2[0])\n            else:\n                return \'%s * %s\' % (d2[0], d2[2]), d2[2], \')/(%s)\' % (d2[0])\n        if d2[0] == 0 and d1[2] in args:\n\n            if b < 0:\n                return \'%s * %s - %s\' % (-d1[0], d1[2], -b), d1[2], \'+%s)/(%s)\' % (-b, -d1[0])\n            elif b:\n                return \'%s * %s + %s\' % (-d1[0], d1[2], b), d1[2], \'-%s)/(%s)\' % (b, -d1[0])\n            else:\n                return \'%s * %s\' % (-d1[0], d1[2]), d1[2], \')/(%s)\' % (-d1[0])\n        if d1[2] == d2[2] and d1[2] in args:\n            a = d2[0] - d1[0]\n            if not a:\n                return repr(b), None, None\n            if b < 0:\n                return \'%s * %s - %s\' % (a, d1[2], -b), d2[2], \'+%s)/(%s)\' % (-b, a)\n            elif b:\n                return \'%s * %s + %s\' % (a, d1[2], b), d2[2], \'-%s)/(%s)\' % (b, a)\n            else:\n                return \'%s * %s\' % (a, d1[2]), d2[2], \')/(%s)\' % (a)\n        if d1[0] == d2[0] == 1:\n            c = str(d1[2])\n            if c not in args:\n                if _varname_match(c):\n                    outmess(\'\\tgetarrlen:variable "%s" undefined\\n\' % (c))\n                c = \'(%s)\' % c\n            if b == 0:\n                d = \'%s-%s\' % (d2[2], c)\n            elif b < 0:\n                d = \'%s-%s-%s\' % (d2[2], c, -b)\n            else:\n                d = \'%s-%s+%s\' % (d2[2], c, b)\n        elif d1[0] == 0:\n            c2 = str(d2[2])\n            if c2 not in args:\n                if _varname_match(c2):\n                    outmess(\'\\tgetarrlen:variable "%s" undefined\\n\' % (c2))\n                c2 = \'(%s)\' % c2\n            if d2[0] == 1:\n                pass\n            elif d2[0] == -1:\n                c2 = \'-%s\' % c2\n            else:\n                c2 = \'%s*%s\' % (d2[0], c2)\n\n            if b == 0:\n                d = c2\n            elif b < 0:\n                d = \'%s-%s\' % (c2, -b)\n            else:\n                d = \'%s+%s\' % (c2, b)\n        elif d2[0] == 0:\n            c1 = str(d1[2])\n            if c1 not in args:\n                if _varname_match(c1):\n                    outmess(\'\\tgetarrlen:variable "%s" undefined\\n\' % (c1))\n                c1 = \'(%s)\' % c1\n            if d1[0] == 1:\n                c1 = \'-%s\' % c1\n            elif d1[0] == -1:\n                c1 = \'+%s\' % c1\n            elif d1[0] < 0:\n                c1 = \'+%s*%s\' % (-d1[0], c1)\n            else:\n                c1 = \'-%s*%s\' % (d1[0], c1)\n\n            if b == 0:\n                d = c1\n            elif b < 0:\n                d = \'%s-%s\' % (c1, -b)\n            else:\n                d = \'%s+%s\' % (c1, b)\n        else:\n            c1 = str(d1[2])\n            if c1 not in args:\n                if _varname_match(c1):\n                    outmess(\'\\tgetarrlen:variable "%s" undefined\\n\' % (c1))\n                c1 = \'(%s)\' % c1\n            if d1[0] == 1:\n                c1 = \'-%s\' % c1\n            elif d1[0] == -1:\n                c1 = \'+%s\' % c1\n            elif d1[0] < 0:\n                c1 = \'+%s*%s\' % (-d1[0], c1)\n            else:\n                c1 = \'-%s*%s\' % (d1[0], c1)\n\n            c2 = str(d2[2])\n            if c2 not in args:\n                if _varname_match(c2):\n                    outmess(\'\\tgetarrlen:variable "%s" undefined\\n\' % (c2))\n                c2 = \'(%s)\' % c2\n            if d2[0] == 1:\n                pass\n            elif d2[0] == -1:\n                c2 = \'-%s\' % c2\n            else:\n                c2 = \'%s*%s\' % (d2[0], c2)\n\n            if b == 0:\n                d = \'%s%s\' % (c2, c1)\n            elif b < 0:\n                d = \'%s%s-%s\' % (c2, c1, -b)\n            else:\n                d = \'%s%s+%s\' % (c2, c1, b)\n    return d, None, None\n\nword_pattern = re.compile(r\'\\b[a-z][\\w$]*\\b\', re.I)\n\n\ndef _get_depend_dict(name, vars, deps):\n    if name in vars:\n        words = vars[name].get(\'depend\', [])\n\n        if \'=\' in vars[name] and not isstring(vars[name]):\n            for word in word_pattern.findall(vars[name][\'=\']):\n                if word not in words and word in vars:\n                    words.append(word)\n        for word in words[:]:\n            for w in deps.get(word, []) \\\n                    or _get_depend_dict(word, vars, deps):\n                if w not in words:\n                    words.append(w)\n    else:\n        outmess(\'_get_depend_dict: no dependence info for %s\\n\' % (repr(name)))\n        words = []\n    deps[name] = words\n    return words\n\n\ndef _calc_depend_dict(vars):\n    names = list(vars.keys())\n    depend_dict = {}\n    for n in names:\n        _get_depend_dict(n, vars, depend_dict)\n    return depend_dict\n\n\ndef get_sorted_names(vars):\n    \n    depend_dict = _calc_depend_dict(vars)\n    names = []\n    for name in list(depend_dict.keys()):\n        if not depend_dict[name]:\n            names.append(name)\n            del depend_dict[name]\n    while depend_dict:\n        for name, lst in list(depend_dict.items()):\n            new_lst = [n for n in lst if n in depend_dict]\n            if not new_lst:\n                names.append(name)\n                del depend_dict[name]\n            else:\n                depend_dict[name] = new_lst\n    return [name for name in names if name in vars]\n\n\ndef _kind_func(string):\n        if string[0] in "\'\\"":\n        string = string[1:-1]\n    if real16pattern.match(string):\n        return 8\n    elif real8pattern.match(string):\n        return 4\n    return \'kind(\' + string + \')\'\n\n\ndef _selected_int_kind_func(r):\n        m = 10 ** r\n    if m <= 2 ** 8:\n        return 1\n    if m <= 2 ** 16:\n        return 2\n    if m <= 2 ** 32:\n        return 4\n    if m <= 2 ** 63:\n        return 8\n    if m <= 2 ** 128:\n        return 16\n    return -1\n\n\ndef _selected_real_kind_func(p, r=0, radix=0):\n            if p < 7:\n        return 4\n    if p < 16:\n        return 8\n    if platform.machine().lower().startswith(\'power\'):\n        if p <= 20:\n            return 16\n    else:\n        if p < 19:\n            return 10\n        elif p <= 20:\n            return 16\n    return -1\n\n\ndef get_parameters(vars, global_params={}):\n    params = copy.copy(global_params)\n    g_params = copy.copy(global_params)\n    for name, func in [(\'kind\', _kind_func),\n                       (\'selected_int_kind\', _selected_int_kind_func),\n                       (\'selected_real_kind\', _selected_real_kind_func), ]:\n        if name not in g_params:\n            g_params[name] = func\n    param_names = []\n    for n in get_sorted_names(vars):\n        if \'attrspec\' in vars[n] and \'parameter\' in vars[n][\'attrspec\']:\n            param_names.append(n)\n    kind_re = re.compile(r\'\\bkind\\s*\\(\\s*(?P<value>.*)\\s*\\)\', re.I)\n    selected_int_kind_re = re.compile(\n        r\'\\bselected_int_kind\\s*\\(\\s*(?P<value>.*)\\s*\\)\', re.I)\n    selected_kind_re = re.compile(\n        r\'\\bselected_(int|real)_kind\\s*\\(\\s*(?P<value>.*)\\s*\\)\', re.I)\n    for n in param_names:\n        if \'=\' in vars[n]:\n            v = vars[n][\'=\']\n            if islogical(vars[n]):\n                v = v.lower()\n                for repl in [\n                    (\'.false.\', \'False\'),\n                    (\'.true.\', \'True\'),\n                                    ]:\n                    v = v.replace(*repl)\n            v = kind_re.sub(r\'kind("\\1")\', v)\n            v = selected_int_kind_re.sub(r\'selected_int_kind(\\1)\', v)\n            if isinteger(vars[n]) and not selected_kind_re.match(v):\n                v = v.split(\'_\')[0]\n            if isdouble(vars[n]):\n                tt = list(v)\n                for m in real16pattern.finditer(v):\n                    tt[m.start():m.end()] = list(\n                        v[m.start():m.end()].lower().replace(\'d\', \'e\'))\n                v = \'\'.join(tt)\n            if iscomplex(vars[n]):\n                if v[0] == \'(\' and v[-1] == \')\':\n                                        l = markoutercomma(v[1:-1]).split(\'@,@\')\n            try:\n                params[n] = eval(v, g_params, params)\n            except Exception as msg:\n                params[n] = v\n                outmess(\'get_parameters: got "%s" on %s\\n\' % (msg, repr(v)))\n            if isstring(vars[n]) and isinstance(params[n], int):\n                params[n] = chr(params[n])\n            nl = n.lower()\n            if nl != n:\n                params[nl] = params[n]\n        else:\n            print(vars[n])\n            outmess(\n                \'get_parameters:parameter %s does not have value?!\\n\' % (repr(n)))\n    return params\n\n\ndef _eval_length(length, params):\n    if length in [\'(:)\', \'(*)\', \'*\']:\n        return \'(*)\'\n    return _eval_scalar(length, params)\n\n_is_kind_number = re.compile(r\'\\d+_\').match\n\n\ndef _eval_scalar(value, params):\n    if _is_kind_number(value):\n        value = value.split(\'_\')[0]\n    try:\n        value = str(eval(value, {}, params))\n    except (NameError, SyntaxError):\n        return value\n    except Exception as msg:\n        errmess(\'"%s" in evaluating %r \'\n                \'(available names: %s)\\n\'\n                % (msg, value, list(params.keys())))\n    return value\n\n\ndef analyzevars(block):\n    global f90modulevars\n\n    setmesstext(block)\n    implicitrules, attrrules = buildimplicitrules(block)\n    vars = copy.copy(block[\'vars\'])\n    if block[\'block\'] == \'function\' and block[\'name\'] not in vars:\n        vars[block[\'name\']] = {}\n    if \'\' in block[\'vars\']:\n        del vars[\'\']\n        if \'attrspec\' in block[\'vars\'][\'\']:\n            gen = block[\'vars\'][\'\'][\'attrspec\']\n            for n in list(vars.keys()):\n                for k in [\'public\', \'private\']:\n                    if k in gen:\n                        vars[n] = setattrspec(vars[n], k)\n    svars = []\n    args = block[\'args\']\n    for a in args:\n        try:\n            vars[a]\n            svars.append(a)\n        except KeyError:\n            pass\n    for n in list(vars.keys()):\n        if n not in args:\n            svars.append(n)\n\n    params = get_parameters(vars, get_useparameters(block))\n\n    dep_matches = {}\n    name_match = re.compile(r\'\\w[\\w\\d_$]*\').match\n    for v in list(vars.keys()):\n        m = name_match(v)\n        if m:\n            n = v[m.start():m.end()]\n            try:\n                dep_matches[n]\n            except KeyError:\n                dep_matches[n] = re.compile(r\'.*\\b%s\\b\' % (v), re.I).match\n    for n in svars:\n        if n[0] in list(attrrules.keys()):\n            vars[n] = setattrspec(vars[n], attrrules[n[0]])\n        if \'typespec\' not in vars[n]:\n            if not(\'attrspec\' in vars[n] and \'external\' in vars[n][\'attrspec\']):\n                if implicitrules:\n                    ln0 = n[0].lower()\n                    for k in list(implicitrules[ln0].keys()):\n                        if k == \'typespec\' and implicitrules[ln0][k] == \'undefined\':\n                            continue\n                        if k not in vars[n]:\n                            vars[n][k] = implicitrules[ln0][k]\n                        elif k == \'attrspec\':\n                            for l in implicitrules[ln0][k]:\n                                vars[n] = setattrspec(vars[n], l)\n                elif n in block[\'args\']:\n                    outmess(\'analyzevars: typespec of variable %s is not defined in routine %s.\\n\' % (\n                        repr(n), block[\'name\']))\n\n        if \'charselector\' in vars[n]:\n            if \'len\' in vars[n][\'charselector\']:\n                l = vars[n][\'charselector\'][\'len\']\n                try:\n                    l = str(eval(l, {}, params))\n                except:\n                    pass\n                vars[n][\'charselector\'][\'len\'] = l\n\n        if \'kindselector\' in vars[n]:\n            if \'kind\' in vars[n][\'kindselector\']:\n                l = vars[n][\'kindselector\'][\'kind\']\n                try:\n                    l = str(eval(l, {}, params))\n                except:\n                    pass\n                vars[n][\'kindselector\'][\'kind\'] = l\n\n        savelindims = {}\n        if \'attrspec\' in vars[n]:\n            attr = vars[n][\'attrspec\']\n            attr.reverse()\n            vars[n][\'attrspec\'] = []\n            dim, intent, depend, check, note = None, None, None, None, None\n            for a in attr:\n                if a[:9] == \'dimension\':\n                    dim = (a[9:].strip())[1:-1]\n                elif a[:6] == \'intent\':\n                    intent = (a[6:].strip())[1:-1]\n                elif a[:6] == \'depend\':\n                    depend = (a[6:].strip())[1:-1]\n                elif a[:5] == \'check\':\n                    check = (a[5:].strip())[1:-1]\n                elif a[:4] == \'note\':\n                    note = (a[4:].strip())[1:-1]\n                else:\n                    vars[n] = setattrspec(vars[n], a)\n                if intent:\n                    if \'intent\' not in vars[n]:\n                        vars[n][\'intent\'] = []\n                    for c in [x.strip() for x in markoutercomma(intent).split(\'@,@\')]:\n                                                tmp = c.replace(\' \', \'\')\n                        if tmp not in vars[n][\'intent\']:\n                            vars[n][\'intent\'].append(tmp)\n                    intent = None\n                if note:\n                    note = note.replace(\'\\\\n\\\\n\', \'\\n\\n\')\n                    note = note.replace(\'\\\\n \', \'\\n\')\n                    if \'note\' not in vars[n]:\n                        vars[n][\'note\'] = [note]\n                    else:\n                        vars[n][\'note\'].append(note)\n                    note = None\n                if depend is not None:\n                    if \'depend\' not in vars[n]:\n                        vars[n][\'depend\'] = []\n                    for c in rmbadname([x.strip() for x in markoutercomma(depend).split(\'@,@\')]):\n                        if c not in vars[n][\'depend\']:\n                            vars[n][\'depend\'].append(c)\n                    depend = None\n                if check is not None:\n                    if \'check\' not in vars[n]:\n                        vars[n][\'check\'] = []\n                    for c in [x.strip() for x in markoutercomma(check).split(\'@,@\')]:\n                        if c not in vars[n][\'check\']:\n                            vars[n][\'check\'].append(c)\n                    check = None\n            if dim and \'dimension\' not in vars[n]:\n                vars[n][\'dimension\'] = []\n                for d in rmbadname([x.strip() for x in markoutercomma(dim).split(\'@,@\')]):\n                    star = \'*\'\n                    if d == \':\':\n                        star = \':\'\n                    if d in params:\n                        d = str(params[d])\n                    for p in list(params.keys()):\n                        re_1 = re.compile(r\'(?P<before>.*?)\\b\' + p + r\'\\b(?P<after>.*)\', re.I)\n                        m = re_1.match(d)\n                        while m:\n                            d = m.group(\'before\') + \\\n                                str(params[p]) + m.group(\'after\')\n                            m = re_1.match(d)\n                    if d == star:\n                        dl = [star]\n                    else:\n                        dl = markoutercomma(d, \':\').split(\'@:@\')\n                    if len(dl) == 2 and \'*\' in dl:                          dl = [\'*\']\n                        d = \'*\'\n                    if len(dl) == 1 and not dl[0] == star:\n                        dl = [\'1\', dl[0]]\n                    if len(dl) == 2:\n                        d, v, di = getarrlen(dl, list(block[\'vars\'].keys()))\n                        if d[:4] == \'1 * \':\n                            d = d[4:]\n                        if di and di[-4:] == \'/(1)\':\n                            di = di[:-4]\n                        if v:\n                            savelindims[d] = v, di\n                    vars[n][\'dimension\'].append(d)\n        if \'dimension\' in vars[n]:\n            if isintent_c(vars[n]):\n                shape_macro = \'shape\'\n            else:\n                shape_macro = \'shape\'              if isstringarray(vars[n]):\n                if \'charselector\' in vars[n]:\n                    d = vars[n][\'charselector\']\n                    if \'*\' in d:\n                        d = d[\'*\']\n                        errmess(\'analyzevars: character array "character*%s %s(%s)" is considered as "character %s(%s)"; "intent(c)" is forced.\\n\'\n                                % (d, n,\n                                   \',\'.join(vars[n][\'dimension\']),\n                                   n, \',\'.join(vars[n][\'dimension\'] + [d])))\n                        vars[n][\'dimension\'].append(d)\n                        del vars[n][\'charselector\']\n                        if \'intent\' not in vars[n]:\n                            vars[n][\'intent\'] = []\n                        if \'c\' not in vars[n][\'intent\']:\n                            vars[n][\'intent\'].append(\'c\')\n                    else:\n                        errmess(\n                            "analyzevars: charselector=%r unhandled." % (d))\n        if \'check\' not in vars[n] and \'args\' in block and n in block[\'args\']:\n            flag = \'depend\' not in vars[n]\n            if flag:\n                vars[n][\'depend\'] = []\n            vars[n][\'check\'] = []\n            if \'dimension\' in vars[n]:\n                                i = -1\n                ni = len(vars[n][\'dimension\'])\n                for d in vars[n][\'dimension\']:\n                    ddeps = []                      ad = \'\'\n                    pd = \'\'\n                    if d not in vars:\n                        if d in savelindims:\n                            pd, ad = \'(\', savelindims[d][1]\n                            d = savelindims[d][0]\n                        else:\n                            for r in block[\'args\']:\n                                if r not in vars:\n                                    continue\n                                if re.match(r\'.*?\\b\' + r + r\'\\b\', d, re.I):\n                                    ddeps.append(r)\n                    if d in vars:\n                        if \'attrspec\' in vars[d]:\n                            for aa in vars[d][\'attrspec\']:\n                                if aa[:6] == \'depend\':\n                                    ddeps += aa[6:].strip()[1:-1].split(\',\')\n                        if \'depend\' in vars[d]:\n                            ddeps = ddeps + vars[d][\'depend\']\n                    i = i + 1\n                    if d in vars and (\'depend\' not in vars[d]) \\\n                       and (\'=\' not in vars[d]) and (d not in vars[n][\'depend\']) \\\n                       and l_or(isintent_in, isintent_inout, isintent_inplace)(vars[n]):\n                        vars[d][\'depend\'] = [n]\n                        if ni > 1:\n                            vars[d][\'=\'] = \'%s%s(%s,%s)%s\' % (\n                                pd, shape_macro, n, i, ad)\n                        else:\n                            vars[d][\'=\'] = \'%slen(%s)%s\' % (pd, n, ad)\n                                                if 1 and \'check\' not in vars[d]:\n                            if ni > 1:\n                                vars[d][\'check\'] = [\'%s%s(%s,%i)%s==%s\'\n                                                    % (pd, shape_macro, n, i, ad, d)]\n                            else:\n                                vars[d][\'check\'] = [\n                                    \'%slen(%s)%s>=%s\' % (pd, n, ad, d)]\n                        if \'attrspec\' not in vars[d]:\n                            vars[d][\'attrspec\'] = [\'optional\']\n                        if (\'optional\' not in vars[d][\'attrspec\']) and\\\n                           (\'required\' not in vars[d][\'attrspec\']):\n                            vars[d][\'attrspec\'].append(\'optional\')\n                    elif d not in [\'*\', \':\']:\n                                                if flag:\n                            if d in vars:\n                                if n not in ddeps:\n                                    vars[n][\'depend\'].append(d)\n                            else:\n                                vars[n][\'depend\'] = vars[n][\'depend\'] + ddeps\n            elif isstring(vars[n]):\n                length = \'1\'\n                if \'charselector\' in vars[n]:\n                    if \'*\' in vars[n][\'charselector\']:\n                        length = _eval_length(vars[n][\'charselector\'][\'*\'],\n                                              params)\n                        vars[n][\'charselector\'][\'*\'] = length\n                    elif \'len\' in vars[n][\'charselector\']:\n                        length = _eval_length(vars[n][\'charselector\'][\'len\'],\n                                              params)\n                        del vars[n][\'charselector\'][\'len\']\n                        vars[n][\'charselector\'][\'*\'] = length\n\n            if not vars[n][\'check\']:\n                del vars[n][\'check\']\n            if flag and not vars[n][\'depend\']:\n                del vars[n][\'depend\']\n        if \'=\' in vars[n]:\n            if \'attrspec\' not in vars[n]:\n                vars[n][\'attrspec\'] = []\n            if (\'optional\' not in vars[n][\'attrspec\']) and \\\n               (\'required\' not in vars[n][\'attrspec\']):\n                vars[n][\'attrspec\'].append(\'optional\')\n            if \'depend\' not in vars[n]:\n                vars[n][\'depend\'] = []\n                for v, m in list(dep_matches.items()):\n                    if m(vars[n][\'=\']):\n                        vars[n][\'depend\'].append(v)\n                if not vars[n][\'depend\']:\n                    del vars[n][\'depend\']\n            if isscalar(vars[n]):\n                vars[n][\'=\'] = _eval_scalar(vars[n][\'=\'], params)\n\n    for n in list(vars.keys()):\n        if n == block[\'name\']:              if \'note\' in vars[n]:\n                block[\'note\'] = vars[n][\'note\']\n            if block[\'block\'] == \'function\':\n                if \'result\' in block and block[\'result\'] in vars:\n                    vars[n] = appenddecl(vars[n], vars[block[\'result\']])\n                if \'prefix\' in block:\n                    pr = block[\'prefix\']\n                    ispure = 0\n                    isrec = 1\n                    pr1 = pr.replace(\'pure\', \'\')\n                    ispure = (not pr == pr1)\n                    pr = pr1.replace(\'recursive\', \'\')\n                    isrec = (not pr == pr1)\n                    m = typespattern[0].match(pr)\n                    if m:\n                        typespec, selector, attr, edecl = cracktypespec0(\n                            m.group(\'this\'), m.group(\'after\'))\n                        kindselect, charselect, typename = cracktypespec(\n                            typespec, selector)\n                        vars[n][\'typespec\'] = typespec\n                        if kindselect:\n                            if \'kind\' in kindselect:\n                                try:\n                                    kindselect[\'kind\'] = eval(\n                                        kindselect[\'kind\'], {}, params)\n                                except:\n                                    pass\n                            vars[n][\'kindselector\'] = kindselect\n                        if charselect:\n                            vars[n][\'charselector\'] = charselect\n                        if typename:\n                            vars[n][\'typename\'] = typename\n                        if ispure:\n                            vars[n] = setattrspec(vars[n], \'pure\')\n                        if isrec:\n                            vars[n] = setattrspec(vars[n], \'recursive\')\n                    else:\n                        outmess(\n                            \'analyzevars: prefix (%s) were not used\\n\' % repr(block[\'prefix\']))\n    if not block[\'block\'] in [\'module\', \'pythonmodule\', \'python module\', \'block data\']:\n        if \'commonvars\' in block:\n            neededvars = copy.copy(block[\'args\'] + block[\'commonvars\'])\n        else:\n            neededvars = copy.copy(block[\'args\'])\n        for n in list(vars.keys()):\n            if l_or(isintent_callback, isintent_aux)(vars[n]):\n                neededvars.append(n)\n        if \'entry\' in block:\n            neededvars.extend(list(block[\'entry\'].keys()))\n            for k in list(block[\'entry\'].keys()):\n                for n in block[\'entry\'][k]:\n                    if n not in neededvars:\n                        neededvars.append(n)\n        if block[\'block\'] == \'function\':\n            if \'result\' in block:\n                neededvars.append(block[\'result\'])\n            else:\n                neededvars.append(block[\'name\'])\n        if block[\'block\'] in [\'subroutine\', \'function\']:\n            name = block[\'name\']\n            if name in vars and \'intent\' in vars[name]:\n                block[\'intent\'] = vars[name][\'intent\']\n        if block[\'block\'] == \'type\':\n            neededvars.extend(list(vars.keys()))\n        for n in list(vars.keys()):\n            if n not in neededvars:\n                del vars[n]\n    return vars\n\nanalyzeargs_re_1 = re.compile(r\'\\A[a-z]+[\\w$]*\\Z\', re.I)\n\n\ndef expr2name(a, block, args=[]):\n    orig_a = a\n    a_is_expr = not analyzeargs_re_1.match(a)\n    if a_is_expr:          implicitrules, attrrules = buildimplicitrules(block)\n        at = determineexprtype(a, block[\'vars\'], implicitrules)\n        na = \'e_\'\n        for c in a:\n            c = c.lower()\n            if c not in string.ascii_lowercase + string.digits:\n                c = \'_\'\n            na = na + c\n        if na[-1] == \'_\':\n            na = na + \'e\'\n        else:\n            na = na + \'_e\'\n        a = na\n        while a in block[\'vars\'] or a in block[\'args\']:\n            a = a + \'r\'\n    if a in args:\n        k = 1\n        while a + str(k) in args:\n            k = k + 1\n        a = a + str(k)\n    if a_is_expr:\n        block[\'vars\'][a] = at\n    else:\n        if a not in block[\'vars\']:\n            if orig_a in block[\'vars\']:\n                block[\'vars\'][a] = block[\'vars\'][orig_a]\n            else:\n                block[\'vars\'][a] = {}\n        if \'externals\' in block and orig_a in block[\'externals\'] + block[\'interfaced\']:\n            block[\'vars\'][a] = setattrspec(block[\'vars\'][a], \'external\')\n    return a\n\n\ndef analyzeargs(block):\n    setmesstext(block)\n    implicitrules, attrrules = buildimplicitrules(block)\n    if \'args\' not in block:\n        block[\'args\'] = []\n    args = []\n    for a in block[\'args\']:\n        a = expr2name(a, block, args)\n        args.append(a)\n    block[\'args\'] = args\n    if \'entry\' in block:\n        for k, args1 in list(block[\'entry\'].items()):\n            for a in args1:\n                if a not in block[\'vars\']:\n                    block[\'vars\'][a] = {}\n\n    for b in block[\'body\']:\n        if b[\'name\'] in args:\n            if \'externals\' not in block:\n                block[\'externals\'] = []\n            if b[\'name\'] not in block[\'externals\']:\n                block[\'externals\'].append(b[\'name\'])\n    if \'result\' in block and block[\'result\'] not in block[\'vars\']:\n        block[\'vars\'][block[\'result\']] = {}\n    return block\n\ndetermineexprtype_re_1 = re.compile(r\'\\A\\(.+?[,].+?\\)\\Z\', re.I)\ndetermineexprtype_re_2 = re.compile(r\'\\A[+-]?\\d+(_(P<name>[\\w]+)|)\\Z\', re.I)\ndetermineexprtype_re_3 = re.compile(\n    r\'\\A[+-]?[\\d.]+[\\d+-de.]*(_(P<name>[\\w]+)|)\\Z\', re.I)\ndetermineexprtype_re_4 = re.compile(r\'\\A\\(.*\\)\\Z\', re.I)\ndetermineexprtype_re_5 = re.compile(r\'\\A(?P<name>\\w+)\\s*\\(.*?\\)\\s*\\Z\', re.I)\n\n\ndef _ensure_exprdict(r):\n    if isinstance(r, int):\n        return {\'typespec\': \'integer\'}\n    if isinstance(r, float):\n        return {\'typespec\': \'real\'}\n    if isinstance(r, complex):\n        return {\'typespec\': \'complex\'}\n    if isinstance(r, dict):\n        return r\n    raise AssertionError(repr(r))\n\n\ndef determineexprtype(expr, vars, rules={}):\n    if expr in vars:\n        return _ensure_exprdict(vars[expr])\n    expr = expr.strip()\n    if determineexprtype_re_1.match(expr):\n        return {\'typespec\': \'complex\'}\n    m = determineexprtype_re_2.match(expr)\n    if m:\n        if \'name\' in m.groupdict() and m.group(\'name\'):\n            outmess(\n                \'determineexprtype: selected kind types not supported (%s)\\n\' % repr(expr))\n        return {\'typespec\': \'integer\'}\n    m = determineexprtype_re_3.match(expr)\n    if m:\n        if \'name\' in m.groupdict() and m.group(\'name\'):\n            outmess(\n                \'determineexprtype: selected kind types not supported (%s)\\n\' % repr(expr))\n        return {\'typespec\': \'real\'}\n    for op in [\'+\', \'-\', \'*\', \'/\']:\n        for e in [x.strip() for x in markoutercomma(expr, comma=op).split(\'@\' + op + \'@\')]:\n            if e in vars:\n                return _ensure_exprdict(vars[e])\n    t = {}\n    if determineexprtype_re_4.match(expr):          t = determineexprtype(expr[1:-1], vars, rules)\n    else:\n        m = determineexprtype_re_5.match(expr)\n        if m:\n            rn = m.group(\'name\')\n            t = determineexprtype(m.group(\'name\'), vars, rules)\n            if t and \'attrspec\' in t:\n                del t[\'attrspec\']\n            if not t:\n                if rn[0] in rules:\n                    return _ensure_exprdict(rules[rn[0]])\n    if expr[0] in \'\\\'"\':\n        return {\'typespec\': \'character\', \'charselector\': {\'*\': \'*\'}}\n    if not t:\n        outmess(\n            \'determineexprtype: could not determine expressions (%s) type.\\n\' % (repr(expr)))\n    return t\n\n\n\ndef crack2fortrangen(block, tab=\'\\n\', as_interface=False):\n    global skipfuncs, onlyfuncs\n\n    setmesstext(block)\n    ret = \'\'\n    if isinstance(block, list):\n        for g in block:\n            if g and g[\'block\'] in [\'function\', \'subroutine\']:\n                if g[\'name\'] in skipfuncs:\n                    continue\n                if onlyfuncs and g[\'name\'] not in onlyfuncs:\n                    continue\n            ret = ret + crack2fortrangen(g, tab, as_interface=as_interface)\n        return ret\n    prefix = \'\'\n    name = \'\'\n    args = \'\'\n    blocktype = block[\'block\']\n    if blocktype == \'program\':\n        return \'\'\n    argsl = []\n    if \'name\' in block:\n        name = block[\'name\']\n    if \'args\' in block:\n        vars = block[\'vars\']\n        for a in block[\'args\']:\n            a = expr2name(a, block, argsl)\n            if not isintent_callback(vars[a]):\n                argsl.append(a)\n        if block[\'block\'] == \'function\' or argsl:\n            args = \'(%s)\' % \',\'.join(argsl)\n    f2pyenhancements = \'\'\n    if \'f2pyenhancements\' in block:\n        for k in list(block[\'f2pyenhancements\'].keys()):\n            f2pyenhancements = \'%s%s%s %s\' % (\n                f2pyenhancements, tab + tabchar, k, block[\'f2pyenhancements\'][k])\n    intent_lst = block.get(\'intent\', [])[:]\n    if blocktype == \'function\' and \'callback\' in intent_lst:\n        intent_lst.remove(\'callback\')\n    if intent_lst:\n        f2pyenhancements = \'%s%sintent(%s) %s\' %\\\n                           (f2pyenhancements, tab + tabchar,\n                            \',\'.join(intent_lst), name)\n    use = \'\'\n    if \'use\' in block:\n        use = use2fortran(block[\'use\'], tab + tabchar)\n    common = \'\'\n    if \'common\' in block:\n        common = common2fortran(block[\'common\'], tab + tabchar)\n    if name == \'unknown_interface\':\n        name = \'\'\n    result = \'\'\n    if \'result\' in block:\n        result = \' result (%s)\' % block[\'result\']\n        if block[\'result\'] not in argsl:\n            argsl.append(block[\'result\'])\n    body = crack2fortrangen(block[\'body\'], tab + tabchar)\n    vars = vars2fortran(\n        block, block[\'vars\'], argsl, tab + tabchar, as_interface=as_interface)\n    mess = \'\'\n    if \'from\' in block and not as_interface:\n        mess = \'! in %s\' % block[\'from\']\n    if \'entry\' in block:\n        entry_stmts = \'\'\n        for k, i in list(block[\'entry\'].items()):\n            entry_stmts = \'%s%sentry %s(%s)\' \\\n                          % (entry_stmts, tab + tabchar, k, \',\'.join(i))\n        body = body + entry_stmts\n    if blocktype == \'block data\' and name == \'_BLOCK_DATA_\':\n        name = \'\'\n    ret = \'%s%s%s %s%s%s %s%s%s%s%s%s%send %s %s\' % (\n        tab, prefix, blocktype, name, args, result, mess, f2pyenhancements, use, vars, common, body, tab, blocktype, name)\n    return ret\n\n\ndef common2fortran(common, tab=\'\'):\n    ret = \'\'\n    for k in list(common.keys()):\n        if k == \'_BLNK_\':\n            ret = \'%s%scommon %s\' % (ret, tab, \',\'.join(common[k]))\n        else:\n            ret = \'%s%scommon /%s/ %s\' % (ret, tab, k, \',\'.join(common[k]))\n    return ret\n\n\ndef use2fortran(use, tab=\'\'):\n    ret = \'\'\n    for m in list(use.keys()):\n        ret = \'%s%suse %s,\' % (ret, tab, m)\n        if use[m] == {}:\n            if ret and ret[-1] == \',\':\n                ret = ret[:-1]\n            continue\n        if \'only\' in use[m] and use[m][\'only\']:\n            ret = \'%s only:\' % (ret)\n        if \'map\' in use[m] and use[m][\'map\']:\n            c = \' \'\n            for k in list(use[m][\'map\'].keys()):\n                if k == use[m][\'map\'][k]:\n                    ret = \'%s%s%s\' % (ret, c, k)\n                    c = \',\'\n                else:\n                    ret = \'%s%s%s=>%s\' % (ret, c, k, use[m][\'map\'][k])\n                    c = \',\'\n        if ret and ret[-1] == \',\':\n            ret = ret[:-1]\n    return ret\n\n\ndef true_intent_list(var):\n    lst = var[\'intent\']\n    ret = []\n    for intent in lst:\n        try:\n            c = eval(\'isintent_%s(var)\' % intent)\n        except NameError:\n            c = 0\n        if c:\n            ret.append(intent)\n    return ret\n\n\ndef vars2fortran(block, vars, args, tab=\'\', as_interface=False):\n    \n    setmesstext(block)\n    ret = \'\'\n    nout = []\n    for a in args:\n        if a in block[\'vars\']:\n            nout.append(a)\n    if \'commonvars\' in block:\n        for a in block[\'commonvars\']:\n            if a in vars:\n                if a not in nout:\n                    nout.append(a)\n            else:\n                errmess(\n                    \'vars2fortran: Confused?!: "%s" is not defined in vars.\\n\' % a)\n    if \'varnames\' in block:\n        nout.extend(block[\'varnames\'])\n    if not as_interface:\n        for a in list(vars.keys()):\n            if a not in nout:\n                nout.append(a)\n    for a in nout:\n        if \'depend\' in vars[a]:\n            for d in vars[a][\'depend\']:\n                if d in vars and \'depend\' in vars[d] and a in vars[d][\'depend\']:\n                    errmess(\n                        \'vars2fortran: Warning: cross-dependence between variables "%s" and "%s"\\n\' % (a, d))\n        if \'externals\' in block and a in block[\'externals\']:\n            if isintent_callback(vars[a]):\n                ret = \'%s%sintent(callback) %s\' % (ret, tab, a)\n            ret = \'%s%sexternal %s\' % (ret, tab, a)\n            if isoptional(vars[a]):\n                ret = \'%s%soptional %s\' % (ret, tab, a)\n            if a in vars and \'typespec\' not in vars[a]:\n                continue\n            cont = 1\n            for b in block[\'body\']:\n                if a == b[\'name\'] and b[\'block\'] == \'function\':\n                    cont = 0\n                    break\n            if cont:\n                continue\n        if a not in vars:\n            show(vars)\n            outmess(\'vars2fortran: No definition for argument "%s".\\n\' % a)\n            continue\n        if a == block[\'name\'] and not block[\'block\'] == \'function\':\n            continue\n        if \'typespec\' not in vars[a]:\n            if \'attrspec\' in vars[a] and \'external\' in vars[a][\'attrspec\']:\n                if a in args:\n                    ret = \'%s%sexternal %s\' % (ret, tab, a)\n                continue\n            show(vars[a])\n            outmess(\'vars2fortran: No typespec for argument "%s".\\n\' % a)\n            continue\n        vardef = vars[a][\'typespec\']\n        if vardef == \'type\' and \'typename\' in vars[a]:\n            vardef = \'%s(%s)\' % (vardef, vars[a][\'typename\'])\n        selector = {}\n        if \'kindselector\' in vars[a]:\n            selector = vars[a][\'kindselector\']\n        elif \'charselector\' in vars[a]:\n            selector = vars[a][\'charselector\']\n        if \'*\' in selector:\n            if selector[\'*\'] in [\'*\', \':\']:\n                vardef = \'%s*(%s)\' % (vardef, selector[\'*\'])\n            else:\n                vardef = \'%s*%s\' % (vardef, selector[\'*\'])\n        else:\n            if \'len\' in selector:\n                vardef = \'%s(len=%s\' % (vardef, selector[\'len\'])\n                if \'kind\' in selector:\n                    vardef = \'%s,kind=%s)\' % (vardef, selector[\'kind\'])\n                else:\n                    vardef = \'%s)\' % (vardef)\n            elif \'kind\' in selector:\n                vardef = \'%s(kind=%s)\' % (vardef, selector[\'kind\'])\n        c = \' \'\n        if \'attrspec\' in vars[a]:\n            attr = []\n            for l in vars[a][\'attrspec\']:\n                if l not in [\'external\']:\n                    attr.append(l)\n            if attr:\n                vardef = \'%s, %s\' % (vardef, \',\'.join(attr))\n                c = \',\'\n        if \'dimension\' in vars[a]:\n            vardef = \'%s%sdimension(%s)\' % (\n                vardef, c, \',\'.join(vars[a][\'dimension\']))\n            c = \',\'\n        if \'intent\' in vars[a]:\n            lst = true_intent_list(vars[a])\n            if lst:\n                vardef = \'%s%sintent(%s)\' % (vardef, c, \',\'.join(lst))\n            c = \',\'\n        if \'check\' in vars[a]:\n            vardef = \'%s%scheck(%s)\' % (vardef, c, \',\'.join(vars[a][\'check\']))\n            c = \',\'\n        if \'depend\' in vars[a]:\n            vardef = \'%s%sdepend(%s)\' % (\n                vardef, c, \',\'.join(vars[a][\'depend\']))\n            c = \',\'\n        if \'=\' in vars[a]:\n            v = vars[a][\'=\']\n            if vars[a][\'typespec\'] in [\'complex\', \'double complex\']:\n                try:\n                    v = eval(v)\n                    v = \'(%s,%s)\' % (v.real, v.imag)\n                except:\n                    pass\n            vardef = \'%s :: %s=%s\' % (vardef, a, v)\n        else:\n            vardef = \'%s :: %s\' % (vardef, a)\n        ret = \'%s%s%s\' % (ret, tab, vardef)\n    return ret\n\n\ndef crackfortran(files):\n    global usermodules\n\n    outmess(\'Reading fortran codes...\\n\', 0)\n    readfortrancode(files, crackline)\n    outmess(\'Post-processing...\\n\', 0)\n    usermodules = []\n    postlist = postcrack(grouplist[0])\n    outmess(\'Post-processing (stage 2)...\\n\', 0)\n    postlist = postcrack2(postlist)\n    return usermodules + postlist\n\n\ndef crack2fortran(block):\n    global f2py_version\n\n    pyf = crack2fortrangen(block) + \'\\n\'\n    header = \n    footer =  % (f2py_version)\n    return header + pyf + footer\n\nif __name__ == "__main__":\n    files = []\n    funcs = []\n    f = 1\n    f2 = 0\n    f3 = 0\n    showblocklist = 0\n    for l in sys.argv[1:]:\n        if l == \'\':\n            pass\n        elif l[0] == \':\':\n            f = 0\n        elif l == \'-quiet\':\n            quiet = 1\n            verbose = 0\n        elif l == \'-verbose\':\n            verbose = 2\n            quiet = 0\n        elif l == \'-fix\':\n            if strictf77:\n                outmess(\n                    \'Use option -f90 before -fix if Fortran 90 code is in fix form.\\n\', 0)\n            skipemptyends = 1\n            sourcecodeform = \'fix\'\n        elif l == \'-skipemptyends\':\n            skipemptyends = 1\n        elif l == \'--ignore-contains\':\n            ignorecontains = 1\n        elif l == \'-f77\':\n            strictf77 = 1\n            sourcecodeform = \'fix\'\n        elif l == \'-f90\':\n            strictf77 = 0\n            sourcecodeform = \'free\'\n            skipemptyends = 1\n        elif l == \'-h\':\n            f2 = 1\n        elif l == \'-show\':\n            showblocklist = 1\n        elif l == \'-m\':\n            f3 = 1\n        elif l[0] == \'-\':\n            errmess(\'Unknown option %s\\n\' % repr(l))\n        elif f2:\n            f2 = 0\n            pyffilename = l\n        elif f3:\n            f3 = 0\n            f77modulename = l\n        elif f:\n            try:\n                open(l).close()\n                files.append(l)\n            except IOError as detail:\n                errmess(\'IOError: %s\\n\' % str(detail))\n        else:\n            funcs.append(l)\n    if not strictf77 and f77modulename and not skipemptyends:\n        outmess(, 0)\n\n    postlist = crackfortran(files, funcs)\n    if pyffilename:\n        outmess(\'Writing fortran code to file %s\\n\' % repr(pyffilename), 0)\n        pyf = crack2fortran(postlist)\n        f = open(pyffilename, \'w\')\n        f.write(pyf)\n        f.close()\n    if showblocklist:\n        show(postlist)\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'load_library\', \'ndpointer\', \'test\', \'ctypes_load_library\',\n           \'c_intp\', \'as_ctypes\', \'as_array\']\n\nimport sys, os\nfrom numpy import integer, ndarray, dtype as _dtype, deprecate, array\nfrom numpy.core.multiarray import _flagdict, flagsobj\n\ntry:\n    import ctypes\nexcept ImportError:\n    ctypes = None\n\nif ctypes is None:\n    def _dummy(*args, **kwds):\n        \n        raise ImportError("ctypes is not available.")\n    ctypes_load_library = _dummy\n    load_library = _dummy\n    as_ctypes = _dummy\n    as_array = _dummy\n    from numpy import intp as c_intp\n    _ndptr_base = object\nelse:\n    import numpy.core._internal as nic\n    c_intp = nic._getintp_ctype()\n    del nic\n    _ndptr_base = ctypes.c_void_p\n\n        def load_library(libname, loader_path):\n        \n        if ctypes.__version__ < \'1.0.1\':\n            import warnings\n            warnings.warn("All features of ctypes interface may not work " \\\n                          "with ctypes < 1.0.1")\n\n        ext = os.path.splitext(libname)[1]\n        if not ext:\n                                                from numpy.distutils.misc_util import get_shared_lib_extension\n            so_ext = get_shared_lib_extension()\n            libname_ext = [libname + so_ext]\n                                    so_ext2 = get_shared_lib_extension(is_python_ext=True)\n            if not so_ext2 == so_ext:\n                libname_ext.insert(0, libname + so_ext2)\n        else:\n            libname_ext = [libname]\n\n        loader_path = os.path.abspath(loader_path)\n        if not os.path.isdir(loader_path):\n            libdir = os.path.dirname(loader_path)\n        else:\n            libdir = loader_path\n\n        for ln in libname_ext:\n            libpath = os.path.join(libdir, ln)\n            if os.path.exists(libpath):\n                try:\n                    return ctypes.cdll[libpath]\n                except OSError:\n                                        raise\n                raise OSError("no file with expected extension")\n\n    ctypes_load_library = deprecate(load_library, \'ctypes_load_library\',\n                                    \'load_library\')\n\ndef _num_fromflags(flaglist):\n    num = 0\n    for val in flaglist:\n        num += _flagdict[val]\n    return num\n\n_flagnames = [\'C_CONTIGUOUS\', \'F_CONTIGUOUS\', \'ALIGNED\', \'WRITEABLE\',\n              \'OWNDATA\', \'UPDATEIFCOPY\']\ndef _flags_fromnum(num):\n    res = []\n    for key in _flagnames:\n        value = _flagdict[key]\n        if (num & value):\n            res.append(key)\n    return res\n\n\nclass _ndptr(_ndptr_base):\n\n    def _check_retval_(self):\n        \n        return array(self)\n\n    @property\n    def __array_interface__(self):\n        return {\'descr\': self._dtype_.descr,\n                \'__ref\': self,\n                \'strides\': None,\n                \'shape\': self._shape_,\n                \'version\': 3,\n                \'typestr\': self._dtype_.descr[0][1],\n                \'data\': (self.value, False),\n                }\n\n    @classmethod\n    def from_param(cls, obj):\n        if not isinstance(obj, ndarray):\n            raise TypeError("argument must be an ndarray")\n        if cls._dtype_ is not None \\\n               and obj.dtype != cls._dtype_:\n            raise TypeError("array must have data type %s" % cls._dtype_)\n        if cls._ndim_ is not None \\\n               and obj.ndim != cls._ndim_:\n            raise TypeError("array must have %d dimension(s)" % cls._ndim_)\n        if cls._shape_ is not None \\\n               and obj.shape != cls._shape_:\n            raise TypeError("array must have shape %s" % str(cls._shape_))\n        if cls._flags_ is not None \\\n               and ((obj.flags.num & cls._flags_) != cls._flags_):\n            raise TypeError("array must have flags %s" %\n                    _flags_fromnum(cls._flags_))\n        return obj.ctypes\n\n\n_pointer_type_cache = {}\ndef ndpointer(dtype=None, ndim=None, shape=None, flags=None):\n    \n\n    if dtype is not None:\n        dtype = _dtype(dtype)\n    num = None\n    if flags is not None:\n        if isinstance(flags, str):\n            flags = flags.split(\',\')\n        elif isinstance(flags, (int, integer)):\n            num = flags\n            flags = _flags_fromnum(num)\n        elif isinstance(flags, flagsobj):\n            num = flags.num\n            flags = _flags_fromnum(num)\n        if num is None:\n            try:\n                flags = [x.strip().upper() for x in flags]\n            except:\n                raise TypeError("invalid flags specification")\n            num = _num_fromflags(flags)\n    try:\n        return _pointer_type_cache[(dtype, ndim, shape, num)]\n    except KeyError:\n        pass\n    if dtype is None:\n        name = \'any\'\n    elif dtype.names:\n        name = str(id(dtype))\n    else:\n        name = dtype.str\n    if ndim is not None:\n        name += "_%dd" % ndim\n    if shape is not None:\n        try:\n            strshape = [str(x) for x in shape]\n        except TypeError:\n            strshape = [str(shape)]\n            shape = (shape,)\n        shape = tuple(shape)\n        name += "_"+"x".join(strshape)\n    if flags is not None:\n        name += "_"+"_".join(flags)\n    else:\n        flags = []\n    klass = type("ndpointer_%s"%name, (_ndptr,),\n                 {"_dtype_": dtype,\n                  "_shape_" : shape,\n                  "_ndim_" : ndim,\n                  "_flags_" : num})\n    _pointer_type_cache[dtype] = klass\n    return klass\n\nif ctypes is not None:\n    ct = ctypes\n        \n            _typecodes = {}\n\n    def prep_simple(simple_type, dtype):\n        \n        try: simple_type.__array_interface__\n        except AttributeError: pass\n        else: return\n\n        typestr = _dtype(dtype).str\n        _typecodes[typestr] = simple_type\n\n        def __array_interface__(self):\n            return {\'descr\': [(\'\', typestr)],\n                    \'__ref\': self,\n                    \'strides\': None,\n                    \'shape\': (),\n                    \'version\': 3,\n                    \'typestr\': typestr,\n                    \'data\': (ct.addressof(self), False),\n                    }\n\n        simple_type.__array_interface__ = property(__array_interface__)\n\n    simple_types = [\n        ((ct.c_byte, ct.c_short, ct.c_int, ct.c_long, ct.c_longlong), "i"),\n        ((ct.c_ubyte, ct.c_ushort, ct.c_uint, ct.c_ulong, ct.c_ulonglong), "u"),\n        ((ct.c_float, ct.c_double), "f"),\n    ]\n\n        for types, code in simple_types:\n        for tp in types:\n            prep_simple(tp, "%c%d" % (code, ct.sizeof(tp)))\n\n        \n    _ARRAY_TYPE = type(ct.c_int * 1)\n\n    def prep_array(array_type):\n        \n        try: array_type.__array_interface__\n        except AttributeError: pass\n        else: return\n\n        shape = []\n        ob = array_type\n        while type(ob) is _ARRAY_TYPE:\n            shape.append(ob._length_)\n            ob = ob._type_\n        shape = tuple(shape)\n        ai = ob().__array_interface__\n        descr = ai[\'descr\']\n        typestr = ai[\'typestr\']\n\n        def __array_interface__(self):\n            return {\'descr\': descr,\n                    \'__ref\': self,\n                    \'strides\': None,\n                    \'shape\': shape,\n                    \'version\': 3,\n                    \'typestr\': typestr,\n                    \'data\': (ct.addressof(self), False),\n                    }\n\n        array_type.__array_interface__ = property(__array_interface__)\n\n    def prep_pointer(pointer_obj, shape):\n        \n        try: pointer_obj.__array_interface__\n        except AttributeError: pass\n        else: return\n\n        contents = pointer_obj.contents\n        dtype = _dtype(type(contents))\n\n        inter = {\'version\': 3,\n                 \'typestr\': dtype.str,\n                 \'data\': (ct.addressof(contents), False),\n                 \'shape\': shape}\n\n        pointer_obj.__array_interface__ = inter\n\n        \n    def as_array(obj, shape=None):\n        \n        tp = type(obj)\n        try: tp.__array_interface__\n        except AttributeError:\n            if hasattr(obj, \'contents\'):\n                prep_pointer(obj, shape)\n            else:\n                prep_array(tp)\n        return array(obj, copy=False)\n\n    def as_ctypes(obj):\n        \n        ai = obj.__array_interface__\n        if ai["strides"]:\n            raise TypeError("strided arrays not supported")\n        if ai["version"] != 3:\n            raise TypeError("only __array_interface__ version 3 supported")\n        addr, readonly = ai["data"]\n        if readonly:\n            raise TypeError("readonly arrays unsupported")\n        tp = _typecodes[ai["typestr"]]\n        for dim in ai["shape"][::-1]:\n            tp = tp * dim\n        result = tp.from_address(addr)\n        result.__keep = ai\n        return result\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom os.path import dirname\n\nfrom code_generators.genapi import fullapi_hash\nfrom code_generators.numpy_api import full_api\n\nif __name__ == \'__main__\':\n    curdir = dirname(__file__)\n    print(fullapi_hash(full_api))\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport collections\n\n\ndef slow(t):\n    \n\n    t.slow = True\n    return t\n\ndef setastest(tf=True):\n    \n    def set_test(t):\n        t.__test__ = tf\n        return t\n    return set_test\n\ndef skipif(skip_condition, msg=None):\n    \n\n    def skip_decorator(f):\n                        import nose\n\n                if isinstance(skip_condition, collections.Callable):\n            skip_val = lambda: skip_condition()\n        else:\n            skip_val = lambda: skip_condition\n\n        def get_msg(func,msg=None):\n            \n            if msg is None:\n                out = \'Test skipped due to test condition\'\n            else:\n                out = msg\n\n            return "Skipping test: %s: %s" % (func.__name__, out)\n\n                        def skipper_func(*args, **kwargs):\n            \n            if skip_val():\n                raise nose.SkipTest(get_msg(f, msg))\n            else:\n                return f(*args, **kwargs)\n\n        def skipper_gen(*args, **kwargs):\n            \n            if skip_val():\n                raise nose.SkipTest(get_msg(f, msg))\n            else:\n                for x in f(*args, **kwargs):\n                    yield x\n\n                if nose.util.isgenerator(f):\n            skipper = skipper_gen\n        else:\n            skipper = skipper_func\n\n        return nose.tools.make_decorator(f)(skipper)\n\n    return skip_decorator\n\n\ndef knownfailureif(fail_condition, msg=None):\n    \n    if msg is None:\n        msg = \'Test skipped due to known failure\'\n\n        if isinstance(fail_condition, collections.Callable):\n        fail_val = lambda: fail_condition()\n    else:\n        fail_val = lambda: fail_condition\n\n    def knownfail_decorator(f):\n                        import nose\n        from .noseclasses import KnownFailureTest\n\n        def knownfailer(*args, **kwargs):\n            if fail_val():\n                raise KnownFailureTest(msg)\n            else:\n                return f(*args, **kwargs)\n        return nose.tools.make_decorator(f)(knownfailer)\n\n    return knownfail_decorator\n\ndef deprecated(conditional=True):\n    \n    def deprecate_decorator(f):\n                        import nose\n\n        def _deprecated_imp(*args, **kwargs):\n                        with warnings.catch_warnings(record=True) as l:\n                warnings.simplefilter(\'always\')\n                f(*args, **kwargs)\n                if not len(l) > 0:\n                    raise AssertionError("No warning raised when calling %s"\n                            % f.__name__)\n                if not l[0].category is DeprecationWarning:\n                    raise AssertionError("First warning for %s is not a "\n                            "DeprecationWarning( is %s)" % (f.__name__, l[0]))\n\n        if isinstance(conditional, collections.Callable):\n            cond = conditional()\n        else:\n            cond = conditional\n        if cond:\n            return nose.tools.make_decorator(f)(_deprecated_imp)\n        else:\n            return f\n    return deprecate_decorator\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nfrom .numerictypes import string_, unicode_, integer, object_, bool_, character\nfrom .numeric import ndarray, compare_chararrays\nfrom .numeric import array as narray\nfrom numpy.core.multiarray import _vec_string\nfrom numpy.compat import asbytes, long\nimport numpy\n\n__all__ = [\n    \'chararray\', \'equal\', \'not_equal\', \'greater_equal\', \'less_equal\',\n    \'greater\', \'less\', \'str_len\', \'add\', \'multiply\', \'mod\', \'capitalize\',\n    \'center\', \'count\', \'decode\', \'encode\', \'endswith\', \'expandtabs\',\n    \'find\', \'index\', \'isalnum\', \'isalpha\', \'isdigit\', \'islower\', \'isspace\',\n    \'istitle\', \'isupper\', \'join\', \'ljust\', \'lower\', \'lstrip\', \'partition\',\n    \'replace\', \'rfind\', \'rindex\', \'rjust\', \'rpartition\', \'rsplit\',\n    \'rstrip\', \'split\', \'splitlines\', \'startswith\', \'strip\', \'swapcase\',\n    \'title\', \'translate\', \'upper\', \'zfill\', \'isnumeric\', \'isdecimal\',\n    \'array\', \'asarray\'\n    ]\n\n\n_globalvar = 0\nif sys.version_info[0] >= 3:\n    _unicode = str\n    _bytes = bytes\nelse:\n    _unicode = unicode\n    _bytes = str\n_len = len\n\ndef _use_unicode(*args):\n    \n    for x in args:\n        if (isinstance(x, _unicode) or\n                issubclass(numpy.asarray(x).dtype.type, unicode_)):\n            return unicode_\n    return string_\n\ndef _to_string_or_unicode_array(result):\n    \n    return numpy.asarray(result.tolist())\n\ndef _clean_args(*args):\n    \n    newargs = []\n    for chk in args:\n        if chk is None:\n            break\n        newargs.append(chk)\n    return newargs\n\ndef _get_num_chars(a):\n    \n    if issubclass(a.dtype.type, unicode_):\n        return a.itemsize // 4\n    return a.itemsize\n\n\ndef equal(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'==\', True)\n\ndef not_equal(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'!=\', True)\n\ndef greater_equal(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'>=\', True)\n\ndef less_equal(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'<=\', True)\n\ndef greater(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'>\', True)\n\ndef less(x1, x2):\n    \n    return compare_chararrays(x1, x2, \'<\', True)\n\ndef str_len(a):\n    \n    return _vec_string(a, integer, \'__len__\')\n\ndef add(x1, x2):\n    \n    arr1 = numpy.asarray(x1)\n    arr2 = numpy.asarray(x2)\n    out_size = _get_num_chars(arr1) + _get_num_chars(arr2)\n    dtype = _use_unicode(arr1, arr2)\n    return _vec_string(arr1, (dtype, out_size), \'__add__\', (arr2,))\n\ndef multiply(a, i):\n    \n    a_arr = numpy.asarray(a)\n    i_arr = numpy.asarray(i)\n    if not issubclass(i_arr.dtype.type, integer):\n        raise ValueError("Can only multiply by integers")\n    out_size = _get_num_chars(a_arr) * max(long(i_arr.max()), 0)\n    return _vec_string(\n        a_arr, (a_arr.dtype.type, out_size), \'__mul__\', (i_arr,))\n\ndef mod(a, values):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'__mod__\', (values,)))\n\ndef capitalize(a):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'capitalize\')\n\n\ndef center(a, width, fillchar=\' \'):\n    \n    a_arr = numpy.asarray(a)\n    width_arr = numpy.asarray(width)\n    size = long(numpy.max(width_arr.flat))\n    if numpy.issubdtype(a_arr.dtype, numpy.string_):\n        fillchar = asbytes(fillchar)\n    return _vec_string(\n        a_arr, (a_arr.dtype.type, size), \'center\', (width_arr, fillchar))\n\n\ndef count(a, sub, start=0, end=None):\n    \n    return _vec_string(a, integer, \'count\', [sub, start] + _clean_args(end))\n\n\ndef decode(a, encoding=None, errors=None):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'decode\', _clean_args(encoding, errors)))\n\n\ndef encode(a, encoding=None, errors=None):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'encode\', _clean_args(encoding, errors)))\n\n\ndef endswith(a, suffix, start=0, end=None):\n    \n    return _vec_string(\n        a, bool_, \'endswith\', [suffix, start] + _clean_args(end))\n\n\ndef expandtabs(a, tabsize=8):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'expandtabs\', (tabsize,)))\n\n\ndef find(a, sub, start=0, end=None):\n    \n    return _vec_string(\n        a, integer, \'find\', [sub, start] + _clean_args(end))\n\n\ndef index(a, sub, start=0, end=None):\n    \n    return _vec_string(\n        a, integer, \'index\', [sub, start] + _clean_args(end))\n\ndef isalnum(a):\n    \n    return _vec_string(a, bool_, \'isalnum\')\n\ndef isalpha(a):\n    \n    return _vec_string(a, bool_, \'isalpha\')\n\ndef isdigit(a):\n    \n    return _vec_string(a, bool_, \'isdigit\')\n\ndef islower(a):\n    \n    return _vec_string(a, bool_, \'islower\')\n\ndef isspace(a):\n    \n    return _vec_string(a, bool_, \'isspace\')\n\ndef istitle(a):\n    \n    return _vec_string(a, bool_, \'istitle\')\n\ndef isupper(a):\n    \n    return _vec_string(a, bool_, \'isupper\')\n\ndef join(sep, seq):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(sep, object_, \'join\', (seq,)))\n\n\ndef ljust(a, width, fillchar=\' \'):\n    \n    a_arr = numpy.asarray(a)\n    width_arr = numpy.asarray(width)\n    size = long(numpy.max(width_arr.flat))\n    if numpy.issubdtype(a_arr.dtype, numpy.string_):\n        fillchar = asbytes(fillchar)\n    return _vec_string(\n        a_arr, (a_arr.dtype.type, size), \'ljust\', (width_arr, fillchar))\n\n\ndef lower(a):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'lower\')\n\n\ndef lstrip(a, chars=None):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'lstrip\', (chars,))\n\n\ndef partition(a, sep):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'partition\', (sep,)))\n\n\ndef replace(a, old, new, count=None):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(\n            a, object_, \'replace\', [old, new] + _clean_args(count)))\n\n\ndef rfind(a, sub, start=0, end=None):\n    \n    return _vec_string(\n        a, integer, \'rfind\', [sub, start] + _clean_args(end))\n\n\ndef rindex(a, sub, start=0, end=None):\n    \n    return _vec_string(\n        a, integer, \'rindex\', [sub, start] + _clean_args(end))\n\n\ndef rjust(a, width, fillchar=\' \'):\n    \n    a_arr = numpy.asarray(a)\n    width_arr = numpy.asarray(width)\n    size = long(numpy.max(width_arr.flat))\n    if numpy.issubdtype(a_arr.dtype, numpy.string_):\n        fillchar = asbytes(fillchar)\n    return _vec_string(\n        a_arr, (a_arr.dtype.type, size), \'rjust\', (width_arr, fillchar))\n\n\ndef rpartition(a, sep):\n    \n    return _to_string_or_unicode_array(\n        _vec_string(a, object_, \'rpartition\', (sep,)))\n\n\ndef rsplit(a, sep=None, maxsplit=None):\n    \n            return _vec_string(\n        a, object_, \'rsplit\', [sep] + _clean_args(maxsplit))\n\n\ndef rstrip(a, chars=None):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'rstrip\', (chars,))\n\n\ndef split(a, sep=None, maxsplit=None):\n    \n            return _vec_string(\n        a, object_, \'split\', [sep] + _clean_args(maxsplit))\n\n\ndef splitlines(a, keepends=None):\n    \n    return _vec_string(\n        a, object_, \'splitlines\', _clean_args(keepends))\n\n\ndef startswith(a, prefix, start=0, end=None):\n    \n    return _vec_string(\n        a, bool_, \'startswith\', [prefix, start] + _clean_args(end))\n\n\ndef strip(a, chars=None):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'strip\', _clean_args(chars))\n\n\ndef swapcase(a):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'swapcase\')\n\n\ndef title(a):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'title\')\n\n\ndef translate(a, table, deletechars=None):\n    \n    a_arr = numpy.asarray(a)\n    if issubclass(a_arr.dtype.type, unicode_):\n        return _vec_string(\n            a_arr, a_arr.dtype, \'translate\', (table,))\n    else:\n        return _vec_string(\n            a_arr, a_arr.dtype, \'translate\', [table] + _clean_args(deletechars))\n\n\ndef upper(a):\n    \n    a_arr = numpy.asarray(a)\n    return _vec_string(a_arr, a_arr.dtype, \'upper\')\n\n\ndef zfill(a, width):\n    \n    a_arr = numpy.asarray(a)\n    width_arr = numpy.asarray(width)\n    size = long(numpy.max(width_arr.flat))\n    return _vec_string(\n        a_arr, (a_arr.dtype.type, size), \'zfill\', (width_arr,))\n\n\ndef isnumeric(a):\n    \n    if _use_unicode(a) != unicode_:\n        raise TypeError("isnumeric is only available for Unicode strings and arrays")\n    return _vec_string(a, bool_, \'isnumeric\')\n\n\ndef isdecimal(a):\n    \n    if _use_unicode(a) != unicode_:\n        raise TypeError("isnumeric is only available for Unicode strings and arrays")\n    return _vec_string(a, bool_, \'isdecimal\')\n\n\nclass chararray(ndarray):\n    \n    def __new__(subtype, shape, itemsize=1, unicode=False, buffer=None,\n                offset=0, strides=None, order=\'C\'):\n        global _globalvar\n\n        if unicode:\n            dtype = unicode_\n        else:\n            dtype = string_\n\n                                itemsize = long(itemsize)\n\n        if sys.version_info[0] >= 3 and isinstance(buffer, _unicode):\n                        filler = buffer\n            buffer = None\n        else:\n            filler = None\n\n        _globalvar = 1\n        if buffer is None:\n            self = ndarray.__new__(subtype, shape, (dtype, itemsize),\n                                   order=order)\n        else:\n            self = ndarray.__new__(subtype, shape, (dtype, itemsize),\n                                   buffer=buffer,\n                                   offset=offset, strides=strides,\n                                   order=order)\n        if filler is not None:\n            self[...] = filler\n        _globalvar = 0\n        return self\n\n    def __array_finalize__(self, obj):\n                if not _globalvar and self.dtype.char not in \'SUbc\':\n            raise ValueError("Can only create a chararray from string data.")\n\n    def __getitem__(self, obj):\n        val = ndarray.__getitem__(self, obj)\n\n        if isinstance(val, character):\n            temp = val.rstrip()\n            if _len(temp) == 0:\n                val = \'\'\n            else:\n                val = temp\n\n        return val\n\n                \n    def __eq__(self, other):\n        \n        return equal(self, other)\n\n    def __ne__(self, other):\n        \n        return not_equal(self, other)\n\n    def __ge__(self, other):\n        \n        return greater_equal(self, other)\n\n    def __le__(self, other):\n        \n        return less_equal(self, other)\n\n    def __gt__(self, other):\n        \n        return greater(self, other)\n\n    def __lt__(self, other):\n        \n        return less(self, other)\n\n    def __add__(self, other):\n        \n        return asarray(add(self, other))\n\n    def __radd__(self, other):\n        \n        return asarray(add(numpy.asarray(other), self))\n\n    def __mul__(self, i):\n        \n        return asarray(multiply(self, i))\n\n    def __rmul__(self, i):\n        \n        return asarray(multiply(self, i))\n\n    def __mod__(self, i):\n        \n        return asarray(mod(self, i))\n\n    def __rmod__(self, other):\n        return NotImplemented\n\n    def argsort(self, axis=-1, kind=\'quicksort\', order=None):\n        \n        return self.__array__().argsort(axis, kind, order)\n    argsort.__doc__ = ndarray.argsort.__doc__\n\n    def capitalize(self):\n        \n        return asarray(capitalize(self))\n\n    def center(self, width, fillchar=\' \'):\n        \n        return asarray(center(self, width, fillchar))\n\n    def count(self, sub, start=0, end=None):\n        \n        return count(self, sub, start, end)\n\n    def decode(self, encoding=None, errors=None):\n        \n        return decode(self, encoding, errors)\n\n    def encode(self, encoding=None, errors=None):\n        \n        return encode(self, encoding, errors)\n\n    def endswith(self, suffix, start=0, end=None):\n        \n        return endswith(self, suffix, start, end)\n\n    def expandtabs(self, tabsize=8):\n        \n        return asarray(expandtabs(self, tabsize))\n\n    def find(self, sub, start=0, end=None):\n        \n        return find(self, sub, start, end)\n\n    def index(self, sub, start=0, end=None):\n        \n        return index(self, sub, start, end)\n\n    def isalnum(self):\n        \n        return isalnum(self)\n\n    def isalpha(self):\n        \n        return isalpha(self)\n\n    def isdigit(self):\n        \n        return isdigit(self)\n\n    def islower(self):\n        \n        return islower(self)\n\n    def isspace(self):\n        \n        return isspace(self)\n\n    def istitle(self):\n        \n        return istitle(self)\n\n    def isupper(self):\n        \n        return isupper(self)\n\n    def join(self, seq):\n        \n        return join(self, seq)\n\n    def ljust(self, width, fillchar=\' \'):\n        \n        return asarray(ljust(self, width, fillchar))\n\n    def lower(self):\n        \n        return asarray(lower(self))\n\n    def lstrip(self, chars=None):\n        \n        return asarray(lstrip(self, chars))\n\n    def partition(self, sep):\n        \n        return asarray(partition(self, sep))\n\n    def replace(self, old, new, count=None):\n        \n        return asarray(replace(self, old, new, count))\n\n    def rfind(self, sub, start=0, end=None):\n        \n        return rfind(self, sub, start, end)\n\n    def rindex(self, sub, start=0, end=None):\n        \n        return rindex(self, sub, start, end)\n\n    def rjust(self, width, fillchar=\' \'):\n        \n        return asarray(rjust(self, width, fillchar))\n\n    def rpartition(self, sep):\n        \n        return asarray(rpartition(self, sep))\n\n    def rsplit(self, sep=None, maxsplit=None):\n        \n        return rsplit(self, sep, maxsplit)\n\n    def rstrip(self, chars=None):\n        \n        return asarray(rstrip(self, chars))\n\n    def split(self, sep=None, maxsplit=None):\n        \n        return split(self, sep, maxsplit)\n\n    def splitlines(self, keepends=None):\n        \n        return splitlines(self, keepends)\n\n    def startswith(self, prefix, start=0, end=None):\n        \n        return startswith(self, prefix, start, end)\n\n    def strip(self, chars=None):\n        \n        return asarray(strip(self, chars))\n\n    def swapcase(self):\n        \n        return asarray(swapcase(self))\n\n    def title(self):\n        \n        return asarray(title(self))\n\n    def translate(self, table, deletechars=None):\n        \n        return asarray(translate(self, table, deletechars))\n\n    def upper(self):\n        \n        return asarray(upper(self))\n\n    def zfill(self, width):\n        \n        return asarray(zfill(self, width))\n\n    def isnumeric(self):\n        \n        return isnumeric(self)\n\n    def isdecimal(self):\n        \n        return isdecimal(self)\n\n\ndef array(obj, itemsize=None, copy=True, unicode=None, order=None):\n    \n    if isinstance(obj, (_bytes, _unicode)):\n        if unicode is None:\n            if isinstance(obj, _unicode):\n                unicode = True\n            else:\n                unicode = False\n\n        if itemsize is None:\n            itemsize = _len(obj)\n        shape = _len(obj) // itemsize\n\n        if unicode:\n            if sys.maxunicode == 0xffff:\n                                                                                                                                                                if sys.hexversion >= 0x2060000:\n                    obj = obj.encode(\'utf_32\')\n                else:\n                    if isinstance(obj, str):\n                        ascii = numpy.frombuffer(obj, \'u1\')\n                        ucs4 = numpy.array(ascii, \'u4\')\n                        obj = ucs4.data\n                    else:\n                        ucs2 = numpy.frombuffer(obj, \'u2\')\n                        ucs4 = numpy.array(ucs2, \'u4\')\n                        obj = ucs4.data\n            else:\n                obj = _unicode(obj)\n        else:\n                                    obj = _bytes(obj)\n\n        return chararray(shape, itemsize=itemsize, unicode=unicode,\n                         buffer=obj, order=order)\n\n    if isinstance(obj, (list, tuple)):\n        obj = numpy.asarray(obj)\n\n    if isinstance(obj, ndarray) and issubclass(obj.dtype.type, character):\n                        if not isinstance(obj, chararray):\n            obj = obj.view(chararray)\n\n        if itemsize is None:\n            itemsize = obj.itemsize\n                                                if issubclass(obj.dtype.type, unicode_):\n                itemsize //= 4\n\n        if unicode is None:\n            if issubclass(obj.dtype.type, unicode_):\n                unicode = True\n            else:\n                unicode = False\n\n        if unicode:\n            dtype = unicode_\n        else:\n            dtype = string_\n\n        if order is not None:\n            obj = numpy.asarray(obj, order=order)\n        if (copy or\n                (itemsize != obj.itemsize) or\n                (not unicode and isinstance(obj, unicode_)) or\n                (unicode and isinstance(obj, string_))):\n            obj = obj.astype((dtype, long(itemsize)))\n        return obj\n\n    if isinstance(obj, ndarray) and issubclass(obj.dtype.type, object):\n        if itemsize is None:\n                                                obj = obj.tolist()\n            \n    if unicode:\n        dtype = unicode_\n    else:\n        dtype = string_\n\n    if itemsize is None:\n        val = narray(obj, dtype=dtype, order=order, subok=True)\n    else:\n        val = narray(obj, dtype=(dtype, itemsize), order=order, subok=True)\n    return val.view(chararray)\n\n\ndef asarray(obj, itemsize=None, unicode=None, order=None):\n    \n    return array(obj, itemsize, copy=False,\n                 unicode=unicode, order=order)\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'matrix\', \'bmat\', \'mat\', \'asmatrix\']\n\nimport sys\nimport numpy.core.numeric as N\nfrom numpy.core.numeric import concatenate, isscalar, binary_repr, identity, asanyarray\nfrom numpy.core.numerictypes import issubdtype\n\n_numchars = \'0123456789.-+jeEL\'\n\nif sys.version_info[0] >= 3:\n    class _NumCharTable:\n        def __getitem__(self, i):\n            if chr(i) in _numchars:\n                return chr(i)\n            else:\n                return None\n    _table = _NumCharTable()\n    def _eval(astr):\n        str_ = astr.translate(_table)\n        if not str_:\n            raise TypeError("Invalid data string supplied: " + astr)\n        else:\n            return eval(str_)\n\nelse:\n    _table = [None]*256\n    for k in range(256):\n        _table[k] = chr(k)\n    _table = \'\'.join(_table)\n\n    _todelete = []\n    for k in _table:\n        if k not in _numchars:\n            _todelete.append(k)\n    _todelete = \'\'.join(_todelete)\n    del k\n\n    def _eval(astr):\n        str_ = astr.translate(_table, _todelete)\n        if not str_:\n            raise TypeError("Invalid data string supplied: " + astr)\n        else:\n            return eval(str_)\n\ndef _convert_from_string(data):\n    rows = data.split(\';\')\n    newdata = []\n    count = 0\n    for row in rows:\n        trow = row.split(\',\')\n        newrow = []\n        for col in trow:\n            temp = col.split()\n            newrow.extend(map(_eval, temp))\n        if count == 0:\n            Ncols = len(newrow)\n        elif len(newrow) != Ncols:\n            raise ValueError("Rows not the same size.")\n        count += 1\n        newdata.append(newrow)\n    return newdata\n\ndef asmatrix(data, dtype=None):\n    \n    return matrix(data, dtype=dtype, copy=False)\n\ndef matrix_power(M, n):\n    \n    M = asanyarray(M)\n    if len(M.shape) != 2 or M.shape[0] != M.shape[1]:\n        raise ValueError("input must be a square array")\n    if not issubdtype(type(n), int):\n        raise TypeError("exponent must be an integer")\n\n    from numpy.linalg import inv\n\n    if n==0:\n        M = M.copy()\n        M[:] = identity(M.shape[0])\n        return M\n    elif n<0:\n        M = inv(M)\n        n *= -1\n\n    result = M\n    if n <= 3:\n        for _ in range(n-1):\n            result=N.dot(result, M)\n        return result\n\n            beta = binary_repr(n)\n    Z, q, t = M, 0, len(beta)\n    while beta[t-q-1] == \'0\':\n        Z = N.dot(Z, Z)\n        q += 1\n    result = Z\n    for k in range(q+1, t):\n        Z = N.dot(Z, Z)\n        if beta[t-k-1] == \'1\':\n            result = N.dot(result, Z)\n    return result\n\n\nclass matrix(N.ndarray):\n    \n    __array_priority__ = 10.0\n    def __new__(subtype, data, dtype=None, copy=True):\n        if isinstance(data, matrix):\n            dtype2 = data.dtype\n            if (dtype is None):\n                dtype = dtype2\n            if (dtype2 == dtype) and (not copy):\n                return data\n            return data.astype(dtype)\n\n        if isinstance(data, N.ndarray):\n            if dtype is None:\n                intype = data.dtype\n            else:\n                intype = N.dtype(dtype)\n            new = data.view(subtype)\n            if intype != data.dtype:\n                return new.astype(intype)\n            if copy: return new.copy()\n            else: return new\n\n        if isinstance(data, str):\n            data = _convert_from_string(data)\n\n                arr = N.array(data, dtype=dtype, copy=copy)\n        ndim = arr.ndim\n        shape = arr.shape\n        if (ndim > 2):\n            raise ValueError("matrix must be 2-dimensional")\n        elif ndim == 0:\n            shape = (1, 1)\n        elif ndim == 1:\n            shape = (1, shape[0])\n\n        order = False\n        if (ndim == 2) and arr.flags.fortran:\n            order = True\n\n        if not (order or arr.flags.contiguous):\n            arr = arr.copy()\n\n        ret = N.ndarray.__new__(subtype, shape, arr.dtype,\n                                buffer=arr,\n                                order=order)\n        return ret\n\n    def __array_finalize__(self, obj):\n        self._getitem = False\n        if (isinstance(obj, matrix) and obj._getitem): return\n        ndim = self.ndim\n        if (ndim == 2):\n            return\n        if (ndim > 2):\n            newshape = tuple([x for x in self.shape if x > 1])\n            ndim = len(newshape)\n            if ndim == 2:\n                self.shape = newshape\n                return\n            elif (ndim > 2):\n                raise ValueError("shape too large to be a matrix.")\n        else:\n            newshape = self.shape\n        if ndim == 0:\n            self.shape = (1, 1)\n        elif ndim == 1:\n            self.shape = (1, newshape[0])\n        return\n\n    def __getitem__(self, index):\n        self._getitem = True\n\n        try:\n            out = N.ndarray.__getitem__(self, index)\n        finally:\n            self._getitem = False\n\n        if not isinstance(out, N.ndarray):\n            return out\n\n        if out.ndim == 0:\n            return out[()]\n        if out.ndim == 1:\n            sh = out.shape[0]\n                        try:\n                n = len(index)\n            except:\n                n = 0\n            if n > 1 and isscalar(index[1]):\n                out.shape = (sh, 1)\n            else:\n                out.shape = (1, sh)\n        return out\n\n    def __mul__(self, other):\n        if isinstance(other, (N.ndarray, list, tuple)) :\n                        return N.dot(self, asmatrix(other))\n        if isscalar(other) or not hasattr(other, \'__rmul__\') :\n            return N.dot(self, other)\n        return NotImplemented\n\n    def __rmul__(self, other):\n        return N.dot(other, self)\n\n    def __imul__(self, other):\n        self[:] = self * other\n        return self\n\n    def __pow__(self, other):\n        return matrix_power(self, other)\n\n    def __ipow__(self, other):\n        self[:] = self ** other\n        return self\n\n    def __rpow__(self, other):\n        return NotImplemented\n\n    def __repr__(self):\n        s = repr(self.__array__()).replace(\'array\', \'matrix\')\n                        l = s.splitlines()\n        for i in range(1, len(l)):\n            if l[i]:\n                l[i] = \' \' + l[i]\n        return \'\\n\'.join(l)\n\n    def __str__(self):\n        return str(self.__array__())\n\n    def _align(self, axis):\n        \n        if axis is None:\n            return self[0, 0]\n        elif axis==0:\n            return self\n        elif axis==1:\n            return self.transpose()\n        else:\n            raise ValueError("unsupported axis")\n\n    def _collapse(self, axis):\n        \n        if axis is None:\n            return self[0, 0]\n        else:\n            return self\n\n            def tolist(self):\n        \n        return self.__array__().tolist()\n\n        def sum(self, axis=None, dtype=None, out=None):\n        \n        return N.ndarray.sum(self, axis, dtype, out, keepdims=True)._collapse(axis)\n\n\n        def squeeze(self, axis=None):\n        \n        return N.ndarray.squeeze(self, axis=axis)\n\n\n        def flatten(self, order=\'C\'):\n        \n        return N.ndarray.flatten(self, order=order)\n\n    def mean(self, axis=None, dtype=None, out=None):\n        \n        return N.ndarray.mean(self, axis, dtype, out, keepdims=True)._collapse(axis)\n\n    def std(self, axis=None, dtype=None, out=None, ddof=0):\n        \n        return N.ndarray.std(self, axis, dtype, out, ddof, keepdims=True)._collapse(axis)\n\n    def var(self, axis=None, dtype=None, out=None, ddof=0):\n        \n        return N.ndarray.var(self, axis, dtype, out, ddof, keepdims=True)._collapse(axis)\n\n    def prod(self, axis=None, dtype=None, out=None):\n        \n        return N.ndarray.prod(self, axis, dtype, out, keepdims=True)._collapse(axis)\n\n    def any(self, axis=None, out=None):\n        \n        return N.ndarray.any(self, axis, out, keepdims=True)._collapse(axis)\n\n    def all(self, axis=None, out=None):\n        \n        return N.ndarray.all(self, axis, out, keepdims=True)._collapse(axis)\n\n    def max(self, axis=None, out=None):\n        \n        return N.ndarray.max(self, axis, out, keepdims=True)._collapse(axis)\n\n    def argmax(self, axis=None, out=None):\n        \n        return N.ndarray.argmax(self, axis, out)._align(axis)\n\n    def min(self, axis=None, out=None):\n        \n        return N.ndarray.min(self, axis, out, keepdims=True)._collapse(axis)\n\n    def argmin(self, axis=None, out=None):\n        \n        return N.ndarray.argmin(self, axis, out)._align(axis)\n\n    def ptp(self, axis=None, out=None):\n        \n        return N.ndarray.ptp(self, axis, out)._align(axis)\n\n    def getI(self):\n        \n        M, N = self.shape\n        if M == N:\n            from numpy.dual import inv as func\n        else:\n            from numpy.dual import pinv as func\n        return asmatrix(func(self))\n\n    def getA(self):\n        \n        return self.__array__()\n\n    def getA1(self):\n        \n        return self.__array__().ravel()\n\n\n    def ravel(self, order=\'C\'):\n        \n        return N.ndarray.ravel(self, order=order)\n\n\n    def getT(self):\n        \n        return self.transpose()\n\n    def getH(self):\n        \n        if issubclass(self.dtype.type, N.complexfloating):\n            return self.transpose().conjugate()\n        else:\n            return self.transpose()\n\n    T = property(getT, None)\n    A = property(getA, None)\n    A1 = property(getA1, None)\n    H = property(getH, None)\n    I = property(getI, None)\n\ndef _from_string(str, gdict, ldict):\n    rows = str.split(\';\')\n    rowtup = []\n    for row in rows:\n        trow = row.split(\',\')\n        newrow = []\n        for x in trow:\n            newrow.extend(x.split())\n        trow = newrow\n        coltup = []\n        for col in trow:\n            col = col.strip()\n            try:\n                thismat = ldict[col]\n            except KeyError:\n                try:\n                    thismat = gdict[col]\n                except KeyError:\n                    raise KeyError("%s not found" % (col,))\n\n            coltup.append(thismat)\n        rowtup.append(concatenate(coltup, axis=-1))\n    return concatenate(rowtup, axis=0)\n\n\ndef bmat(obj, ldict=None, gdict=None):\n    \n    if isinstance(obj, str):\n        if gdict is None:\n                        frame = sys._getframe().f_back\n            glob_dict = frame.f_globals\n            loc_dict = frame.f_locals\n        else:\n            glob_dict = gdict\n            loc_dict = ldict\n\n        return matrix(_from_string(obj, glob_dict, loc_dict))\n\n    if isinstance(obj, (tuple, list)):\n                arr_rows = []\n        for row in obj:\n            if isinstance(row, N.ndarray):                  return matrix(concatenate(obj, axis=-1))\n            else:\n                arr_rows.append(concatenate(row, axis=-1))\n        return matrix(concatenate(arr_rows, axis=0))\n    if isinstance(obj, N.ndarray):\n        return matrix(obj)\n\nmat = asmatrix\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom setuptools.command.develop import develop as old_develop\n\nclass develop(old_develop):\n    __doc__ = old_develop.__doc__\n    def install_for_development(self):\n                self.reinitialize_command(\'build_src\', inplace=1)\n                self.run_command(\'build_scripts\')\n        old_develop.install_for_development(self)\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport sys\nimport tempfile\n\n\ndef run_command(cmd):\n    print(\'Running %r:\' % (cmd))\n    os.system(cmd)\n    print(\'------\')\n\n\ndef run():\n    _path = os.getcwd()\n    os.chdir(tempfile.gettempdir())\n    print(\'------\')\n    print(\'os.name=%r\' % (os.name))\n    print(\'------\')\n    print(\'sys.platform=%r\' % (sys.platform))\n    print(\'------\')\n    print(\'sys.version:\')\n    print(sys.version)\n    print(\'------\')\n    print(\'sys.prefix:\')\n    print(sys.prefix)\n    print(\'------\')\n    print(\'sys.path=%r\' % (\':\'.join(sys.path)))\n    print(\'------\')\n\n    try:\n        import numpy\n        has_newnumpy = 1\n    except ImportError:\n        print(\'Failed to import new numpy:\', sys.exc_info()[1])\n        has_newnumpy = 0\n\n    try:\n        from numpy.f2py import f2py2e\n        has_f2py2e = 1\n    except ImportError:\n        print(\'Failed to import f2py2e:\', sys.exc_info()[1])\n        has_f2py2e = 0\n\n    try:\n        import numpy.distutils\n        has_numpy_distutils = 2\n    except ImportError:\n        try:\n            import numpy_distutils\n            has_numpy_distutils = 1\n        except ImportError:\n            print(\'Failed to import numpy_distutils:\', sys.exc_info()[1])\n            has_numpy_distutils = 0\n\n    if has_newnumpy:\n        try:\n            print(\'Found new numpy version %r in %s\' %\n                  (numpy.__version__, numpy.__file__))\n        except Exception as msg:\n            print(\'error:\', msg)\n            print(\'------\')\n\n    if has_f2py2e:\n        try:\n            print(\'Found f2py2e version %r in %s\' %\n                  (f2py2e.__version__.version, f2py2e.__file__))\n        except Exception as msg:\n            print(\'error:\', msg)\n            print(\'------\')\n\n    if has_numpy_distutils:\n        try:\n            if has_numpy_distutils == 2:\n                print(\'Found numpy.distutils version %r in %r\' % (\n                    numpy.distutils.__version__,\n                    numpy.distutils.__file__))\n            else:\n                print(\'Found numpy_distutils version %r in %r\' % (\n                    numpy_distutils.numpy_distutils_version.numpy_distutils_version,\n                    numpy_distutils.__file__))\n            print(\'------\')\n        except Exception as msg:\n            print(\'error:\', msg)\n            print(\'------\')\n        try:\n            if has_numpy_distutils == 1:\n                print(\n                    \'Importing numpy_distutils.command.build_flib ...\', end=\' \')\n                import numpy_distutils.command.build_flib as build_flib\n                print(\'ok\')\n                print(\'------\')\n                try:\n                    print(\n                        \'Checking availability of supported Fortran compilers:\')\n                    for compiler_class in build_flib.all_compilers:\n                        compiler_class(verbose=1).is_available()\n                        print(\'------\')\n                except Exception as msg:\n                    print(\'error:\', msg)\n                    print(\'------\')\n        except Exception as msg:\n            print(\n                \'error:\', msg, \'(ignore it, build_flib is obsolute for numpy.distutils 0.2.2 and up)\')\n            print(\'------\')\n        try:\n            if has_numpy_distutils == 2:\n                print(\'Importing numpy.distutils.fcompiler ...\', end=\' \')\n                import numpy.distutils.fcompiler as fcompiler\n            else:\n                print(\'Importing numpy_distutils.fcompiler ...\', end=\' \')\n                import numpy_distutils.fcompiler as fcompiler\n            print(\'ok\')\n            print(\'------\')\n            try:\n                print(\'Checking availability of supported Fortran compilers:\')\n                fcompiler.show_fcompilers()\n                print(\'------\')\n            except Exception as msg:\n                print(\'error:\', msg)\n                print(\'------\')\n        except Exception as msg:\n            print(\'error:\', msg)\n            print(\'------\')\n        try:\n            if has_numpy_distutils == 2:\n                print(\'Importing numpy.distutils.cpuinfo ...\', end=\' \')\n                from numpy.distutils.cpuinfo import cpuinfo\n                print(\'ok\')\n                print(\'------\')\n            else:\n                try:\n                    print(\n                        \'Importing numpy_distutils.command.cpuinfo ...\', end=\' \')\n                    from numpy_distutils.command.cpuinfo import cpuinfo\n                    print(\'ok\')\n                    print(\'------\')\n                except Exception as msg:\n                    print(\'error:\', msg, \'(ignore it)\')\n                    print(\'Importing numpy_distutils.cpuinfo ...\', end=\' \')\n                    from numpy_distutils.cpuinfo import cpuinfo\n                    print(\'ok\')\n                    print(\'------\')\n            cpu = cpuinfo()\n            print(\'CPU information:\', end=\' \')\n            for name in dir(cpuinfo):\n                if name[0] == \'_\' and name[1] != \'_\' and getattr(cpu, name[1:])():\n                    print(name[1:], end=\' \')\n            print(\'------\')\n        except Exception as msg:\n            print(\'error:\', msg)\n            print(\'------\')\n    os.chdir(_path)\nif __name__ == "__main__":\n    run()\n\nfrom __future__ import division, absolute_import, print_function\n\n\n__all__ = [\'fft\', \'ifft\', \'fftn\', \'ifftn\', \'fft2\', \'ifft2\',\n           \'norm\', \'inv\', \'svd\', \'solve\', \'det\', \'eig\', \'eigvals\',\n           \'eigh\', \'eigvalsh\', \'lstsq\', \'pinv\', \'cholesky\', \'i0\']\n\nimport numpy.linalg as linpkg\nimport numpy.fft as fftpkg\nfrom numpy.lib import i0\nimport sys\n\n\nfft = fftpkg.fft\nifft = fftpkg.ifft\nfftn = fftpkg.fftn\nifftn = fftpkg.ifftn\nfft2 = fftpkg.fft2\nifft2 = fftpkg.ifft2\n\nnorm = linpkg.norm\ninv = linpkg.inv\nsvd = linpkg.svd\nsolve = linpkg.solve\ndet = linpkg.det\neig = linpkg.eig\neigvals = linpkg.eigvals\neigh = linpkg.eigh\neigvalsh = linpkg.eigvalsh\nlstsq = linpkg.lstsq\npinv = linpkg.pinv\ncholesky = linpkg.cholesky\n\n_restore_dict = {}\n\ndef register_func(name, func):\n    if name not in __all__:\n        raise ValueError("%s not a dual function." % name)\n    f = sys._getframe(0).f_globals\n    _restore_dict[name] = f[name]\n    f[name] = func\n\ndef restore_func(name):\n    if name not in __all__:\n        raise ValueError("%s not a dual function." % name)\n    try:\n        val = _restore_dict[name]\n    except KeyError:\n        return\n    else:\n        sys._getframe(0).f_globals[name] = val\n\ndef restore_all():\n    for name in _restore_dict.keys():\n        restore_func(name)\nfrom __future__ import division, absolute_import, print_function\n\nfrom setuptools.command.egg_info import egg_info as _egg_info\n\nclass egg_info(_egg_info):\n    def run(self):\n                                self.run_command("build_src")\n        _egg_info.run(self)\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nfrom distutils.dist import Distribution\n\n__metaclass__ = type\n\nclass EnvironmentConfig(object):\n    def __init__(self, distutils_section=\'ALL\', **kw):\n        self._distutils_section = distutils_section\n        self._conf_keys = kw\n        self._conf = None\n        self._hook_handler = None\n\n    def dump_variable(self, name):\n        conf_desc = self._conf_keys[name]\n        hook, envvar, confvar, convert = conf_desc\n        if not convert:\n            convert = lambda x : x\n        print(\'%s.%s:\' % (self._distutils_section, name))\n        v = self._hook_handler(name, hook)\n        print(\'  hook   : %s\' % (convert(v),))\n        if envvar:\n            v = os.environ.get(envvar, None)\n            print(\'  environ: %s\' % (convert(v),))\n        if confvar and self._conf:\n            v = self._conf.get(confvar, (None, None))[1]\n            print(\'  config : %s\' % (convert(v),))\n\n    def dump_variables(self):\n        for name in self._conf_keys:\n            self.dump_variable(name)\n\n    def __getattr__(self, name):\n        try:\n            conf_desc = self._conf_keys[name]\n        except KeyError:\n            raise AttributeError(name)\n        return self._get_var(name, conf_desc)\n\n    def get(self, name, default=None):\n        try:\n            conf_desc = self._conf_keys[name]\n        except KeyError:\n            return default\n        var = self._get_var(name, conf_desc)\n        if var is None:\n            var = default\n        return var\n\n    def _get_var(self, name, conf_desc):\n        hook, envvar, confvar, convert = conf_desc\n        var = self._hook_handler(name, hook)\n        if envvar is not None:\n            var = os.environ.get(envvar, var)\n        if confvar is not None and self._conf:\n            var = self._conf.get(confvar, (None, var))[1]\n        if convert is not None:\n            var = convert(var)\n        return var\n\n    def clone(self, hook_handler):\n        ec = self.__class__(distutils_section=self._distutils_section,\n                            **self._conf_keys)\n        ec._hook_handler = hook_handler\n        return ec\n\n    def use_distribution(self, dist):\n        if isinstance(dist, Distribution):\n            self._conf = dist.get_option_dict(self._distutils_section)\n        else:\n            self._conf = dist\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'exec_command\', \'find_executable\']\n\nimport os\nimport sys\nimport shlex\n\nfrom numpy.distutils.misc_util import is_sequence, make_temp_file\nfrom numpy.distutils import log\nfrom numpy.distutils.compat import get_exception\n\nfrom numpy.compat import open_latin1\n\ndef temp_file_name():\n    fo, name = make_temp_file()\n    fo.close()\n    return name\n\ndef get_pythonexe():\n    pythonexe = sys.executable\n    if os.name in [\'nt\', \'dos\']:\n        fdir, fn = os.path.split(pythonexe)\n        fn = fn.upper().replace(\'PYTHONW\', \'PYTHON\')\n        pythonexe = os.path.join(fdir, fn)\n        assert os.path.isfile(pythonexe), \'%r is not a file\' % (pythonexe,)\n    return pythonexe\n\ndef find_executable(exe, path=None, _cache={}):\n    \n    key = exe, path\n    try:\n        return _cache[key]\n    except KeyError:\n        pass\n    log.debug(\'find_executable(%r)\' % exe)\n    orig_exe = exe\n\n    if path is None:\n        path = os.environ.get(\'PATH\', os.defpath)\n    if os.name==\'posix\':\n        realpath = os.path.realpath\n    else:\n        realpath = lambda a:a\n\n    if exe.startswith(\'"\'):\n        exe = exe[1:-1]\n\n    suffixes = [\'\']\n    if os.name in [\'nt\', \'dos\', \'os2\']:\n        fn, ext = os.path.splitext(exe)\n        extra_suffixes = [\'.exe\', \'.com\', \'.bat\']\n        if ext.lower() not in extra_suffixes:\n            suffixes = extra_suffixes\n\n    if os.path.isabs(exe):\n        paths = [\'\']\n    else:\n        paths = [ os.path.abspath(p) for p in path.split(os.pathsep) ]\n\n    for path in paths:\n        fn = os.path.join(path, exe)\n        for s in suffixes:\n            f_ext = fn+s\n            if not os.path.islink(f_ext):\n                f_ext = realpath(f_ext)\n            if os.path.isfile(f_ext) and os.access(f_ext, os.X_OK):\n                log.info(\'Found executable %s\' % f_ext)\n                _cache[key] = f_ext\n                return f_ext\n\n    log.warn(\'Could not locate executable %s\' % orig_exe)\n    return None\n\n\ndef _preserve_environment( names ):\n    log.debug(\'_preserve_environment(%r)\' % (names))\n    env = {}\n    for name in names:\n        env[name] = os.environ.get(name)\n    return env\n\ndef _update_environment( **env ):\n    log.debug(\'_update_environment(...)\')\n    for name, value in env.items():\n        os.environ[name] = value or \'\'\n\ndef _supports_fileno(stream):\n    \n    if hasattr(stream, \'fileno\'):\n        try:\n            r = stream.fileno()\n            return True\n        except IOError:\n            return False\n    else:\n        return False\n\ndef exec_command(command, execute_in=\'\', use_shell=None, use_tee=None,\n                 _with_python = 1, **env ):\n    \n    log.debug(\'exec_command(%r,%s)\' % (command,\\\n         \',\'.join([\'%s=%r\'%kv for kv in env.items()])))\n\n    if use_tee is None:\n        use_tee = os.name==\'posix\'\n    if use_shell is None:\n        use_shell = os.name==\'posix\'\n    execute_in = os.path.abspath(execute_in)\n    oldcwd = os.path.abspath(os.getcwd())\n\n    if __name__[-12:] == \'exec_command\':\n        exec_dir = os.path.dirname(os.path.abspath(__file__))\n    elif os.path.isfile(\'exec_command.py\'):\n        exec_dir = os.path.abspath(\'.\')\n    else:\n        exec_dir = os.path.abspath(sys.argv[0])\n        if os.path.isfile(exec_dir):\n            exec_dir = os.path.dirname(exec_dir)\n\n    if oldcwd!=execute_in:\n        os.chdir(execute_in)\n        log.debug(\'New cwd: %s\' % execute_in)\n    else:\n        log.debug(\'Retaining cwd: %s\' % oldcwd)\n\n    oldenv = _preserve_environment( list(env.keys()) )\n    _update_environment( **env )\n\n    try:\n                                                                                if (_with_python and _supports_fileno(sys.stdout) and\n                            sys.stdout.fileno() == -1):\n            st = _exec_command_python(command,\n                                      exec_command_dir = exec_dir,\n                                      **env)\n        elif os.name==\'posix\':\n            st = _exec_command_posix(command,\n                                     use_shell=use_shell,\n                                     use_tee=use_tee,\n                                     **env)\n        else:\n            st = _exec_command(command, use_shell=use_shell,\n                               use_tee=use_tee,**env)\n    finally:\n        if oldcwd!=execute_in:\n            os.chdir(oldcwd)\n            log.debug(\'Restored cwd to %s\' % oldcwd)\n        _update_environment(**oldenv)\n\n    return st\n\ndef _exec_command_posix( command,\n                         use_shell = None,\n                         use_tee = None,\n                         **env ):\n    log.debug(\'_exec_command_posix(...)\')\n\n    if is_sequence(command):\n        command_str = \' \'.join(list(command))\n    else:\n        command_str = command\n\n    tmpfile = temp_file_name()\n    stsfile = None\n    if use_tee:\n        stsfile = temp_file_name()\n        filter = \'\'\n        if use_tee == 2:\n            filter = r\'| tr -cd "\\n" | tr "\\n" "."; echo\'\n        command_posix = \'( %s ; echo $? > %s ) 2>&1 | tee %s %s\'\\\n                      % (command_str, stsfile, tmpfile, filter)\n    else:\n        stsfile = temp_file_name()\n        command_posix = \'( %s ; echo $? > %s ) > %s 2>&1\'\\\n                        % (command_str, stsfile, tmpfile)\n        \n    log.debug(\'Running os.system(%r)\' % (command_posix))\n    status = os.system(command_posix)\n\n    if use_tee:\n        if status:\n                        log.warn(\'_exec_command_posix failed (status=%s)\' % status)\n            return _exec_command(command, use_shell=use_shell, **env)\n\n    if stsfile is not None:\n        f = open_latin1(stsfile, \'r\')\n        status_text = f.read()\n        status = int(status_text)\n        f.close()\n        os.remove(stsfile)\n\n    f = open_latin1(tmpfile, \'r\')\n    text = f.read()\n    f.close()\n    os.remove(tmpfile)\n\n    if text[-1:]==\'\\n\':\n        text = text[:-1]\n\n    return status, text\n\n\ndef _exec_command_python(command,\n                         exec_command_dir=\'\', **env):\n    log.debug(\'_exec_command_python(...)\')\n\n    python_exe = get_pythonexe()\n    cmdfile = temp_file_name()\n    stsfile = temp_file_name()\n    outfile = temp_file_name()\n\n    f = open(cmdfile, \'w\')\n    f.write(\'import os\\n\')\n    f.write(\'import sys\\n\')\n    f.write(\'sys.path.insert(0,%r)\\n\' % (exec_command_dir))\n    f.write(\'from exec_command import exec_command\\n\')\n    f.write(\'del sys.path[0]\\n\')\n    f.write(\'cmd = %r\\n\' % command)\n    f.write(\'os.environ = %r\\n\' % (os.environ))\n    f.write(\'s,o = exec_command(cmd, _with_python=0, **%r)\\n\' % (env))\n    f.write(\'f=open(%r,"w")\\nf.write(str(s))\\nf.close()\\n\' % (stsfile))\n    f.write(\'f=open(%r,"w")\\nf.write(o)\\nf.close()\\n\' % (outfile))\n    f.close()\n\n    cmd = \'%s %s\' % (python_exe, cmdfile)\n    status = os.system(cmd)\n    if status:\n        raise RuntimeError("%r failed" % (cmd,))\n    os.remove(cmdfile)\n\n    f = open_latin1(stsfile, \'r\')\n    status = int(f.read())\n    f.close()\n    os.remove(stsfile)\n\n    f = open_latin1(outfile, \'r\')\n    text = f.read()\n    f.close()\n    os.remove(outfile)\n\n    return status, text\n\ndef quote_arg(arg):\n    if arg[0]!=\'"\' and \' \' in arg:\n        return \'"%s"\' % arg\n    return arg\n\ndef _exec_command( command, use_shell=None, use_tee = None, **env ):\n    log.debug(\'_exec_command(...)\')\n\n    if use_shell is None:\n        use_shell = os.name==\'posix\'\n    if use_tee is None:\n        use_tee = os.name==\'posix\'\n    using_command = 0\n    if use_shell:\n                        sh = os.environ.get(\'SHELL\', \'/bin/sh\')\n        if is_sequence(command):\n            argv = [sh, \'-c\', \' \'.join(list(command))]\n        else:\n            argv = [sh, \'-c\', command]\n    else:\n                        if is_sequence(command):\n            argv = command[:]\n        else:\n            argv = shlex.split(command)\n\n    if hasattr(os, \'spawnvpe\'):\n        spawn_command = os.spawnvpe\n    else:\n        spawn_command = os.spawnve\n        argv[0] = find_executable(argv[0]) or argv[0]\n        if not os.path.isfile(argv[0]):\n            log.warn(\'Executable %s does not exist\' % (argv[0]))\n            if os.name in [\'nt\', \'dos\']:\n                                argv = [os.environ[\'COMSPEC\'], \'/C\'] + argv\n                using_command = 1\n\n    _so_has_fileno = _supports_fileno(sys.stdout)\n    _se_has_fileno = _supports_fileno(sys.stderr)\n    so_flush = sys.stdout.flush\n    se_flush = sys.stderr.flush\n    if _so_has_fileno:\n        so_fileno = sys.stdout.fileno()\n        so_dup = os.dup(so_fileno)\n    if _se_has_fileno:\n        se_fileno = sys.stderr.fileno()\n        se_dup = os.dup(se_fileno)\n\n    outfile = temp_file_name()\n    fout = open(outfile, \'w\')\n    if using_command:\n        errfile = temp_file_name()\n        ferr = open(errfile, \'w\')\n\n    log.debug(\'Running %s(%s,%r,%r,os.environ)\' \\\n              % (spawn_command.__name__, os.P_WAIT, argv[0], argv))\n\n    if sys.version_info[0] >= 3 and os.name == \'nt\':\n                                                                        encoded_environ = {}\n        for k, v in os.environ.items():\n            try:\n                encoded_environ[k.encode(sys.getfilesystemencoding())] = v.encode(\n                    sys.getfilesystemencoding())\n            except UnicodeEncodeError:\n                log.debug("ignoring un-encodable env entry %s", k)\n    else:\n        encoded_environ = os.environ\n\n    argv0 = argv[0]\n    if not using_command:\n        argv[0] = quote_arg(argv0)\n\n    so_flush()\n    se_flush()\n    if _so_has_fileno:\n        os.dup2(fout.fileno(), so_fileno)\n\n    if _se_has_fileno:\n        if using_command:\n                                    os.dup2(ferr.fileno(), se_fileno)\n        else:\n            os.dup2(fout.fileno(), se_fileno)\n    try:\n        status = spawn_command(os.P_WAIT, argv0, argv, encoded_environ)\n    except Exception:\n        errmess = str(get_exception())\n        status = 999\n        sys.stderr.write(\'%s: %s\'%(errmess, argv[0]))\n\n    so_flush()\n    se_flush()\n    if _so_has_fileno:\n        os.dup2(so_dup, so_fileno)\n        os.close(so_dup)\n    if _se_has_fileno:\n        os.dup2(se_dup, se_fileno)\n        os.close(se_dup)\n\n    fout.close()\n    fout = open_latin1(outfile, \'r\')\n    text = fout.read()\n    fout.close()\n    os.remove(outfile)\n\n    if using_command:\n        ferr.close()\n        ferr = open_latin1(errfile, \'r\')\n        errmess = ferr.read()\n        ferr.close()\n        os.remove(errfile)\n        if errmess and not status:\n                                                            if text:\n                text = text + \'\\n\'\n                        text = text + errmess\n            print (errmess)\n    if text[-1:]==\'\\n\':\n        text = text[:-1]\n    if status is None:\n        status = 0\n\n    if use_tee:\n        print (text)\n\n    return status, text\n\n\ndef test_nt(**kws):\n    pythonexe = get_pythonexe()\n    echo = find_executable(\'echo\')\n    using_cygwin_echo = echo != \'echo\'\n    if using_cygwin_echo:\n        log.warn(\'Using cygwin echo in win32 environment is not supported\')\n\n        s, o=exec_command(pythonexe\\\n                         +\' -c "import os;print os.environ.get(\\\'AAA\\\',\\\'\\\')"\')\n        assert s==0 and o==\'\', (s, o)\n\n        s, o=exec_command(pythonexe\\\n                         +\' -c "import os;print os.environ.get(\\\'AAA\\\')"\',\n                         AAA=\'Tere\')\n        assert s==0 and o==\'Tere\', (s, o)\n\n        os.environ[\'BBB\'] = \'Hi\'\n        s, o=exec_command(pythonexe\\\n                         +\' -c "import os;print os.environ.get(\\\'BBB\\\',\\\'\\\')"\')\n        assert s==0 and o==\'Hi\', (s, o)\n\n        s, o=exec_command(pythonexe\\\n                         +\' -c "import os;print os.environ.get(\\\'BBB\\\',\\\'\\\')"\',\n                         BBB=\'Hey\')\n        assert s==0 and o==\'Hey\', (s, o)\n\n        s, o=exec_command(pythonexe\\\n                         +\' -c "import os;print os.environ.get(\\\'BBB\\\',\\\'\\\')"\')\n        assert s==0 and o==\'Hi\', (s, o)\n    elif 0:\n        s, o=exec_command(\'echo Hello\')\n        assert s==0 and o==\'Hello\', (s, o)\n\n        s, o=exec_command(\'echo a%AAA%\')\n        assert s==0 and o==\'a\', (s, o)\n\n        s, o=exec_command(\'echo a%AAA%\', AAA=\'Tere\')\n        assert s==0 and o==\'aTere\', (s, o)\n\n        os.environ[\'BBB\'] = \'Hi\'\n        s, o=exec_command(\'echo a%BBB%\')\n        assert s==0 and o==\'aHi\', (s, o)\n\n        s, o=exec_command(\'echo a%BBB%\', BBB=\'Hey\')\n        assert s==0 and o==\'aHey\', (s, o)\n        s, o=exec_command(\'echo a%BBB%\')\n        assert s==0 and o==\'aHi\', (s, o)\n\n        s, o=exec_command(\'this_is_not_a_command\')\n        assert s and o!=\'\', (s, o)\n\n        s, o=exec_command(\'type not_existing_file\')\n        assert s and o!=\'\', (s, o)\n\n    s, o=exec_command(\'echo path=%path%\')\n    assert s==0 and o!=\'\', (s, o)\n\n    s, o=exec_command(\'%s -c "import sys;sys.stderr.write(sys.platform)"\' \\\n                     % pythonexe)\n    assert s==0 and o==\'win32\', (s, o)\n\n    s, o=exec_command(\'%s -c "raise \\\'Ignore me.\\\'"\' % pythonexe)\n    assert s==1 and o, (s, o)\n\n    s, o=exec_command(\'%s -c "import sys;sys.stderr.write(\\\'0\\\');sys.stderr.write(\\\'1\\\');sys.stderr.write(\\\'2\\\')"\'\\\n                     % pythonexe)\n    assert s==0 and o==\'012\', (s, o)\n\n    s, o=exec_command(\'%s -c "import sys;sys.exit(15)"\' % pythonexe)\n    assert s==15 and o==\'\', (s, o)\n\n    s, o=exec_command(\'%s -c "print \\\'Heipa\\\'"\' % pythonexe)\n    assert s==0 and o==\'Heipa\', (s, o)\n\n    print (\'ok\')\n\ndef test_posix(**kws):\n    s, o=exec_command("echo Hello",**kws)\n    assert s==0 and o==\'Hello\', (s, o)\n\n    s, o=exec_command(\'echo $AAA\',**kws)\n    assert s==0 and o==\'\', (s, o)\n\n    s, o=exec_command(\'echo "$AAA"\',AAA=\'Tere\',**kws)\n    assert s==0 and o==\'Tere\', (s, o)\n\n\n    s, o=exec_command(\'echo "$AAA"\',**kws)\n    assert s==0 and o==\'\', (s, o)\n\n    os.environ[\'BBB\'] = \'Hi\'\n    s, o=exec_command(\'echo "$BBB"\',**kws)\n    assert s==0 and o==\'Hi\', (s, o)\n\n    s, o=exec_command(\'echo "$BBB"\',BBB=\'Hey\',**kws)\n    assert s==0 and o==\'Hey\', (s, o)\n\n    s, o=exec_command(\'echo "$BBB"\',**kws)\n    assert s==0 and o==\'Hi\', (s, o)\n\n\n    s, o=exec_command(\'this_is_not_a_command\',**kws)\n    assert s!=0 and o!=\'\', (s, o)\n\n    s, o=exec_command(\'echo path=$PATH\',**kws)\n    assert s==0 and o!=\'\', (s, o)\n\n    s, o=exec_command(\'python -c "import sys,os;sys.stderr.write(os.name)"\',**kws)\n    assert s==0 and o==\'posix\', (s, o)\n\n    s, o=exec_command(\'python -c "raise \\\'Ignore me.\\\'"\',**kws)\n    assert s==1 and o, (s, o)\n\n    s, o=exec_command(\'python -c "import sys;sys.stderr.write(\\\'0\\\');sys.stderr.write(\\\'1\\\');sys.stderr.write(\\\'2\\\')"\',**kws)\n    assert s==0 and o==\'012\', (s, o)\n\n    s, o=exec_command(\'python -c "import sys;sys.exit(15)"\',**kws)\n    assert s==15 and o==\'\', (s, o)\n\n    s, o=exec_command(\'python -c "print \\\'Heipa\\\'"\',**kws)\n    assert s==0 and o==\'Heipa\', (s, o)\n\n    print (\'ok\')\n\ndef test_execute_in(**kws):\n    pythonexe = get_pythonexe()\n    tmpfile = temp_file_name()\n    fn = os.path.basename(tmpfile)\n    tmpdir = os.path.dirname(tmpfile)\n    f = open(tmpfile, \'w\')\n    f.write(\'Hello\')\n    f.close()\n\n    s, o = exec_command(\'%s -c "print \\\'Ignore the following IOError:\\\',\'\\\n                       \'open(%r,\\\'r\\\')"\' % (pythonexe, fn),**kws)\n    assert s and o!=\'\', (s, o)\n    s, o = exec_command(\'%s -c "print open(%r,\\\'r\\\').read()"\' % (pythonexe, fn),\n                       execute_in = tmpdir,**kws)\n    assert s==0 and o==\'Hello\', (s, o)\n    os.remove(tmpfile)\n    print (\'ok\')\n\ndef test_svn(**kws):\n    s, o = exec_command([\'svn\', \'status\'],**kws)\n    assert s, (s, o)\n    print (\'svn ok\')\n\ndef test_cl(**kws):\n    if os.name==\'nt\':\n        s, o = exec_command([\'cl\', \'/V\'],**kws)\n        assert s, (s, o)\n        print (\'cl ok\')\n\nif os.name==\'posix\':\n    test = test_posix\nelif os.name in [\'nt\', \'dos\']:\n    test = test_nt\nelse:\n    raise NotImplementedError(\'exec_command tests for \', os.name)\n\n\nif __name__ == "__main__":\n\n    test(use_tee=0)\n    test(use_tee=1)\n    test_execute_in(use_tee=0)\n    test_execute_in(use_tee=1)\n    test_svn(use_tee=1)\n    test_cl(use_tee=1)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport re\nfrom distutils.extension import Extension as old_Extension\n\nif sys.version_info[0] >= 3:\n    basestring = str\n\n\ncxx_ext_re = re.compile(r\'.*[.](cpp|cxx|cc)\\Z\', re.I).match\nfortran_pyf_ext_re = re.compile(r\'.*[.](f90|f95|f77|for|ftn|f|pyf)\\Z\', re.I).match\n\nclass Extension(old_Extension):\n    def __init__ (self, name, sources,\n                  include_dirs=None,\n                  define_macros=None,\n                  undef_macros=None,\n                  library_dirs=None,\n                  libraries=None,\n                  runtime_library_dirs=None,\n                  extra_objects=None,\n                  extra_compile_args=None,\n                  extra_link_args=None,\n                  export_symbols=None,\n                  swig_opts=None,\n                  depends=None,\n                  language=None,\n                  f2py_options=None,\n                  module_dirs=None,\n                  extra_f77_compile_args=None,\n                  extra_f90_compile_args=None,\n                 ):\n        old_Extension.__init__(self, name, [],\n                               include_dirs,\n                               define_macros,\n                               undef_macros,\n                               library_dirs,\n                               libraries,\n                               runtime_library_dirs,\n                               extra_objects,\n                               extra_compile_args,\n                               extra_link_args,\n                               export_symbols)\n                self.sources = sources\n\n                self.swig_opts = swig_opts or []\n                        if isinstance(self.swig_opts, basestring):\n            import warnings\n            msg = "swig_opts is specified as a string instead of a list"\n            warnings.warn(msg, SyntaxWarning)\n            self.swig_opts = self.swig_opts.split()\n\n                self.depends = depends or []\n        self.language = language\n\n                self.f2py_options = f2py_options or []\n        self.module_dirs = module_dirs or []\n        self.extra_f77_compile_args = extra_f77_compile_args or []\n        self.extra_f90_compile_args = extra_f90_compile_args or []\n\n        return\n\n    def has_cxx_sources(self):\n        for source in self.sources:\n            if cxx_ext_re(str(source)):\n                return True\n        return False\n\n    def has_f2py_sources(self):\n        for source in self.sources:\n            if fortran_pyf_ext_re(source):\n                return True\n        return False\n\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\n    \'apply_along_axis\', \'apply_over_axes\', \'atleast_1d\', \'atleast_2d\',\n    \'atleast_3d\', \'average\', \'clump_masked\', \'clump_unmasked\',\n    \'column_stack\', \'compress_cols\', \'compress_nd\', \'compress_rowcols\',\n    \'compress_rows\', \'count_masked\', \'corrcoef\', \'cov\', \'diagflat\', \'dot\',\n    \'dstack\', \'ediff1d\', \'flatnotmasked_contiguous\', \'flatnotmasked_edges\',\n    \'hsplit\', \'hstack\', \'in1d\', \'intersect1d\', \'mask_cols\', \'mask_rowcols\',\n    \'mask_rows\', \'masked_all\', \'masked_all_like\', \'median\', \'mr_\',\n    \'notmasked_contiguous\', \'notmasked_edges\', \'polyfit\', \'row_stack\',\n    \'setdiff1d\', \'setxor1d\', \'unique\', \'union1d\', \'vander\', \'vstack\',\n    ]\n\nimport itertools\nimport warnings\n\nfrom . import core as ma\nfrom .core import (\n    MaskedArray, MAError, add, array, asarray, concatenate, filled,\n    getmask, getmaskarray, make_mask_descr, masked, masked_array, mask_or,\n    nomask, ones, sort, zeros, getdata\n    )\n\nimport numpy as np\nfrom numpy import ndarray, array as nxarray\nimport numpy.core.umath as umath\nfrom numpy.lib.index_tricks import AxisConcatenator\n\n\ndef issequence(seq):\n    \n    if isinstance(seq, (ndarray, tuple, list)):\n        return True\n    return False\n\ndef count_masked(arr, axis=None):\n    \n    m = getmaskarray(arr)\n    return m.sum(axis)\n\ndef masked_all(shape, dtype=float):\n    \n    a = masked_array(np.empty(shape, dtype),\n                     mask=np.ones(shape, make_mask_descr(dtype)))\n    return a\n\ndef masked_all_like(arr):\n    \n    a = np.empty_like(arr).view(MaskedArray)\n    a._mask = np.ones(a.shape, dtype=make_mask_descr(a.dtype))\n    return a\n\n\nclass _fromnxfunction:\n    \n\n    def __init__(self, funcname):\n        self.__name__ = funcname\n        self.__doc__ = self.getdoc()\n\n    def getdoc(self):\n        \n        npfunc = getattr(np, self.__name__, None)\n        doc = getattr(npfunc, \'__doc__\', None)\n        if doc:\n            sig = self.__name__ + ma.get_object_signature(npfunc)\n            locdoc = "Notes\\n-----\\nThe function is applied to both the _data"\\\n                     " and the _mask, if any."\n            return \'\\n\'.join((sig, doc, locdoc))\n        return\n\n    def __call__(self, *args, **params):\n        func = getattr(np, self.__name__)\n        if len(args) == 1:\n            x = args[0]\n            if isinstance(x, ndarray):\n                _d = func(x.__array__(), **params)\n                _m = func(getmaskarray(x), **params)\n                return masked_array(_d, mask=_m)\n            elif isinstance(x, tuple) or isinstance(x, list):\n                _d = func(tuple([np.asarray(a) for a in x]), **params)\n                _m = func(tuple([getmaskarray(a) for a in x]), **params)\n                return masked_array(_d, mask=_m)\n        else:\n            arrays = []\n            args = list(args)\n            while len(args) > 0 and issequence(args[0]):\n                arrays.append(args.pop(0))\n            res = []\n            for x in arrays:\n                _d = func(np.asarray(x), *args, **params)\n                _m = func(getmaskarray(x), *args, **params)\n                res.append(masked_array(_d, mask=_m))\n            return res\n\natleast_1d = _fromnxfunction(\'atleast_1d\')\natleast_2d = _fromnxfunction(\'atleast_2d\')\natleast_3d = _fromnxfunction(\'atleast_3d\')\n\nvstack = row_stack = _fromnxfunction(\'vstack\')\nhstack = _fromnxfunction(\'hstack\')\ncolumn_stack = _fromnxfunction(\'column_stack\')\ndstack = _fromnxfunction(\'dstack\')\n\nhsplit = _fromnxfunction(\'hsplit\')\n\ndiagflat = _fromnxfunction(\'diagflat\')\n\n\ndef flatten_inplace(seq):\n    \n    k = 0\n    while (k != len(seq)):\n        while hasattr(seq[k], \'__iter__\'):\n            seq[k:(k + 1)] = seq[k]\n        k += 1\n    return seq\n\n\ndef apply_along_axis(func1d, axis, arr, *args, **kwargs):\n    \n    arr = array(arr, copy=False, subok=True)\n    nd = arr.ndim\n    if axis < 0:\n        axis += nd\n    if (axis >= nd):\n        raise ValueError("axis must be less than arr.ndim; axis=%d, rank=%d."\n            % (axis, nd))\n    ind = [0] * (nd - 1)\n    i = np.zeros(nd, \'O\')\n    indlist = list(range(nd))\n    indlist.remove(axis)\n    i[axis] = slice(None, None)\n    outshape = np.asarray(arr.shape).take(indlist)\n    i.put(indlist, ind)\n    j = i.copy()\n    res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n        asscalar = np.isscalar(res)\n    if not asscalar:\n        try:\n            len(res)\n        except TypeError:\n            asscalar = True\n                dtypes = []\n    if asscalar:\n        dtypes.append(np.asarray(res).dtype)\n        outarr = zeros(outshape, object)\n        outarr[tuple(ind)] = res\n        Ntot = np.product(outshape)\n        k = 1\n        while k < Ntot:\n                        ind[-1] += 1\n            n = -1\n            while (ind[n] >= outshape[n]) and (n > (1 - nd)):\n                ind[n - 1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(ind)] = res\n            dtypes.append(asarray(res).dtype)\n            k += 1\n    else:\n        res = array(res, copy=False, subok=True)\n        j = i.copy()\n        j[axis] = ([slice(None, None)] * res.ndim)\n        j.put(indlist, ind)\n        Ntot = np.product(outshape)\n        holdshape = outshape\n        outshape = list(arr.shape)\n        outshape[axis] = res.shape\n        dtypes.append(asarray(res).dtype)\n        outshape = flatten_inplace(outshape)\n        outarr = zeros(outshape, object)\n        outarr[tuple(flatten_inplace(j.tolist()))] = res\n        k = 1\n        while k < Ntot:\n                        ind[-1] += 1\n            n = -1\n            while (ind[n] >= holdshape[n]) and (n > (1 - nd)):\n                ind[n - 1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            j.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(flatten_inplace(j.tolist()))] = res\n            dtypes.append(asarray(res).dtype)\n            k += 1\n    max_dtypes = np.dtype(np.asarray(dtypes).max())\n    if not hasattr(arr, \'_mask\'):\n        result = np.asarray(outarr, dtype=max_dtypes)\n    else:\n        result = asarray(outarr, dtype=max_dtypes)\n        result.fill_value = ma.default_fill_value(result)\n    return result\napply_along_axis.__doc__ = np.apply_along_axis.__doc__\n\n\ndef apply_over_axes(func, a, axes):\n    \n    val = asarray(a)\n    N = a.ndim\n    if array(axes).ndim == 0:\n        axes = (axes,)\n    for axis in axes:\n        if axis < 0:\n            axis = N + axis\n        args = (val, axis)\n        res = func(*args)\n        if res.ndim == val.ndim:\n            val = res\n        else:\n            res = ma.expand_dims(res, axis)\n            if res.ndim == val.ndim:\n                val = res\n            else:\n                raise ValueError("function is not returning "\n                        "an array of the correct shape")\n    return val\n\nif apply_over_axes.__doc__ is not None:\n    apply_over_axes.__doc__ = np.apply_over_axes.__doc__[\n        :np.apply_over_axes.__doc__.find(\'Notes\')].rstrip() + \\\n    \n\n\ndef average(a, axis=None, weights=None, returned=False):\n    \n    a = asarray(a)\n    mask = a.mask\n    ash = a.shape\n    if ash == ():\n        ash = (1,)\n    if axis is None:\n        if mask is nomask:\n            if weights is None:\n                n = a.sum(axis=None)\n                d = float(a.size)\n            else:\n                w = filled(weights, 0.0).ravel()\n                n = umath.add.reduce(a._data.ravel() * w)\n                d = umath.add.reduce(w)\n                del w\n        else:\n            if weights is None:\n                n = a.filled(0).sum(axis=None)\n                d = float(umath.add.reduce((~mask).ravel()))\n            else:\n                w = array(filled(weights, 0.0), float, mask=mask).ravel()\n                n = add.reduce(a.ravel() * w)\n                d = add.reduce(w)\n                del w\n    else:\n        if mask is nomask:\n            if weights is None:\n                d = ash[axis] * 1.0\n                n = add.reduce(a._data, axis)\n            else:\n                w = filled(weights, 0.0)\n                wsh = w.shape\n                if wsh == ():\n                    wsh = (1,)\n                if wsh == ash:\n                    w = np.array(w, float, copy=0)\n                    n = add.reduce(a * w, axis)\n                    d = add.reduce(w, axis)\n                    del w\n                elif wsh == (ash[axis],):\n                    r = [None] * len(ash)\n                    r[axis] = slice(None, None, 1)\n                    w = eval("w[" + repr(tuple(r)) + "] * ones(ash, float)")\n                    n = add.reduce(a * w, axis)\n                    d = add.reduce(w, axis, dtype=float)\n                    del w, r\n                else:\n                    raise ValueError(\'average: weights wrong shape.\')\n        else:\n            if weights is None:\n                n = add.reduce(a, axis)\n                d = umath.add.reduce((~mask), axis=axis, dtype=float)\n            else:\n                w = filled(weights, 0.0)\n                wsh = w.shape\n                if wsh == ():\n                    wsh = (1,)\n                if wsh == ash:\n                    w = array(w, dtype=float, mask=mask, copy=0)\n                    n = add.reduce(a * w, axis)\n                    d = add.reduce(w, axis, dtype=float)\n                elif wsh == (ash[axis],):\n                    r = [None] * len(ash)\n                    r[axis] = slice(None, None, 1)\n                    w = eval("w[" + repr(tuple(r)) +\n                             "] * masked_array(ones(ash, float), mask)")\n                    n = add.reduce(a * w, axis)\n                    d = add.reduce(w, axis, dtype=float)\n                else:\n                    raise ValueError(\'average: weights wrong shape.\')\n                del w\n    if n is masked or d is masked:\n        return masked\n    result = n / d\n    del n\n\n    if isinstance(result, MaskedArray):\n        if ((axis is None) or (axis == 0 and a.ndim == 1)) and \\\n           (result.mask is nomask):\n            result = result._data\n        if returned:\n            if not isinstance(d, MaskedArray):\n                d = masked_array(d)\n            if isinstance(d, ndarray) and (not d.shape == result.shape):\n                d = ones(result.shape, dtype=float) * d\n    if returned:\n        return result, d\n    else:\n        return result\n\n\ndef median(a, axis=None, out=None, overwrite_input=False):\n    \n    if not hasattr(a, \'mask\') or np.count_nonzero(a.mask) == 0:\n        return masked_array(np.median(getdata(a, subok=True), axis=axis,\n                      out=out, overwrite_input=overwrite_input), copy=False)\n    if overwrite_input:\n        if axis is None:\n            asorted = a.ravel()\n            asorted.sort()\n        else:\n            a.sort(axis=axis)\n            asorted = a\n    else:\n        asorted = sort(a, axis=axis)\n    if axis is None:\n        axis = 0\n    elif axis < 0:\n        axis += a.ndim\n\n    counts = asorted.shape[axis] - (asorted.mask).sum(axis=axis)\n    h = counts // 2\n        axes_grid = [np.arange(x) for i, x in enumerate(asorted.shape)\n                 if i != axis]\n    ind = np.meshgrid(*axes_grid, sparse=True, indexing=\'ij\')\n        ind.insert(axis, h - 1)\n    low = asorted[ind]\n    ind[axis] = h\n    high = asorted[ind]\n        odd = counts % 2 == 1\n    if asorted.ndim == 1:\n        if odd:\n            low = high\n    else:\n        low[odd] = high[odd]\n\n    if np.issubdtype(asorted.dtype, np.inexact):\n                s = np.ma.sum([low, high], axis=0, out=out)\n        np.true_divide(s.data, 2., casting=\'unsafe\', out=s.data)\n    else:\n        s = np.ma.mean([low, high], axis=0, out=out)\n    return s\n\n\ndef compress_nd(x, axis=None):\n    \n    x = asarray(x)\n    m = getmask(x)\n        if isinstance(axis, int):\n        axis = (axis,)\n    elif axis is None:\n        axis = tuple(range(x.ndim))\n    elif not isinstance(axis, tuple):\n        raise ValueError(\'Invalid type for axis argument\')\n        axis = [ax + x.ndim if ax < 0 else ax for ax in axis]\n    if not all(0 <= ax < x.ndim for ax in axis):\n        raise ValueError("\'axis\' entry is out of bounds")\n    if len(axis) != len(set(axis)):\n        raise ValueError("duplicate value in \'axis\'")\n        if m is nomask or not m.any():\n        return x._data\n        if m.all():\n        return nxarray([])\n        data = x._data\n    for ax in axis:\n        axes = tuple(list(range(ax)) + list(range(ax + 1, x.ndim)))\n        data = data[(slice(None),)*ax + (~m.any(axis=axes),)]\n    return data\n\ndef compress_rowcols(x, axis=None):\n    \n    if asarray(x).ndim != 2:\n        raise NotImplementedError("compress_rowcols works for 2D arrays only.")\n    return compress_nd(x, axis=axis)\n\n\ndef compress_rows(a):\n    \n    a = asarray(a)\n    if a.ndim != 2:\n        raise NotImplementedError("compress_rows works for 2D arrays only.")\n    return compress_rowcols(a, 0)\n\ndef compress_cols(a):\n    \n    a = asarray(a)\n    if a.ndim != 2:\n        raise NotImplementedError("compress_cols works for 2D arrays only.")\n    return compress_rowcols(a, 1)\n\ndef mask_rowcols(a, axis=None):\n    \n    a = array(a, subok=False)\n    if a.ndim != 2:\n        raise NotImplementedError("mask_rowcols works for 2D arrays only.")\n    m = getmask(a)\n        if m is nomask or not m.any():\n        return a\n    maskedval = m.nonzero()\n    a._mask = a._mask.copy()\n    if not axis:\n        a[np.unique(maskedval[0])] = masked\n    if axis in [None, 1, -1]:\n        a[:, np.unique(maskedval[1])] = masked\n    return a\n\ndef mask_rows(a, axis=None):\n    \n    return mask_rowcols(a, 0)\n\ndef mask_cols(a, axis=None):\n    \n    return mask_rowcols(a, 1)\n\n\ndef dot(a, b, strict=False):\n    \n        if strict and (a.ndim == 2) and (b.ndim == 2):\n        a = mask_rows(a)\n        b = mask_cols(b)\n    return a.dot(b)\n\n\ndef ediff1d(arr, to_end=None, to_begin=None):\n    \n    arr = ma.asanyarray(arr).flat\n    ed = arr[1:] - arr[:-1]\n    arrays = [ed]\n        if to_begin is not None:\n        arrays.insert(0, to_begin)\n    if to_end is not None:\n        arrays.append(to_end)\n        if len(arrays) != 1:\n                        ed = hstack(arrays)\n        return ed\n\n\ndef unique(ar1, return_index=False, return_inverse=False):\n    \n    output = np.unique(ar1,\n                       return_index=return_index,\n                       return_inverse=return_inverse)\n    if isinstance(output, tuple):\n        output = list(output)\n        output[0] = output[0].view(MaskedArray)\n        output = tuple(output)\n    else:\n        output = output.view(MaskedArray)\n    return output\n\n\ndef intersect1d(ar1, ar2, assume_unique=False):\n    \n    if assume_unique:\n        aux = ma.concatenate((ar1, ar2))\n    else:\n                aux = ma.concatenate((unique(ar1), unique(ar2)))\n    aux.sort()\n    return aux[:-1][aux[1:] == aux[:-1]]\n\n\ndef setxor1d(ar1, ar2, assume_unique=False):\n    \n    if not assume_unique:\n        ar1 = unique(ar1)\n        ar2 = unique(ar2)\n\n    aux = ma.concatenate((ar1, ar2))\n    if aux.size == 0:\n        return aux\n    aux.sort()\n    auxf = aux.filled()\n    flag = ma.concatenate(([True], (auxf[1:] != auxf[:-1]), [True]))\n    flag2 = (flag[1:] == flag[:-1])\n    return aux[flag2]\n\ndef in1d(ar1, ar2, assume_unique=False, invert=False):\n    \n    if not assume_unique:\n        ar1, rev_idx = unique(ar1, return_inverse=True)\n        ar2 = unique(ar2)\n\n    ar = ma.concatenate((ar1, ar2))\n                order = ar.argsort(kind=\'mergesort\')\n    sar = ar[order]\n    if invert:\n        bool_ar = (sar[1:] != sar[:-1])\n    else:\n        bool_ar = (sar[1:] == sar[:-1])\n    flag = ma.concatenate((bool_ar, [invert]))\n    indx = order.argsort(kind=\'mergesort\')[:len(ar1)]\n\n    if assume_unique:\n        return flag[indx]\n    else:\n        return flag[indx][rev_idx]\n\n\ndef union1d(ar1, ar2):\n    \n    return unique(ma.concatenate((ar1, ar2)))\n\n\ndef setdiff1d(ar1, ar2, assume_unique=False):\n    \n    if assume_unique:\n        ar1 = ma.asarray(ar1).ravel()\n    else:\n        ar1 = unique(ar1)\n        ar2 = unique(ar2)\n    return ar1[in1d(ar1, ar2, assume_unique=True, invert=True)]\n\n\n\n\ndef _covhelper(x, y=None, rowvar=True, allow_masked=True):\n    \n    x = ma.array(x, ndmin=2, copy=True, dtype=float)\n    xmask = ma.getmaskarray(x)\n        if not allow_masked and xmask.any():\n        raise ValueError("Cannot process masked data.")\n        if x.shape[0] == 1:\n        rowvar = True\n        rowvar = int(bool(rowvar))\n    axis = 1 - rowvar\n    if rowvar:\n        tup = (slice(None), None)\n    else:\n        tup = (None, slice(None))\n        if y is None:\n        xnotmask = np.logical_not(xmask).astype(int)\n    else:\n        y = array(y, copy=False, ndmin=2, dtype=float)\n        ymask = ma.getmaskarray(y)\n        if not allow_masked and ymask.any():\n            raise ValueError("Cannot process masked data.")\n        if xmask.any() or ymask.any():\n            if y.shape == x.shape:\n                                common_mask = np.logical_or(xmask, ymask)\n                if common_mask is not nomask:\n                    x.unshare_mask()\n                    y.unshare_mask()\n                    xmask = x._mask = y._mask = ymask = common_mask\n        x = ma.concatenate((x, y), axis)\n        xnotmask = np.logical_not(np.concatenate((xmask, ymask), axis)).astype(int)\n    x -= x.mean(axis=rowvar)[tup]\n    return (x, xnotmask, rowvar)\n\n\ndef cov(x, y=None, rowvar=True, bias=False, allow_masked=True, ddof=None):\n    \n        if ddof is not None and ddof != int(ddof):\n        raise ValueError("ddof must be an integer")\n        if ddof is None:\n        if bias:\n            ddof = 0\n        else:\n            ddof = 1\n\n    (x, xnotmask, rowvar) = _covhelper(x, y, rowvar, allow_masked)\n    if not rowvar:\n        fact = np.dot(xnotmask.T, xnotmask) * 1. - ddof\n        result = (dot(x.T, x.conj(), strict=False) / fact).squeeze()\n    else:\n        fact = np.dot(xnotmask, xnotmask.T) * 1. - ddof\n        result = (dot(x, x.T.conj(), strict=False) / fact).squeeze()\n    return result\n\n\ndef corrcoef(x, y=None, rowvar=True, bias=np._NoValue, allow_masked=True,\n             ddof=np._NoValue):\n    \n    msg = \'bias and ddof have no effect and are deprecated\'\n    if bias is not np._NoValue or ddof is not np._NoValue:\n                warnings.warn(msg, DeprecationWarning)\n        (x, xnotmask, rowvar) = _covhelper(x, y, rowvar, allow_masked)\n        if not rowvar:\n        fact = np.dot(xnotmask.T, xnotmask) * 1.\n        c = (dot(x.T, x.conj(), strict=False) / fact).squeeze()\n    else:\n        fact = np.dot(xnotmask, xnotmask.T) * 1.\n        c = (dot(x, x.T.conj(), strict=False) / fact).squeeze()\n        try:\n        diag = ma.diagonal(c)\n    except ValueError:\n        return 1\n        if xnotmask.all():\n        _denom = ma.sqrt(ma.multiply.outer(diag, diag))\n    else:\n        _denom = diagflat(diag)\n        n = x.shape[1 - rowvar]\n        if rowvar:\n            for i in range(n - 1):\n                for j in range(i + 1, n):\n                    _x = mask_cols(vstack((x[i], x[j]))).var(axis=1)\n                    _denom[i, j] = _denom[j, i] = ma.sqrt(ma.multiply.reduce(_x))\n        else:\n            for i in range(n - 1):\n                for j in range(i + 1, n):\n                    _x = mask_cols(\n                            vstack((x[:, i], x[:, j]))).var(axis=1)\n                    _denom[i, j] = _denom[j, i] = ma.sqrt(ma.multiply.reduce(_x))\n    return c / _denom\n\n\nclass MAxisConcatenator(AxisConcatenator):\n    \n\n    def __init__(self, axis=0):\n        AxisConcatenator.__init__(self, axis, matrix=False)\n\n    def __getitem__(self, key):\n        if isinstance(key, str):\n            raise MAError("Unavailable for masked array.")\n        if not isinstance(key, tuple):\n            key = (key,)\n        objs = []\n        scalars = []\n        final_dtypedescr = None\n        for k in range(len(key)):\n            scalar = False\n            if isinstance(key[k], slice):\n                step = key[k].step\n                start = key[k].start\n                stop = key[k].stop\n                if start is None:\n                    start = 0\n                if step is None:\n                    step = 1\n                if isinstance(step, complex):\n                    size = int(abs(step))\n                    newobj = np.linspace(start, stop, num=size)\n                else:\n                    newobj = np.arange(start, stop, step)\n            elif isinstance(key[k], str):\n                if (key[k] in \'rc\'):\n                    self.matrix = True\n                    self.col = (key[k] == \'c\')\n                    continue\n                try:\n                    self.axis = int(key[k])\n                    continue\n                except (ValueError, TypeError):\n                    raise ValueError("Unknown special directive")\n            elif type(key[k]) in np.ScalarType:\n                newobj = asarray([key[k]])\n                scalars.append(k)\n                scalar = True\n            else:\n                newobj = key[k]\n            objs.append(newobj)\n            if isinstance(newobj, ndarray) and not scalar:\n                if final_dtypedescr is None:\n                    final_dtypedescr = newobj.dtype\n                elif newobj.dtype > final_dtypedescr:\n                    final_dtypedescr = newobj.dtype\n        if final_dtypedescr is not None:\n            for k in scalars:\n                objs[k] = objs[k].astype(final_dtypedescr)\n        res = concatenate(tuple(objs), axis=self.axis)\n        return self._retval(res)\n\nclass mr_class(MAxisConcatenator):\n    \n    def __init__(self):\n        MAxisConcatenator.__init__(self, 0)\n\nmr_ = mr_class()\n\n\ndef flatnotmasked_edges(a):\n    \n    m = getmask(a)\n    if m is nomask or not np.any(m):\n        return np.array([0, a.size - 1])\n    unmasked = np.flatnonzero(~m)\n    if len(unmasked) > 0:\n        return unmasked[[0, -1]]\n    else:\n        return None\n\n\ndef notmasked_edges(a, axis=None):\n    \n    a = asarray(a)\n    if axis is None or a.ndim == 1:\n        return flatnotmasked_edges(a)\n    m = getmaskarray(a)\n    idx = array(np.indices(a.shape), mask=np.asarray([m] * a.ndim))\n    return [tuple([idx[i].min(axis).compressed() for i in range(a.ndim)]),\n            tuple([idx[i].max(axis).compressed() for i in range(a.ndim)]), ]\n\n\ndef flatnotmasked_contiguous(a):\n    \n    m = getmask(a)\n    if m is nomask:\n        return slice(0, a.size, None)\n    i = 0\n    result = []\n    for (k, g) in itertools.groupby(m.ravel()):\n        n = len(list(g))\n        if not k:\n            result.append(slice(i, i + n))\n        i += n\n    return result or None\n\ndef notmasked_contiguous(a, axis=None):\n    \n    a = asarray(a)\n    nd = a.ndim\n    if nd > 2:\n        raise NotImplementedError("Currently limited to atmost 2D array.")\n    if axis is None or nd == 1:\n        return flatnotmasked_contiguous(a)\n        result = []\n        other = (axis + 1) % 2\n    idx = [0, 0]\n    idx[axis] = slice(None, None)\n        for i in range(a.shape[other]):\n        idx[other] = i\n        result.append(flatnotmasked_contiguous(a[idx]) or None)\n    return result\n\n\ndef _ezclump(mask):\n    \n    if mask.ndim > 1:\n        mask = mask.ravel()\n    idx = (mask[1:] ^ mask[:-1]).nonzero()\n    idx = idx[0] + 1\n\n    if mask[0]:\n        if len(idx) == 0:\n            return [slice(0, mask.size)]\n\n        r = [slice(0, idx[0])]\n        r.extend((slice(left, right)\n                  for left, right in zip(idx[1:-1:2], idx[2::2])))\n    else:\n        if len(idx) == 0:\n            return []\n\n        r = [slice(left, right) for left, right in zip(idx[:-1:2], idx[1::2])]\n\n    if mask[-1]:\n        r.append(slice(idx[-1], mask.size))\n    return r\n\n\ndef clump_unmasked(a):\n    \n    mask = getattr(a, \'_mask\', nomask)\n    if mask is nomask:\n        return [slice(0, a.size)]\n    return _ezclump(~mask)\n\n\ndef clump_masked(a):\n    \n    mask = ma.getmask(a)\n    if mask is nomask:\n        return []\n    return _ezclump(mask)\n\n\n\n\ndef vander(x, n=None):\n    \n    _vander = np.vander(x, n)\n    m = getmask(x)\n    if m is not nomask:\n        _vander[m] = 0\n    return _vander\n\nvander.__doc__ = ma.doc_note(np.vander.__doc__, vander.__doc__)\n\n\ndef polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False):\n    \n    x = asarray(x)\n    y = asarray(y)\n\n    m = getmask(x)\n    if y.ndim == 1:\n        m = mask_or(m, getmask(y))\n    elif y.ndim == 2:\n        my = getmask(mask_rows(y))\n        if my is not nomask:\n            m = mask_or(m, my[:, 0])\n    else:\n        raise TypeError("Expected a 1D or 2D array for y!")\n\n    if w is not None:\n        w = asarray(w)\n        if w.ndim != 1:\n            raise TypeError("expected a 1-d array for weights")\n        if w.shape[0] != y.shape[0]:\n            raise TypeError("expected w and y to have the same length")\n        m = mask_or(m, getmask(w))\n\n    if m is not nomask:\n        not_m = ~m\n        if w is not None:\n            w = w[not_m]\n        return np.polyfit(x[not_m], y[not_m], deg, rcond, full, w, cov)\n    else:\n        return np.polyfit(x, y, deg, rcond, full, w, cov)\n\npolyfit.__doc__ = ma.doc_note(np.polyfit.__doc__, polyfit.__doc__)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport os\nimport pprint\nimport re\n\nfrom . import crackfortran\nfrom . import rules\nfrom . import cb_rules\nfrom . import auxfuncs\nfrom . import cfuncs\nfrom . import f90mod_rules\nfrom . import __version__\n\nf2py_version = __version__.version\nerrmess = sys.stderr.write\nshow = pprint.pprint\noutmess = auxfuncs.outmess\n\ntry:\n    from numpy import __version__ as numpy_version\nexcept ImportError:\n    numpy_version = \'N/A\'\n\n__usage__ =  % (f2py_version, numpy_version)\n\n\ndef scaninputline(inputline):\n    files, skipfuncs, onlyfuncs, debug = [], [], [], []\n    f, f2, f3, f5, f6, f7, f8, f9 = 1, 0, 0, 0, 0, 0, 0, 0\n    verbose = 1\n    dolc = -1\n    dolatexdoc = 0\n    dorestdoc = 0\n    wrapfuncs = 1\n    buildpath = \'.\'\n    include_paths = []\n    signsfile, modulename = None, None\n    options = {\'buildpath\': buildpath,\n               \'coutput\': None,\n               \'f2py_wrapper_output\': None}\n    for l in inputline:\n        if l == \'\':\n            pass\n        elif l == \'only:\':\n            f = 0\n        elif l == \'skip:\':\n            f = -1\n        elif l == \':\':\n            f = 1\n        elif l[:8] == \'--debug-\':\n            debug.append(l[8:])\n        elif l == \'--lower\':\n            dolc = 1\n        elif l == \'--build-dir\':\n            f6 = 1\n        elif l == \'--no-lower\':\n            dolc = 0\n        elif l == \'--quiet\':\n            verbose = 0\n        elif l == \'--verbose\':\n            verbose += 1\n        elif l == \'--latex-doc\':\n            dolatexdoc = 1\n        elif l == \'--no-latex-doc\':\n            dolatexdoc = 0\n        elif l == \'--rest-doc\':\n            dorestdoc = 1\n        elif l == \'--no-rest-doc\':\n            dorestdoc = 0\n        elif l == \'--wrap-functions\':\n            wrapfuncs = 1\n        elif l == \'--no-wrap-functions\':\n            wrapfuncs = 0\n        elif l == \'--short-latex\':\n            options[\'shortlatex\'] = 1\n        elif l == \'--coutput\':\n            f8 = 1\n        elif l == \'--f2py-wrapper-output\':\n            f9 = 1\n        elif l == \'--overwrite-signature\':\n            options[\'h-overwrite\'] = 1\n        elif l == \'-h\':\n            f2 = 1\n        elif l == \'-m\':\n            f3 = 1\n        elif l[:2] == \'-v\':\n            print(f2py_version)\n            sys.exit()\n        elif l == \'--show-compilers\':\n            f5 = 1\n        elif l[:8] == \'-include\':\n            cfuncs.outneeds[\'userincludes\'].append(l[9:-1])\n            cfuncs.userincludes[l[9:-1]] = \'        elif l[:15] in \'--include_paths\':\n            outmess(\n                \'f2py option --include_paths is deprecated, use --include-paths instead.\\n\')\n            f7 = 1\n        elif l[:15] in \'--include-paths\':\n            f7 = 1\n        elif l[0] == \'-\':\n            errmess(\'Unknown option %s\\n\' % repr(l))\n            sys.exit()\n        elif f2:\n            f2 = 0\n            signsfile = l\n        elif f3:\n            f3 = 0\n            modulename = l\n        elif f6:\n            f6 = 0\n            buildpath = l\n        elif f7:\n            f7 = 0\n            include_paths.extend(l.split(os.pathsep))\n        elif f8:\n            f8 = 0\n            options["coutput"] = l\n        elif f9:\n            f9 = 0\n            options["f2py_wrapper_output"] = l\n        elif f == 1:\n            try:\n                open(l).close()\n                files.append(l)\n            except IOError as detail:\n                errmess(\'IOError: %s. Skipping file "%s".\\n\' %\n                        (str(detail), l))\n        elif f == -1:\n            skipfuncs.append(l)\n        elif f == 0:\n            onlyfuncs.append(l)\n    if not f5 and not files and not modulename:\n        print(__usage__)\n        sys.exit()\n    if not os.path.isdir(buildpath):\n        if not verbose:\n            outmess(\'Creating build directory %s\' % (buildpath))\n        os.mkdir(buildpath)\n    if signsfile:\n        signsfile = os.path.join(buildpath, signsfile)\n    if signsfile and os.path.isfile(signsfile) and \'h-overwrite\' not in options:\n        errmess(\n            \'Signature file "%s" exists!!! Use --overwrite-signature to overwrite.\\n\' % (signsfile))\n        sys.exit()\n\n    options[\'debug\'] = debug\n    options[\'verbose\'] = verbose\n    if dolc == -1 and not signsfile:\n        options[\'do-lower\'] = 0\n    else:\n        options[\'do-lower\'] = dolc\n    if modulename:\n        options[\'module\'] = modulename\n    if signsfile:\n        options[\'signsfile\'] = signsfile\n    if onlyfuncs:\n        options[\'onlyfuncs\'] = onlyfuncs\n    if skipfuncs:\n        options[\'skipfuncs\'] = skipfuncs\n    options[\'dolatexdoc\'] = dolatexdoc\n    options[\'dorestdoc\'] = dorestdoc\n    options[\'wrapfuncs\'] = wrapfuncs\n    options[\'buildpath\'] = buildpath\n    options[\'include_paths\'] = include_paths\n    return files, options\n\n\ndef callcrackfortran(files, options):\n    rules.options = options\n    crackfortran.debug = options[\'debug\']\n    crackfortran.verbose = options[\'verbose\']\n    if \'module\' in options:\n        crackfortran.f77modulename = options[\'module\']\n    if \'skipfuncs\' in options:\n        crackfortran.skipfuncs = options[\'skipfuncs\']\n    if \'onlyfuncs\' in options:\n        crackfortran.onlyfuncs = options[\'onlyfuncs\']\n    crackfortran.include_paths[:] = options[\'include_paths\']\n    crackfortran.dolowercase = options[\'do-lower\']\n    postlist = crackfortran.crackfortran(files)\n    if \'signsfile\' in options:\n        outmess(\'Saving signatures to file "%s"\\n\' % (options[\'signsfile\']))\n        pyf = crackfortran.crack2fortran(postlist)\n        if options[\'signsfile\'][-6:] == \'stdout\':\n            sys.stdout.write(pyf)\n        else:\n            f = open(options[\'signsfile\'], \'w\')\n            f.write(pyf)\n            f.close()\n    if options["coutput"] is None:\n        for mod in postlist:\n            mod["coutput"] = "%smodule.c" % mod["name"]\n    else:\n        for mod in postlist:\n            mod["coutput"] = options["coutput"]\n    if options["f2py_wrapper_output"] is None:\n        for mod in postlist:\n            mod["f2py_wrapper_output"] = "%s-f2pywrappers.f" % mod["name"]\n    else:\n        for mod in postlist:\n            mod["f2py_wrapper_output"] = options["f2py_wrapper_output"]\n    return postlist\n\n\ndef buildmodules(lst):\n    cfuncs.buildcfuncs()\n    outmess(\'Building modules...\\n\')\n    modules, mnames, isusedby = [], [], {}\n    for i in range(len(lst)):\n        if \'__user__\' in lst[i][\'name\']:\n            cb_rules.buildcallbacks(lst[i])\n        else:\n            if \'use\' in lst[i]:\n                for u in lst[i][\'use\'].keys():\n                    if u not in isusedby:\n                        isusedby[u] = []\n                    isusedby[u].append(lst[i][\'name\'])\n            modules.append(lst[i])\n            mnames.append(lst[i][\'name\'])\n    ret = {}\n    for i in range(len(mnames)):\n        if mnames[i] in isusedby:\n            outmess(\'\\tSkipping module "%s" which is used by %s.\\n\' % (\n                mnames[i], \',\'.join([\'"%s"\' % s for s in isusedby[mnames[i]]])))\n        else:\n            um = []\n            if \'use\' in modules[i]:\n                for u in modules[i][\'use\'].keys():\n                    if u in isusedby and u in mnames:\n                        um.append(modules[mnames.index(u)])\n                    else:\n                        outmess(\n                            \'\\tModule "%s" uses nonexisting "%s" which will be ignored.\\n\' % (mnames[i], u))\n            ret[mnames[i]] = {}\n            dict_append(ret[mnames[i]], rules.buildmodule(modules[i], um))\n    return ret\n\n\ndef dict_append(d_out, d_in):\n    for (k, v) in d_in.items():\n        if k not in d_out:\n            d_out[k] = []\n        if isinstance(v, list):\n            d_out[k] = d_out[k] + v\n        else:\n            d_out[k].append(v)\n\n\ndef run_main(comline_list):\n    \n    crackfortran.reset_global_f2py_vars()\n    f2pydir = os.path.dirname(os.path.abspath(cfuncs.__file__))\n    fobjhsrc = os.path.join(f2pydir, \'src\', \'fortranobject.h\')\n    fobjcsrc = os.path.join(f2pydir, \'src\', \'fortranobject.c\')\n    files, options = scaninputline(comline_list)\n    auxfuncs.options = options\n    postlist = callcrackfortran(files, options)\n    isusedby = {}\n    for i in range(len(postlist)):\n        if \'use\' in postlist[i]:\n            for u in postlist[i][\'use\'].keys():\n                if u not in isusedby:\n                    isusedby[u] = []\n                isusedby[u].append(postlist[i][\'name\'])\n    for i in range(len(postlist)):\n        if postlist[i][\'block\'] == \'python module\' and \'__user__\' in postlist[i][\'name\']:\n            if postlist[i][\'name\'] in isusedby:\n                                outmess(\'Skipping Makefile build for module "%s" which is used by %s\\n\' % (\n                    postlist[i][\'name\'], \',\'.join([\'"%s"\' % s for s in isusedby[postlist[i][\'name\']]])))\n    if \'signsfile\' in options:\n        if options[\'verbose\'] > 1:\n            outmess(\n                \'Stopping. Edit the signature file and then run f2py on the signature file: \')\n            outmess(\'%s %s\\n\' %\n                    (os.path.basename(sys.argv[0]), options[\'signsfile\']))\n        return\n    for i in range(len(postlist)):\n        if postlist[i][\'block\'] != \'python module\':\n            if \'python module\' not in options:\n                errmess(\n                    \'Tip: If your original code is Fortran source then you must use -m option.\\n\')\n            raise TypeError(\'All blocks must be python module blocks but got %s\' % (\n                repr(postlist[i][\'block\'])))\n    auxfuncs.debugoptions = options[\'debug\']\n    f90mod_rules.options = options\n    auxfuncs.wrapfuncs = options[\'wrapfuncs\']\n\n    ret = buildmodules(postlist)\n\n    for mn in ret.keys():\n        dict_append(ret[mn], {\'csrc\': fobjcsrc, \'h\': fobjhsrc})\n    return ret\n\n\ndef filter_files(prefix, suffix, files, remove_prefix=None):\n    \n    filtered, rest = [], []\n    match = re.compile(prefix + r\'.*\' + suffix + r\'\\Z\').match\n    if remove_prefix:\n        ind = len(prefix)\n    else:\n        ind = 0\n    for file in [x.strip() for x in files]:\n        if match(file):\n            filtered.append(file[ind:])\n        else:\n            rest.append(file)\n    return filtered, rest\n\n\ndef get_prefix(module):\n    p = os.path.dirname(os.path.dirname(module.__file__))\n    return p\n\n\ndef run_compile():\n    \n    import tempfile\n\n    i = sys.argv.index(\'-c\')\n    del sys.argv[i]\n\n    remove_build_dir = 0\n    try:\n        i = sys.argv.index(\'--build-dir\')\n    except ValueError:\n        i = None\n    if i is not None:\n        build_dir = sys.argv[i + 1]\n        del sys.argv[i + 1]\n        del sys.argv[i]\n    else:\n        remove_build_dir = 1\n        build_dir = tempfile.mkdtemp()\n\n    _reg1 = re.compile(r\'[-][-]link[-]\')\n    sysinfo_flags = [_m for _m in sys.argv[1:] if _reg1.match(_m)]\n    sys.argv = [_m for _m in sys.argv if _m not in sysinfo_flags]\n    if sysinfo_flags:\n        sysinfo_flags = [f[7:] for f in sysinfo_flags]\n\n    _reg2 = re.compile(\n        r\'[-][-]((no[-]|)(wrap[-]functions|lower)|debug[-]capi|quiet)|[-]include\')\n    f2py_flags = [_m for _m in sys.argv[1:] if _reg2.match(_m)]\n    sys.argv = [_m for _m in sys.argv if _m not in f2py_flags]\n    f2py_flags2 = []\n    fl = 0\n    for a in sys.argv[1:]:\n        if a in [\'only:\', \'skip:\']:\n            fl = 1\n        elif a == \':\':\n            fl = 0\n        if fl or a == \':\':\n            f2py_flags2.append(a)\n    if f2py_flags2 and f2py_flags2[-1] != \':\':\n        f2py_flags2.append(\':\')\n    f2py_flags.extend(f2py_flags2)\n\n    sys.argv = [_m for _m in sys.argv if _m not in f2py_flags2]\n    _reg3 = re.compile(\n        r\'[-][-]((f(90)?compiler([-]exec|)|compiler)=|help[-]compiler)\')\n    flib_flags = [_m for _m in sys.argv[1:] if _reg3.match(_m)]\n    sys.argv = [_m for _m in sys.argv if _m not in flib_flags]\n    _reg4 = re.compile(\n        r\'[-][-]((f(77|90)(flags|exec)|opt|arch)=|(debug|noopt|noarch|help[-]fcompiler))\')\n    fc_flags = [_m for _m in sys.argv[1:] if _reg4.match(_m)]\n    sys.argv = [_m for _m in sys.argv if _m not in fc_flags]\n\n    if 1:\n        del_list = []\n        for s in flib_flags:\n            v = \'--fcompiler=\'\n            if s[:len(v)] == v:\n                from numpy.distutils import fcompiler\n                fcompiler.load_all_fcompiler_classes()\n                allowed_keys = list(fcompiler.fcompiler_class.keys())\n                nv = ov = s[len(v):].lower()\n                if ov not in allowed_keys:\n                    vmap = {}                      try:\n                        nv = vmap[ov]\n                    except KeyError:\n                        if ov not in vmap.values():\n                            print(\'Unknown vendor: "%s"\' % (s[len(v):]))\n                    nv = ov\n                i = flib_flags.index(s)\n                flib_flags[i] = \'--fcompiler=\' + nv\n                continue\n        for s in del_list:\n            i = flib_flags.index(s)\n            del flib_flags[i]\n        assert len(flib_flags) <= 2, repr(flib_flags)\n\n    _reg5 = re.compile(r\'[-][-](verbose)\')\n    setup_flags = [_m for _m in sys.argv[1:] if _reg5.match(_m)]\n    sys.argv = [_m for _m in sys.argv if _m not in setup_flags]\n\n    if \'--quiet\' in f2py_flags:\n        setup_flags.append(\'--quiet\')\n\n    modulename = \'untitled\'\n    sources = sys.argv[1:]\n\n    for optname in [\'--include_paths\', \'--include-paths\']:\n        if optname in sys.argv:\n            i = sys.argv.index(optname)\n            f2py_flags.extend(sys.argv[i:i + 2])\n            del sys.argv[i + 1], sys.argv[i]\n            sources = sys.argv[1:]\n\n    if \'-m\' in sys.argv:\n        i = sys.argv.index(\'-m\')\n        modulename = sys.argv[i + 1]\n        del sys.argv[i + 1], sys.argv[i]\n        sources = sys.argv[1:]\n    else:\n        from numpy.distutils.command.build_src import get_f2py_modulename\n        pyf_files, sources = filter_files(\'\', \'[.]pyf([.]src|)\', sources)\n        sources = pyf_files + sources\n        for f in pyf_files:\n            modulename = get_f2py_modulename(f)\n            if modulename:\n                break\n\n    extra_objects, sources = filter_files(\'\', \'[.](o|a|so)\', sources)\n    include_dirs, sources = filter_files(\'-I\', \'\', sources, remove_prefix=1)\n    library_dirs, sources = filter_files(\'-L\', \'\', sources, remove_prefix=1)\n    libraries, sources = filter_files(\'-l\', \'\', sources, remove_prefix=1)\n    undef_macros, sources = filter_files(\'-U\', \'\', sources, remove_prefix=1)\n    define_macros, sources = filter_files(\'-D\', \'\', sources, remove_prefix=1)\n    for i in range(len(define_macros)):\n        name_value = define_macros[i].split(\'=\', 1)\n        if len(name_value) == 1:\n            name_value.append(None)\n        if len(name_value) == 2:\n            define_macros[i] = tuple(name_value)\n        else:\n            print(\'Invalid use of -D:\', name_value)\n\n    from numpy.distutils.system_info import get_info\n\n    num_info = {}\n    if num_info:\n        include_dirs.extend(num_info.get(\'include_dirs\', []))\n\n    from numpy.distutils.core import setup, Extension\n    ext_args = {\'name\': modulename, \'sources\': sources,\n                \'include_dirs\': include_dirs,\n                \'library_dirs\': library_dirs,\n                \'libraries\': libraries,\n                \'define_macros\': define_macros,\n                \'undef_macros\': undef_macros,\n                \'extra_objects\': extra_objects,\n                \'f2py_options\': f2py_flags,\n                }\n\n    if sysinfo_flags:\n        from numpy.distutils.misc_util import dict_append\n        for n in sysinfo_flags:\n            i = get_info(n)\n            if not i:\n                outmess(\'No %s resources found in system\'\n                        \' (try `f2py --help-link`)\\n\' % (repr(n)))\n            dict_append(ext_args, **i)\n\n    ext = Extension(**ext_args)\n    sys.argv = [sys.argv[0]] + setup_flags\n    sys.argv.extend([\'build\',\n                     \'--build-temp\', build_dir,\n                     \'--build-base\', build_dir,\n                     \'--build-platlib\', \'.\'])\n    if fc_flags:\n        sys.argv.extend([\'config_fc\'] + fc_flags)\n    if flib_flags:\n        sys.argv.extend([\'build_ext\'] + flib_flags)\n\n    setup(ext_modules=[ext])\n\n    if remove_build_dir and os.path.exists(build_dir):\n        import shutil\n        outmess(\'Removing build directory %s\\n\' % (build_dir))\n        shutil.rmtree(build_dir)\n\n\ndef main():\n    if \'--help-link\' in sys.argv[1:]:\n        sys.argv.remove(\'--help-link\')\n        from numpy.distutils.system_info import show_all\n        show_all()\n        return\n    if \'-c\' in sys.argv[1:]:\n        run_compile()\n    else:\n        run_main(sys.argv[1:])\n\n\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport re\n\nfrom numpy.testing.utils import jiffies, memusage\n\n\ndef cmdline():\n    m = re.compile(r\'\\A\\d+\\Z\')\n    args = []\n    repeat = 1\n    for a in sys.argv[1:]:\n        if m.match(a):\n            repeat = eval(a)\n        else:\n            args.append(a)\n    f2py_opts = \' \'.join(args)\n    return repeat, f2py_opts\n\n\ndef run(runtest, test_functions, repeat=1):\n    l = [(t, repr(t.__doc__.split(\'\\n\')[1].strip())) for t in test_functions]\n    start_memusage = memusage()\n    diff_memusage = None\n    start_jiffies = jiffies()\n    i = 0\n    while i < repeat:\n        i += 1\n        for t, fname in l:\n            runtest(t)\n            if start_memusage is None:\n                continue\n            if diff_memusage is None:\n                diff_memusage = memusage() - start_memusage\n            else:\n                diff_memusage2 = memusage() - start_memusage\n                if diff_memusage2 != diff_memusage:\n                    print(\'memory usage change at step %i:\' % i,\n                          diff_memusage2 - diff_memusage,\n                          fname)\n                    diff_memusage = diff_memusage2\n    current_memusage = memusage()\n    print(\'run\', repeat * len(test_functions), \'tests\',\n          \'in %.2f seconds\' % ((jiffies() - start_jiffies) / 100.0))\n    if start_memusage:\n        print(\'initial virtual memory size:\', start_memusage, \'bytes\')\n        print(\'current virtual memory size:\', current_memusage, \'bytes\')\n\nfrom __future__ import division, absolute_import, print_function\n\n__version__ = "$Revision: 1.27 $"[10:-1]\n\nf2py_version = \'See `f2py -v`\'\n\nimport numpy as np\n\nfrom .auxfuncs import (\n    applyrules, dictappend, hasbody, hasnote, isallocatable, isfunction,\n    isintent_hide, ismodule, isprivate, isroutine, isstringarray, l_or,\n    outmess\n)\nfrom . import capi_maps\nfrom . import func2subr\nfrom .crackfortran import undo_rmbadname, undo_rmbadname1\n\noptions = {}\n\n\ndef findf90modules(m):\n    if ismodule(m):\n        return [m]\n    if not hasbody(m):\n        return []\n    ret = []\n    for b in m[\'body\']:\n        if ismodule(b):\n            ret.append(b)\n        else:\n            ret = ret + findf90modules(b)\n    return ret\n\nfgetdims1 =  % np.intp().itemsize\n\nfgetdims2 = \n\nfgetdims2_sa = \n\n\ndef buildhooks(pymod):\n    global fgetdims1, fgetdims2\n    from . import rules\n    ret = {\'f90modhooks\': [], \'initf90modhooks\': [], \'body\': [],\n           \'need\': [\'F_FUNC\', \'arrayobject.h\'],\n           \'separatorsfor\': {\'includes0\': \'\\n\', \'includes\': \'\\n\'},\n           \'docs\': [\'"Fortran 90/95 modules:\\\\n"\'],\n           \'latexdoc\': []}\n    fhooks = [\'\']\n\n    def fadd(line, s=fhooks):\n        s[0] = \'%s\\n      %s\' % (s[0], line)\n    doc = [\'\']\n\n    def dadd(line, s=doc):\n        s[0] = \'%s\\n%s\' % (s[0], line)\n    for m in findf90modules(pymod):\n        sargs, fargs, efargs, modobjs, notvars, onlyvars = [], [], [], [], [\n            m[\'name\']], []\n        sargsp = []\n        ifargs = []\n        mfargs = []\n        if hasbody(m):\n            for b in m[\'body\']:\n                notvars.append(b[\'name\'])\n        for n in m[\'vars\'].keys():\n            var = m[\'vars\'][n]\n            if (n not in notvars) and (not l_or(isintent_hide, isprivate)(var)):\n                onlyvars.append(n)\n                mfargs.append(n)\n        outmess(\'\\t\\tConstructing F90 module support for "%s"...\\n\' %\n                (m[\'name\']))\n        if onlyvars:\n            outmess(\'\\t\\t  Variables: %s\\n\' % (\' \'.join(onlyvars)))\n        chooks = [\'\']\n\n        def cadd(line, s=chooks):\n            s[0] = \'%s\\n%s\' % (s[0], line)\n        ihooks = [\'\']\n\n        def iadd(line, s=ihooks):\n            s[0] = \'%s\\n%s\' % (s[0], line)\n\n        vrd = capi_maps.modsign2map(m)\n        cadd(\'static FortranDataDef f2py_%s_def[] = {\' % (m[\'name\']))\n        dadd(\'\\\\subsection{Fortran 90/95 module \\\\texttt{%s}}\\n\' % (m[\'name\']))\n        if hasnote(m):\n            note = m[\'note\']\n            if isinstance(note, list):\n                note = \'\\n\'.join(note)\n            dadd(note)\n        if onlyvars:\n            dadd(\'\\\\begin{description}\')\n        for n in onlyvars:\n            var = m[\'vars\'][n]\n            modobjs.append(n)\n            ct = capi_maps.getctype(var)\n            at = capi_maps.c2capi_map[ct]\n            dm = capi_maps.getarrdims(n, var)\n            dms = dm[\'dims\'].replace(\'*\', \'-1\').strip()\n            dms = dms.replace(\':\', \'-1\').strip()\n            if not dms:\n                dms = \'-1\'\n            use_fgetdims2 = fgetdims2\n            if isstringarray(var):\n                if \'charselector\' in var and \'len\' in var[\'charselector\']:\n                    cadd(\'\\t{"%s",%s,{{%s,%s}},%s},\'\n                         % (undo_rmbadname1(n), dm[\'rank\'], dms, var[\'charselector\'][\'len\'], at))\n                    use_fgetdims2 = fgetdims2_sa\n                else:\n                    cadd(\'\\t{"%s",%s,{{%s}},%s},\' %\n                         (undo_rmbadname1(n), dm[\'rank\'], dms, at))\n            else:\n                cadd(\'\\t{"%s",%s,{{%s}},%s},\' %\n                     (undo_rmbadname1(n), dm[\'rank\'], dms, at))\n            dadd(\'\\\\item[]{{}\\\\verb@%s@{}}\' %\n                 (capi_maps.getarrdocsign(n, var)))\n            if hasnote(var):\n                note = var[\'note\']\n                if isinstance(note, list):\n                    note = \'\\n\'.join(note)\n                dadd(\'--- %s\' % (note))\n            if isallocatable(var):\n                fargs.append(\'f2py_%s_getdims_%s\' % (m[\'name\'], n))\n                efargs.append(fargs[-1])\n                sargs.append(\n                    \'void (*%s)(int*,int*,void(*)(char*,int*),int*)\' % (n))\n                sargsp.append(\'void (*)(int*,int*,void(*)(char*,int*),int*)\')\n                iadd(\'\\tf2py_%s_def[i_f2py++].func = %s;\' % (m[\'name\'], n))\n                fadd(\'subroutine %s(r,s,f2pysetdata,flag)\' % (fargs[-1]))\n                fadd(\'use %s, only: d => %s\\n\' %\n                     (m[\'name\'], undo_rmbadname1(n)))\n                fadd(\'integer flag\\n\')\n                fhooks[0] = fhooks[0] + fgetdims1\n                dms = eval(\'range(1,%s+1)\' % (dm[\'rank\']))\n                fadd(\' allocate(d(%s))\\n\' %\n                     (\',\'.join([\'s(%s)\' % i for i in dms])))\n                fhooks[0] = fhooks[0] + use_fgetdims2\n                fadd(\'end subroutine %s\' % (fargs[-1]))\n            else:\n                fargs.append(n)\n                sargs.append(\'char *%s\' % (n))\n                sargsp.append(\'char*\')\n                iadd(\'\\tf2py_%s_def[i_f2py++].data = %s;\' % (m[\'name\'], n))\n        if onlyvars:\n            dadd(\'\\\\end{description}\')\n        if hasbody(m):\n            for b in m[\'body\']:\n                if not isroutine(b):\n                    print(\'Skipping\', b[\'block\'], b[\'name\'])\n                    continue\n                modobjs.append(\'%s()\' % (b[\'name\']))\n                b[\'modulename\'] = m[\'name\']\n                api, wrap = rules.buildapi(b)\n                if isfunction(b):\n                    fhooks[0] = fhooks[0] + wrap\n                    fargs.append(\'f2pywrap_%s_%s\' % (m[\'name\'], b[\'name\']))\n                    ifargs.append(func2subr.createfuncwrapper(b, signature=1))\n                else:\n                    if wrap:\n                        fhooks[0] = fhooks[0] + wrap\n                        fargs.append(\'f2pywrap_%s_%s\' % (m[\'name\'], b[\'name\']))\n                        ifargs.append(\n                            func2subr.createsubrwrapper(b, signature=1))\n                    else:\n                        fargs.append(b[\'name\'])\n                        mfargs.append(fargs[-1])\n                api[\'externroutines\'] = []\n                ar = applyrules(api, vrd)\n                ar[\'docs\'] = []\n                ar[\'docshort\'] = []\n                ret = dictappend(ret, ar)\n                cadd(\'\\t{"%s",-1,{{-1}},0,NULL,(void *)f2py_rout_                     (b[\'name\'], m[\'name\'], b[\'name\'], m[\'name\'], b[\'name\']))\n                sargs.append(\'char *%s\' % (b[\'name\']))\n                sargsp.append(\'char *\')\n                iadd(\'\\tf2py_%s_def[i_f2py++].data = %s;\' %\n                     (m[\'name\'], b[\'name\']))\n        cadd(\'\\t{NULL}\\n};\\n\')\n        iadd(\'}\')\n        ihooks[0] = \'static void f2py_setup_%s(%s) {\\n\\tint i_f2py=0;%s\' % (\n            m[\'name\'], \',\'.join(sargs), ihooks[0])\n        if \'_\' in m[\'name\']:\n            F_FUNC = \'F_FUNC_US\'\n        else:\n            F_FUNC = \'F_FUNC\'\n        iadd(\'extern void %s(f2pyinit%s,F2PYINIT%s)(void (*)(%s));\'\n             % (F_FUNC, m[\'name\'], m[\'name\'].upper(), \',\'.join(sargsp)))\n        iadd(\'static void f2py_init_%s(void) {\' % (m[\'name\']))\n        iadd(\'\\t%s(f2pyinit%s,F2PYINIT%s)(f2py_setup_%s);\'\n             % (F_FUNC, m[\'name\'], m[\'name\'].upper(), m[\'name\']))\n        iadd(\'}\\n\')\n        ret[\'f90modhooks\'] = ret[\'f90modhooks\'] + chooks + ihooks\n        ret[\'initf90modhooks\'] = [\'\\tPyDict_SetItemString(d, "%s", PyFortranObject_New(f2py_%s_def,f2py_init_%s));\' % (\n            m[\'name\'], m[\'name\'], m[\'name\'])] + ret[\'initf90modhooks\']\n        fadd(\'\')\n        fadd(\'subroutine f2pyinit%s(f2pysetupfunc)\' % (m[\'name\']))\n        if mfargs:\n            for a in undo_rmbadname(mfargs):\n                fadd(\'use %s, only : %s\' % (m[\'name\'], a))\n        if ifargs:\n            fadd(\' \'.join([\'interface\'] + ifargs))\n            fadd(\'end interface\')\n        fadd(\'external f2pysetupfunc\')\n        if efargs:\n            for a in undo_rmbadname(efargs):\n                fadd(\'external %s\' % (a))\n        fadd(\'call f2pysetupfunc(%s)\' % (\',\'.join(undo_rmbadname(fargs))))\n        fadd(\'end subroutine f2pyinit%s\\n\' % (m[\'name\']))\n\n        dadd(\'\\n\'.join(ret[\'latexdoc\']).replace(\n            r\'\\subsection{\', r\'\\subsubsection{\'))\n\n        ret[\'latexdoc\'] = []\n        ret[\'docs\'].append(\'"\\t%s --- %s"\' % (m[\'name\'],\n                                              \',\'.join(undo_rmbadname(modobjs))))\n\n    ret[\'routine_defs\'] = \'\'\n    ret[\'doc\'] = []\n    ret[\'docshort\'] = []\n    ret[\'latexdoc\'] = doc[0]\n    if len(ret[\'docs\']) <= 1:\n        ret[\'docs\'] = \'\'\n    return ret, fhooks[0]\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\n__all__ = [\'fv\', \'pmt\', \'nper\', \'ipmt\', \'ppmt\', \'pv\', \'rate\',\n           \'irr\', \'npv\', \'mirr\']\n\n_when_to_num = {\'end\':0, \'begin\':1,\n                \'e\':0, \'b\':1,\n                0:0, 1:1,\n                \'beginning\':1,\n                \'start\':1,\n                \'finish\':0}\n\ndef _convert_when(when):\n            if isinstance(when, np.ndarray):\n        return when\n    try:\n        return _when_to_num[when]\n    except (KeyError, TypeError):\n        return [_when_to_num[x] for x in when]\n\n\ndef fv(rate, nper, pmt, pv, when=\'end\'):\n    \n    when = _convert_when(when)\n    (rate, nper, pmt, pv, when) = map(np.asarray, [rate, nper, pmt, pv, when])\n    temp = (1+rate)**nper\n    miter = np.broadcast(rate, nper, pmt, pv, when)\n    zer = np.zeros(miter.shape)\n    fact = np.where(rate == zer, nper + zer,\n                    (1 + rate*when)*(temp - 1)/rate + zer)\n    return -(pv*temp + pmt*fact)\n\ndef pmt(rate, nper, pv, fv=0, when=\'end\'):\n    \n    when = _convert_when(when)\n    (rate, nper, pv, fv, when) = map(np.asarray, [rate, nper, pv, fv, when])\n    temp = (1 + rate)**nper\n    mask = (rate == 0.0)\n    np.copyto(rate, 1.0, where=mask)\n    z = np.zeros(np.broadcast(rate, nper, pv, fv, when).shape)\n    fact = np.where(mask != z, nper + z, (1 + rate*when)*(temp - 1)/rate + z)\n    return -(fv + pv*temp) / fact\n\ndef nper(rate, pmt, pv, fv=0, when=\'end\'):\n    \n    when = _convert_when(when)\n    (rate, pmt, pv, fv, when) = map(np.asarray, [rate, pmt, pv, fv, when])\n\n    use_zero_rate = False\n    with np.errstate(divide="raise"):\n        try:\n            z = pmt*(1.0+rate*when)/rate\n        except FloatingPointError:\n            use_zero_rate = True\n\n    if use_zero_rate:\n        return (-fv + pv) / (pmt + 0.0)\n    else:\n        A = -(fv + pv)/(pmt+0.0)\n        B = np.log((-fv+z) / (pv+z))/np.log(1.0+rate)\n        miter = np.broadcast(rate, pmt, pv, fv, when)\n        zer = np.zeros(miter.shape)\n        return np.where(rate == zer, A + zer, B + zer) + 0.0\n\ndef ipmt(rate, per, nper, pv, fv=0.0, when=\'end\'):\n    \n    when = _convert_when(when)\n    rate, per, nper, pv, fv, when = np.broadcast_arrays(rate, per, nper,\n                                                        pv, fv, when)\n    total_pmt = pmt(rate, nper, pv, fv, when)\n    ipmt = _rbl(rate, per, total_pmt, pv, when)*rate\n    try:\n        ipmt = np.where(when == 1, ipmt/(1 + rate), ipmt)\n        ipmt = np.where(np.logical_and(when == 1, per == 1), 0.0, ipmt)\n    except IndexError:\n        pass\n    return ipmt\n\ndef _rbl(rate, per, pmt, pv, when):\n    \n    return fv(rate, (per - 1), pmt, pv, when)\n\ndef ppmt(rate, per, nper, pv, fv=0.0, when=\'end\'):\n    \n    total = pmt(rate, nper, pv, fv, when)\n    return total - ipmt(rate, per, nper, pv, fv, when)\n\ndef pv(rate, nper, pmt, fv=0.0, when=\'end\'):\n    \n    when = _convert_when(when)\n    (rate, nper, pmt, fv, when) = map(np.asarray, [rate, nper, pmt, fv, when])\n    temp = (1+rate)**nper\n    miter = np.broadcast(rate, nper, pmt, fv, when)\n    zer = np.zeros(miter.shape)\n    fact = np.where(rate == zer, nper+zer, (1+rate*when)*(temp-1)/rate+zer)\n    return -(fv + pmt*fact)/temp\n\n\ndef _g_div_gp(r, n, p, x, y, w):\n    t1 = (r+1)**n\n    t2 = (r+1)**(n-1)\n    return ((y + t1*x + p*(t1 - 1)*(r*w + 1)/r) /\n                (n*t2*x - p*(t1 - 1)*(r*w + 1)/(r**2) + n*p*t2*(r*w + 1)/r +\n                 p*(t1 - 1)*w/r))\n\ndef rate(nper, pmt, pv, fv, when=\'end\', guess=0.10, tol=1e-6, maxiter=100):\n    \n    when = _convert_when(when)\n    (nper, pmt, pv, fv, when) = map(np.asarray, [nper, pmt, pv, fv, when])\n    rn = guess\n    iter = 0\n    close = False\n    while (iter < maxiter) and not close:\n        rnp1 = rn - _g_div_gp(rn, nper, pmt, pv, fv, when)\n        diff = abs(rnp1-rn)\n        close = np.all(diff < tol)\n        iter += 1\n        rn = rnp1\n    if not close:\n                return np.nan + rn\n    else:\n        return rn\n\ndef irr(values):\n    \n    res = np.roots(values[::-1])\n    mask = (res.imag == 0) & (res.real > 0)\n    if res.size == 0:\n        return np.nan\n    res = res[mask].real\n            rate = 1.0/res - 1\n    rate = rate.item(np.argmin(np.abs(rate)))\n    return rate\n\ndef npv(rate, values):\n    \n    values = np.asarray(values)\n    return (values / (1+rate)**np.arange(0, len(values))).sum(axis=0)\n\ndef mirr(values, finance_rate, reinvest_rate):\n    \n    values = np.asarray(values, dtype=np.double)\n    n = values.size\n    pos = values > 0\n    neg = values < 0\n    if not (pos.any() and neg.any()):\n        return np.nan\n    numer = np.abs(npv(reinvest_rate, values*pos))\n    denom = np.abs(npv(finance_rate, values*neg))\n    return (numer/denom)**(1.0/(n - 1))*(1 + reinvest_rate) - 1\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy\nimport sys\nimport io\nimport warnings\nfrom numpy.lib.utils import safe_eval\nfrom numpy.compat import asbytes, asstr, isfileobj, long, basestring\n\nif sys.version_info[0] >= 3:\n    import pickle\nelse:\n    import cPickle as pickle\n\nMAGIC_PREFIX = asbytes(\'\\x93NUMPY\')\nMAGIC_LEN = len(MAGIC_PREFIX) + 2\nBUFFER_SIZE = 2**18  \n\ndef _check_version(version):\n    if version not in [(1, 0), (2, 0), None]:\n        msg = "we only support format version (1,0) and (2, 0), not %s"\n        raise ValueError(msg % (version,))\n\ndef magic(major, minor):\n    \n    if major < 0 or major > 255:\n        raise ValueError("major version must be 0 <= major < 256")\n    if minor < 0 or minor > 255:\n        raise ValueError("minor version must be 0 <= minor < 256")\n    if sys.version_info[0] < 3:\n        return MAGIC_PREFIX + chr(major) + chr(minor)\n    else:\n        return MAGIC_PREFIX + bytes([major, minor])\n\ndef read_magic(fp):\n    \n    magic_str = _read_bytes(fp, MAGIC_LEN, "magic string")\n    if magic_str[:-2] != MAGIC_PREFIX:\n        msg = "the magic string is not correct; expected %r, got %r"\n        raise ValueError(msg % (MAGIC_PREFIX, magic_str[:-2]))\n    if sys.version_info[0] < 3:\n        major, minor = map(ord, magic_str[-2:])\n    else:\n        major, minor = magic_str[-2:]\n    return major, minor\n\ndef dtype_to_descr(dtype):\n    \n    if dtype.names is not None:\n                                        return dtype.descr\n    else:\n        return dtype.str\n\ndef header_data_from_array_1_0(array):\n    \n    d = {}\n    d[\'shape\'] = array.shape\n    if array.flags.c_contiguous:\n        d[\'fortran_order\'] = False\n    elif array.flags.f_contiguous:\n        d[\'fortran_order\'] = True\n    else:\n                                d[\'fortran_order\'] = False\n\n    d[\'descr\'] = dtype_to_descr(array.dtype)\n    return d\n\ndef _write_array_header(fp, d, version=None):\n    \n    import struct\n    header = ["{"]\n    for key, value in sorted(d.items()):\n                header.append("\'%s\': %s, " % (key, repr(value)))\n    header.append("}")\n    header = "".join(header)\n                    current_header_len = MAGIC_LEN + 2 + len(header) + 1      topad = 16 - (current_header_len % 16)\n    header = header + \' \'*topad + \'\\n\'\n    header = asbytes(_filter_header(header))\n\n    hlen = len(header)\n    if hlen < 256*256 and version in (None, (1, 0)):\n        version = (1, 0)\n        header_prefix = magic(1, 0) + struct.pack(\'<H\', hlen)\n    elif hlen < 2**32 and version in (None, (2, 0)):\n        version = (2, 0)\n        header_prefix = magic(2, 0) + struct.pack(\'<I\', hlen)\n    else:\n        msg = "Header length %s too big for version=%s"\n        msg %= (hlen, version)\n        raise ValueError(msg)\n\n    fp.write(header_prefix)\n    fp.write(header)\n    return version\n\ndef write_array_header_1_0(fp, d):\n    \n    _write_array_header(fp, d, (1, 0))\n\n\ndef write_array_header_2_0(fp, d):\n    \n    _write_array_header(fp, d, (2, 0))\n\ndef read_array_header_1_0(fp):\n    \n    return _read_array_header(fp, version=(1, 0))\n\ndef read_array_header_2_0(fp):\n    \n    return _read_array_header(fp, version=(2, 0))\n\n\ndef _filter_header(s):\n    \n    import tokenize\n    if sys.version_info[0] >= 3:\n        from io import StringIO\n    else:\n        from StringIO import StringIO\n\n    tokens = []\n    last_token_was_number = False\n    for token in tokenize.generate_tokens(StringIO(asstr(s)).read):\n        token_type = token[0]\n        token_string = token[1]\n        if (last_token_was_number and\n                token_type == tokenize.NAME and\n                token_string == "L"):\n            continue\n        else:\n            tokens.append(token)\n        last_token_was_number = (token_type == tokenize.NUMBER)\n    return tokenize.untokenize(tokens)\n\n\ndef _read_array_header(fp, version):\n    \n            import struct\n    if version == (1, 0):\n        hlength_str = _read_bytes(fp, 2, "array header length")\n        header_length = struct.unpack(\'<H\', hlength_str)[0]\n        header = _read_bytes(fp, header_length, "array header")\n    elif version == (2, 0):\n        hlength_str = _read_bytes(fp, 4, "array header length")\n        header_length = struct.unpack(\'<I\', hlength_str)[0]\n        header = _read_bytes(fp, header_length, "array header")\n    else:\n        raise ValueError("Invalid version %r" % version)\n\n                            header = _filter_header(header)\n    try:\n        d = safe_eval(header)\n    except SyntaxError as e:\n        msg = "Cannot parse header: %r\\nException: %r"\n        raise ValueError(msg % (header, e))\n    if not isinstance(d, dict):\n        msg = "Header is not a dictionary: %r"\n        raise ValueError(msg % d)\n    keys = sorted(d.keys())\n    if keys != [\'descr\', \'fortran_order\', \'shape\']:\n        msg = "Header does not contain the correct keys: %r"\n        raise ValueError(msg % (keys,))\n\n        if (not isinstance(d[\'shape\'], tuple) or\n            not numpy.all([isinstance(x, (int, long)) for x in d[\'shape\']])):\n        msg = "shape is not valid: %r"\n        raise ValueError(msg % (d[\'shape\'],))\n    if not isinstance(d[\'fortran_order\'], bool):\n        msg = "fortran_order is not a valid bool: %r"\n        raise ValueError(msg % (d[\'fortran_order\'],))\n    try:\n        dtype = numpy.dtype(d[\'descr\'])\n    except TypeError as e:\n        msg = "descr is not a valid dtype descriptor: %r"\n        raise ValueError(msg % (d[\'descr\'],))\n\n    return d[\'shape\'], d[\'fortran_order\'], dtype\n\ndef write_array(fp, array, version=None, allow_pickle=True, pickle_kwargs=None):\n    \n    _check_version(version)\n    used_ver = _write_array_header(fp, header_data_from_array_1_0(array),\n                                   version)\n        if version != (2, 0) and used_ver == (2, 0):\n        warnings.warn("Stored array in format 2.0. It can only be"\n                      "read by NumPy >= 1.9", UserWarning)\n\n        buffersize = max(16 * 1024 ** 2 // array.itemsize, 1)\n\n    if array.dtype.hasobject:\n                                if not allow_pickle:\n            raise ValueError("Object arrays cannot be saved when "\n                             "allow_pickle=False")\n        if pickle_kwargs is None:\n            pickle_kwargs = {}\n        pickle.dump(array, fp, protocol=2, **pickle_kwargs)\n    elif array.flags.f_contiguous and not array.flags.c_contiguous:\n        if isfileobj(fp):\n            array.T.tofile(fp)\n        else:\n            for chunk in numpy.nditer(\n                    array, flags=[\'external_loop\', \'buffered\', \'zerosize_ok\'],\n                    buffersize=buffersize, order=\'F\'):\n                fp.write(chunk.tobytes(\'C\'))\n    else:\n        if isfileobj(fp):\n            array.tofile(fp)\n        else:\n            for chunk in numpy.nditer(\n                    array, flags=[\'external_loop\', \'buffered\', \'zerosize_ok\'],\n                    buffersize=buffersize, order=\'C\'):\n                fp.write(chunk.tobytes(\'C\'))\n\n\ndef read_array(fp, allow_pickle=True, pickle_kwargs=None):\n    \n    version = read_magic(fp)\n    _check_version(version)\n    shape, fortran_order, dtype = _read_array_header(fp, version)\n    if len(shape) == 0:\n        count = 1\n    else:\n        count = numpy.multiply.reduce(shape)\n\n        if dtype.hasobject:\n                if not allow_pickle:\n            raise ValueError("Object arrays cannot be loaded when "\n                             "allow_pickle=False")\n        if pickle_kwargs is None:\n            pickle_kwargs = {}\n        try:\n            array = pickle.load(fp, **pickle_kwargs)\n        except UnicodeError as err:\n            if sys.version_info[0] >= 3:\n                                raise UnicodeError("Unpickling a python object failed: %r\\n"\n                                   "You may need to pass the encoding= option "\n                                   "to numpy.load" % (err,))\n            raise\n    else:\n        if isfileobj(fp):\n                        array = numpy.fromfile(fp, dtype=dtype, count=count)\n        else:\n                                                                                    \n            max_read_count = BUFFER_SIZE // min(BUFFER_SIZE, dtype.itemsize)\n\n            array = numpy.empty(count, dtype=dtype)\n            for i in range(0, count, max_read_count):\n                read_count = min(max_read_count, count - i)\n                read_size = int(read_count * dtype.itemsize)\n                data = _read_bytes(fp, read_size, "array data")\n                array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n                                                         count=read_count)\n\n        if fortran_order:\n            array.shape = shape[::-1]\n            array = array.transpose()\n        else:\n            array.shape = shape\n\n    return array\n\n\ndef open_memmap(filename, mode=\'r+\', dtype=None, shape=None,\n                fortran_order=False, version=None):\n    \n    if not isinstance(filename, basestring):\n        raise ValueError("Filename must be a string.  Memmap cannot use"\n                         " existing file handles.")\n\n    if \'w\' in mode:\n                        _check_version(version)\n                        dtype = numpy.dtype(dtype)\n        if dtype.hasobject:\n            msg = "Array can\'t be memory-mapped: Python objects in dtype."\n            raise ValueError(msg)\n        d = dict(\n            descr=dtype_to_descr(dtype),\n            fortran_order=fortran_order,\n            shape=shape,\n        )\n                fp = open(filename, mode+\'b\')\n        try:\n            used_ver = _write_array_header(fp, d, version)\n                        if version != (2, 0) and used_ver == (2, 0):\n                warnings.warn("Stored array in format 2.0. It can only be"\n                              "read by NumPy >= 1.9", UserWarning)\n            offset = fp.tell()\n        finally:\n            fp.close()\n    else:\n                fp = open(filename, \'rb\')\n        try:\n            version = read_magic(fp)\n            _check_version(version)\n\n            shape, fortran_order, dtype = _read_array_header(fp, version)\n            if dtype.hasobject:\n                msg = "Array can\'t be memory-mapped: Python objects in dtype."\n                raise ValueError(msg)\n            offset = fp.tell()\n        finally:\n            fp.close()\n\n    if fortran_order:\n        order = \'F\'\n    else:\n        order = \'C\'\n\n            if mode == \'w+\':\n        mode = \'r+\'\n\n    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n        mode=mode, offset=offset)\n\n    return marray\n\n\ndef _read_bytes(fp, size, error_template="ran out of data"):\n    \n    data = bytes()\n    while True:\n                                try:\n            r = fp.read(size - len(data))\n            data += r\n            if len(r) == 0 or len(data) == size:\n                break\n        except io.BlockingIOError:\n            pass\n    if len(data) != size:\n        msg = "EOF: reading %s, expected %d bytes got %d"\n        raise ValueError(msg % (error_template, size, len(data)))\n    else:\n        return data\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'process_str\', \'process_file\']\n\nimport os\nimport sys\nimport re\n\nroutine_start_re = re.compile(r\'(\\n|\\A)((     (\\$|\\*))|)\\s*(subroutine|function)\\b\', re.I)\nroutine_end_re = re.compile(r\'\\n\\s*end\\s*(subroutine|function)\\b.*(\\n|\\Z)\', re.I)\nfunction_start_re = re.compile(r\'\\n     (\\$|\\*)\\s*function\\b\', re.I)\n\ndef parse_structure(astr):\n    \n\n    spanlist = []\n    ind = 0\n    while True:\n        m = routine_start_re.search(astr, ind)\n        if m is None:\n            break\n        start = m.start()\n        if function_start_re.match(astr, start, m.end()):\n            while True:\n                i = astr.rfind(\'\\n\', ind, start)\n                if i==-1:\n                    break\n                start = i\n                if astr[i:i+7]!=\'\\n     $\':\n                    break\n        start += 1\n        m = routine_end_re.search(astr, m.end())\n        ind = end = m and m.end()-1 or len(astr)\n        spanlist.append((start, end))\n    return spanlist\n\ntemplate_re = re.compile(r"<\\s*(\\w[\\w\\d]*)\\s*>")\nnamed_re = re.compile(r"<\\s*(\\w[\\w\\d]*)\\s*=\\s*(.*?)\\s*>")\nlist_re = re.compile(r"<\\s*((.*?))\\s*>")\n\ndef find_repl_patterns(astr):\n    reps = named_re.findall(astr)\n    names = {}\n    for rep in reps:\n        name = rep[0].strip() or unique_key(names)\n        repl = rep[1].replace(\'\\,\', \'@comma@\')\n        thelist = conv(repl)\n        names[name] = thelist\n    return names\n\nitem_re = re.compile(r"\\A\\\\(?P<index>\\d+)\\Z")\ndef conv(astr):\n    b = astr.split(\',\')\n    l = [x.strip() for x in b]\n    for i in range(len(l)):\n        m = item_re.match(l[i])\n        if m:\n            j = int(m.group(\'index\'))\n            l[i] = l[j]\n    return \',\'.join(l)\n\ndef unique_key(adict):\n    \n    allkeys = list(adict.keys())\n    done = False\n    n = 1\n    while not done:\n        newkey = \'__l%s\' % (n)\n        if newkey in allkeys:\n            n += 1\n        else:\n            done = True\n    return newkey\n\n\ntemplate_name_re = re.compile(r\'\\A\\s*(\\w[\\w\\d]*)\\s*\\Z\')\ndef expand_sub(substr, names):\n    substr = substr.replace(\'\\>\', \'@rightarrow@\')\n    substr = substr.replace(\'\\<\', \'@leftarrow@\')\n    lnames = find_repl_patterns(substr)\n    substr = named_re.sub(r"<\\1>", substr)  \n    def listrepl(mobj):\n        thelist = conv(mobj.group(1).replace(\'\\,\', \'@comma@\'))\n        if template_name_re.match(thelist):\n            return "<%s>" % (thelist)\n        name = None\n        for key in lnames.keys():                if lnames[key] == thelist:\n                name = key\n        if name is None:                  name = unique_key(lnames)\n            lnames[name] = thelist\n        return "<%s>" % name\n\n    substr = list_re.sub(listrepl, substr)                                            \n    numsubs = None\n    base_rule = None\n    rules = {}\n    for r in template_re.findall(substr):\n        if r not in rules:\n            thelist = lnames.get(r, names.get(r, None))\n            if thelist is None:\n                raise ValueError(\'No replicates found for <%s>\' % (r))\n            if r not in names and not thelist.startswith(\'_\'):\n                names[r] = thelist\n            rule = [i.replace(\'@comma@\', \',\') for i in thelist.split(\',\')]\n            num = len(rule)\n\n            if numsubs is None:\n                numsubs = num\n                rules[r] = rule\n                base_rule = r\n            elif num == numsubs:\n                rules[r] = rule\n            else:\n                print("Mismatch in number of replacements (base <%s=%s>)"\n                      " for <%s=%s>. Ignoring." %\n                      (base_rule, \',\'.join(rules[base_rule]), r, thelist))\n    if not rules:\n        return substr\n\n    def namerepl(mobj):\n        name = mobj.group(1)\n        return rules.get(name, (k+1)*[name])[k]\n\n    newstr = \'\'\n    for k in range(numsubs):\n        newstr += template_re.sub(namerepl, substr) + \'\\n\\n\'\n\n    newstr = newstr.replace(\'@rightarrow@\', \'>\')\n    newstr = newstr.replace(\'@leftarrow@\', \'<\')\n    return newstr\n\ndef process_str(allstr):\n    newstr = allstr\n    writestr = \'\' \n    struct = parse_structure(newstr)\n\n    oldend = 0\n    names = {}\n    names.update(_special_names)\n    for sub in struct:\n        writestr += newstr[oldend:sub[0]]\n        names.update(find_repl_patterns(newstr[oldend:sub[0]]))\n        writestr += expand_sub(newstr[sub[0]:sub[1]], names)\n        oldend =  sub[1]\n    writestr += newstr[oldend:]\n\n    return writestr\n\ninclude_src_re = re.compile(r"(\\n|\\A)\\s*include\\s*[\'\\"](?P<name>[\\w\\d./\\\\]+[.]src)[\'\\"]", re.I)\n\ndef resolve_includes(source):\n    d = os.path.dirname(source)\n    fid = open(source)\n    lines = []\n    for line in fid:\n        m = include_src_re.match(line)\n        if m:\n            fn = m.group(\'name\')\n            if not os.path.isabs(fn):\n                fn = os.path.join(d, fn)\n            if os.path.isfile(fn):\n                print(\'Including file\', fn)\n                lines.extend(resolve_includes(fn))\n            else:\n                lines.append(line)\n        else:\n            lines.append(line)\n    fid.close()\n    return lines\n\ndef process_file(source):\n    lines = resolve_includes(source)\n    return process_str(\'\'.join(lines))\n\n_special_names = find_repl_patterns()\n\nif __name__ == "__main__":\n\n    try:\n        file = sys.argv[1]\n    except IndexError:\n        fid = sys.stdin\n        outfile = sys.stdout\n    else:\n        fid = open(file, \'r\')\n        (base, ext) = os.path.splitext(file)\n        newname = base\n        outfile = open(newname, \'w\')\n\n    allstr = fid.read()\n    writestr = process_str(allstr)\n    outfile.write(writestr)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport types\nimport warnings\n\nimport numpy as np\nfrom .. import VisibleDeprecationWarning\nfrom . import multiarray as mu\nfrom . import umath as um\nfrom . import numerictypes as nt\nfrom .numeric import asarray, array, asanyarray, concatenate\nfrom . import _methods\n\n\n_dt_ = nt.sctype2char\n\n\n__all__ = [\n    \'alen\', \'all\', \'alltrue\', \'amax\', \'amin\', \'any\', \'argmax\',\n    \'argmin\', \'argpartition\', \'argsort\', \'around\', \'choose\', \'clip\',\n    \'compress\', \'cumprod\', \'cumproduct\', \'cumsum\', \'diagonal\', \'mean\',\n    \'ndim\', \'nonzero\', \'partition\', \'prod\', \'product\', \'ptp\', \'put\',\n    \'rank\', \'ravel\', \'repeat\', \'reshape\', \'resize\', \'round_\',\n    \'searchsorted\', \'shape\', \'size\', \'sometrue\', \'sort\', \'squeeze\',\n    \'std\', \'sum\', \'swapaxes\', \'take\', \'trace\', \'transpose\', \'var\',\n    ]\n\n\ntry:\n    _gentype = types.GeneratorType\nexcept AttributeError:\n    _gentype = type(None)\n\n_sum_ = sum\n\n\ndef _wrapit(obj, method, *args, **kwds):\n    try:\n        wrap = obj.__array_wrap__\n    except AttributeError:\n        wrap = None\n    result = getattr(asarray(obj), method)(*args, **kwds)\n    if wrap:\n        if not isinstance(result, mu.ndarray):\n            result = asarray(result)\n        result = wrap(result)\n    return result\n\n\ndef take(a, indices, axis=None, out=None, mode=\'raise\'):\n    \n    try:\n        take = a.take\n    except AttributeError:\n        return _wrapit(a, \'take\', indices, axis, out, mode)\n    return take(indices, axis, out, mode)\n\n\ndef reshape(a, newshape, order=\'C\'):\n    \n    try:\n        reshape = a.reshape\n    except AttributeError:\n        return _wrapit(a, \'reshape\', newshape, order=order)\n    return reshape(newshape, order=order)\n\n\ndef choose(a, choices, out=None, mode=\'raise\'):\n    \n    try:\n        choose = a.choose\n    except AttributeError:\n        return _wrapit(a, \'choose\', choices, out=out, mode=mode)\n    return choose(choices, out=out, mode=mode)\n\n\ndef repeat(a, repeats, axis=None):\n    \n    try:\n        repeat = a.repeat\n    except AttributeError:\n        return _wrapit(a, \'repeat\', repeats, axis)\n    return repeat(repeats, axis)\n\n\ndef put(a, ind, v, mode=\'raise\'):\n    \n    return a.put(ind, v, mode)\n\n\ndef swapaxes(a, axis1, axis2):\n    \n    try:\n        swapaxes = a.swapaxes\n    except AttributeError:\n        return _wrapit(a, \'swapaxes\', axis1, axis2)\n    return swapaxes(axis1, axis2)\n\n\ndef transpose(a, axes=None):\n    \n    try:\n        transpose = a.transpose\n    except AttributeError:\n        return _wrapit(a, \'transpose\', axes)\n    return transpose(axes)\n\n\ndef partition(a, kth, axis=-1, kind=\'introselect\', order=None):\n    \n    if axis is None:\n        a = asanyarray(a).flatten()\n        axis = 0\n    else:\n        a = asanyarray(a).copy(order="K")\n    a.partition(kth, axis=axis, kind=kind, order=order)\n    return a\n\n\ndef argpartition(a, kth, axis=-1, kind=\'introselect\', order=None):\n    \n    try:\n        argpartition = a.argpartition\n    except AttributeError:\n        return _wrapit(a, \'argpartition\',kth, axis, kind, order)\n    return argpartition(kth, axis, kind=kind, order=order)\n\n\ndef sort(a, axis=-1, kind=\'quicksort\', order=None):\n    \n    if axis is None:\n        a = asanyarray(a).flatten()\n        axis = 0\n    else:\n        a = asanyarray(a).copy(order="K")\n    a.sort(axis, kind, order)\n    return a\n\n\ndef argsort(a, axis=-1, kind=\'quicksort\', order=None):\n    \n    try:\n        argsort = a.argsort\n    except AttributeError:\n        return _wrapit(a, \'argsort\', axis, kind, order)\n    return argsort(axis, kind, order)\n\n\ndef argmax(a, axis=None, out=None):\n    \n    try:\n        argmax = a.argmax\n    except AttributeError:\n        return _wrapit(a, \'argmax\', axis, out)\n    return argmax(axis, out)\n\n\ndef argmin(a, axis=None, out=None):\n    \n    try:\n        argmin = a.argmin\n    except AttributeError:\n        return _wrapit(a, \'argmin\', axis, out)\n    return argmin(axis, out)\n\n\ndef searchsorted(a, v, side=\'left\', sorter=None):\n    \n    try:\n        searchsorted = a.searchsorted\n    except AttributeError:\n        return _wrapit(a, \'searchsorted\', v, side, sorter)\n    return searchsorted(v, side, sorter)\n\n\ndef resize(a, new_shape):\n    \n    if isinstance(new_shape, (int, nt.integer)):\n        new_shape = (new_shape,)\n    a = ravel(a)\n    Na = len(a)\n    if not Na:\n        return mu.zeros(new_shape, a.dtype.char)\n    total_size = um.multiply.reduce(new_shape)\n    n_copies = int(total_size / Na)\n    extra = total_size % Na\n\n    if total_size == 0:\n        return a[:0]\n\n    if extra != 0:\n        n_copies = n_copies+1\n        extra = Na-extra\n\n    a = concatenate((a,)*n_copies)\n    if extra > 0:\n        a = a[:-extra]\n\n    return reshape(a, new_shape)\n\n\ndef squeeze(a, axis=None):\n    \n    try:\n        squeeze = a.squeeze\n    except AttributeError:\n        return _wrapit(a, \'squeeze\')\n    try:\n                return squeeze(axis=axis)\n    except TypeError:\n                return squeeze()\n\n\ndef diagonal(a, offset=0, axis1=0, axis2=1):\n    \n    if isinstance(a, np.matrix):\n                return asarray(a).diagonal(offset, axis1, axis2)\n    else:\n        return asanyarray(a).diagonal(offset, axis1, axis2)\n\n\ndef trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None):\n    \n    return asarray(a).trace(offset, axis1, axis2, dtype, out)\n\n\ndef ravel(a, order=\'C\'):\n    \n    if isinstance(a, np.matrix):\n        return asarray(a).ravel(order)\n    else:\n        return asanyarray(a).ravel(order)\n\n\ndef nonzero(a):\n    \n    try:\n        nonzero = a.nonzero\n    except AttributeError:\n        res = _wrapit(a, \'nonzero\')\n    else:\n        res = nonzero()\n    return res\n\n\ndef shape(a):\n    \n    try:\n        result = a.shape\n    except AttributeError:\n        result = asarray(a).shape\n    return result\n\n\ndef compress(condition, a, axis=None, out=None):\n    \n    try:\n        compress = a.compress\n    except AttributeError:\n        return _wrapit(a, \'compress\', condition, axis, out)\n    return compress(condition, axis, out)\n\n\ndef clip(a, a_min, a_max, out=None):\n    \n    try:\n        clip = a.clip\n    except AttributeError:\n        return _wrapit(a, \'clip\', a_min, a_max, out)\n    return clip(a_min, a_max, out)\n\n\ndef sum(a, axis=None, dtype=None, out=None, keepdims=False):\n    \n    if isinstance(a, _gentype):\n        res = _sum_(a)\n        if out is not None:\n            out[...] = res\n            return out\n        return res\n    elif type(a) is not mu.ndarray:\n        try:\n            sum = a.sum\n        except AttributeError:\n            return _methods._sum(a, axis=axis, dtype=dtype,\n                                 out=out, keepdims=keepdims)\n                return sum(axis=axis, dtype=dtype, out=out)\n    else:\n        return _methods._sum(a, axis=axis, dtype=dtype,\n                             out=out, keepdims=keepdims)\n\n\ndef product(a, axis=None, dtype=None, out=None, keepdims=False):\n    \n    return um.multiply.reduce(a, axis=axis, dtype=dtype,\n                              out=out, keepdims=keepdims)\n\n\ndef sometrue(a, axis=None, out=None, keepdims=False):\n    \n    arr = asanyarray(a)\n\n    try:\n        return arr.any(axis=axis, out=out, keepdims=keepdims)\n    except TypeError:\n        return arr.any(axis=axis, out=out)\n\n\ndef alltrue(a, axis=None, out=None, keepdims=False):\n    \n    arr = asanyarray(a)\n\n    try:\n        return arr.all(axis=axis, out=out, keepdims=keepdims)\n    except TypeError:\n        return arr.all(axis=axis, out=out)\n\n\ndef any(a, axis=None, out=None, keepdims=False):\n    \n    arr = asanyarray(a)\n\n    try:\n        return arr.any(axis=axis, out=out, keepdims=keepdims)\n    except TypeError:\n        return arr.any(axis=axis, out=out)\n\n\ndef all(a, axis=None, out=None, keepdims=False):\n    \n    arr = asanyarray(a)\n\n    try:\n        return arr.all(axis=axis, out=out, keepdims=keepdims)\n    except TypeError:\n        return arr.all(axis=axis, out=out)\n\n\ndef cumsum(a, axis=None, dtype=None, out=None):\n    \n    try:\n        cumsum = a.cumsum\n    except AttributeError:\n        return _wrapit(a, \'cumsum\', axis, dtype, out)\n    return cumsum(axis, dtype, out)\n\n\ndef cumproduct(a, axis=None, dtype=None, out=None):\n    \n    try:\n        cumprod = a.cumprod\n    except AttributeError:\n        return _wrapit(a, \'cumprod\', axis, dtype, out)\n    return cumprod(axis, dtype, out)\n\n\ndef ptp(a, axis=None, out=None):\n    \n    try:\n        ptp = a.ptp\n    except AttributeError:\n        return _wrapit(a, \'ptp\', axis, out)\n    return ptp(axis, out)\n\n\ndef amax(a, axis=None, out=None, keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            amax = a.max\n        except AttributeError:\n            return _methods._amax(a, axis=axis,\n                                  out=out, keepdims=keepdims)\n                return amax(axis=axis, out=out)\n    else:\n        return _methods._amax(a, axis=axis,\n                              out=out, keepdims=keepdims)\n\n\ndef amin(a, axis=None, out=None, keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            amin = a.min\n        except AttributeError:\n            return _methods._amin(a, axis=axis,\n                                  out=out, keepdims=keepdims)\n                return amin(axis=axis, out=out)\n    else:\n        return _methods._amin(a, axis=axis,\n                              out=out, keepdims=keepdims)\n\n\ndef alen(a):\n    \n    try:\n        return len(a)\n    except TypeError:\n        return len(array(a, ndmin=1))\n\n\ndef prod(a, axis=None, dtype=None, out=None, keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            prod = a.prod\n        except AttributeError:\n            return _methods._prod(a, axis=axis, dtype=dtype,\n                                  out=out, keepdims=keepdims)\n        return prod(axis=axis, dtype=dtype, out=out)\n    else:\n        return _methods._prod(a, axis=axis, dtype=dtype,\n                              out=out, keepdims=keepdims)\n\n\ndef cumprod(a, axis=None, dtype=None, out=None):\n    \n    try:\n        cumprod = a.cumprod\n    except AttributeError:\n        return _wrapit(a, \'cumprod\', axis, dtype, out)\n    return cumprod(axis, dtype, out)\n\n\ndef ndim(a):\n    \n    try:\n        return a.ndim\n    except AttributeError:\n        return asarray(a).ndim\n\n\ndef rank(a):\n    \n        warnings.warn(\n        "`rank` is deprecated; use the `ndim` attribute or function instead. "\n        "To find the rank of a matrix see `numpy.linalg.matrix_rank`.",\n        VisibleDeprecationWarning)\n    try:\n        return a.ndim\n    except AttributeError:\n        return asarray(a).ndim\n\n\ndef size(a, axis=None):\n    \n    if axis is None:\n        try:\n            return a.size\n        except AttributeError:\n            return asarray(a).size\n    else:\n        try:\n            return a.shape[axis]\n        except AttributeError:\n            return asarray(a).shape[axis]\n\n\ndef around(a, decimals=0, out=None):\n    \n    try:\n        round = a.round\n    except AttributeError:\n        return _wrapit(a, \'round\', decimals, out)\n    return round(decimals, out)\n\n\ndef round_(a, decimals=0, out=None):\n    \n    try:\n        round = a.round\n    except AttributeError:\n        return _wrapit(a, \'round\', decimals, out)\n    return round(decimals, out)\n\n\ndef mean(a, axis=None, dtype=None, out=None, keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            mean = a.mean\n            return mean(axis=axis, dtype=dtype, out=out)\n        except AttributeError:\n            pass\n\n    return _methods._mean(a, axis=axis, dtype=dtype,\n                          out=out, keepdims=keepdims)\n\n\ndef std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            std = a.std\n            return std(axis=axis, dtype=dtype, out=out, ddof=ddof)\n        except AttributeError:\n            pass\n\n    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         keepdims=keepdims)\n\n\ndef var(a, axis=None, dtype=None, out=None, ddof=0,\n        keepdims=False):\n    \n    if type(a) is not mu.ndarray:\n        try:\n            var = a.var\n            return var(axis=axis, dtype=dtype, out=out, ddof=ddof)\n        except AttributeError:\n            pass\n\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         keepdims=keepdims)\n\nfrom __future__ import division, absolute_import, print_function\n\n__version__ = "$Revision: 1.16 $"[10:-1]\n\nf2py_version = \'See `f2py -v`\'\n\nimport copy\n\nfrom .auxfuncs import (\n    getfortranname, isexternal, isfunction, isfunction_wrap, isintent_in,\n    isintent_out, islogicalfunction, ismoduleroutine, isscalar,\n    issubroutine, issubroutine_wrap, outmess, show\n)\n\n\ndef var2fixfortran(vars, a, fa=None, f90mode=None):\n    if fa is None:\n        fa = a\n    if a not in vars:\n        show(vars)\n        outmess(\'var2fixfortran: No definition for argument "%s".\\n\' % a)\n        return \'\'\n    if \'typespec\' not in vars[a]:\n        show(vars[a])\n        outmess(\'var2fixfortran: No typespec for argument "%s".\\n\' % a)\n        return \'\'\n    vardef = vars[a][\'typespec\']\n    if vardef == \'type\' and \'typename\' in vars[a]:\n        vardef = \'%s(%s)\' % (vardef, vars[a][\'typename\'])\n    selector = {}\n    lk = \'\'\n    if \'kindselector\' in vars[a]:\n        selector = vars[a][\'kindselector\']\n        lk = \'kind\'\n    elif \'charselector\' in vars[a]:\n        selector = vars[a][\'charselector\']\n        lk = \'len\'\n    if \'*\' in selector:\n        if f90mode:\n            if selector[\'*\'] in [\'*\', \':\', \'(*)\']:\n                vardef = \'%s(len=*)\' % (vardef)\n            else:\n                vardef = \'%s(%s=%s)\' % (vardef, lk, selector[\'*\'])\n        else:\n            if selector[\'*\'] in [\'*\', \':\']:\n                vardef = \'%s*(%s)\' % (vardef, selector[\'*\'])\n            else:\n                vardef = \'%s*%s\' % (vardef, selector[\'*\'])\n    else:\n        if \'len\' in selector:\n            vardef = \'%s(len=%s\' % (vardef, selector[\'len\'])\n            if \'kind\' in selector:\n                vardef = \'%s,kind=%s)\' % (vardef, selector[\'kind\'])\n            else:\n                vardef = \'%s)\' % (vardef)\n        elif \'kind\' in selector:\n            vardef = \'%s(kind=%s)\' % (vardef, selector[\'kind\'])\n\n    vardef = \'%s %s\' % (vardef, fa)\n    if \'dimension\' in vars[a]:\n        vardef = \'%s(%s)\' % (vardef, \',\'.join(vars[a][\'dimension\']))\n    return vardef\n\n\ndef createfuncwrapper(rout, signature=0):\n    assert isfunction(rout)\n\n    extra_args = []\n    vars = rout[\'vars\']\n    for a in rout[\'args\']:\n        v = rout[\'vars\'][a]\n        for i, d in enumerate(v.get(\'dimension\', [])):\n            if d == \':\':\n                dn = \'f2py_%s_d%s\' % (a, i)\n                dv = dict(typespec=\'integer\', intent=[\'hide\'])\n                dv[\'=\'] = \'shape(%s, %s)\' % (a, i)\n                extra_args.append(dn)\n                vars[dn] = dv\n                v[\'dimension\'][i] = dn\n    rout[\'args\'].extend(extra_args)\n    need_interface = bool(extra_args)\n\n    ret = [\'\']\n\n    def add(line, ret=ret):\n        ret[0] = \'%s\\n      %s\' % (ret[0], line)\n    name = rout[\'name\']\n    fortranname = getfortranname(rout)\n    f90mode = ismoduleroutine(rout)\n    newname = \'%sf2pywrap\' % (name)\n\n    if newname not in vars:\n        vars[newname] = vars[name]\n        args = [newname] + rout[\'args\'][1:]\n    else:\n        args = [newname] + rout[\'args\']\n\n    l = var2fixfortran(vars, name, newname, f90mode)\n    if l[:13] == \'character*(*)\':\n        if f90mode:\n            l = \'character(len=10)\' + l[13:]\n        else:\n            l = \'character*10\' + l[13:]\n        charselect = vars[name][\'charselector\']\n        if charselect.get(\'*\', \'\') == \'(*)\':\n            charselect[\'*\'] = \'10\'\n    sargs = \', \'.join(args)\n    if f90mode:\n        add(\'subroutine f2pywrap_%s_%s (%s)\' %\n            (rout[\'modulename\'], name, sargs))\n        if not signature:\n            add(\'use %s, only : %s\' % (rout[\'modulename\'], fortranname))\n    else:\n        add(\'subroutine f2pywrap%s (%s)\' % (name, sargs))\n        if not need_interface:\n            add(\'external %s\' % (fortranname))\n            l = l + \', \' + fortranname\n    if need_interface:\n        for line in rout[\'saved_interface\'].split(\'\\n\'):\n            if line.lstrip().startswith(\'use \'):\n                add(line)\n\n    args = args[1:]\n    dumped_args = []\n    for a in args:\n        if isexternal(vars[a]):\n            add(\'external %s\' % (a))\n            dumped_args.append(a)\n    for a in args:\n        if a in dumped_args:\n            continue\n        if isscalar(vars[a]):\n            add(var2fixfortran(vars, a, f90mode=f90mode))\n            dumped_args.append(a)\n    for a in args:\n        if a in dumped_args:\n            continue\n        if isintent_in(vars[a]):\n            add(var2fixfortran(vars, a, f90mode=f90mode))\n            dumped_args.append(a)\n    for a in args:\n        if a in dumped_args:\n            continue\n        add(var2fixfortran(vars, a, f90mode=f90mode))\n\n    add(l)\n\n    if need_interface:\n        if f90mode:\n                        pass\n        else:\n            add(\'interface\')\n            add(rout[\'saved_interface\'].lstrip())\n            add(\'end interface\')\n\n    sargs = \', \'.join([a for a in args if a not in extra_args])\n\n    if not signature:\n        if islogicalfunction(rout):\n            add(\'%s = .not.(.not.%s(%s))\' % (newname, fortranname, sargs))\n        else:\n            add(\'%s = %s(%s)\' % (newname, fortranname, sargs))\n    if f90mode:\n        add(\'end subroutine f2pywrap_%s_%s\' % (rout[\'modulename\'], name))\n    else:\n        add(\'end\')\n    return ret[0]\n\n\ndef createsubrwrapper(rout, signature=0):\n    assert issubroutine(rout)\n\n    extra_args = []\n    vars = rout[\'vars\']\n    for a in rout[\'args\']:\n        v = rout[\'vars\'][a]\n        for i, d in enumerate(v.get(\'dimension\', [])):\n            if d == \':\':\n                dn = \'f2py_%s_d%s\' % (a, i)\n                dv = dict(typespec=\'integer\', intent=[\'hide\'])\n                dv[\'=\'] = \'shape(%s, %s)\' % (a, i)\n                extra_args.append(dn)\n                vars[dn] = dv\n                v[\'dimension\'][i] = dn\n    rout[\'args\'].extend(extra_args)\n    need_interface = bool(extra_args)\n\n    ret = [\'\']\n\n    def add(line, ret=ret):\n        ret[0] = \'%s\\n      %s\' % (ret[0], line)\n    name = rout[\'name\']\n    fortranname = getfortranname(rout)\n    f90mode = ismoduleroutine(rout)\n\n    args = rout[\'args\']\n\n    sargs = \', \'.join(args)\n    if f90mode:\n        add(\'subroutine f2pywrap_%s_%s (%s)\' %\n            (rout[\'modulename\'], name, sargs))\n        if not signature:\n            add(\'use %s, only : %s\' % (rout[\'modulename\'], fortranname))\n    else:\n        add(\'subroutine f2pywrap%s (%s)\' % (name, sargs))\n        if not need_interface:\n            add(\'external %s\' % (fortranname))\n\n    if need_interface:\n        for line in rout[\'saved_interface\'].split(\'\\n\'):\n            if line.lstrip().startswith(\'use \'):\n                add(line)\n\n    dumped_args = []\n    for a in args:\n        if isexternal(vars[a]):\n            add(\'external %s\' % (a))\n            dumped_args.append(a)\n    for a in args:\n        if a in dumped_args:\n            continue\n        if isscalar(vars[a]):\n            add(var2fixfortran(vars, a, f90mode=f90mode))\n            dumped_args.append(a)\n    for a in args:\n        if a in dumped_args:\n            continue\n        add(var2fixfortran(vars, a, f90mode=f90mode))\n\n    if need_interface:\n        if f90mode:\n                        pass\n        else:\n            add(\'interface\')\n            add(rout[\'saved_interface\'].lstrip())\n            add(\'end interface\')\n\n    sargs = \', \'.join([a for a in args if a not in extra_args])\n\n    if not signature:\n        add(\'call %s(%s)\' % (fortranname, sargs))\n    if f90mode:\n        add(\'end subroutine f2pywrap_%s_%s\' % (rout[\'modulename\'], name))\n    else:\n        add(\'end\')\n    return ret[0]\n\n\ndef assubr(rout):\n    if isfunction_wrap(rout):\n        fortranname = getfortranname(rout)\n        name = rout[\'name\']\n        outmess(\'\\t\\tCreating wrapper for Fortran function "%s"("%s")...\\n\' % (\n            name, fortranname))\n        rout = copy.copy(rout)\n        fname = name\n        rname = fname\n        if \'result\' in rout:\n            rname = rout[\'result\']\n            rout[\'vars\'][fname] = rout[\'vars\'][rname]\n        fvar = rout[\'vars\'][fname]\n        if not isintent_out(fvar):\n            if \'intent\' not in fvar:\n                fvar[\'intent\'] = []\n            fvar[\'intent\'].append(\'out\')\n            flag = 1\n            for i in fvar[\'intent\']:\n                if i.startswith(\'out=\'):\n                    flag = 0\n                    break\n            if flag:\n                fvar[\'intent\'].append(\'out=%s\' % (rname))\n        rout[\'args\'][:] = [fname] + rout[\'args\']\n        return rout, createfuncwrapper(rout)\n    if issubroutine_wrap(rout):\n        fortranname = getfortranname(rout)\n        name = rout[\'name\']\n        outmess(\'\\t\\tCreating wrapper for Fortran subroutine "%s"("%s")...\\n\' % (\n            name, fortranname))\n        rout = copy.copy(rout)\n        return rout, createsubrwrapper(rout)\n    return rout, \'\'\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport sys\nimport collections\nimport operator\n\nimport numpy as np\nimport numpy.core.numeric as _nx\nfrom numpy.core import linspace, atleast_1d, atleast_2d\nfrom numpy.core.numeric import (\n    ones, zeros, arange, concatenate, array, asarray, asanyarray, empty,\n    empty_like, ndarray, around, floor, ceil, take, dot, where, intp,\n    integer, isscalar\n    )\nfrom numpy.core.umath import (\n    pi, multiply, add, arctan2, frompyfunc, cos, less_equal, sqrt, sin,\n    mod, exp, log10\n    )\nfrom numpy.core.fromnumeric import (\n    ravel, nonzero, sort, partition, mean, any, sum\n    )\nfrom numpy.core.numerictypes import typecodes, number\nfrom numpy.lib.twodim_base import diag\nfrom .utils import deprecate\nfrom numpy.core.multiarray import _insert, add_docstring\nfrom numpy.core.multiarray import digitize, bincount, interp as compiled_interp\nfrom numpy.core.umath import _add_newdoc_ufunc as add_newdoc_ufunc\nfrom numpy.compat import long\nfrom numpy.compat.py3k import basestring\n\nif sys.version_info[0] < 3:\n    range = xrange\n\n\n__all__ = [\n    \'select\', \'piecewise\', \'trim_zeros\', \'copy\', \'iterable\', \'percentile\',\n    \'diff\', \'gradient\', \'angle\', \'unwrap\', \'sort_complex\', \'disp\',\n    \'extract\', \'place\', \'vectorize\', \'asarray_chkfinite\', \'average\',\n    \'histogram\', \'histogramdd\', \'bincount\', \'digitize\', \'cov\', \'corrcoef\',\n    \'msort\', \'median\', \'sinc\', \'hamming\', \'hanning\', \'bartlett\',\n    \'blackman\', \'kaiser\', \'trapz\', \'i0\', \'add_newdoc\', \'add_docstring\',\n    \'meshgrid\', \'delete\', \'insert\', \'append\', \'interp\', \'add_newdoc_ufunc\'\n    ]\n\n\ndef iterable(y):\n    \n    try:\n        iter(y)\n    except:\n        return 0\n    return 1\n\n\ndef _hist_optim_numbins_estimator(a, estimator):\n    \n    assert isinstance(estimator, basestring)\n    \n    if a.size == 0:\n        return 1\n\n    def sturges(x):\n        \n        return np.ceil(np.log2(x.size)) + 1\n\n    def rice(x):\n        \n        return np.ceil(2 * x.size ** (1.0 / 3))\n\n    def scott(x):\n        \n        h = 3.5 * x.std() * x.size ** (-1.0 / 3)\n        if h > 0:\n            return np.ceil(x.ptp() / h)\n        return 1\n\n    def fd(x):\n        \n        iqr = np.subtract(*np.percentile(x, [75, 25]))\n\n        if iqr > 0:\n            h = (2 * iqr * x.size ** (-1.0 / 3))\n            return np.ceil(x.ptp() / h)\n\n                return 1\n\n    def auto(x):\n        \n        return max(fd(x), sturges(x))\n\n    optimal_numbins_methods = {\'sturges\': sturges, \'rice\': rice, \'scott\': scott,\n                               \'fd\': fd, \'auto\': auto}\n    try:\n        estimator_func = optimal_numbins_methods[estimator.lower()]\n    except KeyError:\n        raise ValueError("{0} not a valid method for `bins`".format(estimator))\n    else:\n                return int(estimator_func(a))\n\n\ndef histogram(a, bins=10, range=None, normed=False, weights=None,\n              density=None):\n    \n\n    a = asarray(a)\n    if weights is not None:\n        weights = asarray(weights)\n        if np.any(weights.shape != a.shape):\n            raise ValueError(\n                \'weights should have the same shape as a.\')\n        weights = weights.ravel()\n    a = a.ravel()\n\n    if (range is not None):\n        mn, mx = range\n        if (mn > mx):\n            raise AttributeError(\n                \'max must be larger than min in range parameter.\')\n\n    if isinstance(bins, basestring):\n        bins = _hist_optim_numbins_estimator(a, bins)\n                \n        if weights is None:\n        ntype = np.dtype(np.intp)\n    else:\n        ntype = weights.dtype\n\n            BLOCK = 65536\n\n    if not iterable(bins):\n        if np.isscalar(bins) and bins < 1:\n            raise ValueError(\n                \'`bins` should be a positive integer.\')\n        if range is None:\n            if a.size == 0:\n                                range = (0, 1)\n            else:\n                range = (a.min(), a.max())\n        mn, mx = [mi + 0.0 for mi in range]\n        if mn == mx:\n            mn -= 0.5\n            mx += 0.5\n                        if weights is not None and not (np.can_cast(weights.dtype, np.double) or\n                                        np.can_cast(weights.dtype, np.complex)):\n            bins = linspace(mn, mx, bins + 1, endpoint=True)\n\n    if not iterable(bins):\n                \n                n = np.zeros(bins, ntype)\n                norm = bins / (mx - mn)\n\n                                        for i in arange(0, len(a), BLOCK):\n            tmp_a = a[i:i+BLOCK]\n            if weights is None:\n                tmp_w = None\n            else:\n                tmp_w = weights[i:i + BLOCK]\n\n                        keep = (tmp_a >= mn)\n            keep &= (tmp_a <= mx)\n            if not np.logical_and.reduce(keep):\n                tmp_a = tmp_a[keep]\n                if tmp_w is not None:\n                    tmp_w = tmp_w[keep]\n            tmp_a = tmp_a.astype(float)\n            tmp_a -= mn\n            tmp_a *= norm\n\n                                    indices = tmp_a.astype(np.intp)\n            indices[indices == bins] -= 1\n\n                        if ntype.kind == \'c\':\n                n.real += np.bincount(indices, weights=tmp_w.real, minlength=bins)\n                n.imag += np.bincount(indices, weights=tmp_w.imag, minlength=bins)\n            else:\n                n += np.bincount(indices, weights=tmp_w, minlength=bins).astype(ntype)\n\n                bins = linspace(mn, mx, bins + 1, endpoint=True)\n    else:\n        bins = asarray(bins)\n        if (np.diff(bins) < 0).any():\n            raise AttributeError(\n                \'bins must increase monotonically.\')\n\n                n = np.zeros(bins.shape, ntype)\n\n        if weights is None:\n            for i in arange(0, len(a), BLOCK):\n                sa = sort(a[i:i+BLOCK])\n                n += np.r_[sa.searchsorted(bins[:-1], \'left\'),\n                           sa.searchsorted(bins[-1], \'right\')]\n        else:\n            zero = array(0, dtype=ntype)\n            for i in arange(0, len(a), BLOCK):\n                tmp_a = a[i:i+BLOCK]\n                tmp_w = weights[i:i+BLOCK]\n                sorting_index = np.argsort(tmp_a)\n                sa = tmp_a[sorting_index]\n                sw = tmp_w[sorting_index]\n                cw = np.concatenate(([zero, ], sw.cumsum()))\n                bin_index = np.r_[sa.searchsorted(bins[:-1], \'left\'),\n                                  sa.searchsorted(bins[-1], \'right\')]\n                n += cw[bin_index]\n\n\n        n = np.diff(n)\n\n    if density is not None:\n        if density:\n            db = array(np.diff(bins), float)\n            return n/db/n.sum(), bins\n        else:\n            return n, bins\n    else:\n                if normed:\n            db = array(np.diff(bins), float)\n            return n/(n*db).sum(), bins\n        else:\n            return n, bins\n\n\ndef histogramdd(sample, bins=10, range=None, normed=False, weights=None):\n    \n\n    try:\n                N, D = sample.shape\n    except (AttributeError, ValueError):\n                sample = atleast_2d(sample).T\n        N, D = sample.shape\n\n    nbin = empty(D, int)\n    edges = D*[None]\n    dedges = D*[None]\n    if weights is not None:\n        weights = asarray(weights)\n\n    try:\n        M = len(bins)\n        if M != D:\n            raise AttributeError(\n                \'The dimension of bins must be equal to the dimension of the \'\n                \' sample x.\')\n    except TypeError:\n                bins = D*[bins]\n\n            if range is None:\n                if N == 0:\n            smin = zeros(D)\n            smax = ones(D)\n        else:\n            smin = atleast_1d(array(sample.min(0), float))\n            smax = atleast_1d(array(sample.max(0), float))\n    else:\n        smin = zeros(D)\n        smax = zeros(D)\n        for i in arange(D):\n            smin[i], smax[i] = range[i]\n\n        for i in arange(len(smin)):\n        if smin[i] == smax[i]:\n            smin[i] = smin[i] - .5\n            smax[i] = smax[i] + .5\n\n        if np.issubdtype(sample.dtype, np.inexact):\n        edge_dt = sample.dtype\n    else:\n        edge_dt = float\n        for i in arange(D):\n        if isscalar(bins[i]):\n            if bins[i] < 1:\n                raise ValueError(\n                    "Element at index %s in `bins` should be a positive "\n                    "integer." % i)\n            nbin[i] = bins[i] + 2              edges[i] = linspace(smin[i], smax[i], nbin[i]-1, dtype=edge_dt)\n        else:\n            edges[i] = asarray(bins[i], edge_dt)\n            nbin[i] = len(edges[i]) + 1          dedges[i] = diff(edges[i])\n        if np.any(np.asarray(dedges[i]) <= 0):\n            raise ValueError(\n                "Found bin edge of size <= 0. Did you specify `bins` with"\n                "non-monotonic sequence?")\n\n    nbin = asarray(nbin)\n\n        if N == 0:\n        return np.zeros(nbin-2), edges\n\n        Ncount = {}\n    for i in arange(D):\n        Ncount[i] = digitize(sample[:, i], edges[i])\n\n                for i in arange(D):\n                mindiff = dedges[i].min()\n        if not np.isinf(mindiff):\n            decimal = int(-log10(mindiff)) + 6\n                        not_smaller_than_edge = (sample[:, i] >= edges[i][-1])\n            on_edge = (around(sample[:, i], decimal) ==\n                       around(edges[i][-1], decimal))\n                        Ncount[i][where(on_edge & not_smaller_than_edge)[0]] -= 1\n\n                hist = zeros(nbin, float).reshape(-1)\n\n        ni = nbin.argsort()\n    xy = zeros(N, int)\n    for i in arange(0, D-1):\n        xy += Ncount[ni[i]] * nbin[ni[i+1:]].prod()\n    xy += Ncount[ni[-1]]\n\n            if len(xy) == 0:\n        return zeros(nbin-2, int), edges\n\n    flatcount = bincount(xy, weights)\n    a = arange(len(flatcount))\n    hist[a] = flatcount\n\n        hist = hist.reshape(sort(nbin))\n    for i in arange(nbin.size):\n        j = ni.argsort()[i]\n        hist = hist.swapaxes(i, j)\n        ni[i], ni[j] = ni[j], ni[i]\n\n        core = D*[slice(1, -1)]\n    hist = hist[core]\n\n        if normed:\n        s = hist.sum()\n        for i in arange(D):\n            shape = ones(D, int)\n            shape[i] = nbin[i] - 2\n            hist = hist / dedges[i].reshape(shape)\n        hist /= s\n\n    if (hist.shape != nbin - 2).any():\n        raise RuntimeError(\n            "Internal Shape Error")\n    return hist, edges\n\n\ndef average(a, axis=None, weights=None, returned=False):\n    \n    if not isinstance(a, np.matrix):\n        a = np.asarray(a)\n\n    if weights is None:\n        avg = a.mean(axis)\n        scl = avg.dtype.type(a.size/avg.size)\n    else:\n        a = a + 0.0\n        wgt = np.asarray(weights)\n                if a.shape != wgt.shape:\n            if axis is None:\n                raise TypeError(\n                    "Axis must be specified when shapes of a and weights "\n                    "differ.")\n            if wgt.ndim != 1:\n                raise TypeError(\n                    "1D weights expected when shapes of a and weights differ.")\n            if wgt.shape[0] != a.shape[axis]:\n                raise ValueError(\n                    "Length of weights not compatible with specified axis.")\n\n                        wgt = np.array(wgt, copy=0, ndmin=a.ndim).swapaxes(-1, axis)\n\n        scl = wgt.sum(axis=axis, dtype=np.result_type(a.dtype, wgt.dtype))\n        if (scl == 0.0).any():\n            raise ZeroDivisionError(\n                "Weights sum to zero, can\'t be normalized")\n\n        avg = np.multiply(a, wgt).sum(axis)/scl\n\n    if returned:\n        scl = np.multiply(avg, 0) + scl\n        return avg, scl\n    else:\n        return avg\n\n\ndef asarray_chkfinite(a, dtype=None, order=None):\n    \n    a = asarray(a, dtype=dtype, order=order)\n    if a.dtype.char in typecodes[\'AllFloat\'] and not np.isfinite(a).all():\n        raise ValueError(\n            "array must not contain infs or NaNs")\n    return a\n\n\ndef piecewise(x, condlist, funclist, *args, **kw):\n    \n    x = asanyarray(x)\n    n2 = len(funclist)\n    if (isscalar(condlist) or not (isinstance(condlist[0], list) or\n                                   isinstance(condlist[0], ndarray))):\n        condlist = [condlist]\n    condlist = array(condlist, dtype=bool)\n    n = len(condlist)\n                zerod = False\n    if x.ndim == 0:\n        x = x[None]\n        zerod = True\n        if condlist.shape[-1] != 1:\n            condlist = condlist.T\n    if n == n2 - 1:          totlist = np.logical_or.reduce(condlist, axis=0)\n        condlist = np.vstack([condlist, ~totlist])\n        n += 1\n    if (n != n2):\n        raise ValueError(\n                "function list and condition list must be the same")\n\n    y = zeros(x.shape, x.dtype)\n    for k in range(n):\n        item = funclist[k]\n        if not isinstance(item, collections.Callable):\n            y[condlist[k]] = item\n        else:\n            vals = x[condlist[k]]\n            if vals.size > 0:\n                y[condlist[k]] = item(vals, *args, **kw)\n    if zerod:\n        y = y.squeeze()\n    return y\n\n\ndef select(condlist, choicelist, default=0):\n    \n        if len(condlist) != len(choicelist):\n        raise ValueError(\n            \'list of cases must be same length as list of conditions\')\n\n        if len(condlist) == 0:\n                warnings.warn("select with an empty condition list is not possible"\n                      "and will be deprecated",\n                      DeprecationWarning)\n        return np.asarray(default)[()]\n\n    choicelist = [np.asarray(choice) for choice in choicelist]\n    choicelist.append(np.asarray(default))\n\n            dtype = np.result_type(*choicelist)\n\n                condlist = np.broadcast_arrays(*condlist)\n    choicelist = np.broadcast_arrays(*choicelist)\n\n        deprecated_ints = False\n    for i in range(len(condlist)):\n        cond = condlist[i]\n        if cond.dtype.type is not np.bool_:\n            if np.issubdtype(cond.dtype, np.integer):\n                                                condlist[i] = condlist[i].astype(bool)\n                deprecated_ints = True\n            else:\n                raise ValueError(\n                    \'invalid entry in choicelist: should be boolean ndarray\')\n\n    if deprecated_ints:\n                msg = "select condlists containing integer ndarrays is deprecated " \\\n            "and will be removed in the future. Use `.astype(bool)` to " \\\n            "convert to bools."\n        warnings.warn(msg, DeprecationWarning)\n\n    if choicelist[0].ndim == 0:\n                result_shape = condlist[0].shape\n    else:\n        result_shape = np.broadcast_arrays(condlist[0], choicelist[0])[0].shape\n\n    result = np.full(result_shape, choicelist[-1], dtype)\n\n                choicelist = choicelist[-2::-1]\n    condlist = condlist[::-1]\n    for choice, cond in zip(choicelist, condlist):\n        np.copyto(result, choice, where=cond)\n\n    return result\n\n\ndef copy(a, order=\'K\'):\n    \n    return array(a, order=order, copy=True)\n\n\n\ndef gradient(f, *varargs, **kwargs):\n    \n    f = np.asanyarray(f)\n    N = len(f.shape)  \n    axes = kwargs.pop(\'axis\', None)\n    if axes is None:\n        axes = tuple(range(N))\n        if isinstance(axes, int):\n        axes = (axes,)\n    if not isinstance(axes, tuple):\n        raise TypeError("A tuple of integers or a single integer is required")\n\n        axes = tuple(x + N if x < 0 else x for x in axes)\n    if max(axes) >= N or min(axes) < 0:\n        raise ValueError("\'axis\' entry is out of bounds")\n\n    if len(set(axes)) != len(axes):\n        raise ValueError("duplicate value in \'axis\'")\n\n    n = len(varargs)\n    if n == 0:\n        dx = [1.0]*N\n    elif n == 1:\n        dx = [varargs[0]]*N\n    elif n == len(axes):\n        dx = list(varargs)\n    else:\n        raise SyntaxError(\n            "invalid number of arguments")\n\n    edge_order = kwargs.pop(\'edge_order\', 1)\n    if kwargs:\n        raise TypeError(\'"{}" are not valid keyword arguments.\'.format(\n                                                  \'", "\'.join(kwargs.keys())))\n    if edge_order > 2:\n        raise ValueError("\'edge_order\' greater than 2 not supported")\n\n        \n    outvals = []\n\n        slice1 = [slice(None)]*N\n    slice2 = [slice(None)]*N\n    slice3 = [slice(None)]*N\n    slice4 = [slice(None)]*N\n\n    otype = f.dtype.char\n    if otype not in [\'f\', \'d\', \'F\', \'D\', \'m\', \'M\']:\n        otype = \'d\'\n\n        if otype == \'M\':\n                otype = f.dtype.name.replace(\'datetime\', \'timedelta\')\n    elif otype == \'m\':\n                otype = f.dtype\n\n                if f.dtype.char in ["M", "m"]:\n        y = f.view(\'int64\')\n    else:\n        y = f\n\n    for i, axis in enumerate(axes):\n\n        if y.shape[axis] < 2:\n            raise ValueError(\n                "Shape of array too small to calculate a numerical gradient, "\n                "at least two elements are required.")\n\n                if y.shape[axis] == 2 or edge_order == 1:\n                        out = np.empty_like(y, dtype=otype)\n\n            slice1[axis] = slice(1, -1)\n            slice2[axis] = slice(2, None)\n            slice3[axis] = slice(None, -2)\n                        out[slice1] = (y[slice2] - y[slice3])/2.0\n\n            slice1[axis] = 0\n            slice2[axis] = 1\n            slice3[axis] = 0\n                        out[slice1] = (y[slice2] - y[slice3])\n\n            slice1[axis] = -1\n            slice2[axis] = -1\n            slice3[axis] = -2\n                        out[slice1] = (y[slice2] - y[slice3])\n\n                else:\n                        out = np.empty_like(y, dtype=otype)\n\n            slice1[axis] = slice(1, -1)\n            slice2[axis] = slice(2, None)\n            slice3[axis] = slice(None, -2)\n                        out[slice1] = (y[slice2] - y[slice3])/2.0\n\n            slice1[axis] = 0\n            slice2[axis] = 0\n            slice3[axis] = 1\n            slice4[axis] = 2\n                        out[slice1] = -(3.0*y[slice2] - 4.0*y[slice3] + y[slice4])/2.0\n\n            slice1[axis] = -1\n            slice2[axis] = -1\n            slice3[axis] = -2\n            slice4[axis] = -3\n                        out[slice1] = (3.0*y[slice2] - 4.0*y[slice3] + y[slice4])/2.0\n\n                out /= dx[i]\n        outvals.append(out)\n\n                slice1[axis] = slice(None)\n        slice2[axis] = slice(None)\n        slice3[axis] = slice(None)\n        slice4[axis] = slice(None)\n\n    if len(axes) == 1:\n        return outvals[0]\n    else:\n        return outvals\n\n\ndef diff(a, n=1, axis=-1):\n    \n    if n == 0:\n        return a\n    if n < 0:\n        raise ValueError(\n            "order must be non-negative but got " + repr(n))\n    a = asanyarray(a)\n    nd = len(a.shape)\n    slice1 = [slice(None)]*nd\n    slice2 = [slice(None)]*nd\n    slice1[axis] = slice(1, None)\n    slice2[axis] = slice(None, -1)\n    slice1 = tuple(slice1)\n    slice2 = tuple(slice2)\n    if n > 1:\n        return diff(a[slice1]-a[slice2], n-1, axis=axis)\n    else:\n        return a[slice1]-a[slice2]\n\n\ndef interp(x, xp, fp, left=None, right=None, period=None):\n    \n    if period is None:\n        if isinstance(x, (float, int, number)):\n            return compiled_interp([x], xp, fp, left, right).item()\n        elif isinstance(x, np.ndarray) and x.ndim == 0:\n            return compiled_interp([x], xp, fp, left, right).item()\n        else:\n            return compiled_interp(x, xp, fp, left, right)\n    else:\n        if period == 0:\n            raise ValueError("period must be a non-zero value")\n        period = abs(period)\n        left = None\n        right = None\n        return_array = True\n        if isinstance(x, (float, int, number)):\n            return_array = False\n            x = [x]\n        x = np.asarray(x, dtype=np.float64)\n        xp = np.asarray(xp, dtype=np.float64)\n        fp = np.asarray(fp, dtype=np.float64)\n        if xp.ndim != 1 or fp.ndim != 1:\n            raise ValueError("Data points must be 1-D sequences")\n        if xp.shape[0] != fp.shape[0]:\n            raise ValueError("fp and xp are not of the same length")\n                x = x % period\n        xp = xp % period\n        asort_xp = np.argsort(xp)\n        xp = xp[asort_xp]\n        fp = fp[asort_xp]\n        xp = np.concatenate((xp[-1:]-period, xp, xp[0:1]+period))\n        fp = np.concatenate((fp[-1:], fp, fp[0:1]))\n        if return_array:\n            return compiled_interp(x, xp, fp, left, right)\n        else:\n            return compiled_interp(x, xp, fp, left, right).item()\n\n\ndef angle(z, deg=0):\n    \n    if deg:\n        fact = 180/pi\n    else:\n        fact = 1.0\n    z = asarray(z)\n    if (issubclass(z.dtype.type, _nx.complexfloating)):\n        zimag = z.imag\n        zreal = z.real\n    else:\n        zimag = 0\n        zreal = z\n    return arctan2(zimag, zreal) * fact\n\n\ndef unwrap(p, discont=pi, axis=-1):\n    \n    p = asarray(p)\n    nd = len(p.shape)\n    dd = diff(p, axis=axis)\n    slice1 = [slice(None, None)]*nd         slice1[axis] = slice(1, None)\n    ddmod = mod(dd + pi, 2*pi) - pi\n    _nx.copyto(ddmod, pi, where=(ddmod == -pi) & (dd > 0))\n    ph_correct = ddmod - dd\n    _nx.copyto(ph_correct, 0, where=abs(dd) < discont)\n    up = array(p, copy=True, dtype=\'d\')\n    up[slice1] = p[slice1] + ph_correct.cumsum(axis)\n    return up\n\n\ndef sort_complex(a):\n    \n    b = array(a, copy=True)\n    b.sort()\n    if not issubclass(b.dtype.type, _nx.complexfloating):\n        if b.dtype.char in \'bhBH\':\n            return b.astype(\'F\')\n        elif b.dtype.char == \'g\':\n            return b.astype(\'G\')\n        else:\n            return b.astype(\'D\')\n    else:\n        return b\n\n\ndef trim_zeros(filt, trim=\'fb\'):\n    \n    first = 0\n    trim = trim.upper()\n    if \'F\' in trim:\n        for i in filt:\n            if i != 0.:\n                break\n            else:\n                first = first + 1\n    last = len(filt)\n    if \'B\' in trim:\n        for i in filt[::-1]:\n            if i != 0.:\n                break\n            else:\n                last = last - 1\n    return filt[first:last]\n\n\n@deprecate\ndef unique(x):\n    \n    try:\n        tmp = x.flatten()\n        if tmp.size == 0:\n            return tmp\n        tmp.sort()\n        idx = concatenate(([True], tmp[1:] != tmp[:-1]))\n        return tmp[idx]\n    except AttributeError:\n        items = sorted(set(x))\n        return asarray(items)\n\n\ndef extract(condition, arr):\n    \n    return _nx.take(ravel(arr), nonzero(ravel(condition))[0])\n\n\ndef place(arr, mask, vals):\n    \n    return _insert(arr, mask, vals)\n\n\ndef disp(mesg, device=None, linefeed=True):\n    \n    if device is None:\n        device = sys.stdout\n    if linefeed:\n        device.write(\'%s\\n\' % mesg)\n    else:\n        device.write(\'%s\' % mesg)\n    device.flush()\n    return\n\n\nclass vectorize(object):\n    \n\n    def __init__(self, pyfunc, otypes=\'\', doc=None, excluded=None,\n                 cache=False):\n        self.pyfunc = pyfunc\n        self.cache = cache\n        self._ufunc = None    \n        if doc is None:\n            self.__doc__ = pyfunc.__doc__\n        else:\n            self.__doc__ = doc\n\n        if isinstance(otypes, str):\n            self.otypes = otypes\n            for char in self.otypes:\n                if char not in typecodes[\'All\']:\n                    raise ValueError(\n                        "Invalid otype specified: %s" % (char,))\n        elif iterable(otypes):\n            self.otypes = \'\'.join([_nx.dtype(x).char for x in otypes])\n        else:\n            raise ValueError(\n                "Invalid otype specification")\n\n                if excluded is None:\n            excluded = set()\n        self.excluded = set(excluded)\n\n    def __call__(self, *args, **kwargs):\n        \n        excluded = self.excluded\n        if not kwargs and not excluded:\n            func = self.pyfunc\n            vargs = args\n        else:\n                                                nargs = len(args)\n\n            names = [_n for _n in kwargs if _n not in excluded]\n            inds = [_i for _i in range(nargs) if _i not in excluded]\n            the_args = list(args)\n\n            def func(*vargs):\n                for _n, _i in enumerate(inds):\n                    the_args[_i] = vargs[_n]\n                kwargs.update(zip(names, vargs[len(inds):]))\n                return self.pyfunc(*the_args, **kwargs)\n\n            vargs = [args[_i] for _i in inds]\n            vargs.extend([kwargs[_n] for _n in names])\n\n        return self._vectorize_call(func=func, args=vargs)\n\n    def _get_ufunc_and_otypes(self, func, args):\n        \n                if not args:\n            raise ValueError(\'args can not be empty\')\n\n        if self.otypes:\n            otypes = self.otypes\n            nout = len(otypes)\n\n                                    if func is self.pyfunc and self._ufunc is not None:\n                ufunc = self._ufunc\n            else:\n                ufunc = self._ufunc = frompyfunc(func, len(args), nout)\n        else:\n                                                                        inputs = [asarray(_a).flat[0] for _a in args]\n            outputs = func(*inputs)\n\n                                                            if self.cache:\n                _cache = [outputs]\n\n                def _func(*vargs):\n                    if _cache:\n                        return _cache.pop()\n                    else:\n                        return func(*vargs)\n            else:\n                _func = func\n\n            if isinstance(outputs, tuple):\n                nout = len(outputs)\n            else:\n                nout = 1\n                outputs = (outputs,)\n\n            otypes = \'\'.join([asarray(outputs[_k]).dtype.char\n                              for _k in range(nout)])\n\n                                                ufunc = frompyfunc(_func, len(args), nout)\n\n        return ufunc, otypes\n\n    def _vectorize_call(self, func, args):\n        \n        if not args:\n            _res = func()\n        else:\n            ufunc, otypes = self._get_ufunc_and_otypes(func=func, args=args)\n\n                        inputs = [array(_a, copy=False, subok=True, dtype=object)\n                      for _a in args]\n\n            outputs = ufunc(*inputs)\n\n            if ufunc.nout == 1:\n                _res = array(outputs,\n                             copy=False, subok=True, dtype=otypes[0])\n            else:\n                _res = tuple([array(_x, copy=False, subok=True, dtype=_t)\n                              for _x, _t in zip(outputs, otypes)])\n        return _res\n\n\ndef cov(m, y=None, rowvar=1, bias=0, ddof=None, fweights=None, aweights=None):\n    \n        if ddof is not None and ddof != int(ddof):\n        raise ValueError(\n            "ddof must be integer")\n\n        m = np.asarray(m)\n    if y is None:\n        dtype = np.result_type(m, np.float64)\n    else:\n        y = np.asarray(y)\n        dtype = np.result_type(m, y, np.float64)\n    X = array(m, ndmin=2, dtype=dtype)\n    if rowvar == 0 and X.shape[0] != 1:\n        X = X.T\n    if X.shape[0] == 0:\n        return np.array([]).reshape(0, 0)\n    if y is not None:\n        y = array(y, copy=False, ndmin=2, dtype=dtype)\n        if rowvar == 0 and y.shape[0] != 1:\n            y = y.T\n        X = np.vstack((X, y))\n\n    if ddof is None:\n        if bias == 0:\n            ddof = 1\n        else:\n            ddof = 0\n\n        w = None\n    if fweights is not None:\n        fweights = np.asarray(fweights, dtype=np.float)\n        if not np.all(fweights == np.around(fweights)):\n            raise TypeError(\n                "fweights must be integer")\n        if fweights.ndim > 1:\n            raise RuntimeError(\n                "cannot handle multidimensional fweights")\n        if fweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                "incompatible numbers of samples and fweights")\n        if any(fweights < 0):\n            raise ValueError(\n                "fweights cannot be negative")\n        w = fweights\n    if aweights is not None:\n        aweights = np.asarray(aweights, dtype=np.float)\n        if aweights.ndim > 1:\n            raise RuntimeError(\n                "cannot handle multidimensional aweights")\n        if aweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                "incompatible numbers of samples and aweights")\n        if any(aweights < 0):\n            raise ValueError(\n                "aweights cannot be negative")\n        if w is None:\n            w = aweights\n        else:\n            w *= aweights\n\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)\n    w_sum = w_sum[0]\n\n        if w is None:\n        fact = X.shape[1] - ddof\n    elif ddof == 0:\n        fact = w_sum\n    elif aweights is None:\n        fact = w_sum - ddof\n    else:\n        fact = w_sum - ddof*sum(w*aweights)/w_sum\n\n    if fact <= 0:\n        warnings.warn("Degrees of freedom <= 0 for slice", RuntimeWarning)\n        fact = 0.0\n\n    X -= avg[:, None]\n    if w is None:\n        X_T = X.T\n    else:\n        X_T = (X*w).T\n    c = dot(X, X_T.conj())\n    c *= 1. / np.float64(fact)\n    return c.squeeze()\n\n\ndef corrcoef(x, y=None, rowvar=1, bias=np._NoValue, ddof=np._NoValue):\n    \n    if bias is not np._NoValue or ddof is not np._NoValue:\n                warnings.warn(\'bias and ddof have no effect and are deprecated\',\n                      DeprecationWarning)\n    c = cov(x, y, rowvar)\n    try:\n        d = diag(c)\n    except ValueError:                  return c / c\n    d = sqrt(d)\n        for i in range(0, d.size):\n        c[i,:] /= (d * d[i])\n    return c\n\n\ndef blackman(M):\n    \n    if M < 1:\n        return array([])\n    if M == 1:\n        return ones(1, float)\n    n = arange(0, M)\n    return 0.42 - 0.5*cos(2.0*pi*n/(M-1)) + 0.08*cos(4.0*pi*n/(M-1))\n\n\ndef bartlett(M):\n    \n    if M < 1:\n        return array([])\n    if M == 1:\n        return ones(1, float)\n    n = arange(0, M)\n    return where(less_equal(n, (M-1)/2.0), 2.0*n/(M-1), 2.0 - 2.0*n/(M-1))\n\n\ndef hanning(M):\n    \n    if M < 1:\n        return array([])\n    if M == 1:\n        return ones(1, float)\n    n = arange(0, M)\n    return 0.5 - 0.5*cos(2.0*pi*n/(M-1))\n\n\ndef hamming(M):\n    \n    if M < 1:\n        return array([])\n    if M == 1:\n        return ones(1, float)\n    n = arange(0, M)\n    return 0.54 - 0.46*cos(2.0*pi*n/(M-1))\n\n\n_i0A = [\n    -4.41534164647933937950E-18,\n    3.33079451882223809783E-17,\n    -2.43127984654795469359E-16,\n    1.71539128555513303061E-15,\n    -1.16853328779934516808E-14,\n    7.67618549860493561688E-14,\n    -4.85644678311192946090E-13,\n    2.95505266312963983461E-12,\n    -1.72682629144155570723E-11,\n    9.67580903537323691224E-11,\n    -5.18979560163526290666E-10,\n    2.65982372468238665035E-9,\n    -1.30002500998624804212E-8,\n    6.04699502254191894932E-8,\n    -2.67079385394061173391E-7,\n    1.11738753912010371815E-6,\n    -4.41673835845875056359E-6,\n    1.64484480707288970893E-5,\n    -5.75419501008210370398E-5,\n    1.88502885095841655729E-4,\n    -5.76375574538582365885E-4,\n    1.63947561694133579842E-3,\n    -4.32430999505057594430E-3,\n    1.05464603945949983183E-2,\n    -2.37374148058994688156E-2,\n    4.93052842396707084878E-2,\n    -9.49010970480476444210E-2,\n    1.71620901522208775349E-1,\n    -3.04682672343198398683E-1,\n    6.76795274409476084995E-1\n    ]\n\n_i0B = [\n    -7.23318048787475395456E-18,\n    -4.83050448594418207126E-18,\n    4.46562142029675999901E-17,\n    3.46122286769746109310E-17,\n    -2.82762398051658348494E-16,\n    -3.42548561967721913462E-16,\n    1.77256013305652638360E-15,\n    3.81168066935262242075E-15,\n    -9.55484669882830764870E-15,\n    -4.15056934728722208663E-14,\n    1.54008621752140982691E-14,\n    3.85277838274214270114E-13,\n    7.18012445138366623367E-13,\n    -1.79417853150680611778E-12,\n    -1.32158118404477131188E-11,\n    -3.14991652796324136454E-11,\n    1.18891471078464383424E-11,\n    4.94060238822496958910E-10,\n    3.39623202570838634515E-9,\n    2.26666899049817806459E-8,\n    2.04891858946906374183E-7,\n    2.89137052083475648297E-6,\n    6.88975834691682398426E-5,\n    3.36911647825569408990E-3,\n    8.04490411014108831608E-1\n    ]\n\n\ndef _chbevl(x, vals):\n    b0 = vals[0]\n    b1 = 0.0\n\n    for i in range(1, len(vals)):\n        b2 = b1\n        b1 = b0\n        b0 = x*b1 - b2 + vals[i]\n\n    return 0.5*(b0 - b2)\n\n\ndef _i0_1(x):\n    return exp(x) * _chbevl(x/2.0-2, _i0A)\n\n\ndef _i0_2(x):\n    return exp(x) * _chbevl(32.0/x - 2.0, _i0B) / sqrt(x)\n\n\ndef i0(x):\n    \n    x = atleast_1d(x).copy()\n    y = empty_like(x)\n    ind = (x < 0)\n    x[ind] = -x[ind]\n    ind = (x <= 8.0)\n    y[ind] = _i0_1(x[ind])\n    ind2 = ~ind\n    y[ind2] = _i0_2(x[ind2])\n    return y.squeeze()\n\n\n\ndef kaiser(M, beta):\n    \n    from numpy.dual import i0\n    if M == 1:\n        return np.array([1.])\n    n = arange(0, M)\n    alpha = (M-1)/2.0\n    return i0(beta * sqrt(1-((n-alpha)/alpha)**2.0))/i0(float(beta))\n\n\ndef sinc(x):\n    \n    x = np.asanyarray(x)\n    y = pi * where(x == 0, 1.0e-20, x)\n    return sin(y)/y\n\n\ndef msort(a):\n    \n    b = array(a, subok=True, copy=True)\n    b.sort(0)\n    return b\n\n\ndef _ureduce(a, func, **kwargs):\n    \n    a = np.asanyarray(a)\n    axis = kwargs.get(\'axis\', None)\n    if axis is not None:\n        keepdim = list(a.shape)\n        nd = a.ndim\n        try:\n            axis = operator.index(axis)\n            if axis >= nd or axis < -nd:\n                raise IndexError("axis %d out of bounds (%d)" % (axis, a.ndim))\n            keepdim[axis] = 1\n        except TypeError:\n            sax = set()\n            for x in axis:\n                if x >= nd or x < -nd:\n                    raise IndexError("axis %d out of bounds (%d)" % (x, nd))\n                if x in sax:\n                    raise ValueError("duplicate value in axis")\n                sax.add(x % nd)\n                keepdim[x] = 1\n            keep = sax.symmetric_difference(frozenset(range(nd)))\n            nkeep = len(keep)\n                        for i, s in enumerate(sorted(keep)):\n                a = a.swapaxes(i, s)\n                        a = a.reshape(a.shape[:nkeep] + (-1,))\n            kwargs[\'axis\'] = -1\n    else:\n        keepdim = [1] * a.ndim\n\n    r = func(a, **kwargs)\n    return r, keepdim\n\n\ndef median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \n    r, k = _ureduce(a, func=_median, axis=axis, out=out,\n                    overwrite_input=overwrite_input)\n    if keepdims:\n        return r.reshape(k)\n    else:\n        return r\n\ndef _median(a, axis=None, out=None, overwrite_input=False):\n            a = np.asanyarray(a)\n\n        if axis is None:\n        sz = a.size\n    else:\n        sz = a.shape[axis]\n    if sz % 2 == 0:\n        szh = sz // 2\n        kth = [szh - 1, szh]\n    else:\n        kth = [(sz - 1) // 2]\n        if np.issubdtype(a.dtype, np.inexact):\n        kth.append(-1)\n\n    if overwrite_input:\n        if axis is None:\n            part = a.ravel()\n            part.partition(kth)\n        else:\n            a.partition(kth, axis=axis)\n            part = a\n    else:\n        part = partition(a, kth, axis=axis)\n\n    if part.shape == ():\n                return part.item()\n    if axis is None:\n        axis = 0\n\n    indexer = [slice(None)] * part.ndim\n    index = part.shape[axis] // 2\n    if part.shape[axis] % 2 == 1:\n                indexer[axis] = slice(index, index+1)\n    else:\n        indexer[axis] = slice(index-1, index+1)\n\n        if np.issubdtype(a.dtype, np.inexact):\n                rout = mean(part[indexer], axis=axis, out=out)\n        part = np.rollaxis(part, axis, part.ndim)\n        n = np.isnan(part[..., -1])\n        if rout.ndim == 0:\n            if n == True:\n                warnings.warn("Invalid value encountered in median",\n                              RuntimeWarning)\n                if out is not None:\n                    out[...] = a.dtype.type(np.nan)\n                    rout = out\n                else:\n                    rout = a.dtype.type(np.nan)\n        elif np.count_nonzero(n.ravel()) > 0:\n            warnings.warn("Invalid value encountered in median for" +\n                          " %d results" % np.count_nonzero(n.ravel()),\n                          RuntimeWarning)\n            rout[n] = np.nan\n        return rout\n    else:\n                                return mean(part[indexer], axis=axis, out=out)\n\n\ndef percentile(a, q, axis=None, out=None,\n               overwrite_input=False, interpolation=\'linear\', keepdims=False):\n    \n    q = array(q, dtype=np.float64, copy=True)\n    r, k = _ureduce(a, func=_percentile, q=q, axis=axis, out=out,\n                    overwrite_input=overwrite_input,\n                    interpolation=interpolation)\n    if keepdims:\n        if q.ndim == 0:\n            return r.reshape(k)\n        else:\n            return r.reshape([len(q)] + k)\n    else:\n        return r\n\n\ndef _percentile(a, q, axis=None, out=None,\n                overwrite_input=False, interpolation=\'linear\', keepdims=False):\n    a = asarray(a)\n    if q.ndim == 0:\n                zerod = True\n        q = q[None]\n    else:\n        zerod = False\n\n        if q.size < 10:\n        for i in range(q.size):\n            if q[i] < 0. or q[i] > 100.:\n                raise ValueError("Percentiles must be in the range [0,100]")\n            q[i] /= 100.\n    else:\n                if np.count_nonzero(q < 0.) or np.count_nonzero(q > 100.):\n            raise ValueError("Percentiles must be in the range [0,100]")\n        q /= 100.\n\n        if overwrite_input:\n        if axis is None:\n            ap = a.ravel()\n        else:\n            ap = a\n    else:\n        if axis is None:\n            ap = a.flatten()\n        else:\n            ap = a.copy()\n\n    if axis is None:\n        axis = 0\n\n    Nx = ap.shape[axis]\n    indices = q * (Nx - 1)\n\n        if interpolation == \'lower\':\n        indices = floor(indices).astype(intp)\n    elif interpolation == \'higher\':\n        indices = ceil(indices).astype(intp)\n    elif interpolation == \'midpoint\':\n        indices = floor(indices) + 0.5\n    elif interpolation == \'nearest\':\n        indices = around(indices).astype(intp)\n    elif interpolation == \'linear\':\n        pass      else:\n        raise ValueError(\n            "interpolation can only be \'linear\', \'lower\' \'higher\', "\n            "\'midpoint\', or \'nearest\'")\n\n    n = np.array(False, dtype=bool)     if indices.dtype == intp:                  if np.issubdtype(a.dtype, np.inexact):\n            indices = concatenate((indices, [-1]))\n\n        ap.partition(indices, axis=axis)\n                ap = np.rollaxis(ap, axis, 0)\n        axis = 0\n\n                if np.issubdtype(a.dtype, np.inexact):\n            indices = indices[:-1]\n            n = np.isnan(ap[-1:, ...])\n\n        if zerod:\n            indices = indices[0]\n        r = take(ap, indices, axis=axis, out=out)\n\n\n    else:          indices_below = floor(indices).astype(intp)\n        indices_above = indices_below + 1\n        indices_above[indices_above > Nx - 1] = Nx - 1\n\n                if np.issubdtype(a.dtype, np.inexact):\n            indices_above = concatenate((indices_above, [-1]))\n\n        weights_above = indices - indices_below\n        weights_below = 1.0 - weights_above\n\n        weights_shape = [1, ] * ap.ndim\n        weights_shape[axis] = len(indices)\n        weights_below.shape = weights_shape\n        weights_above.shape = weights_shape\n\n        ap.partition(concatenate((indices_below, indices_above)), axis=axis)\n\n                ap = np.rollaxis(ap, axis, 0)\n        weights_below = np.rollaxis(weights_below, axis, 0)\n        weights_above = np.rollaxis(weights_above, axis, 0)\n        axis = 0\n\n                if np.issubdtype(a.dtype, np.inexact):\n            indices_above = indices_above[:-1]\n            n = np.isnan(ap[-1:, ...])\n\n        x1 = take(ap, indices_below, axis=axis) * weights_below\n        x2 = take(ap, indices_above, axis=axis) * weights_above\n\n                x1 = np.rollaxis(x1, axis, 0)\n        x2 = np.rollaxis(x2, axis, 0)\n\n        if zerod:\n            x1 = x1.squeeze(0)\n            x2 = x2.squeeze(0)\n\n        if out is not None:\n            r = add(x1, x2, out=out)\n        else:\n            r = add(x1, x2)\n\n    if np.any(n):\n        warnings.warn("Invalid value encountered in median",\n                              RuntimeWarning)\n        if zerod:\n            if ap.ndim == 1:\n                if out is not None:\n                    out[...] = a.dtype.type(np.nan)\n                    r = out\n                else:\n                    r = a.dtype.type(np.nan)\n            else:\n                r[..., n.squeeze(0)] = a.dtype.type(np.nan)\n        else:\n            if r.ndim == 1:\n                r[:] = a.dtype.type(np.nan)\n            else:\n                r[..., n.repeat(q.size, 0)] = a.dtype.type(np.nan)\n\n    return r\n\n\ndef trapz(y, x=None, dx=1.0, axis=-1):\n    \n    y = asanyarray(y)\n    if x is None:\n        d = dx\n    else:\n        x = asanyarray(x)\n        if x.ndim == 1:\n            d = diff(x)\n                        shape = [1]*y.ndim\n            shape[axis] = d.shape[0]\n            d = d.reshape(shape)\n        else:\n            d = diff(x, axis=axis)\n    nd = len(y.shape)\n    slice1 = [slice(None)]*nd\n    slice2 = [slice(None)]*nd\n    slice1[axis] = slice(1, None)\n    slice2[axis] = slice(None, -1)\n    try:\n        ret = (d * (y[slice1] + y[slice2]) / 2.0).sum(axis)\n    except ValueError:\n                d = np.asarray(d)\n        y = np.asarray(y)\n        ret = add.reduce(d * (y[slice1]+y[slice2])/2.0, axis)\n    return ret\n\n\ndef add_newdoc(place, obj, doc):\n    \n    try:\n        new = getattr(__import__(place, globals(), {}, [obj]), obj)\n        if isinstance(doc, str):\n            add_docstring(new, doc.strip())\n        elif isinstance(doc, tuple):\n            add_docstring(getattr(new, doc[0]), doc[1].strip())\n        elif isinstance(doc, list):\n            for val in doc:\n                add_docstring(getattr(new, val[0]), val[1].strip())\n    except:\n        pass\n\n\ndef meshgrid(*xi, **kwargs):\n    \n    ndim = len(xi)\n\n    copy_ = kwargs.pop(\'copy\', True)\n    sparse = kwargs.pop(\'sparse\', False)\n    indexing = kwargs.pop(\'indexing\', \'xy\')\n\n    if kwargs:\n        raise TypeError("meshgrid() got an unexpected keyword argument \'%s\'"\n                        % (list(kwargs)[0],))\n\n    if indexing not in [\'xy\', \'ij\']:\n        raise ValueError(\n            "Valid values for `indexing` are \'xy\' and \'ij\'.")\n\n    s0 = (1,) * ndim\n    output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1::])\n              for i, x in enumerate(xi)]\n\n    shape = [x.size for x in output]\n\n    if indexing == \'xy\' and ndim > 1:\n                output[0].shape = (1, -1) + (1,)*(ndim - 2)\n        output[1].shape = (-1, 1) + (1,)*(ndim - 2)\n        shape[0], shape[1] = shape[1], shape[0]\n\n    if sparse:\n        if copy_:\n            return [x.copy() for x in output]\n        else:\n            return output\n    else:\n                if copy_:\n            mult_fact = np.ones(shape, dtype=int)\n            return [x * mult_fact for x in output]\n        else:\n            return np.broadcast_arrays(*output)\n\n\ndef delete(arr, obj, axis=None):\n    \n    wrap = None\n    if type(arr) is not ndarray:\n        try:\n            wrap = arr.__array_wrap__\n        except AttributeError:\n            pass\n\n    arr = asarray(arr)\n    ndim = arr.ndim\n    if axis is None:\n        if ndim != 1:\n            arr = arr.ravel()\n        ndim = arr.ndim\n        axis = ndim - 1\n    if ndim == 0:\n                warnings.warn(\n            "in the future the special handling of scalars will be removed "\n            "from delete and raise an error", DeprecationWarning)\n        if wrap:\n            return wrap(arr)\n        else:\n            return arr.copy()\n\n    slobj = [slice(None)]*ndim\n    N = arr.shape[axis]\n    newshape = list(arr.shape)\n\n    if isinstance(obj, slice):\n        start, stop, step = obj.indices(N)\n        xr = range(start, stop, step)\n        numtodel = len(xr)\n\n        if numtodel <= 0:\n            if wrap:\n                return wrap(arr.copy())\n            else:\n                return arr.copy()\n\n                if step < 0:\n            step = -step\n            start = xr[-1]\n            stop = xr[0] + 1\n\n        newshape[axis] -= numtodel\n        new = empty(newshape, arr.dtype, arr.flags.fnc)\n                if start == 0:\n            pass\n        else:\n            slobj[axis] = slice(None, start)\n            new[slobj] = arr[slobj]\n                if stop == N:\n            pass\n        else:\n            slobj[axis] = slice(stop-numtodel, None)\n            slobj2 = [slice(None)]*ndim\n            slobj2[axis] = slice(stop, None)\n            new[slobj] = arr[slobj2]\n                if step == 1:\n            pass\n        else:              keep = ones(stop-start, dtype=bool)\n            keep[:stop-start:step] = False\n            slobj[axis] = slice(start, stop-numtodel)\n            slobj2 = [slice(None)]*ndim\n            slobj2[axis] = slice(start, stop)\n            arr = arr[slobj2]\n            slobj2[axis] = keep\n            new[slobj] = arr[slobj2]\n        if wrap:\n            return wrap(new)\n        else:\n            return new\n\n    _obj = obj\n    obj = np.asarray(obj)\n            if obj.dtype == bool:\n        warnings.warn(\n            "in the future insert will treat boolean arrays and array-likes "\n            "as boolean index instead of casting it to integer", FutureWarning)\n        obj = obj.astype(intp)\n    if isinstance(_obj, (int, long, integer)):\n                obj = obj.item()\n        if (obj < -N or obj >= N):\n            raise IndexError(\n                "index %i is out of bounds for axis %i with "\n                "size %i" % (obj, axis, N))\n        if (obj < 0):\n            obj += N\n        newshape[axis] -= 1\n        new = empty(newshape, arr.dtype, arr.flags.fnc)\n        slobj[axis] = slice(None, obj)\n        new[slobj] = arr[slobj]\n        slobj[axis] = slice(obj, None)\n        slobj2 = [slice(None)]*ndim\n        slobj2[axis] = slice(obj+1, None)\n        new[slobj] = arr[slobj2]\n    else:\n        if obj.size == 0 and not isinstance(_obj, np.ndarray):\n            obj = obj.astype(intp)\n        if not np.can_cast(obj, intp, \'same_kind\'):\n                                                warnings.warn(\n                "using a non-integer array as obj in delete will result in an "\n                "error in the future", DeprecationWarning)\n            obj = obj.astype(intp)\n        keep = ones(N, dtype=bool)\n\n                inside_bounds = (obj < N) & (obj >= -N)\n        if not inside_bounds.all():\n                        warnings.warn(\n                "in the future out of bounds indices will raise an error "\n                "instead of being ignored by `numpy.delete`.",\n                DeprecationWarning)\n            obj = obj[inside_bounds]\n        positive_indices = obj >= 0\n        if not positive_indices.all():\n            warnings.warn(\n                "in the future negative indices will not be ignored by "\n                "`numpy.delete`.", FutureWarning)\n            obj = obj[positive_indices]\n\n        keep[obj, ] = False\n        slobj[axis] = keep\n        new = arr[slobj]\n\n    if wrap:\n        return wrap(new)\n    else:\n        return new\n\n\ndef insert(arr, obj, values, axis=None):\n    \n    wrap = None\n    if type(arr) is not ndarray:\n        try:\n            wrap = arr.__array_wrap__\n        except AttributeError:\n            pass\n\n    arr = asarray(arr)\n    ndim = arr.ndim\n    if axis is None:\n        if ndim != 1:\n            arr = arr.ravel()\n        ndim = arr.ndim\n        axis = ndim - 1\n    else:\n        if ndim > 0 and (axis < -ndim or axis >= ndim):\n            raise IndexError(\n                "axis %i is out of bounds for an array of "\n                "dimension %i" % (axis, ndim))\n        if (axis < 0):\n            axis += ndim\n    if (ndim == 0):\n                warnings.warn(\n            "in the future the special handling of scalars will be removed "\n            "from insert and raise an error", DeprecationWarning)\n        arr = arr.copy()\n        arr[...] = values\n        if wrap:\n            return wrap(arr)\n        else:\n            return arr\n    slobj = [slice(None)]*ndim\n    N = arr.shape[axis]\n    newshape = list(arr.shape)\n\n    if isinstance(obj, slice):\n                indices = arange(*obj.indices(N), **{\'dtype\': intp})\n    else:\n                indices = np.array(obj)\n        if indices.dtype == bool:\n                        warnings.warn(\n                "in the future insert will treat boolean arrays and "\n                "array-likes as a boolean index instead of casting it to "\n                "integer", FutureWarning)\n            indices = indices.astype(intp)\n                                                                    elif indices.ndim > 1:\n            raise ValueError(\n                "index array argument obj to insert must be one dimensional "\n                "or scalar")\n    if indices.size == 1:\n        index = indices.item()\n        if index < -N or index > N:\n            raise IndexError(\n                "index %i is out of bounds for axis %i with "\n                "size %i" % (obj, axis, N))\n        if (index < 0):\n            index += N\n\n                        values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n        if indices.ndim == 0:\n                                                values = np.rollaxis(values, 0, (axis % values.ndim) + 1)\n        numnew = values.shape[axis]\n        newshape[axis] += numnew\n        new = empty(newshape, arr.dtype, arr.flags.fnc)\n        slobj[axis] = slice(None, index)\n        new[slobj] = arr[slobj]\n        slobj[axis] = slice(index, index+numnew)\n        new[slobj] = values\n        slobj[axis] = slice(index+numnew, None)\n        slobj2 = [slice(None)] * ndim\n        slobj2[axis] = slice(index, None)\n        new[slobj] = arr[slobj2]\n        if wrap:\n            return wrap(new)\n        return new\n    elif indices.size == 0 and not isinstance(obj, np.ndarray):\n                indices = indices.astype(intp)\n\n    if not np.can_cast(indices, intp, \'same_kind\'):\n                warnings.warn(\n            "using a non-integer array as obj in insert will result in an "\n            "error in the future", DeprecationWarning)\n        indices = indices.astype(intp)\n\n    indices[indices < 0] += N\n\n    numnew = len(indices)\n    order = indices.argsort(kind=\'mergesort\')       indices[order] += np.arange(numnew)\n\n    newshape[axis] += numnew\n    old_mask = ones(newshape[axis], dtype=bool)\n    old_mask[indices] = False\n\n    new = empty(newshape, arr.dtype, arr.flags.fnc)\n    slobj2 = [slice(None)]*ndim\n    slobj[axis] = indices\n    slobj2[axis] = old_mask\n    new[slobj] = values\n    new[slobj2] = arr\n\n    if wrap:\n        return wrap(new)\n    return new\n\n\ndef append(arr, values, axis=None):\n    \n    arr = asanyarray(arr)\n    if axis is None:\n        if arr.ndim != 1:\n            arr = arr.ravel()\n        values = ravel(values)\n        axis = arr.ndim-1\n    return concatenate((arr, values), axis=axis)\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'G95FCompiler\']\n\nclass G95FCompiler(FCompiler):\n    compiler_type = \'g95\'\n    description = \'G95 Fortran Compiler\'\n\n        \n    version_pattern = r\'G95 \\((GCC (?P<gccversion>[\\d.]+)|.*?) \\(g95 (?P<version>.*)!\\) (?P<date>.*)\\).*\'\n        \n    executables = {\n        \'version_cmd\'  : ["<F90>", "--version"],\n        \'compiler_f77\' : ["g95", "-ffixed-form"],\n        \'compiler_fix\' : ["g95", "-ffixed-form"],\n        \'compiler_f90\' : ["g95"],\n        \'linker_so\'    : ["<F90>", "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n    pic_flags = [\'-fpic\']\n    module_dir_switch = \'-fmod=\'\n    module_include_switch = \'-I\'\n\n    def get_flags(self):\n        return [\'-fno-second-underscore\']\n    def get_flags_opt(self):\n        return [\'-O\']\n    def get_flags_debug(self):\n        return [\'-g\']\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    compiler = G95FCompiler()\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys, os, re\ntry:\n    import hashlib\n    md5new = hashlib.md5\nexcept ImportError:\n    import md5\n    md5new = md5.new\n\nimport textwrap\n\nfrom os.path import join\n\n__docformat__ = \'restructuredtext\'\n\nAPI_FILES = [join(\'multiarray\', \'alloc.c\'),\n             join(\'multiarray\', \'array_assign_array.c\'),\n             join(\'multiarray\', \'array_assign_scalar.c\'),\n             join(\'multiarray\', \'arrayobject.c\'),\n             join(\'multiarray\', \'arraytypes.c.src\'),\n             join(\'multiarray\', \'buffer.c\'),\n             join(\'multiarray\', \'calculation.c\'),\n             join(\'multiarray\', \'conversion_utils.c\'),\n             join(\'multiarray\', \'convert.c\'),\n             join(\'multiarray\', \'convert_datatype.c\'),\n             join(\'multiarray\', \'ctors.c\'),\n             join(\'multiarray\', \'datetime.c\'),\n             join(\'multiarray\', \'datetime_busday.c\'),\n             join(\'multiarray\', \'datetime_busdaycal.c\'),\n             join(\'multiarray\', \'datetime_strings.c\'),\n             join(\'multiarray\', \'descriptor.c\'),\n             join(\'multiarray\', \'einsum.c.src\'),\n             join(\'multiarray\', \'flagsobject.c\'),\n             join(\'multiarray\', \'getset.c\'),\n             join(\'multiarray\', \'item_selection.c\'),\n             join(\'multiarray\', \'iterators.c\'),\n             join(\'multiarray\', \'mapping.c\'),\n             join(\'multiarray\', \'methods.c\'),\n             join(\'multiarray\', \'multiarraymodule.c\'),\n             join(\'multiarray\', \'nditer_api.c\'),\n             join(\'multiarray\', \'nditer_constr.c\'),\n             join(\'multiarray\', \'nditer_pywrap.c\'),\n             join(\'multiarray\', \'nditer_templ.c.src\'),\n             join(\'multiarray\', \'number.c\'),\n             join(\'multiarray\', \'refcount.c\'),\n             join(\'multiarray\', \'scalartypes.c.src\'),\n             join(\'multiarray\', \'scalarapi.c\'),\n             join(\'multiarray\', \'sequence.c\'),\n             join(\'multiarray\', \'shape.c\'),\n             join(\'multiarray\', \'usertypes.c\'),\n             join(\'umath\', \'loops.c.src\'),\n             join(\'umath\', \'ufunc_object.c\'),\n             join(\'umath\', \'ufunc_type_resolution.c\'),\n             join(\'umath\', \'reduction.c\'),\n            ]\nTHIS_DIR = os.path.dirname(__file__)\nAPI_FILES = [os.path.join(THIS_DIR, \'..\', \'src\', a) for a in API_FILES]\n\ndef file_in_this_dir(filename):\n    return os.path.join(THIS_DIR, filename)\n\ndef remove_whitespace(s):\n    return \'\'.join(s.split())\n\ndef _repl(str):\n    return str.replace(\'Bool\', \'npy_bool\')\n\n\nclass StealRef:\n    def __init__(self, arg):\n        self.arg = arg \n    def __str__(self):\n        try:\n            return \' \'.join(\'NPY_STEALS_REF_TO_ARG(%d)\' % x for x in self.arg)\n        except TypeError:\n            return \'NPY_STEALS_REF_TO_ARG(%d)\' % self.arg\n\n\nclass NonNull:\n    def __init__(self, arg):\n        self.arg = arg \n    def __str__(self):\n        try:\n            return \' \'.join(\'NPY_GCC_NONNULL(%d)\' % x for x in self.arg)\n        except TypeError:\n            return \'NPY_GCC_NONNULL(%d)\' % self.arg\n\n\nclass Function(object):\n    def __init__(self, name, return_type, args, doc=\'\'):\n        self.name = name\n        self.return_type = _repl(return_type)\n        self.args = args\n        self.doc = doc\n\n    def _format_arg(self, typename, name):\n        if typename.endswith(\'*\'):\n            return typename + name\n        else:\n            return typename + \' \' + name\n\n    def __str__(self):\n        argstr = \', \'.join([self._format_arg(*a) for a in self.args])\n        if self.doc:\n            doccomment = \'/* %s */\\n\' % self.doc\n        else:\n            doccomment = \'\'\n        return \'%s%s %s(%s)\' % (doccomment, self.return_type, self.name, argstr)\n\n    def to_ReST(self):\n        lines = [\'::\', \'\', \'  \' + self.return_type]\n        argstr = \',\\000\'.join([self._format_arg(*a) for a in self.args])\n        name = \'  %s\' % (self.name,)\n        s = textwrap.wrap(\'(%s)\' % (argstr,), width=72,\n                          initial_indent=name,\n                          subsequent_indent=\' \' * (len(name)+1),\n                          break_long_words=False)\n        for l in s:\n            lines.append(l.replace(\'\\000\', \' \').rstrip())\n        lines.append(\'\')\n        if self.doc:\n            lines.append(textwrap.dedent(self.doc))\n        return \'\\n\'.join(lines)\n\n    def api_hash(self):\n        m = md5new()\n        m.update(remove_whitespace(self.return_type))\n        m.update(\'\\000\')\n        m.update(self.name)\n        m.update(\'\\000\')\n        for typename, name in self.args:\n            m.update(remove_whitespace(typename))\n            m.update(\'\\000\')\n        return m.hexdigest()[:8]\n\nclass ParseError(Exception):\n    def __init__(self, filename, lineno, msg):\n        self.filename = filename\n        self.lineno = lineno\n        self.msg = msg\n\n    def __str__(self):\n        return \'%s:%s:%s\' % (self.filename, self.lineno, self.msg)\n\ndef skip_brackets(s, lbrac, rbrac):\n    count = 0\n    for i, c in enumerate(s):\n        if c == lbrac:\n            count += 1\n        elif c == rbrac:\n            count -= 1\n        if count == 0:\n            return i\n    raise ValueError("no match \'%s\' for \'%s\' (%r)" % (lbrac, rbrac, s))\n\ndef split_arguments(argstr):\n    arguments = []\n    bracket_counts = {\'(\': 0, \'[\': 0}\n    current_argument = []\n    state = 0\n    i = 0\n    def finish_arg():\n        if current_argument:\n            argstr = \'\'.join(current_argument).strip()\n            m = re.match(r\'(.*(\\s+|[*]))(\\w+)$\', argstr)\n            if m:\n                typename = m.group(1).strip()\n                name = m.group(3)\n            else:\n                typename = argstr\n                name = \'\'\n            arguments.append((typename, name))\n            del current_argument[:]\n    while i < len(argstr):\n        c = argstr[i]\n        if c == \',\':\n            finish_arg()\n        elif c == \'(\':\n            p = skip_brackets(argstr[i:], \'(\', \')\')\n            current_argument += argstr[i:i+p]\n            i += p-1\n        else:\n            current_argument += c\n        i += 1\n    finish_arg()\n    return arguments\n\n\ndef find_functions(filename, tag=\'API\'):\n    \n    fo = open(filename, \'r\')\n    functions = []\n    return_type = None\n    function_name = None\n    function_args = []\n    doclist = []\n    SCANNING, STATE_DOC, STATE_RETTYPE, STATE_NAME, STATE_ARGS = list(range(5))\n    state = SCANNING\n    tagcomment = \'/*\' + tag\n    for lineno, line in enumerate(fo):\n        try:\n            line = line.strip()\n            if state == SCANNING:\n                if line.startswith(tagcomment):\n                    if line.endswith(\'*/\'):\n                        state = STATE_RETTYPE\n                    else:\n                        state = STATE_DOC\n            elif state == STATE_DOC:\n                if line.startswith(\'*/\'):\n                    state = STATE_RETTYPE\n                else:\n                    line = line.lstrip(\' *\')\n                    doclist.append(line)\n            elif state == STATE_RETTYPE:\n                                m = re.match(r\'NPY_NO_EXPORT\\s+(.*)$\', line)\n                if m:\n                    line = m.group(1)\n                return_type = line\n                state = STATE_NAME\n            elif state == STATE_NAME:\n                                m = re.match(r\'(\\w+)\\s*\\(\', line)\n                if m:\n                    function_name = m.group(1)\n                else:\n                    raise ParseError(filename, lineno+1,\n                                     \'could not find function name\')\n                function_args.append(line[m.end():])\n                state = STATE_ARGS\n            elif state == STATE_ARGS:\n                if line.startswith(\'{\'):\n                                        fargs_str = \' \'.join(function_args).rstrip(\' )\')\n                    fargs = split_arguments(fargs_str)\n                    f = Function(function_name, return_type, fargs,\n                                 \'\\n\'.join(doclist))\n                    functions.append(f)\n                    return_type = None\n                    function_name = None\n                    function_args = []\n                    doclist = []\n                    state = SCANNING\n                else:\n                    function_args.append(line)\n        except:\n            print(filename, lineno + 1)\n            raise\n    fo.close()\n    return functions\n\ndef should_rebuild(targets, source_files):\n    from distutils.dep_util import newer_group\n    for t in targets:\n        if not os.path.exists(t):\n            return True\n    sources = API_FILES + list(source_files) + [__file__]\n    if newer_group(sources, targets[0], missing=\'newer\'):\n        return True\n    return False\n\nclass TypeApi(object):\n    def __init__(self, name, index, ptr_cast, api_name):\n        self.index = index\n        self.name = name\n        self.ptr_cast = ptr_cast\n        self.api_name = api_name\n\n    def define_from_array_api_string(self):\n        return "                                               self.ptr_cast,\n                                               self.api_name,\n                                               self.index)\n\n    def array_api_define(self):\n        return "        (void *) &%s" % self.name\n\n    def internal_define(self):\n        astr =  % {\'type\': self.name}\n        return astr\n\nclass GlobalVarApi(object):\n    def __init__(self, name, index, type, api_name):\n        self.name = name\n        self.index = index\n        self.type = type\n        self.api_name = api_name\n\n    def define_from_array_api_string(self):\n        return "                                                        self.type,\n                                                        self.api_name,\n                                                        self.index)\n\n    def array_api_define(self):\n        return "        (%s *) &%s" % (self.type, self.name)\n\n    def internal_define(self):\n        astr =  % {\'type\': self.type, \'name\': self.name}\n        return astr\n\nclass BoolValuesApi(object):\n    def __init__(self, name, index, api_name):\n        self.name = name\n        self.index = index\n        self.type = \'PyBoolScalarObject\'\n        self.api_name = api_name\n\n    def define_from_array_api_string(self):\n        return "                                              self.type,\n                                              self.api_name,\n                                              self.index)\n\n    def array_api_define(self):\n        return "        (void *) &%s" % self.name\n\n    def internal_define(self):\n        astr = \n        return astr\n\nclass FunctionApi(object):\n    def __init__(self, name, index, annotations, return_type, args, api_name):\n        self.name = name\n        self.index = index\n        self.annotations = annotations\n        self.return_type = return_type\n        self.args = args\n        self.api_name = api_name\n\n    def _argtypes_string(self):\n        if not self.args:\n            return \'void\'\n        argstr = \', \'.join([_repl(a[0]) for a in self.args])\n        return argstr\n\n    def define_from_array_api_string(self):\n        define =  % (self.name,\n                                self.return_type,\n                                self._argtypes_string(),\n                                self.api_name,\n                                self.index)\n        return define\n\n    def array_api_define(self):\n        return "        (void *) %s" % self.name\n\n    def internal_define(self):\n        annstr = []\n        for a in self.annotations:\n            annstr.append(str(a))\n        annstr = \' \'.join(annstr)\n        astr =  % (annstr, self.return_type,\n                                              self.name,\n                                              self._argtypes_string())\n        return astr\n\ndef order_dict(d):\n    \n    o = list(d.items())\n    def _key(x):\n        return x[1] + (x[0],)\n    return sorted(o, key=_key)\n\ndef merge_api_dicts(dicts):\n    ret = {}\n    for d in dicts:\n        for k, v in d.items():\n            ret[k] = v\n\n    return ret\n\ndef check_api_dict(d):\n    \n                revert_dict = dict([(v, k) for k, v in d.items()])\n    if not len(revert_dict) == len(d):\n                doubled = {}\n        for name, index in d.items():\n            try:\n                doubled[index].append(name)\n            except KeyError:\n                doubled[index] = [name]\n        msg =  % [\'index %d -> %s\' % (index, names) for index, names in doubled.items() \\\n                                          if len(names) != 1]\n        raise ValueError(msg)\n\n        indexes = set(v[0] for v in d.values())\n    expected = set(range(len(indexes)))\n    if not indexes == expected:\n        diff = expected.symmetric_difference(indexes)\n        msg = "There are some holes in the API indexing: " \\\n              "(symmetric diff is %s)" % diff\n        raise ValueError(msg)\n\ndef get_api_functions(tagname, api_dict):\n    \n    functions = []\n    for f in API_FILES:\n        functions.extend(find_functions(f, tagname))\n    dfunctions = []\n    for func in functions:\n        o = api_dict[func.name][0]\n        dfunctions.append( (o, func) )\n    dfunctions.sort()\n    return [a[1] for a in dfunctions]\n\ndef fullapi_hash(api_dicts):\n    \n    a = []\n    for d in api_dicts:\n        for name, data in order_dict(d):\n            a.extend(name)\n            a.extend(\',\'.join(map(str, data)))\n\n    return md5new(\'\'.join(a).encode(\'ascii\')).hexdigest()\n\nVERRE = re.compile(\'(^0x[\\da-f]{8})\\s*=\\s*([\\da-f]{32})\')\n\ndef get_versions_hash():\n    d = []\n\n    file = os.path.join(os.path.dirname(__file__), \'cversions.txt\')\n    fid = open(file, \'r\')\n    try:\n        for line in fid:\n            m = VERRE.match(line)\n            if m:\n                d.append((int(m.group(1), 16), m.group(2)))\n    finally:\n        fid.close()\n\n    return dict(d)\n\ndef main():\n    tagname = sys.argv[1]\n    order_file = sys.argv[2]\n    functions = get_api_functions(tagname, order_file)\n    m = md5new(tagname)\n    for func in functions:\n        print(func)\n        ah = func.api_hash()\n        m.update(ah)\n        print(hex(int(ah, 16)))\n    print(hex(int(m.hexdigest()[:8], 16)))\n\nif __name__ == \'__main__\':\n    main()\nfrom __future__ import division, print_function\n\nimport os\nimport genapi\n\nfrom genapi import \\\n        TypeApi, GlobalVarApi, FunctionApi, BoolValuesApi\n\nimport numpy_api\n\nh_template = r\n\n\nc_template = r\n\nc_api_header = \n\ndef generate_api(output_dir, force=False):\n    basename = \'multiarray_api\'\n\n    h_file = os.path.join(output_dir, \'__%s.h\' % basename)\n    c_file = os.path.join(output_dir, \'__%s.c\' % basename)\n    d_file = os.path.join(output_dir, \'%s.txt\' % basename)\n    targets = (h_file, c_file, d_file)\n\n    sources = numpy_api.multiarray_api\n\n    if (not force and not genapi.should_rebuild(targets, [numpy_api.__file__, __file__])):\n        return targets\n    else:\n        do_generate_api(targets, sources)\n\n    return targets\n\ndef do_generate_api(targets, sources):\n    header_file = targets[0]\n    c_file = targets[1]\n    doc_file = targets[2]\n\n    global_vars = sources[0]\n    scalar_bool_values = sources[1]\n    types_api = sources[2]\n    multiarray_funcs = sources[3]\n\n    multiarray_api = sources[:]\n\n    module_list = []\n    extension_list = []\n    init_list = []\n\n        multiarray_api_index = genapi.merge_api_dicts(multiarray_api)\n    genapi.check_api_dict(multiarray_api_index)\n\n    numpyapi_list = genapi.get_api_functions(\'NUMPY_API\',\n                                              multiarray_funcs)\n    ordered_funcs_api = genapi.order_dict(multiarray_funcs)\n\n        api_name = \'PyArray_API\'\n    multiarray_api_dict = {}\n    for f in numpyapi_list:\n        name = f.name\n        index = multiarray_funcs[name][0]\n        annotations = multiarray_funcs[name][1:]\n        multiarray_api_dict[f.name] = FunctionApi(f.name, index, annotations,\n                                                  f.return_type,\n                                                  f.args, api_name)\n\n    for name, val in global_vars.items():\n        index, type = val\n        multiarray_api_dict[name] = GlobalVarApi(name, index, type, api_name)\n\n    for name, val in scalar_bool_values.items():\n        index = val[0]\n        multiarray_api_dict[name] = BoolValuesApi(name, index, api_name)\n\n    for name, val in types_api.items():\n        index = val[0]\n        multiarray_api_dict[name] = TypeApi(name, index, \'PyTypeObject\', api_name)\n\n    if len(multiarray_api_dict) != len(multiarray_api_index):\n        raise AssertionError("Multiarray API size mismatch %d %d" %\n                        (len(multiarray_api_dict), len(multiarray_api_index)))\n\n    extension_list = []\n    for name, index in genapi.order_dict(multiarray_api_index):\n        api_item = multiarray_api_dict[name]\n        extension_list.append(api_item.define_from_array_api_string())\n        init_list.append(api_item.array_api_define())\n        module_list.append(api_item.internal_define())\n\n        fid = open(header_file, \'w\')\n    s = h_template % (\'\\n\'.join(module_list), \'\\n\'.join(extension_list))\n    fid.write(s)\n    fid.close()\n\n        fid = open(c_file, \'w\')\n    s = c_template % \',\\n\'.join(init_list)\n    fid.write(s)\n    fid.close()\n\n        fid = open(doc_file, \'w\')\n    fid.write(c_api_header)\n    for func in numpyapi_list:\n        fid.write(func.to_ReST())\n        fid.write(\'\\n\\n\')\n    fid.close()\n\n    return targets\nfrom __future__ import division, print_function\n\nimport os\nimport genapi\n\nimport numpy_api\n\nfrom genapi import \\\n        TypeApi, GlobalVarApi, FunctionApi, BoolValuesApi\n\nh_template = r\n\nc_template = r\n\ndef generate_api(output_dir, force=False):\n    basename = \'ufunc_api\'\n\n    h_file = os.path.join(output_dir, \'__%s.h\' % basename)\n    c_file = os.path.join(output_dir, \'__%s.c\' % basename)\n    d_file = os.path.join(output_dir, \'%s.txt\' % basename)\n    targets = (h_file, c_file, d_file)\n\n    sources = [\'ufunc_api_order.txt\']\n\n    if (not force and not genapi.should_rebuild(targets, sources + [__file__])):\n        return targets\n    else:\n        do_generate_api(targets, sources)\n\n    return targets\n\ndef do_generate_api(targets, sources):\n    header_file = targets[0]\n    c_file = targets[1]\n    doc_file = targets[2]\n\n    ufunc_api_index = genapi.merge_api_dicts((\n            numpy_api.ufunc_funcs_api,\n            numpy_api.ufunc_types_api))\n    genapi.check_api_dict(ufunc_api_index)\n\n    ufunc_api_list = genapi.get_api_functions(\'UFUNC_API\', numpy_api.ufunc_funcs_api)\n\n        ufunc_api_dict = {}\n    api_name = \'PyUFunc_API\'\n    for f in ufunc_api_list:\n        name = f.name\n        index = ufunc_api_index[name][0]\n        annotations = ufunc_api_index[name][1:]\n        ufunc_api_dict[name] = FunctionApi(f.name, index, annotations,\n                                           f.return_type, f.args, api_name)\n\n    for name, val in numpy_api.ufunc_types_api.items():\n        index = val[0]\n        ufunc_api_dict[name] = TypeApi(name, index, \'PyTypeObject\', api_name)\n\n        module_list = []\n    extension_list = []\n    init_list = []\n\n    for name, index in genapi.order_dict(ufunc_api_index):\n        api_item = ufunc_api_dict[name]\n        extension_list.append(api_item.define_from_array_api_string())\n        init_list.append(api_item.array_api_define())\n        module_list.append(api_item.internal_define())\n\n        fid = open(header_file, \'w\')\n    s = h_template % (\'\\n\'.join(module_list), \'\\n\'.join(extension_list))\n    fid.write(s)\n    fid.close()\n\n        fid = open(c_file, \'w\')\n    s = c_template % \',\\n\'.join(init_list)\n    fid.write(s)\n    fid.close()\n\n        fid = open(doc_file, \'w\')\n    fid.write()\n    for func in ufunc_api_list:\n        fid.write(func.to_ReST())\n        fid.write(\'\\n\\n\')\n    fid.close()\n\n    return targets\nfrom __future__ import division, print_function\n\nimport os\nimport re\nimport struct\nimport sys\nimport textwrap\n\nsys.path.insert(0, os.path.dirname(__file__))\nimport ufunc_docstrings as docstrings\nsys.path.pop(0)\n\nZero = "PyUFunc_Zero"\nOne = "PyUFunc_One"\nNone_ = "PyUFunc_None"\nReorderableNone = "PyUFunc_ReorderableNone"\n\nclass FullTypeDescr(object):\n    pass\n\nclass FuncNameSuffix(object):\n    \n    def __init__(self, suffix):\n        self.suffix = suffix\n\nclass TypeDescription(object):\n    \n    def __init__(self, type, f=None, in_=None, out=None, astype=None):\n        self.type = type\n        self.func_data = f\n        if astype is None:\n            astype = {}\n        self.astype_dict = astype\n        if in_ is not None:\n            in_ = in_.replace(\'P\', type)\n        self.in_ = in_\n        if out is not None:\n            out = out.replace(\'P\', type)\n        self.out = out\n\n    def finish_signature(self, nin, nout):\n        if self.in_ is None:\n            self.in_ = self.type * nin\n        assert len(self.in_) == nin\n        if self.out is None:\n            self.out = self.type * nout\n        assert len(self.out) == nout\n        self.astype = self.astype_dict.get(self.type, None)\n\n_fdata_map = dict(e=\'npy_%sf\', f=\'npy_%sf\', d=\'npy_%s\', g=\'npy_%sl\',\n                  F=\'nc_%sf\', D=\'nc_%s\', G=\'nc_%sl\')\ndef build_func_data(types, f):\n    func_data = []\n    for t in types:\n        d = _fdata_map.get(t, \'%s\') % (f,)\n        func_data.append(d)\n    return func_data\n\ndef TD(types, f=None, astype=None, in_=None, out=None):\n    if f is not None:\n        if isinstance(f, str):\n            func_data = build_func_data(types, f)\n        else:\n            assert len(f) == len(types)\n            func_data = f\n    else:\n        func_data = (None,) * len(types)\n    if isinstance(in_, str):\n        in_ = (in_,) * len(types)\n    elif in_ is None:\n        in_ = (None,) * len(types)\n    if isinstance(out, str):\n        out = (out,) * len(types)\n    elif out is None:\n        out = (None,) * len(types)\n    tds = []\n    for t, fd, i, o in zip(types, func_data, in_, out):\n        tds.append(TypeDescription(t, f=fd, in_=i, out=o, astype=astype))\n    return tds\n\nclass Ufunc(object):\n    \n    def __init__(self, nin, nout, identity, docstring, typereso,\n                 *type_descriptions):\n        self.nin = nin\n        self.nout = nout\n        if identity is None:\n            identity = None_\n        self.identity = identity\n        self.docstring = docstring\n        self.typereso = typereso\n        self.type_descriptions = []\n        for td in type_descriptions:\n            self.type_descriptions.extend(td)\n        for td in self.type_descriptions:\n            td.finish_signature(self.nin, self.nout)\n\n\nimport string\nif sys.version_info[0] < 3:\n    UPPER_TABLE = string.maketrans(string.ascii_lowercase,\n                                   string.ascii_uppercase)\nelse:\n    UPPER_TABLE = bytes.maketrans(bytes(string.ascii_lowercase, "ascii"),\n                                  bytes(string.ascii_uppercase, "ascii"))\n\ndef english_upper(s):\n    \n    uppered = s.translate(UPPER_TABLE)\n    return uppered\n\n\n\n\nchartoname = {\'?\': \'bool\',\n              \'b\': \'byte\',\n              \'B\': \'ubyte\',\n              \'h\': \'short\',\n              \'H\': \'ushort\',\n              \'i\': \'int\',\n              \'I\': \'uint\',\n              \'l\': \'long\',\n              \'L\': \'ulong\',\n              \'q\': \'longlong\',\n              \'Q\': \'ulonglong\',\n              \'e\': \'half\',\n              \'f\': \'float\',\n              \'d\': \'double\',\n              \'g\': \'longdouble\',\n              \'F\': \'cfloat\',\n              \'D\': \'cdouble\',\n              \'G\': \'clongdouble\',\n              \'M\': \'datetime\',\n              \'m\': \'timedelta\',\n              \'O\': \'OBJECT\',\n                                          \'P\': \'OBJECT\',\n              }\n\nall = \'?bBhHiIlLqQefdgFDGOMm\'\nO = \'O\'\nP = \'P\'\nints = \'bBhHiIlLqQ\'\ntimes = \'Mm\'\ntimedeltaonly = \'m\'\nintsO = ints + O\nbints = \'?\' + ints\nbintsO = bints + O\nflts = \'efdg\'\nfltsO = flts + O\nfltsP = flts + P\ncmplx = \'FDG\'\ncmplxO = cmplx + O\ncmplxP = cmplx + P\ninexact = flts + cmplx\ninexactvec = \'fd\'\nnoint = inexact+O\nnointP = inexact+P\nallP = bints+times+flts+cmplxP\nnobool = all[1:]\nnoobj = all[:-3]+all[-2:]\nnobool_or_obj = all[1:-3]+all[-2:]\nnobool_or_datetime = all[1:-2]+all[-1:]\nintflt = ints+flts\nintfltcmplx = ints+flts+cmplx\nnocmplx = bints+times+flts\nnocmplxO = nocmplx+O\nnocmplxP = nocmplx+P\nnotimes_or_obj = bints + inexact\nnodatetime_or_obj = bints + inexact\n\nint64 = \'\'\nuint64 = \'\'\nfor code in \'bhilq\':\n    if struct.calcsize(code) == 8:\n        int64 = code\n        uint64 = english_upper(code)\n        break\n\ndefdict = {\n\'add\':\n    Ufunc(2, 1, Zero,\n          docstrings.get(\'numpy.core.umath.add\'),\n          \'PyUFunc_AdditionTypeResolver\',\n          TD(notimes_or_obj),\n          [TypeDescription(\'M\', FullTypeDescr, \'Mm\', \'M\'),\n           TypeDescription(\'m\', FullTypeDescr, \'mm\', \'m\'),\n           TypeDescription(\'M\', FullTypeDescr, \'mM\', \'M\'),\n          ],\n          TD(O, f=\'PyNumber_Add\'),\n          ),\n\'subtract\':\n    Ufunc(2, 1, None,           docstrings.get(\'numpy.core.umath.subtract\'),\n          \'PyUFunc_SubtractionTypeResolver\',\n          TD(notimes_or_obj),\n          [TypeDescription(\'M\', FullTypeDescr, \'Mm\', \'M\'),\n           TypeDescription(\'m\', FullTypeDescr, \'mm\', \'m\'),\n           TypeDescription(\'M\', FullTypeDescr, \'MM\', \'m\'),\n          ],\n          TD(O, f=\'PyNumber_Subtract\'),\n          ),\n\'multiply\':\n    Ufunc(2, 1, One,\n          docstrings.get(\'numpy.core.umath.multiply\'),\n          \'PyUFunc_MultiplicationTypeResolver\',\n          TD(notimes_or_obj),\n          [TypeDescription(\'m\', FullTypeDescr, \'mq\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'qm\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'md\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'dm\', \'m\'),\n          ],\n          TD(O, f=\'PyNumber_Multiply\'),\n          ),\n\'divide\':\n    Ufunc(2, 1, None,           docstrings.get(\'numpy.core.umath.divide\'),\n          \'PyUFunc_DivisionTypeResolver\',\n          TD(intfltcmplx),\n          [TypeDescription(\'m\', FullTypeDescr, \'mq\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'md\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'mm\', \'d\'),\n          ],\n          TD(O, f=\'PyNumber_Divide\'),\n          ),\n\'floor_divide\':\n    Ufunc(2, 1, None,           docstrings.get(\'numpy.core.umath.floor_divide\'),\n          \'PyUFunc_DivisionTypeResolver\',\n          TD(intfltcmplx),\n          [TypeDescription(\'m\', FullTypeDescr, \'mq\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'md\', \'m\'),\n                     ],\n          TD(O, f=\'PyNumber_FloorDivide\'),\n          ),\n\'true_divide\':\n    Ufunc(2, 1, None,           docstrings.get(\'numpy.core.umath.true_divide\'),\n          \'PyUFunc_DivisionTypeResolver\',\n          TD(\'bBhH\', out=\'d\'),\n          TD(\'iIlLqQ\', out=\'d\'),\n          TD(flts+cmplx),\n          [TypeDescription(\'m\', FullTypeDescr, \'mq\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'md\', \'m\'),\n           TypeDescription(\'m\', FullTypeDescr, \'mm\', \'d\'),\n          ],\n          TD(O, f=\'PyNumber_TrueDivide\'),\n          ),\n\'conjugate\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.conjugate\'),\n          None,\n          TD(ints+flts+cmplx),\n          TD(P, f=\'conjugate\'),\n          ),\n\'fmod\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.fmod\'),\n          None,\n          TD(ints),\n          TD(flts, f=\'fmod\', astype={\'e\':\'f\'}),\n          TD(P, f=\'fmod\'),\n          ),\n\'square\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.square\'),\n          None,\n          TD(ints+inexact),\n          TD(O, f=\'Py_square\'),\n          ),\n\'reciprocal\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.reciprocal\'),\n          None,\n          TD(ints+inexact),\n          TD(O, f=\'Py_reciprocal\'),\n          ),\n\'_ones_like\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath._ones_like\'),\n          \'PyUFunc_OnesLikeTypeResolver\',\n          TD(noobj),\n          TD(O, f=\'Py_get_one\'),\n          ),\n\'power\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.power\'),\n          None,\n          TD(ints),\n          TD(inexact, f=\'pow\', astype={\'e\':\'f\'}),\n          TD(O, f=\'npy_ObjectPower\'),\n          ),\n\'absolute\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.absolute\'),\n          \'PyUFunc_AbsoluteTypeResolver\',\n          TD(bints+flts+timedeltaonly),\n          TD(cmplx, out=(\'f\', \'d\', \'g\')),\n          TD(O, f=\'PyNumber_Absolute\'),\n          ),\n\'_arg\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath._arg\'),\n          None,\n          TD(cmplx, out=(\'f\', \'d\', \'g\')),\n          ),\n\'negative\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.negative\'),\n          \'PyUFunc_NegativeTypeResolver\',\n          TD(bints+flts+timedeltaonly),\n          TD(cmplx, f=\'neg\'),\n          TD(O, f=\'PyNumber_Negative\'),\n          ),\n\'sign\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.sign\'),\n          \'PyUFunc_SimpleUnaryOperationTypeResolver\',\n          TD(nobool_or_datetime),\n          ),\n\'greater\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.greater\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'greater_equal\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.greater_equal\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'less\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.less\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'less_equal\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.less_equal\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'equal\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.equal\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'not_equal\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.not_equal\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(all, out=\'?\'),\n          ),\n\'logical_and\':\n    Ufunc(2, 1, One,\n          docstrings.get(\'numpy.core.umath.logical_and\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(nodatetime_or_obj, out=\'?\'),\n          TD(O, f=\'npy_ObjectLogicalAnd\'),\n          ),\n\'logical_not\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.logical_not\'),\n          None,\n          TD(nodatetime_or_obj, out=\'?\'),\n          TD(O, f=\'npy_ObjectLogicalNot\'),\n          ),\n\'logical_or\':\n    Ufunc(2, 1, Zero,\n          docstrings.get(\'numpy.core.umath.logical_or\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(nodatetime_or_obj, out=\'?\'),\n          TD(O, f=\'npy_ObjectLogicalOr\'),\n          ),\n\'logical_xor\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.logical_xor\'),\n          \'PyUFunc_SimpleBinaryComparisonTypeResolver\',\n          TD(nodatetime_or_obj, out=\'?\'),\n          TD(P, f=\'logical_xor\'),\n          ),\n\'maximum\':\n    Ufunc(2, 1, ReorderableNone,\n          docstrings.get(\'numpy.core.umath.maximum\'),\n          \'PyUFunc_SimpleBinaryOperationTypeResolver\',\n          TD(noobj),\n          TD(O, f=\'npy_ObjectMax\')\n          ),\n\'minimum\':\n    Ufunc(2, 1, ReorderableNone,\n          docstrings.get(\'numpy.core.umath.minimum\'),\n          \'PyUFunc_SimpleBinaryOperationTypeResolver\',\n          TD(noobj),\n          TD(O, f=\'npy_ObjectMin\')\n          ),\n\'fmax\':\n    Ufunc(2, 1, ReorderableNone,\n          docstrings.get(\'numpy.core.umath.fmax\'),\n          \'PyUFunc_SimpleBinaryOperationTypeResolver\',\n          TD(noobj),\n          TD(O, f=\'npy_ObjectMax\')\n          ),\n\'fmin\':\n    Ufunc(2, 1, ReorderableNone,\n          docstrings.get(\'numpy.core.umath.fmin\'),\n          \'PyUFunc_SimpleBinaryOperationTypeResolver\',\n          TD(noobj),\n          TD(O, f=\'npy_ObjectMin\')\n          ),\n\'logaddexp\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.logaddexp\'),\n          None,\n          TD(flts, f="logaddexp", astype={\'e\':\'f\'})\n          ),\n\'logaddexp2\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.logaddexp2\'),\n          None,\n          TD(flts, f="logaddexp2", astype={\'e\':\'f\'})\n          ),\n\'bitwise_and\':\n    Ufunc(2, 1, One,\n          docstrings.get(\'numpy.core.umath.bitwise_and\'),\n          None,\n          TD(bints),\n          TD(O, f=\'PyNumber_And\'),\n          ),\n\'bitwise_or\':\n    Ufunc(2, 1, Zero,\n          docstrings.get(\'numpy.core.umath.bitwise_or\'),\n          None,\n          TD(bints),\n          TD(O, f=\'PyNumber_Or\'),\n          ),\n\'bitwise_xor\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.bitwise_xor\'),\n          None,\n          TD(bints),\n          TD(O, f=\'PyNumber_Xor\'),\n          ),\n\'invert\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.invert\'),\n          None,\n          TD(bints),\n          TD(O, f=\'PyNumber_Invert\'),\n          ),\n\'left_shift\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.left_shift\'),\n          None,\n          TD(ints),\n          TD(O, f=\'PyNumber_Lshift\'),\n          ),\n\'right_shift\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.right_shift\'),\n          None,\n          TD(ints),\n          TD(O, f=\'PyNumber_Rshift\'),\n          ),\n\'degrees\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.degrees\'),\n          None,\n          TD(fltsP, f=\'degrees\', astype={\'e\':\'f\'}),\n          ),\n\'rad2deg\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.rad2deg\'),\n          None,\n          TD(fltsP, f=\'rad2deg\', astype={\'e\':\'f\'}),\n          ),\n\'radians\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.radians\'),\n          None,\n          TD(fltsP, f=\'radians\', astype={\'e\':\'f\'}),\n          ),\n\'deg2rad\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.deg2rad\'),\n          None,\n          TD(fltsP, f=\'deg2rad\', astype={\'e\':\'f\'}),\n          ),\n\'arccos\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arccos\'),\n          None,\n          TD(inexact, f=\'acos\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arccos\'),\n          ),\n\'arccosh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arccosh\'),\n          None,\n          TD(inexact, f=\'acosh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arccosh\'),\n          ),\n\'arcsin\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arcsin\'),\n          None,\n          TD(inexact, f=\'asin\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arcsin\'),\n          ),\n\'arcsinh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arcsinh\'),\n          None,\n          TD(inexact, f=\'asinh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arcsinh\'),\n          ),\n\'arctan\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arctan\'),\n          None,\n          TD(inexact, f=\'atan\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arctan\'),\n          ),\n\'arctanh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.arctanh\'),\n          None,\n          TD(inexact, f=\'atanh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arctanh\'),\n          ),\n\'cos\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.cos\'),\n          None,\n          TD(inexact, f=\'cos\', astype={\'e\':\'f\'}),\n          TD(P, f=\'cos\'),\n          ),\n\'sin\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.sin\'),\n          None,\n          TD(inexact, f=\'sin\', astype={\'e\':\'f\'}),\n          TD(P, f=\'sin\'),\n          ),\n\'tan\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.tan\'),\n          None,\n          TD(inexact, f=\'tan\', astype={\'e\':\'f\'}),\n          TD(P, f=\'tan\'),\n          ),\n\'cosh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.cosh\'),\n          None,\n          TD(inexact, f=\'cosh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'cosh\'),\n          ),\n\'sinh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.sinh\'),\n          None,\n          TD(inexact, f=\'sinh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'sinh\'),\n          ),\n\'tanh\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.tanh\'),\n          None,\n          TD(inexact, f=\'tanh\', astype={\'e\':\'f\'}),\n          TD(P, f=\'tanh\'),\n          ),\n\'exp\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.exp\'),\n          None,\n          TD(inexact, f=\'exp\', astype={\'e\':\'f\'}),\n          TD(P, f=\'exp\'),\n          ),\n\'exp2\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.exp2\'),\n          None,\n          TD(inexact, f=\'exp2\', astype={\'e\':\'f\'}),\n          TD(P, f=\'exp2\'),\n          ),\n\'expm1\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.expm1\'),\n          None,\n          TD(inexact, f=\'expm1\', astype={\'e\':\'f\'}),\n          TD(P, f=\'expm1\'),\n          ),\n\'log\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.log\'),\n          None,\n          TD(inexact, f=\'log\', astype={\'e\':\'f\'}),\n          TD(P, f=\'log\'),\n          ),\n\'log2\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.log2\'),\n          None,\n          TD(inexact, f=\'log2\', astype={\'e\':\'f\'}),\n          TD(P, f=\'log2\'),\n          ),\n\'log10\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.log10\'),\n          None,\n          TD(inexact, f=\'log10\', astype={\'e\':\'f\'}),\n          TD(P, f=\'log10\'),\n          ),\n\'log1p\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.log1p\'),\n          None,\n          TD(inexact, f=\'log1p\', astype={\'e\':\'f\'}),\n          TD(P, f=\'log1p\'),\n          ),\n\'sqrt\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.sqrt\'),\n          None,\n          TD(inexactvec),\n          TD(inexact, f=\'sqrt\', astype={\'e\':\'f\'}),\n          TD(P, f=\'sqrt\'),\n          ),\n\'cbrt\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.cbrt\'),\n          None,\n          TD(flts, f=\'cbrt\', astype={\'e\':\'f\'}),\n          TD(P, f=\'cbrt\'),\n          ),\n\'ceil\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.ceil\'),\n          None,\n          TD(flts, f=\'ceil\', astype={\'e\':\'f\'}),\n          TD(P, f=\'ceil\'),\n          ),\n\'trunc\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.trunc\'),\n          None,\n          TD(flts, f=\'trunc\', astype={\'e\':\'f\'}),\n          TD(P, f=\'trunc\'),\n          ),\n\'fabs\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.fabs\'),\n          None,\n          TD(flts, f=\'fabs\', astype={\'e\':\'f\'}),\n          TD(P, f=\'fabs\'),\n       ),\n\'floor\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.floor\'),\n          None,\n          TD(flts, f=\'floor\', astype={\'e\':\'f\'}),\n          TD(P, f=\'floor\'),\n          ),\n\'rint\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.rint\'),\n          None,\n          TD(inexact, f=\'rint\', astype={\'e\':\'f\'}),\n          TD(P, f=\'rint\'),\n          ),\n\'arctan2\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.arctan2\'),\n          None,\n          TD(flts, f=\'atan2\', astype={\'e\':\'f\'}),\n          TD(P, f=\'arctan2\'),\n          ),\n\'remainder\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.remainder\'),\n          None,\n          TD(intflt),\n          TD(O, f=\'PyNumber_Remainder\'),\n          ),\n\'hypot\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.hypot\'),\n          None,\n          TD(flts, f=\'hypot\', astype={\'e\':\'f\'}),\n          TD(P, f=\'hypot\'),\n          ),\n\'isnan\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.isnan\'),\n          None,\n          TD(inexact, out=\'?\'),\n          ),\n\'isinf\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.isinf\'),\n          None,\n          TD(inexact, out=\'?\'),\n          ),\n\'isfinite\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.isfinite\'),\n          None,\n          TD(inexact, out=\'?\'),\n          ),\n\'signbit\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.signbit\'),\n          None,\n          TD(flts, out=\'?\'),\n          ),\n\'copysign\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.copysign\'),\n          None,\n          TD(flts),\n          ),\n\'nextafter\':\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.nextafter\'),\n          None,\n          TD(flts),\n          ),\n\'spacing\':\n    Ufunc(1, 1, None,\n          docstrings.get(\'numpy.core.umath.spacing\'),\n          None,\n          TD(flts),\n          ),\n\'modf\':\n    Ufunc(1, 2, None,\n          docstrings.get(\'numpy.core.umath.modf\'),\n          None,\n          TD(flts),\n          ),\n\'ldexp\' :\n    Ufunc(2, 1, None,\n          docstrings.get(\'numpy.core.umath.ldexp\'),\n          None,\n          [TypeDescription(\'e\', None, \'ei\', \'e\'),\n          TypeDescription(\'f\', None, \'fi\', \'f\'),\n          TypeDescription(\'e\', FuncNameSuffix(\'long\'), \'el\', \'e\'),\n          TypeDescription(\'f\', FuncNameSuffix(\'long\'), \'fl\', \'f\'),\n          TypeDescription(\'d\', None, \'di\', \'d\'),\n          TypeDescription(\'d\', FuncNameSuffix(\'long\'), \'dl\', \'d\'),\n          TypeDescription(\'g\', None, \'gi\', \'g\'),\n          TypeDescription(\'g\', FuncNameSuffix(\'long\'), \'gl\', \'g\'),\n          ],\n          ),\n\'frexp\' :\n    Ufunc(1, 2, None,\n          docstrings.get(\'numpy.core.umath.frexp\'),\n          None,\n          [TypeDescription(\'e\', None, \'e\', \'ei\'),\n          TypeDescription(\'f\', None, \'f\', \'fi\'),\n          TypeDescription(\'d\', None, \'d\', \'di\'),\n          TypeDescription(\'g\', None, \'g\', \'gi\'),\n          ],\n          )\n}\n\nif sys.version_info[0] >= 3:\n        del defdict[\'divide\']\n\ndef indent(st, spaces):\n    indention = \' \'*spaces\n    indented = indention + st.replace(\'\\n\', \'\\n\'+indention)\n        indented = re.sub(r\' +$\', r\'\', indented)\n    return indented\n\nchartotype1 = {\'e\': \'e_e\',\n               \'f\': \'f_f\',\n               \'d\': \'d_d\',\n               \'g\': \'g_g\',\n               \'F\': \'F_F\',\n               \'D\': \'D_D\',\n               \'G\': \'G_G\',\n               \'O\': \'O_O\',\n               \'P\': \'O_O_method\'}\n\nchartotype2 = {\'e\': \'ee_e\',\n               \'f\': \'ff_f\',\n               \'d\': \'dd_d\',\n               \'g\': \'gg_g\',\n               \'F\': \'FF_F\',\n               \'D\': \'DD_D\',\n               \'G\': \'GG_G\',\n               \'O\': \'OO_O\',\n               \'P\': \'OO_O_method\'}\n\ndef make_arrays(funcdict):\n                code1list = []\n    code2list = []\n    names = sorted(funcdict.keys())\n    for name in names:\n        uf = funcdict[name]\n        funclist = []\n        datalist = []\n        siglist = []\n        k = 0\n        sub = 0\n\n        if uf.nin > 1:\n            assert uf.nin == 2\n            thedict = chartotype2          else:\n            thedict = chartotype1  \n        for t in uf.type_descriptions:\n            if (t.func_data not in (None, FullTypeDescr) and\n                    not isinstance(t.func_data, FuncNameSuffix)):\n                funclist.append(\'NULL\')\n                astype = \'\'\n                if not t.astype is None:\n                    astype = \'_As_%s\' % thedict[t.astype]\n                astr = (\'%s_functions[%d] = PyUFunc_%s%s;\' %\n                           (name, k, thedict[t.type], astype))\n                code2list.append(astr)\n                if t.type == \'O\':\n                    astr = (\'%s_data[%d] = (void *) %s;\' %\n                               (name, k, t.func_data))\n                    code2list.append(astr)\n                    datalist.append(\'(void *)NULL\')\n                elif t.type == \'P\':\n                    datalist.append(\'(void *)"%s"\' % t.func_data)\n                else:\n                    astr = (\'%s_data[%d] = (void *) %s;\' %\n                               (name, k, t.func_data))\n                    code2list.append(astr)\n                    datalist.append(\'(void *)NULL\')\n                                    sub += 1\n            elif t.func_data is FullTypeDescr:\n                tname = english_upper(chartoname[t.type])\n                datalist.append(\'(void *)NULL\')\n                funclist.append(\n                        \'%s_%s_%s_%s\' % (tname, t.in_, t.out, name))\n            elif isinstance(t.func_data, FuncNameSuffix):\n                datalist.append(\'(void *)NULL\')\n                tname = english_upper(chartoname[t.type])\n                funclist.append(\n                        \'%s_%s_%s\' % (tname, name, t.func_data.suffix))\n            else:\n                datalist.append(\'(void *)NULL\')\n                tname = english_upper(chartoname[t.type])\n                funclist.append(\'%s_%s\' % (tname, name))\n\n            for x in t.in_ + t.out:\n                siglist.append(\'NPY_%s\' % (english_upper(chartoname[x]),))\n\n            k += 1\n\n        funcnames = \', \'.join(funclist)\n        signames = \', \'.join(siglist)\n        datanames = \', \'.join(datalist)\n        code1list.append("static PyUFuncGenericFunction %s_functions[] = {%s};"\n                         % (name, funcnames))\n        code1list.append("static void * %s_data[] = {%s};"\n                         % (name, datanames))\n        code1list.append("static char %s_signatures[] = {%s};"\n                         % (name, signames))\n    return "\\n".join(code1list), "\\n".join(code2list)\n\ndef make_ufuncs(funcdict):\n    code3list = []\n    names = sorted(funcdict.keys())\n    for name in names:\n        uf = funcdict[name]\n        mlist = []\n        docstring = textwrap.dedent(uf.docstring).strip()\n        if sys.version_info[0] < 3:\n            docstring = docstring.encode(\'string-escape\')\n            docstring = docstring.replace(r\'"\', r\'\\"\')\n        else:\n            docstring = docstring.encode(\'unicode-escape\').decode(\'ascii\')\n            docstring = docstring.replace(r\'"\', r\'\\"\')\n                                    docstring = docstring.replace(r"\'", r"\\\'")\n                                docstring = \'\\\\n\\"\\"\'.join(docstring.split(r"\\n"))\n        mlist.append(\\\nr % (name, name, name,\n                                                len(uf.type_descriptions),\n                                                uf.nin, uf.nout,\n                                                uf.identity,\n                                                name, docstring))\n        if uf.typereso != None:\n            mlist.append(\n                r"((PyUFuncObject *)f)->type_resolver = &%s;" % uf.typereso)\n        mlist.append(r % name)\n        mlist.append(r)\n        code3list.append(\'\\n\'.join(mlist))\n    return \'\\n\'.join(code3list)\n\n\ndef make_code(funcdict, filename):\n    code1, code2 = make_arrays(funcdict)\n    code3 = make_ufuncs(funcdict)\n    code2 = indent(code2, 4)\n    code3 = indent(code3, 4)\n    code = r % (filename, code1, code2, code3)\n    return code;\n\n\nif __name__ == "__main__":\n    filename = __file__\n    fid = open(\'__umath_generated.c\', \'w\')\n    code = make_code(defdict, filename)\n    fid.write(code)\n    fid.close()\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'finfo\', \'iinfo\']\n\nfrom .machar import MachAr\nfrom . import numeric\nfrom . import numerictypes as ntypes\nfrom .numeric import array\n\ndef _frz(a):\n    \n    if a.ndim == 0:\n        a.shape = (1,)\n    return a\n\n_convert_to_float = {\n    ntypes.csingle: ntypes.single,\n    ntypes.complex_: ntypes.float_,\n    ntypes.clongfloat: ntypes.longfloat\n    }\n\nclass finfo(object):\n    \n\n    _finfo_cache = {}\n\n    def __new__(cls, dtype):\n        try:\n            dtype = numeric.dtype(dtype)\n        except TypeError:\n                        dtype = numeric.dtype(type(dtype))\n\n        obj = cls._finfo_cache.get(dtype, None)\n        if obj is not None:\n            return obj\n        dtypes = [dtype]\n        newdtype = numeric.obj2sctype(dtype)\n        if newdtype is not dtype:\n            dtypes.append(newdtype)\n            dtype = newdtype\n        if not issubclass(dtype, numeric.inexact):\n            raise ValueError("data type %r not inexact" % (dtype))\n        obj = cls._finfo_cache.get(dtype, None)\n        if obj is not None:\n            return obj\n        if not issubclass(dtype, numeric.floating):\n            newdtype = _convert_to_float[dtype]\n            if newdtype is not dtype:\n                dtypes.append(newdtype)\n                dtype = newdtype\n        obj = cls._finfo_cache.get(dtype, None)\n        if obj is not None:\n            return obj\n        obj = object.__new__(cls)._init(dtype)\n        for dt in dtypes:\n            cls._finfo_cache[dt] = obj\n        return obj\n\n    def _init(self, dtype):\n        self.dtype = numeric.dtype(dtype)\n        if dtype is ntypes.double:\n            itype = ntypes.int64\n            fmt = \'%24.16e\'\n            precname = \'double\'\n        elif dtype is ntypes.single:\n            itype = ntypes.int32\n            fmt = \'%15.7e\'\n            precname = \'single\'\n        elif dtype is ntypes.longdouble:\n            itype = ntypes.longlong\n            fmt = \'%s\'\n            precname = \'long double\'\n        elif dtype is ntypes.half:\n            itype = ntypes.int16\n            fmt = \'%12.5e\'\n            precname = \'half\'\n        else:\n            raise ValueError(repr(dtype))\n\n        machar = MachAr(lambda v:array([v], dtype),\n                        lambda v:_frz(v.astype(itype))[0],\n                        lambda v:array(_frz(v)[0], dtype),\n                        lambda v: fmt % array(_frz(v)[0], dtype),\n                        \'numpy %s precision floating point number\' % precname)\n\n        for word in [\'precision\', \'iexp\',\n                     \'maxexp\', \'minexp\', \'negep\',\n                     \'machep\']:\n            setattr(self, word, getattr(machar, word))\n        for word in [\'tiny\', \'resolution\', \'epsneg\']:\n            setattr(self, word, getattr(machar, word).flat[0])\n        self.max = machar.huge.flat[0]\n        self.min = -self.max\n        self.eps = machar.eps.flat[0]\n        self.nexp = machar.iexp\n        self.nmant = machar.it\n        self.machar = machar\n        self._str_tiny = machar._str_xmin.strip()\n        self._str_max = machar._str_xmax.strip()\n        self._str_epsneg = machar._str_epsneg.strip()\n        self._str_eps = machar._str_eps.strip()\n        self._str_resolution = machar._str_resolution.strip()\n        return self\n\n    def __str__(self):\n        fmt = (\n            \'Machine parameters for %(dtype)s\\n\'\n            \'---------------------------------------------------------------\\n\'\n            \'precision=%(precision)3s   resolution= %(_str_resolution)s\\n\'\n            \'machep=%(machep)6s   eps=        %(_str_eps)s\\n\'\n            \'negep =%(negep)6s   epsneg=     %(_str_epsneg)s\\n\'\n            \'minexp=%(minexp)6s   tiny=       %(_str_tiny)s\\n\'\n            \'maxexp=%(maxexp)6s   max=        %(_str_max)s\\n\'\n            \'nexp  =%(nexp)6s   min=        -max\\n\'\n            \'---------------------------------------------------------------\\n\'\n            )\n        return fmt % self.__dict__\n\n    def __repr__(self):\n        c = self.__class__.__name__\n        d = self.__dict__.copy()\n        d[\'klass\'] = c\n        return (("%(klass)s(resolution=%(resolution)s, min=-%(_str_max)s,"\n                 " max=%(_str_max)s, dtype=%(dtype)s)") % d)\n\n\nclass iinfo(object):\n    \n\n    _min_vals = {}\n    _max_vals = {}\n\n    def __init__(self, int_type):\n        try:\n            self.dtype = numeric.dtype(int_type)\n        except TypeError:\n            self.dtype = numeric.dtype(type(int_type))\n        self.kind = self.dtype.kind\n        self.bits = self.dtype.itemsize * 8\n        self.key = "%s%d" % (self.kind, self.bits)\n        if self.kind not in \'iu\':\n            raise ValueError("Invalid integer data type.")\n\n    def min(self):\n        \n        if self.kind == \'u\':\n            return 0\n        else:\n            try:\n                val = iinfo._min_vals[self.key]\n            except KeyError:\n                val = int(-(1 << (self.bits-1)))\n                iinfo._min_vals[self.key] = val\n            return val\n\n    min = property(min)\n\n    def max(self):\n        \n        try:\n            val = iinfo._max_vals[self.key]\n        except KeyError:\n            if self.kind == \'u\':\n                val = int((1 << self.bits) - 1)\n            else:\n                val = int((1 << (self.bits-1)) - 1)\n            iinfo._max_vals[self.key] = val\n        return val\n\n    max = property(max)\n\n    def __str__(self):\n        \n        fmt = (\n            \'Machine parameters for %(dtype)s\\n\'\n            \'---------------------------------------------------------------\\n\'\n            \'min = %(min)s\\n\'\n            \'max = %(max)s\\n\'\n            \'---------------------------------------------------------------\\n\'\n            )\n        return fmt % {\'dtype\': self.dtype, \'min\': self.min, \'max\': self.max}\n\n    def __repr__(self):\n        return "%s(min=%s, max=%s, dtype=%s)" % (self.__class__.__name__,\n                                    self.min, self.max, self.dtype)\n\nif __name__ == \'__main__\':\n    f = finfo(ntypes.single)\n    print(\'single epsilon:\', f.eps)\n    print(\'single tiny:\', f.tiny)\n    f = finfo(ntypes.float)\n    print(\'float epsilon:\', f.eps)\n    print(\'float tiny:\', f.tiny)\n    f = finfo(ntypes.longfloat)\n    print(\'longfloat epsilon:\', f.eps)\n    print(\'longfloat tiny:\', f.tiny)\n\nfrom __future__ import division, absolute_import, print_function\nfrom __future__ import division, absolute_import, print_function\n\nimport re\nimport os\nimport sys\nimport warnings\nimport platform\nimport tempfile\nfrom subprocess import Popen, PIPE, STDOUT\n\nfrom numpy.distutils.fcompiler import FCompiler\nfrom numpy.distutils.exec_command import exec_command\nfrom numpy.distutils.misc_util import msvc_runtime_library\nfrom numpy.distutils.compat import get_exception\n\ncompilers = [\'GnuFCompiler\', \'Gnu95FCompiler\']\n\nTARGET_R = re.compile("Target: ([a-zA-Z0-9_\\-]*)")\n\ndef is_win64():\n    return sys.platform == "win32" and platform.architecture()[0] == "64bit"\ndef is_win32():\n    return sys.platform == "win32" and platform.architecture()[0] == "32bit"\n\nif is_win64():\n    _EXTRAFLAGS = []\nelse:\n    _EXTRAFLAGS = []\n\nclass GnuFCompiler(FCompiler):\n    compiler_type = \'gnu\'\n    compiler_aliases = (\'g77\',)\n    description = \'GNU Fortran 77 compiler\'\n\n    def gnu_version_match(self, version_string):\n        \n                while version_string.startswith(\'gfortran: warning\'):\n            version_string = version_string[version_string.find(\'\\n\')+1:]\n\n                                        if len(version_string) <= 20:\n                        m = re.search(r\'([0-9.]+)\', version_string)\n            if m:\n                                                if version_string.startswith(\'GNU Fortran\'):\n                    return (\'g77\', m.group(1))\n\n                                                elif m.start() == 0:\n                    return (\'gfortran\', m.group(1))\n        else:\n                        m = re.search(r\'GNU Fortran\\s+95.*?([0-9-.]+)\', version_string)\n            if m:\n                return (\'gfortran\', m.group(1))\n            m = re.search(r\'GNU Fortran.*?\\-?([0-9-.]+)\', version_string)\n            if m:\n                v = m.group(1)\n                if v.startswith(\'0\') or v.startswith(\'2\') or v.startswith(\'3\'):\n                                        return (\'g77\', v)\n                else:\n                                                            return (\'gfortran\', v)\n\n                err = \'A valid Fortran version was not found in this string:\\n\'\n        raise ValueError(err + version_string)\n\n    def version_match(self, version_string):\n        v = self.gnu_version_match(version_string)\n        if not v or v[0] != \'g77\':\n            return None\n        return v[1]\n\n    possible_executables = [\'g77\', \'f77\']\n    executables = {\n        \'version_cmd\'  : [None, "-dumpversion"],\n        \'compiler_f77\' : [None, "-g", "-Wall", "-fno-second-underscore"],\n        \'compiler_f90\' : None,          \'compiler_fix\' : None,\n        \'linker_so\'    : [None, "-g", "-Wall"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"],\n        \'linker_exe\'   : [None, "-g", "-Wall"]\n        }\n    module_dir_switch = None\n    module_include_switch = None\n\n            if os.name != \'nt\' and sys.platform != \'cygwin\':\n        pic_flags = [\'-fPIC\']\n\n        if sys.platform == \'win32\':\n        for key in [\'version_cmd\', \'compiler_f77\', \'linker_so\', \'linker_exe\']:\n            executables[key].append(\'-mno-cygwin\')\n\n    g2c = \'g2c\'\n    suggested_f90_compiler = \'gnu95\'\n\n    def get_flags_linker_so(self):\n        opt = self.linker_so[1:]\n        if sys.platform == \'darwin\':\n            target = os.environ.get(\'MACOSX_DEPLOYMENT_TARGET\', None)\n                                                                        if not target:\n                                                                                                                import distutils.sysconfig as sc\n                g = {}\n                filename = sc.get_makefile_filename()\n                sc.parse_makefile(filename, g)\n                target = g.get(\'MACOSX_DEPLOYMENT_TARGET\', \'10.3\')\n                os.environ[\'MACOSX_DEPLOYMENT_TARGET\'] = target\n                if target == \'10.3\':\n                    s = \'Env. variable MACOSX_DEPLOYMENT_TARGET set to 10.3\'\n                    warnings.warn(s)\n\n            opt.extend([\'-undefined\', \'dynamic_lookup\', \'-bundle\'])\n        else:\n            opt.append("-shared -Wl,-gc-sections -Wl,-s")\n        if sys.platform.startswith(\'sunos\'):\n                                                                                    opt.append(\'-mimpure-text\')\n        return opt\n\n    def get_libgcc_dir(self):\n        status, output = exec_command(self.compiler_f77 +\n                                      [\'-print-libgcc-file-name\'],\n                                      use_tee=0)\n        if not status:\n            return os.path.dirname(output)\n        return None\n\n    def get_library_dirs(self):\n        opt = []\n        if sys.platform[:5] != \'linux\':\n            d = self.get_libgcc_dir()\n            if d:\n                                if sys.platform == \'win32\' and not d.startswith(\'/usr/lib\'):\n                    d = os.path.normpath(d)\n                    path = os.path.join(d, "lib%s.a" % self.g2c)\n                    if not os.path.exists(path):\n                        root = os.path.join(d, *((os.pardir,)*4))\n                        d2 = os.path.abspath(os.path.join(root, \'lib\'))\n                        path = os.path.join(d2, "lib%s.a" % self.g2c)\n                        if os.path.exists(path):\n                            opt.append(d2)\n                opt.append(d)\n        return opt\n\n    def get_libraries(self):\n        opt = []\n        d = self.get_libgcc_dir()\n        if d is not None:\n            g2c = self.g2c + \'-pic\'\n            f = self.static_lib_format % (g2c, self.static_lib_extension)\n            if not os.path.isfile(os.path.join(d, f)):\n                g2c = self.g2c\n        else:\n            g2c = self.g2c\n\n        if g2c is not None:\n            opt.append(g2c)\n        c_compiler = self.c_compiler\n        if sys.platform == \'win32\' and c_compiler and \\\n               c_compiler.compiler_type == \'msvc\':\n                                    opt.append(\'gcc\')\n            runtime_lib = msvc_runtime_library()\n            if runtime_lib:\n                opt.append(runtime_lib)\n        if sys.platform == \'darwin\':\n            opt.append(\'cc_dynamic\')\n        return opt\n\n    def get_flags_debug(self):\n        return [\'-g\']\n\n    def get_flags_opt(self):\n        v = self.get_version()\n        if v and v <= \'3.3.3\':\n                                    opt = [\'-O2\']\n        elif v and v >= \'4.6.0\':\n            if is_win32():\n                                                                opt = [\'-O2 -march=pentium4 -mtune=generic -mfpmath=sse -msse2\'\n                       \' -mlong-double-64 -mincoming-stack-boundary=2\' \n                       \' -ffpe-summary=invalid,zero\']\n            else:\n                opt = [\'-O2 -march=x86-64 -DMS_WIN64 -mtune=generic -msse2\'\n                       \' -mlong-double-64 -ffpe-summary=invalid,zero\']\n        else:\n            opt = [\'-O2\']\n\n        return opt\n\n    def _c_arch_flags(self):\n        \n        from distutils import sysconfig\n        try:\n            cflags = sysconfig.get_config_vars()[\'CFLAGS\']\n        except KeyError:\n            return []\n        arch_re = re.compile(r"-arch\\s+(\\w+)")\n        arch_flags = []\n        for arch in arch_re.findall(cflags):\n            arch_flags += [\'-arch\', arch]\n        return arch_flags\n\n    def get_flags_arch(self):\n        return []\n\n    def runtime_library_dir_option(self, dir):\n        return \'-Wl,-rpath="%s"\' % dir\n\nclass Gnu95FCompiler(GnuFCompiler):\n    compiler_type = \'gnu95\'\n    compiler_aliases = (\'gfortran\',)\n    description = \'GNU Fortran 95 compiler\'\n\n    def version_match(self, version_string):\n        v = self.gnu_version_match(version_string)\n        if not v or v[0] != \'gfortran\':\n            return None\n        v = v[1]\n        if v >= \'4.\':\n                        pass\n        else:\n                                    if sys.platform == \'win32\':\n                for key in [\'version_cmd\', \'compiler_f77\', \'compiler_f90\',\n                            \'compiler_fix\', \'linker_so\', \'linker_exe\']:\n                    self.executables[key].append(\'-mno-cygwin\')\n        return v\n\n    possible_executables = [\'gfortran\', \'f95\']\n    executables = {\n        \'version_cmd\'  : ["<F90>", "-dumpversion"],\n        \'compiler_f77\' : [None, "-Wall", "-g", "-ffixed-form",\n                          "-fno-second-underscore"] + _EXTRAFLAGS,\n        \'compiler_f90\' : [None, "-Wall",\n                          "-fno-second-underscore"] + _EXTRAFLAGS,\n        \'compiler_fix\' : [None, "-Wall",  "-g","-ffixed-form",\n                          "-fno-second-underscore"] + _EXTRAFLAGS,\n        \'linker_so\'    : ["<F90>", "-Wall"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"],\n        \'linker_exe\'   : [None, "-Wall"]\n        }\n\n    module_dir_switch = \'-J\'\n    module_include_switch = \'-I\'\n\n    g2c = \'gfortran\'\n\n    def _universal_flags(self, cmd):\n        \n        if not sys.platform == \'darwin\':\n            return []\n        arch_flags = []\n                c_archs = self._c_arch_flags()\n        if "i386" in c_archs:\n            c_archs[c_archs.index("i386")] = "i686"\n                        for arch in ["ppc", "i686", "x86_64", "ppc64"]:\n            if _can_target(cmd, arch) and arch in c_archs:\n                arch_flags.extend(["-arch", arch])\n        return arch_flags\n\n    def get_flags(self):\n        flags = GnuFCompiler.get_flags(self)\n        arch_flags = self._universal_flags(self.compiler_f90)\n        if arch_flags:\n            flags[:0] = arch_flags\n        return flags\n\n    def get_flags_linker_so(self):\n        flags = GnuFCompiler.get_flags_linker_so(self)\n        arch_flags = self._universal_flags(self.linker_so)\n        if arch_flags:\n            flags[:0] = arch_flags\n        return flags\n\n    def get_library_dirs(self):\n        opt = GnuFCompiler.get_library_dirs(self)\n        if sys.platform == \'win32\':\n            c_compiler = self.c_compiler\n            if c_compiler and c_compiler.compiler_type == "msvc":\n                target = self.get_target()\n                if target:\n                    d = os.path.normpath(self.get_libgcc_dir())\n                    root = os.path.join(d, *((os.pardir,)*4))\n                    path = os.path.join(root, target, "lib")\n                    mingwdir = os.path.normpath(path)\n                    if os.path.exists(os.path.join(mingwdir, "libmingwex.a")):\n                        opt.append(mingwdir)\n        return opt\n\n    def get_libraries(self):\n        opt = GnuFCompiler.get_libraries(self)\n        if sys.platform == \'darwin\':\n            opt.remove(\'cc_dynamic\')\n        if sys.platform == \'win32\':\n            c_compiler = self.c_compiler\n            if c_compiler and c_compiler.compiler_type == "msvc":\n                if "gcc" in opt:\n                    i = opt.index("gcc")\n                    opt.insert(i+1, "mingwex")\n                    opt.insert(i+1, "mingw32")\n                        if is_win64():\n                c_compiler = self.c_compiler\n                if c_compiler and c_compiler.compiler_type == "msvc":\n                    return []\n                else:\n                    pass\n        return opt\n\n    def get_target(self):\n        status, output = exec_command(self.compiler_f77 +\n                                      [\'-v\'],\n                                      use_tee=0)\n        if not status:\n            m = TARGET_R.search(output)\n            if m:\n                return m.group(1)\n        return ""\n\n    def get_flags_opt(self):\n        return GnuFCompiler.get_flags_opt(self)\n\ndef _can_target(cmd, arch):\n    \n    newcmd = cmd[:]\n    fid, filename = tempfile.mkstemp(suffix=".f")\n    try:\n        d = os.path.dirname(filename)\n        output = os.path.splitext(filename)[0] + ".o"\n        try:\n            newcmd.extend(["-arch", arch, "-c", filename])\n            p = Popen(newcmd, stderr=STDOUT, stdout=PIPE, cwd=d)\n            p.communicate()\n            return p.returncode == 0\n        finally:\n            if os.path.exists(output):\n                os.remove(output)\n    finally:\n        os.remove(filename)\n    return False\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n\n    try:\n        compiler = GnuFCompiler()\n        compiler.customize()\n        print(compiler.get_version())\n    except Exception:\n        msg = get_exception()\n        print(msg)\n\n    try:\n        compiler = Gnu95FCompiler()\n        compiler.customize()\n        print(compiler.get_version())\n    except Exception:\n        msg = get_exception()\n        print(msg)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport numpy as np\nimport numpy.linalg as la\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\n__all__ = [\n    \'hermzero\', \'hermone\', \'hermx\', \'hermdomain\', \'hermline\', \'hermadd\',\n    \'hermsub\', \'hermmulx\', \'hermmul\', \'hermdiv\', \'hermpow\', \'hermval\',\n    \'hermder\', \'hermint\', \'herm2poly\', \'poly2herm\', \'hermfromroots\',\n    \'hermvander\', \'hermfit\', \'hermtrim\', \'hermroots\', \'Hermite\',\n    \'hermval2d\', \'hermval3d\', \'hermgrid2d\', \'hermgrid3d\', \'hermvander2d\',\n    \'hermvander3d\', \'hermcompanion\', \'hermgauss\', \'hermweight\']\n\nhermtrim = pu.trimcoef\n\n\ndef poly2herm(pol):\n    \n    [pol] = pu.as_series([pol])\n    deg = len(pol) - 1\n    res = 0\n    for i in range(deg, -1, -1):\n        res = hermadd(hermmulx(res), pol[i])\n    return res\n\n\ndef herm2poly(c):\n    \n    from .polynomial import polyadd, polysub, polymulx\n\n    [c] = pu.as_series([c])\n    n = len(c)\n    if n == 1:\n        return c\n    if n == 2:\n        c[1] *= 2\n        return c\n    else:\n        c0 = c[-2]\n        c1 = c[-1]\n                for i in range(n - 1, 1, -1):\n            tmp = c0\n            c0 = polysub(c[i - 2], c1*(2*(i - 1)))\n            c1 = polyadd(tmp, polymulx(c1)*2)\n        return polyadd(c0, polymulx(c1)*2)\n\n\nhermdomain = np.array([-1, 1])\n\nhermzero = np.array([0])\n\nhermone = np.array([1])\n\nhermx = np.array([0, 1/2])\n\n\ndef hermline(off, scl):\n    \n    if scl != 0:\n        return np.array([off, scl/2])\n    else:\n        return np.array([off])\n\n\ndef hermfromroots(roots):\n    \n    if len(roots) == 0:\n        return np.ones(1)\n    else:\n        [roots] = pu.as_series([roots], trim=False)\n        roots.sort()\n        p = [hermline(-r, 1) for r in roots]\n        n = len(p)\n        while n > 1:\n            m, r = divmod(n, 2)\n            tmp = [hermmul(p[i], p[i+m]) for i in range(m)]\n            if r:\n                tmp[0] = hermmul(tmp[0], p[-1])\n            p = tmp\n            n = m\n        return p[0]\n\n\ndef hermadd(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] += c2\n        ret = c1\n    else:\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef hermsub(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] -= c2\n        ret = c1\n    else:\n        c2 = -c2\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef hermmulx(c):\n    \n        [c] = pu.as_series([c])\n        if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]*0\n    prd[1] = c[0]/2\n    for i in range(1, len(c)):\n        prd[i + 1] = c[i]/2\n        prd[i - 1] += c[i]*i\n    return prd\n\n\ndef hermmul(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n\n    if len(c1) > len(c2):\n        c = c2\n        xs = c1\n    else:\n        c = c1\n        xs = c2\n\n    if len(c) == 1:\n        c0 = c[0]*xs\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]*xs\n        c1 = c[1]*xs\n    else:\n        nd = len(c)\n        c0 = c[-2]*xs\n        c1 = c[-1]*xs\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = hermsub(c[-i]*xs, c1*(2*(nd - 1)))\n            c1 = hermadd(tmp, hermmulx(c1)*2)\n    return hermadd(c0, hermmulx(c1)*2)\n\n\ndef hermdiv(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    lc1 = len(c1)\n    lc2 = len(c2)\n    if lc1 < lc2:\n        return c1[:1]*0, c1\n    elif lc2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    else:\n        quo = np.empty(lc1 - lc2 + 1, dtype=c1.dtype)\n        rem = c1\n        for i in range(lc1 - lc2, - 1, -1):\n            p = hermmul([0]*i + [1], c2)\n            q = rem[-1]/p[-1]\n            rem = rem[:-1] - q*p[:-1]\n            quo[i] = q\n        return quo, pu.trimseq(rem)\n\n\ndef hermpow(c, pow, maxpower=16):\n    \n        [c] = pu.as_series([c])\n    power = int(pow)\n    if power != pow or power < 0:\n        raise ValueError("Power must be a non-negative integer.")\n    elif maxpower is not None and power > maxpower:\n        raise ValueError("Power is too large")\n    elif power == 0:\n        return np.array([1], dtype=c.dtype)\n    elif power == 1:\n        return c\n    else:\n                        prd = c\n        for i in range(2, power + 1):\n            prd = hermmul(prd, c)\n        return prd\n\n\ndef hermder(c, m=1, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of derivation must be integer")\n    if cnt < 0:\n        raise ValueError("The order of derivation must be non-negative")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    n = len(c)\n    if cnt >= n:\n        c = c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=c.dtype)\n            for j in range(n, 0, -1):\n                der[j - 1] = (2*j)*c[j]\n            c = der\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef hermint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if not np.iterable(k):\n        k = [k]\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of integration must be integer")\n    if cnt < 0:\n        raise ValueError("The order of integration must be non-negative")\n    if len(k) > cnt:\n        raise ValueError("Too many integration constants")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    k = list(k) + [0]*(cnt - len(k))\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=c.dtype)\n            tmp[0] = c[0]*0\n            tmp[1] = c[0]/2\n            for j in range(1, n):\n                tmp[j + 1] = c[j]/(2*(j + 1))\n            tmp[0] += k[i] - hermval(lbnd, tmp)\n            c = tmp\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef hermval(x, c, tensor=True):\n    \n    c = np.array(c, ndmin=1, copy=0)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    x2 = x*2\n    if len(c) == 1:\n        c0 = c[0]\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]\n        c1 = c[1]\n    else:\n        nd = len(c)\n        c0 = c[-2]\n        c1 = c[-1]\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = c[-i] - c1*(2*(nd - 1))\n            c1 = tmp + c1*x2\n    return c0 + c1*x2\n\n\ndef hermval2d(x, y, c):\n    \n    try:\n        x, y = np.array((x, y), copy=0)\n    except:\n        raise ValueError(\'x, y are incompatible\')\n\n    c = hermval(x, c)\n    c = hermval(y, c, tensor=False)\n    return c\n\n\ndef hermgrid2d(x, y, c):\n    \n    c = hermval(x, c)\n    c = hermval(y, c)\n    return c\n\n\ndef hermval3d(x, y, z, c):\n    \n    try:\n        x, y, z = np.array((x, y, z), copy=0)\n    except:\n        raise ValueError(\'x, y, z are incompatible\')\n\n    c = hermval(x, c)\n    c = hermval(y, c, tensor=False)\n    c = hermval(z, c, tensor=False)\n    return c\n\n\ndef hermgrid3d(x, y, z, c):\n    \n    c = hermval(x, c)\n    c = hermval(y, c)\n    c = hermval(z, c)\n    return c\n\n\ndef hermvander(x, deg):\n    \n    ideg = int(deg)\n    if ideg != deg:\n        raise ValueError("deg must be integer")\n    if ideg < 0:\n        raise ValueError("deg must be non-negative")\n\n    x = np.array(x, copy=0, ndmin=1) + 0.0\n    dims = (ideg + 1,) + x.shape\n    dtyp = x.dtype\n    v = np.empty(dims, dtype=dtyp)\n    v[0] = x*0 + 1\n    if ideg > 0:\n        x2 = x*2\n        v[1] = x2\n        for i in range(2, ideg + 1):\n            v[i] = (v[i-1]*x2 - v[i-2]*(2*(i - 1)))\n    return np.rollaxis(v, 0, v.ndim)\n\n\ndef hermvander2d(x, y, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy = ideg\n    x, y = np.array((x, y), copy=0) + 0.0\n\n    vx = hermvander(x, degx)\n    vy = hermvander(y, degy)\n    v = vx[..., None]*vy[..., None,:]\n    return v.reshape(v.shape[:-2] + (-1,))\n\n\ndef hermvander3d(x, y, z, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy, degz = ideg\n    x, y, z = np.array((x, y, z), copy=0) + 0.0\n\n    vx = hermvander(x, degx)\n    vy = hermvander(y, degy)\n    vz = hermvander(z, degz)\n    v = vx[..., None, None]*vy[..., None,:, None]*vz[..., None, None,:]\n    return v.reshape(v.shape[:-3] + (-1,))\n\n\ndef hermfit(x, y, deg, rcond=None, full=False, w=None):\n    \n    order = int(deg) + 1\n    x = np.asarray(x) + 0.0\n    y = np.asarray(y) + 0.0\n\n        if deg < 0:\n        raise ValueError("expected deg >= 0")\n    if x.ndim != 1:\n        raise TypeError("expected 1D vector for x")\n    if x.size == 0:\n        raise TypeError("expected non-empty vector for x")\n    if y.ndim < 1 or y.ndim > 2:\n        raise TypeError("expected 1D or 2D array for y")\n    if len(x) != len(y):\n        raise TypeError("expected x and y to have same length")\n\n        lhs = hermvander(x, deg).T\n    rhs = y.T\n    if w is not None:\n        w = np.asarray(w) + 0.0\n        if w.ndim != 1:\n            raise TypeError("expected 1D vector for w")\n        if len(x) != len(w):\n            raise TypeError("expected x and w to have same length")\n                        lhs = lhs * w\n        rhs = rhs * w\n\n        if rcond is None:\n        rcond = len(x)*np.finfo(x.dtype).eps\n\n        if issubclass(lhs.dtype.type, np.complexfloating):\n        scl = np.sqrt((np.square(lhs.real) + np.square(lhs.imag)).sum(1))\n    else:\n        scl = np.sqrt(np.square(lhs).sum(1))\n    scl[scl == 0] = 1\n\n        c, resids, rank, s = la.lstsq(lhs.T/scl, rhs.T, rcond)\n    c = (c.T/scl).T\n\n        if rank != order and not full:\n        msg = "The fit may be poorly conditioned"\n        warnings.warn(msg, pu.RankWarning)\n\n    if full:\n        return c, [resids, rank, s, rcond]\n    else:\n        return c\n\n\ndef hermcompanion(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        raise ValueError(\'Series must have maximum degree of at least 1.\')\n    if len(c) == 2:\n        return np.array([[-.5*c[0]/c[1]]])\n\n    n = len(c) - 1\n    mat = np.zeros((n, n), dtype=c.dtype)\n    scl = np.hstack((1., 1./np.sqrt(2.*np.arange(n - 1, 0, -1))))\n    scl = np.multiply.accumulate(scl)[::-1]\n    top = mat.reshape(-1)[1::n+1]\n    bot = mat.reshape(-1)[n::n+1]\n    top[...] = np.sqrt(.5*np.arange(1, n))\n    bot[...] = top\n    mat[:, -1] -= scl*c[:-1]/(2.0*c[-1])\n    return mat\n\n\ndef hermroots(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) <= 1:\n        return np.array([], dtype=c.dtype)\n    if len(c) == 2:\n        return np.array([-.5*c[0]/c[1]])\n\n    m = hermcompanion(c)\n    r = la.eigvals(m)\n    r.sort()\n    return r\n\n\ndef _normed_hermite_n(x, n):\n    \n    if n == 0:\n        return np.ones(x.shape)/np.sqrt(np.sqrt(np.pi))\n\n    c0 = 0.\n    c1 = 1./np.sqrt(np.sqrt(np.pi))\n    nd = float(n)\n    for i in range(n - 1):\n        tmp = c0\n        c0 = -c1*np.sqrt((nd - 1.)/nd)\n        c1 = tmp + c1*x*np.sqrt(2./nd)\n        nd = nd - 1.0\n    return c0 + c1*x*np.sqrt(2)\n\n\ndef hermgauss(deg):\n    \n    ideg = int(deg)\n    if ideg != deg or ideg < 1:\n        raise ValueError("deg must be a non-negative integer")\n\n            c = np.array([0]*deg + [1], dtype=np.float64)\n    m = hermcompanion(c)\n    x = la.eigvalsh(m)\n\n        dy = _normed_hermite_n(x, ideg)\n    df = _normed_hermite_n(x, ideg - 1) * np.sqrt(2*ideg)\n    x -= dy/df\n\n            fm = _normed_hermite_n(x, ideg - 1)\n    fm /= np.abs(fm).max()\n    w = 1/(fm * fm)\n\n        w = (w + w[::-1])/2\n    x = (x - x[::-1])/2\n\n        w *= np.sqrt(np.pi) / w.sum()\n\n    return x, w\n\n\ndef hermweight(x):\n    \n    w = np.exp(-x**2)\n    return w\n\n\n\nclass Hermite(ABCPolyBase):\n    \n        _add = staticmethod(hermadd)\n    _sub = staticmethod(hermsub)\n    _mul = staticmethod(hermmul)\n    _div = staticmethod(hermdiv)\n    _pow = staticmethod(hermpow)\n    _val = staticmethod(hermval)\n    _int = staticmethod(hermint)\n    _der = staticmethod(hermder)\n    _fit = staticmethod(hermfit)\n    _line = staticmethod(hermline)\n    _roots = staticmethod(hermroots)\n    _fromroots = staticmethod(hermfromroots)\n\n        nickname = \'herm\'\n    domain = np.array(hermdomain)\n    window = np.array(hermdomain)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport numpy as np\nimport numpy.linalg as la\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\n__all__ = [\n    \'hermezero\', \'hermeone\', \'hermex\', \'hermedomain\', \'hermeline\',\n    \'hermeadd\', \'hermesub\', \'hermemulx\', \'hermemul\', \'hermediv\',\n    \'hermepow\', \'hermeval\', \'hermeder\', \'hermeint\', \'herme2poly\',\n    \'poly2herme\', \'hermefromroots\', \'hermevander\', \'hermefit\', \'hermetrim\',\n    \'hermeroots\', \'HermiteE\', \'hermeval2d\', \'hermeval3d\', \'hermegrid2d\',\n    \'hermegrid3d\', \'hermevander2d\', \'hermevander3d\', \'hermecompanion\',\n    \'hermegauss\', \'hermeweight\']\n\nhermetrim = pu.trimcoef\n\n\ndef poly2herme(pol):\n    \n    [pol] = pu.as_series([pol])\n    deg = len(pol) - 1\n    res = 0\n    for i in range(deg, -1, -1):\n        res = hermeadd(hermemulx(res), pol[i])\n    return res\n\n\ndef herme2poly(c):\n    \n    from .polynomial import polyadd, polysub, polymulx\n\n    [c] = pu.as_series([c])\n    n = len(c)\n    if n == 1:\n        return c\n    if n == 2:\n        return c\n    else:\n        c0 = c[-2]\n        c1 = c[-1]\n                for i in range(n - 1, 1, -1):\n            tmp = c0\n            c0 = polysub(c[i - 2], c1*(i - 1))\n            c1 = polyadd(tmp, polymulx(c1))\n        return polyadd(c0, polymulx(c1))\n\n\nhermedomain = np.array([-1, 1])\n\nhermezero = np.array([0])\n\nhermeone = np.array([1])\n\nhermex = np.array([0, 1])\n\n\ndef hermeline(off, scl):\n    \n    if scl != 0:\n        return np.array([off, scl])\n    else:\n        return np.array([off])\n\n\ndef hermefromroots(roots):\n    \n    if len(roots) == 0:\n        return np.ones(1)\n    else:\n        [roots] = pu.as_series([roots], trim=False)\n        roots.sort()\n        p = [hermeline(-r, 1) for r in roots]\n        n = len(p)\n        while n > 1:\n            m, r = divmod(n, 2)\n            tmp = [hermemul(p[i], p[i+m]) for i in range(m)]\n            if r:\n                tmp[0] = hermemul(tmp[0], p[-1])\n            p = tmp\n            n = m\n        return p[0]\n\n\ndef hermeadd(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] += c2\n        ret = c1\n    else:\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef hermesub(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] -= c2\n        ret = c1\n    else:\n        c2 = -c2\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef hermemulx(c):\n    \n        [c] = pu.as_series([c])\n        if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]*0\n    prd[1] = c[0]\n    for i in range(1, len(c)):\n        prd[i + 1] = c[i]\n        prd[i - 1] += c[i]*i\n    return prd\n\n\ndef hermemul(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n\n    if len(c1) > len(c2):\n        c = c2\n        xs = c1\n    else:\n        c = c1\n        xs = c2\n\n    if len(c) == 1:\n        c0 = c[0]*xs\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]*xs\n        c1 = c[1]*xs\n    else:\n        nd = len(c)\n        c0 = c[-2]*xs\n        c1 = c[-1]*xs\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = hermesub(c[-i]*xs, c1*(nd - 1))\n            c1 = hermeadd(tmp, hermemulx(c1))\n    return hermeadd(c0, hermemulx(c1))\n\n\ndef hermediv(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    lc1 = len(c1)\n    lc2 = len(c2)\n    if lc1 < lc2:\n        return c1[:1]*0, c1\n    elif lc2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    else:\n        quo = np.empty(lc1 - lc2 + 1, dtype=c1.dtype)\n        rem = c1\n        for i in range(lc1 - lc2, - 1, -1):\n            p = hermemul([0]*i + [1], c2)\n            q = rem[-1]/p[-1]\n            rem = rem[:-1] - q*p[:-1]\n            quo[i] = q\n        return quo, pu.trimseq(rem)\n\n\ndef hermepow(c, pow, maxpower=16):\n    \n        [c] = pu.as_series([c])\n    power = int(pow)\n    if power != pow or power < 0:\n        raise ValueError("Power must be a non-negative integer.")\n    elif maxpower is not None and power > maxpower:\n        raise ValueError("Power is too large")\n    elif power == 0:\n        return np.array([1], dtype=c.dtype)\n    elif power == 1:\n        return c\n    else:\n                        prd = c\n        for i in range(2, power + 1):\n            prd = hermemul(prd, c)\n        return prd\n\n\ndef hermeder(c, m=1, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of derivation must be integer")\n    if cnt < 0:\n        raise ValueError("The order of derivation must be non-negative")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    n = len(c)\n    if cnt >= n:\n        return c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=c.dtype)\n            for j in range(n, 0, -1):\n                der[j - 1] = j*c[j]\n            c = der\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef hermeint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if not np.iterable(k):\n        k = [k]\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of integration must be integer")\n    if cnt < 0:\n        raise ValueError("The order of integration must be non-negative")\n    if len(k) > cnt:\n        raise ValueError("Too many integration constants")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    k = list(k) + [0]*(cnt - len(k))\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=c.dtype)\n            tmp[0] = c[0]*0\n            tmp[1] = c[0]\n            for j in range(1, n):\n                tmp[j + 1] = c[j]/(j + 1)\n            tmp[0] += k[i] - hermeval(lbnd, tmp)\n            c = tmp\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef hermeval(x, c, tensor=True):\n    \n    c = np.array(c, ndmin=1, copy=0)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    if len(c) == 1:\n        c0 = c[0]\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]\n        c1 = c[1]\n    else:\n        nd = len(c)\n        c0 = c[-2]\n        c1 = c[-1]\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = c[-i] - c1*(nd - 1)\n            c1 = tmp + c1*x\n    return c0 + c1*x\n\n\ndef hermeval2d(x, y, c):\n    \n    try:\n        x, y = np.array((x, y), copy=0)\n    except:\n        raise ValueError(\'x, y are incompatible\')\n\n    c = hermeval(x, c)\n    c = hermeval(y, c, tensor=False)\n    return c\n\n\ndef hermegrid2d(x, y, c):\n    \n    c = hermeval(x, c)\n    c = hermeval(y, c)\n    return c\n\n\ndef hermeval3d(x, y, z, c):\n    \n    try:\n        x, y, z = np.array((x, y, z), copy=0)\n    except:\n        raise ValueError(\'x, y, z are incompatible\')\n\n    c = hermeval(x, c)\n    c = hermeval(y, c, tensor=False)\n    c = hermeval(z, c, tensor=False)\n    return c\n\n\ndef hermegrid3d(x, y, z, c):\n    \n    c = hermeval(x, c)\n    c = hermeval(y, c)\n    c = hermeval(z, c)\n    return c\n\n\ndef hermevander(x, deg):\n    \n    ideg = int(deg)\n    if ideg != deg:\n        raise ValueError("deg must be integer")\n    if ideg < 0:\n        raise ValueError("deg must be non-negative")\n\n    x = np.array(x, copy=0, ndmin=1) + 0.0\n    dims = (ideg + 1,) + x.shape\n    dtyp = x.dtype\n    v = np.empty(dims, dtype=dtyp)\n    v[0] = x*0 + 1\n    if ideg > 0:\n        v[1] = x\n        for i in range(2, ideg + 1):\n            v[i] = (v[i-1]*x - v[i-2]*(i - 1))\n    return np.rollaxis(v, 0, v.ndim)\n\n\ndef hermevander2d(x, y, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy = ideg\n    x, y = np.array((x, y), copy=0) + 0.0\n\n    vx = hermevander(x, degx)\n    vy = hermevander(y, degy)\n    v = vx[..., None]*vy[..., None,:]\n    return v.reshape(v.shape[:-2] + (-1,))\n\n\ndef hermevander3d(x, y, z, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy, degz = ideg\n    x, y, z = np.array((x, y, z), copy=0) + 0.0\n\n    vx = hermevander(x, degx)\n    vy = hermevander(y, degy)\n    vz = hermevander(z, degz)\n    v = vx[..., None, None]*vy[..., None,:, None]*vz[..., None, None,:]\n    return v.reshape(v.shape[:-3] + (-1,))\n\n\ndef hermefit(x, y, deg, rcond=None, full=False, w=None):\n    \n    order = int(deg) + 1\n    x = np.asarray(x) + 0.0\n    y = np.asarray(y) + 0.0\n\n        if deg < 0:\n        raise ValueError("expected deg >= 0")\n    if x.ndim != 1:\n        raise TypeError("expected 1D vector for x")\n    if x.size == 0:\n        raise TypeError("expected non-empty vector for x")\n    if y.ndim < 1 or y.ndim > 2:\n        raise TypeError("expected 1D or 2D array for y")\n    if len(x) != len(y):\n        raise TypeError("expected x and y to have same length")\n\n        lhs = hermevander(x, deg).T\n    rhs = y.T\n    if w is not None:\n        w = np.asarray(w) + 0.0\n        if w.ndim != 1:\n            raise TypeError("expected 1D vector for w")\n        if len(x) != len(w):\n            raise TypeError("expected x and w to have same length")\n                        lhs = lhs * w\n        rhs = rhs * w\n\n        if rcond is None:\n        rcond = len(x)*np.finfo(x.dtype).eps\n\n        if issubclass(lhs.dtype.type, np.complexfloating):\n        scl = np.sqrt((np.square(lhs.real) + np.square(lhs.imag)).sum(1))\n    else:\n        scl = np.sqrt(np.square(lhs).sum(1))\n    scl[scl == 0] = 1\n\n        c, resids, rank, s = la.lstsq(lhs.T/scl, rhs.T, rcond)\n    c = (c.T/scl).T\n\n        if rank != order and not full:\n        msg = "The fit may be poorly conditioned"\n        warnings.warn(msg, pu.RankWarning)\n\n    if full:\n        return c, [resids, rank, s, rcond]\n    else:\n        return c\n\n\ndef hermecompanion(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        raise ValueError(\'Series must have maximum degree of at least 1.\')\n    if len(c) == 2:\n        return np.array([[-c[0]/c[1]]])\n\n    n = len(c) - 1\n    mat = np.zeros((n, n), dtype=c.dtype)\n    scl = np.hstack((1., 1./np.sqrt(np.arange(n - 1, 0, -1))))\n    scl = np.multiply.accumulate(scl)[::-1]\n    top = mat.reshape(-1)[1::n+1]\n    bot = mat.reshape(-1)[n::n+1]\n    top[...] = np.sqrt(np.arange(1, n))\n    bot[...] = top\n    mat[:, -1] -= scl*c[:-1]/c[-1]\n    return mat\n\n\ndef hermeroots(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) <= 1:\n        return np.array([], dtype=c.dtype)\n    if len(c) == 2:\n        return np.array([-c[0]/c[1]])\n\n    m = hermecompanion(c)\n    r = la.eigvals(m)\n    r.sort()\n    return r\n\n\ndef _normed_hermite_e_n(x, n):\n    \n    if n == 0:\n        return np.ones(x.shape)/np.sqrt(np.sqrt(2*np.pi))\n\n    c0 = 0.\n    c1 = 1./np.sqrt(np.sqrt(2*np.pi))\n    nd = float(n)\n    for i in range(n - 1):\n        tmp = c0\n        c0 = -c1*np.sqrt((nd - 1.)/nd)\n        c1 = tmp + c1*x*np.sqrt(1./nd)\n        nd = nd - 1.0\n    return c0 + c1*x\n\n\ndef hermegauss(deg):\n    \n    ideg = int(deg)\n    if ideg != deg or ideg < 1:\n        raise ValueError("deg must be a non-negative integer")\n\n            c = np.array([0]*deg + [1])\n    m = hermecompanion(c)\n    x = la.eigvalsh(m)\n\n        dy = _normed_hermite_e_n(x, ideg)\n    df = _normed_hermite_e_n(x, ideg - 1) * np.sqrt(ideg)\n    x -= dy/df\n\n            fm = _normed_hermite_e_n(x, ideg - 1)\n    fm /= np.abs(fm).max()\n    w = 1/(fm * fm)\n\n        w = (w + w[::-1])/2\n    x = (x - x[::-1])/2\n\n        w *= np.sqrt(2*np.pi) / w.sum()\n\n    return x, w\n\n\ndef hermeweight(x):\n    \n    w = np.exp(-.5*x**2)\n    return w\n\n\n\nclass HermiteE(ABCPolyBase):\n    \n        _add = staticmethod(hermeadd)\n    _sub = staticmethod(hermesub)\n    _mul = staticmethod(hermemul)\n    _div = staticmethod(hermediv)\n    _pow = staticmethod(hermepow)\n    _val = staticmethod(hermeval)\n    _int = staticmethod(hermeint)\n    _der = staticmethod(hermeder)\n    _fit = staticmethod(hermefit)\n    _line = staticmethod(hermeline)\n    _roots = staticmethod(hermeroots)\n    _fromroots = staticmethod(hermefromroots)\n\n        nickname = \'herme\'\n    domain = np.array(hermedomain)\n    window = np.array(hermedomain)\n\nfrom __future__ import division, absolute_import, print_function\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'HPUXFCompiler\']\n\nclass HPUXFCompiler(FCompiler):\n\n    compiler_type = \'hpux\'\n    description = \'HP Fortran 90 Compiler\'\n    version_pattern =  r\'HP F90 (?P<version>[^\\s*,]*)\'\n\n    executables = {\n        \'version_cmd\'  : ["f90", "+version"],\n        \'compiler_f77\' : ["f90"],\n        \'compiler_fix\' : ["f90"],\n        \'compiler_f90\' : ["f90"],\n        \'linker_so\'    : ["ld", "-b"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n    module_dir_switch = None     module_include_switch = None     pic_flags = [\'+Z\']\n    def get_flags(self):\n        return self.pic_flags + [\'+ppu\', \'+DD64\']\n    def get_flags_opt(self):\n        return [\'-O3\']\n    def get_libraries(self):\n        return [\'m\']\n    def get_library_dirs(self):\n        opt = [\'/usr/lib/hpux64\']\n        return opt\n    def get_version(self, force=0, ok_status=[256, 0, 1]):\n                        return FCompiler.get_version(self, force, ok_status)\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(10)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'hpux\')\n    compiler.customize()\n    print(compiler.get_version())\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport re\nimport sys\n\nfrom numpy.distutils.fcompiler import FCompiler\nfrom numpy.distutils.exec_command import exec_command, find_executable\nfrom numpy.distutils.misc_util import make_temp_file\nfrom distutils import log\n\ncompilers = [\'IBMFCompiler\']\n\nclass IBMFCompiler(FCompiler):\n    compiler_type = \'ibm\'\n    description = \'IBM XL Fortran Compiler\'\n    version_pattern =  r\'(xlf\\(1\\)\\s*|)IBM XL Fortran ((Advanced Edition |)Version |Enterprise Edition V|for AIX, V)(?P<version>[^\\s*]*)\'\n    \n    executables = {\n        \'version_cmd\'  : ["<F77>", "-qversion"],\n        \'compiler_f77\' : ["xlf"],\n        \'compiler_fix\' : ["xlf90", "-qfixed"],\n        \'compiler_f90\' : ["xlf90"],\n        \'linker_so\'    : ["xlf95"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    def get_version(self,*args,**kwds):\n        version = FCompiler.get_version(self,*args,**kwds)\n\n        if version is None and sys.platform.startswith(\'aix\'):\n                        lslpp = find_executable(\'lslpp\')\n            xlf = find_executable(\'xlf\')\n            if os.path.exists(xlf) and os.path.exists(lslpp):\n                s, o = exec_command(lslpp + \' -Lc xlfcmp\')\n                m = re.search(\'xlfcmp:(?P<version>\\d+([.]\\d+)+)\', o)\n                if m: version = m.group(\'version\')\n\n        xlf_dir = \'/etc/opt/ibmcmp/xlf\'\n        if version is None and os.path.isdir(xlf_dir):\n                                                            l = sorted(os.listdir(xlf_dir))\n            l.reverse()\n            l = [d for d in l if os.path.isfile(os.path.join(xlf_dir, d, \'xlf.cfg\'))]\n            if l:\n                from distutils.version import LooseVersion\n                self.version = version = LooseVersion(l[0])\n        return version\n\n    def get_flags(self):\n        return [\'-qextname\']\n\n    def get_flags_debug(self):\n        return [\'-g\']\n\n    def get_flags_linker_so(self):\n        opt = []\n        if sys.platform==\'darwin\':\n            opt.append(\'-Wl,-bundle,-flat_namespace,-undefined,suppress\')\n        else:\n            opt.append(\'-bshared\')\n        version = self.get_version(ok_status=[0, 40])\n        if version is not None:\n            if sys.platform.startswith(\'aix\'):\n                xlf_cfg = \'/etc/xlf.cfg\'\n            else:\n                xlf_cfg = \'/etc/opt/ibmcmp/xlf/%s/xlf.cfg\' % version\n            fo, new_cfg = make_temp_file(suffix=\'_xlf.cfg\')\n            log.info(\'Creating \'+new_cfg)\n            fi = open(xlf_cfg, \'r\')\n            crt1_match = re.compile(r\'\\s*crt\\s*[=]\\s*(?P<path>.*)/crt1.o\').match\n            for line in fi:\n                m = crt1_match(line)\n                if m:\n                    fo.write(\'crt = %s/bundle1.o\\n\' % (m.group(\'path\')))\n                else:\n                    fo.write(line)\n            fi.close()\n            fo.close()\n            opt.append(\'-F\'+new_cfg)\n        return opt\n\n    def get_flags_opt(self):\n        return [\'-O3\']\n\nif __name__ == \'__main__\':\n    log.set_verbosity(2)\n    compiler = IBMFCompiler()\n    compiler.customize()\n    print(compiler.get_version())\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport math\n\nimport numpy.core.numeric as _nx\nfrom numpy.core.numeric import (\n    asarray, ScalarType, array, alltrue, cumprod, arange\n    )\nfrom numpy.core.numerictypes import find_common_type, issubdtype\n\nfrom . import function_base\nimport numpy.matrixlib as matrix\nfrom .function_base import diff\nfrom numpy.core.multiarray import ravel_multi_index, unravel_index\nfrom numpy.lib.stride_tricks import as_strided\n\nmakemat = matrix.matrix\n\n\n__all__ = [\n    \'ravel_multi_index\', \'unravel_index\', \'mgrid\', \'ogrid\', \'r_\', \'c_\',\n    \'s_\', \'index_exp\', \'ix_\', \'ndenumerate\', \'ndindex\', \'fill_diagonal\',\n    \'diag_indices\', \'diag_indices_from\'\n    ]\n\n\ndef ix_(*args):\n    \n    out = []\n    nd = len(args)\n    for k, new in enumerate(args):\n        new = asarray(new)\n        if new.ndim != 1:\n            raise ValueError("Cross index must be 1 dimensional")\n        if new.size == 0:\n                        new = new.astype(_nx.intp)\n        if issubdtype(new.dtype, _nx.bool_):\n            new, = new.nonzero()\n        new = new.reshape((1,)*k + (new.size,) + (1,)*(nd-k-1))\n        out.append(new)\n    return tuple(out)\n\nclass nd_grid(object):\n    \n\n    def __init__(self, sparse=False):\n        self.sparse = sparse\n\n    def __getitem__(self, key):\n        try:\n            size = []\n            typ = int\n            for k in range(len(key)):\n                step = key[k].step\n                start = key[k].start\n                if start is None:\n                    start = 0\n                if step is None:\n                    step = 1\n                if isinstance(step, complex):\n                    size.append(int(abs(step)))\n                    typ = float\n                else:\n                    size.append(\n                        int(math.ceil((key[k].stop - start)/(step*1.0))))\n                if (isinstance(step, float) or\n                        isinstance(start, float) or\n                        isinstance(key[k].stop, float)):\n                    typ = float\n            if self.sparse:\n                nn = [_nx.arange(_x, dtype=_t)\n                        for _x, _t in zip(size, (typ,)*len(size))]\n            else:\n                nn = _nx.indices(size, typ)\n            for k in range(len(size)):\n                step = key[k].step\n                start = key[k].start\n                if start is None:\n                    start = 0\n                if step is None:\n                    step = 1\n                if isinstance(step, complex):\n                    step = int(abs(step))\n                    if step != 1:\n                        step = (key[k].stop - start)/float(step-1)\n                nn[k] = (nn[k]*step+start)\n            if self.sparse:\n                slobj = [_nx.newaxis]*len(size)\n                for k in range(len(size)):\n                    slobj[k] = slice(None, None)\n                    nn[k] = nn[k][slobj]\n                    slobj[k] = _nx.newaxis\n            return nn\n        except (IndexError, TypeError):\n            step = key.step\n            stop = key.stop\n            start = key.start\n            if start is None:\n                start = 0\n            if isinstance(step, complex):\n                step = abs(step)\n                length = int(step)\n                if step != 1:\n                    step = (key.stop-start)/float(step-1)\n                stop = key.stop + step\n                return _nx.arange(0, length, 1, float)*step + start\n            else:\n                return _nx.arange(start, stop, step)\n\n    def __getslice__(self, i, j):\n        return _nx.arange(i, j)\n\n    def __len__(self):\n        return 0\n\nmgrid = nd_grid(sparse=False)\nogrid = nd_grid(sparse=True)\nmgrid.__doc__ = None  ogrid.__doc__ = None  \nclass AxisConcatenator(object):\n    \n\n    def _retval(self, res):\n        if self.matrix:\n            oldndim = res.ndim\n            res = makemat(res)\n            if oldndim == 1 and self.col:\n                res = res.T\n        self.axis = self._axis\n        self.matrix = self._matrix\n        self.col = 0\n        return res\n\n    def __init__(self, axis=0, matrix=False, ndmin=1, trans1d=-1):\n        self._axis = axis\n        self._matrix = matrix\n        self.axis = axis\n        self.matrix = matrix\n        self.col = 0\n        self.trans1d = trans1d\n        self.ndmin = ndmin\n\n    def __getitem__(self, key):\n        trans1d = self.trans1d\n        ndmin = self.ndmin\n        if isinstance(key, str):\n            frame = sys._getframe().f_back\n            mymat = matrix.bmat(key, frame.f_globals, frame.f_locals)\n            return mymat\n        if not isinstance(key, tuple):\n            key = (key,)\n        objs = []\n        scalars = []\n        arraytypes = []\n        scalartypes = []\n        for k in range(len(key)):\n            scalar = False\n            if isinstance(key[k], slice):\n                step = key[k].step\n                start = key[k].start\n                stop = key[k].stop\n                if start is None:\n                    start = 0\n                if step is None:\n                    step = 1\n                if isinstance(step, complex):\n                    size = int(abs(step))\n                    newobj = function_base.linspace(start, stop, num=size)\n                else:\n                    newobj = _nx.arange(start, stop, step)\n                if ndmin > 1:\n                    newobj = array(newobj, copy=False, ndmin=ndmin)\n                    if trans1d != -1:\n                        newobj = newobj.swapaxes(-1, trans1d)\n            elif isinstance(key[k], str):\n                if k != 0:\n                    raise ValueError("special directives must be the "\n                            "first entry.")\n                key0 = key[0]\n                if key0 in \'rc\':\n                    self.matrix = True\n                    self.col = (key0 == \'c\')\n                    continue\n                if \',\' in key0:\n                    vec = key0.split(\',\')\n                    try:\n                        self.axis, ndmin = \\\n                                   [int(x) for x in vec[:2]]\n                        if len(vec) == 3:\n                            trans1d = int(vec[2])\n                        continue\n                    except:\n                        raise ValueError("unknown special directive")\n                try:\n                    self.axis = int(key[k])\n                    continue\n                except (ValueError, TypeError):\n                    raise ValueError("unknown special directive")\n            elif type(key[k]) in ScalarType:\n                newobj = array(key[k], ndmin=ndmin)\n                scalars.append(k)\n                scalar = True\n                scalartypes.append(newobj.dtype)\n            else:\n                newobj = key[k]\n                if ndmin > 1:\n                    tempobj = array(newobj, copy=False, subok=True)\n                    newobj = array(newobj, copy=False, subok=True,\n                                   ndmin=ndmin)\n                    if trans1d != -1 and tempobj.ndim < ndmin:\n                        k2 = ndmin-tempobj.ndim\n                        if (trans1d < 0):\n                            trans1d += k2 + 1\n                        defaxes = list(range(ndmin))\n                        k1 = trans1d\n                        axes = defaxes[:k1] + defaxes[k2:] + \\\n                               defaxes[k1:k2]\n                        newobj = newobj.transpose(axes)\n                    del tempobj\n            objs.append(newobj)\n            if not scalar and isinstance(newobj, _nx.ndarray):\n                arraytypes.append(newobj.dtype)\n\n                final_dtype = find_common_type(arraytypes, scalartypes)\n        if final_dtype is not None:\n            for k in scalars:\n                objs[k] = objs[k].astype(final_dtype)\n\n        res = _nx.concatenate(tuple(objs), axis=self.axis)\n        return self._retval(res)\n\n    def __getslice__(self, i, j):\n        res = _nx.arange(i, j)\n        return self._retval(res)\n\n    def __len__(self):\n        return 0\n\n\nclass RClass(AxisConcatenator):\n    \n\n    def __init__(self):\n        AxisConcatenator.__init__(self, 0)\n\nr_ = RClass()\n\nclass CClass(AxisConcatenator):\n    \n\n    def __init__(self):\n        AxisConcatenator.__init__(self, -1, ndmin=2, trans1d=0)\n\nc_ = CClass()\n\nclass ndenumerate(object):\n    \n\n    def __init__(self, arr):\n        self.iter = asarray(arr).flat\n\n    def __next__(self):\n        \n        return self.iter.coords, next(self.iter)\n\n    def __iter__(self):\n        return self\n\n    next = __next__\n\n\nclass ndindex(object):\n    \n\n    def __init__(self, *shape):\n        if len(shape) == 1 and isinstance(shape[0], tuple):\n            shape = shape[0]\n        x = as_strided(_nx.zeros(1), shape=shape,\n                       strides=_nx.zeros_like(shape))\n        self._it = _nx.nditer(x, flags=[\'multi_index\', \'zerosize_ok\'],\n                              order=\'C\')\n\n    def __iter__(self):\n        return self\n\n    def ndincr(self):\n        \n        next(self)\n\n    def __next__(self):\n        \n        next(self._it)\n        return self._it.multi_index\n\n    next = __next__\n\n\n\nclass IndexExpression(object):\n    \n\n    def __init__(self, maketuple):\n        self.maketuple = maketuple\n\n    def __getitem__(self, item):\n        if self.maketuple and not isinstance(item, tuple):\n            return (item,)\n        else:\n            return item\n\nindex_exp = IndexExpression(maketuple=True)\ns_ = IndexExpression(maketuple=False)\n\n\n\n\ndef fill_diagonal(a, val, wrap=False):\n    \n    if a.ndim < 2:\n        raise ValueError("array must be at least 2-d")\n    end = None\n    if a.ndim == 2:\n                        step = a.shape[1] + 1\n                if not wrap:\n            end = a.shape[1] * a.shape[1]\n    else:\n                        if not alltrue(diff(a.shape) == 0):\n            raise ValueError("All dimensions of input must be of equal length")\n        step = 1 + (cumprod(a.shape[:-1])).sum()\n\n        a.flat[:end:step] = val\n\n\ndef diag_indices(n, ndim=2):\n    \n    idx = arange(n)\n    return (idx,) * ndim\n\n\ndef diag_indices_from(arr):\n    \n\n    if not arr.ndim >= 2:\n        raise ValueError("input array must be at least 2-d")\n            if not alltrue(diff(arr.shape) == 0):\n        raise ValueError("All dimensions of input must be of equal length")\n\n    return diag_indices(arr.shape[0], arr.ndim)\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\ndepends = [\'core\']\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nif \'setuptools\' in sys.modules:\n    import setuptools.command.install as old_install_mod\n    have_setuptools = True\nelse:\n    import distutils.command.install as old_install_mod\n    have_setuptools = False\nfrom distutils.file_util import write_file\n\nold_install = old_install_mod.install\n\nclass install(old_install):\n\n            sub_commands = old_install.sub_commands + [\n        (\'install_clib\', lambda x: True)\n    ]\n\n    def finalize_options (self):\n        old_install.finalize_options(self)\n        self.install_lib = self.install_libbase\n\n    def setuptools_run(self):\n        \n        from distutils.command.install import install as distutils_install\n\n                if self.old_and_unmanageable or self.single_version_externally_managed:\n            return distutils_install.run(self)\n\n                                                                        caller = sys._getframe(3)\n        caller_module = caller.f_globals.get(\'__name__\', \'\')\n        caller_name = caller.f_code.co_name\n\n        if caller_module != \'distutils.dist\' or caller_name!=\'run_commands\':\n                                                distutils_install.run(self)\n        else:\n            self.do_egg_install()\n\n    def run(self):\n        if not have_setuptools:\n            r = old_install.run(self)\n        else:\n            r = self.setuptools_run()\n        if self.record:\n                                                f = open(self.record, \'r\')\n            lines = []\n            need_rewrite = False\n            for l in f:\n                l = l.rstrip()\n                if \' \' in l:\n                    need_rewrite = True\n                    l = \'"%s"\' % (l)\n                lines.append(l)\n            f.close()\n            if need_rewrite:\n                self.execute(write_file,\n                             (self.record, lines),\n                             "re-writing list of installed files to \'%s\'" %\n                             self.record)\n        return r\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nfrom distutils.core import Command\nfrom distutils.ccompiler import new_compiler\nfrom numpy.distutils.misc_util import get_cmd\n\nclass install_clib(Command):\n    description = "Command to install installable C libraries"\n\n    user_options = []\n\n    def initialize_options(self):\n        self.install_dir = None\n        self.outfiles = []\n\n    def finalize_options(self):\n        self.set_undefined_options(\'install\', (\'install_lib\', \'install_dir\'))\n\n    def run (self):\n        build_clib_cmd = get_cmd("build_clib")\n        build_dir = build_clib_cmd.build_clib\n\n                if not build_clib_cmd.compiler:\n            compiler = new_compiler(compiler=None)\n            compiler.customize(self.distribution)\n        else:\n            compiler = build_clib_cmd.compiler\n\n        for l in self.distribution.installed_libraries:\n            target_dir = os.path.join(self.install_dir, l.target_dir)\n            name = compiler.library_filename(l.name)\n            source = os.path.join(build_dir, name)\n            self.mkpath(target_dir)\n            self.outfiles.append(self.copy_file(source, target_dir)[0])\n\n    def get_outputs(self):\n        return self.outfiles\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nhave_setuptools = (\'setuptools\' in sys.modules)\n\nfrom distutils.command.install_data import install_data as old_install_data\n\nclass install_data (old_install_data):\n\n    def run(self):\n        old_install_data.run(self)\n\n        if have_setuptools:\n                                    self.run_command(\'install_clib\')\n\n    def finalize_options (self):\n        self.set_undefined_options(\'install\',\n                                   (\'install_lib\', \'install_dir\'),\n                                   (\'root\', \'root\'),\n                                   (\'force\', \'force\'),\n                                  )\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nfrom distutils.command.install_headers import install_headers as old_install_headers\n\nclass install_headers (old_install_headers):\n\n    def run (self):\n        headers = self.distribution.headers\n        if not headers:\n            return\n\n        prefix = os.path.dirname(self.install_dir)\n        for header in headers:\n            if isinstance(header, tuple):\n                                if header[0] == \'numpy.core\':\n                    header = (\'numpy\', header[1])\n                    if os.path.splitext(header[1])[1] == \'.inc\':\n                        continue\n                d = os.path.join(*([prefix]+header[0].split(\'.\')))\n                header = header[1]\n            else:\n                d = self.install_dir\n            self.mkpath(d)\n            (out, _) = self.copy_file(header, d)\n            self.outfiles.append(out)\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\n\nfrom numpy.distutils.ccompiler import simple_version_match\nfrom numpy.distutils.fcompiler import FCompiler, dummy_fortran_file\n\ncompilers = [\'IntelFCompiler\', \'IntelVisualFCompiler\',\n             \'IntelItaniumFCompiler\', \'IntelItaniumVisualFCompiler\',\n             \'IntelEM64VisualFCompiler\', \'IntelEM64TFCompiler\']\n\n\ndef intel_version_match(type):\n        return simple_version_match(start=r\'Intel.*?Fortran.*?(?:%s).*?Version\' % (type,))\n\n\nclass BaseIntelFCompiler(FCompiler):\n    def update_executables(self):\n        f = dummy_fortran_file()\n        self.executables[\'version_cmd\'] = [\'<F77>\', \'-FI\', \'-V\', \'-c\',\n                                           f + \'.f\', \'-o\', f + \'.o\']\n\n    def runtime_library_dir_option(self, dir):\n        return \'-Wl,-rpath="%s"\' % dir\n\n\nclass IntelFCompiler(BaseIntelFCompiler):\n\n    compiler_type = \'intel\'\n    compiler_aliases = (\'ifort\',)\n    description = \'Intel Fortran Compiler for 32-bit apps\'\n    version_match = intel_version_match(\'32-bit|IA-32\')\n\n    possible_executables = [\'ifort\', \'ifc\']\n\n    executables = {\n        \'version_cmd\'  : None,                  \'compiler_f77\' : [None, "-72", "-w90", "-w95"],\n        \'compiler_f90\' : [None],\n        \'compiler_fix\' : [None, "-FI"],\n        \'linker_so\'    : ["<F90>", "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    pic_flags = [\'-fPIC\']\n    module_dir_switch = \'-module \'      module_include_switch = \'-I\'\n\n    def get_flags_free(self):\n        return [\'-FR\']\n\n    def get_flags(self):\n        return [\'-fPIC\']\n\n    def get_flags_opt(self):\n        return [\'-xhost -openmp -fp-model strict\']\n\n    def get_flags_arch(self):\n        return []\n\n    def get_flags_linker_so(self):\n        opt = FCompiler.get_flags_linker_so(self)\n        v = self.get_version()\n        if v and v >= \'8.0\':\n            opt.append(\'-nofor_main\')\n        if sys.platform == \'darwin\':\n                        try:\n                idx = opt.index(\'-shared\')\n                opt.remove(\'-shared\')\n            except ValueError:\n                idx = 0\n            opt[idx:idx] = [\'-dynamiclib\', \'-Wl,-undefined,dynamic_lookup\']\n        return opt\n\n\nclass IntelItaniumFCompiler(IntelFCompiler):\n    compiler_type = \'intele\'\n    compiler_aliases = ()\n    description = \'Intel Fortran Compiler for Itanium apps\'\n\n    version_match = intel_version_match(\'Itanium|IA-64\')\n\n    possible_executables = [\'ifort\', \'efort\', \'efc\']\n\n    executables = {\n        \'version_cmd\'  : None,\n        \'compiler_f77\' : [None, "-FI", "-w90", "-w95"],\n        \'compiler_fix\' : [None, "-FI"],\n        \'compiler_f90\' : [None],\n        \'linker_so\'    : [\'<F90>\', "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n\nclass IntelEM64TFCompiler(IntelFCompiler):\n    compiler_type = \'intelem\'\n    compiler_aliases = ()\n    description = \'Intel Fortran Compiler for 64-bit apps\'\n\n    version_match = intel_version_match(\'EM64T-based|Intel\\\\(R\\\\) 64|64|IA-64|64-bit\')\n\n    possible_executables = [\'ifort\', \'efort\', \'efc\']\n\n    executables = {\n        \'version_cmd\'  : None,\n        \'compiler_f77\' : [None, "-FI"],\n        \'compiler_fix\' : [None, "-FI"],\n        \'compiler_f90\' : [None],\n        \'linker_so\'    : [\'<F90>\', "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    def get_flags(self):\n        return [\'-fPIC\']\n\n    def get_flags_opt(self):\n        return [\'-openmp -fp-model strict\']\n\n    def get_flags_arch(self):\n        return [\'-xSSE4.2\']\n\n\n\nclass IntelVisualFCompiler(BaseIntelFCompiler):\n    compiler_type = \'intelv\'\n    description = \'Intel Visual Fortran Compiler for 32-bit apps\'\n    version_match = intel_version_match(\'32-bit|IA-32\')\n\n    def update_executables(self):\n        f = dummy_fortran_file()\n        self.executables[\'version_cmd\'] = [\'<F77>\', \'/FI\', \'/c\',\n                                           f + \'.f\', \'/o\', f + \'.o\']\n\n    ar_exe = \'lib.exe\'\n    possible_executables = [\'ifort\', \'ifl\']\n\n    executables = {\n        \'version_cmd\'  : None,\n        \'compiler_f77\' : [None],\n        \'compiler_fix\' : [None],\n        \'compiler_f90\' : [None],\n        \'linker_so\'    : [None],\n        \'archiver\'     : [ar_exe, "/verbose", "/OUT:"],\n        \'ranlib\'       : None\n        }\n\n    compile_switch = \'/c \'\n    object_switch = \'/Fo\'         library_switch = \'/OUT:\'      module_dir_switch = \'/module:\'      module_include_switch = \'/I\'\n\n    def get_flags(self):\n        opt = [\'/nologo\', \'/MD\', \'/nbs\', \'/names:lowercase\', \'/assume:underscore\']\n        return opt\n\n    def get_flags_free(self):\n        return []\n\n    def get_flags_debug(self):\n        return [\'/4Yb\', \'/d2\']\n\n    def get_flags_opt(self):\n        return [\'/O1\']  \n    def get_flags_arch(self):\n        return ["/arch:IA32", "/QaxSSE3"]\n\n    def runtime_library_dir_option(self, dir):\n        raise NotImplementedError\n\n\nclass IntelItaniumVisualFCompiler(IntelVisualFCompiler):\n    compiler_type = \'intelev\'\n    description = \'Intel Visual Fortran Compiler for Itanium apps\'\n\n    version_match = intel_version_match(\'Itanium\')\n\n    possible_executables = [\'efl\']      ar_exe = IntelVisualFCompiler.ar_exe\n\n    executables = {\n        \'version_cmd\'  : None,\n        \'compiler_f77\' : [None, "-FI", "-w90", "-w95"],\n        \'compiler_fix\' : [None, "-FI", "-4L72", "-w"],\n        \'compiler_f90\' : [None],\n        \'linker_so\'    : [\'<F90>\', "-shared"],\n        \'archiver\'     : [ar_exe, "/verbose", "/OUT:"],\n        \'ranlib\'       : None\n        }\n\n\nclass IntelEM64VisualFCompiler(IntelVisualFCompiler):\n    compiler_type = \'intelvem\'\n    description = \'Intel Visual Fortran Compiler for 64-bit apps\'\n\n    version_match = simple_version_match(start=\'Intel\\(R\\).*?64,\')\n\n    def get_flags_arch(self):\n        return [\'/QaxSSE4.2\']\n\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'intel\')\n    compiler.customize()\n    print(compiler.get_version())\nfrom __future__ import division, absolute_import, print_function\n\nimport platform\n\nfrom distutils.unixccompiler import UnixCCompiler\nfrom numpy.distutils.exec_command import find_executable\nfrom numpy.distutils.ccompiler import simple_version_match\nif platform.system() == \'Windows\':\n    from numpy.distutils.msvc9compiler import MSVCCompiler\n\n\nclass IntelCCompiler(UnixCCompiler):\n    \n    compiler_type = \'intel\'\n    cc_exe = \'icc\'\n    cc_args = \'fPIC\'\n\n    def __init__(self, verbose=0, dry_run=0, force=0):\n        UnixCCompiler.__init__(self, verbose, dry_run, force)\n        self.cc_exe = (\'icc -fPIC -fp-model strict -O3 \'\n                       \'-fomit-frame-pointer -openmp\')\n        compiler = self.cc_exe\n        if platform.system() == \'Darwin\':\n            shared_flag = \'-Wl,-undefined,dynamic_lookup\'\n        else:\n            shared_flag = \'-shared\'\n        self.set_executables(compiler=compiler,\n                             compiler_so=compiler,\n                             compiler_cxx=compiler,\n                             archiver=\'xiar\' + \' cru\',\n                             linker_exe=compiler + \' -shared-intel\',\n                             linker_so=compiler + \' \' + shared_flag +\n                             \' -shared-intel\')\n\n\nclass IntelItaniumCCompiler(IntelCCompiler):\n    compiler_type = \'intele\'\n\n            for cc_exe in map(find_executable, [\'icc\', \'ecc\']):\n        if cc_exe:\n            break\n\n\nclass IntelEM64TCCompiler(UnixCCompiler):\n    \n    compiler_type = \'intelem\'\n    cc_exe = \'icc -m64\'\n    cc_args = \'-fPIC\'\n\n    def __init__(self, verbose=0, dry_run=0, force=0):\n        UnixCCompiler.__init__(self, verbose, dry_run, force)\n        self.cc_exe = (\'icc -m64 -fPIC -fp-model strict -O3 \'\n                       \'-fomit-frame-pointer -openmp -xSSE4.2\')\n        compiler = self.cc_exe\n        if platform.system() == \'Darwin\':\n            shared_flag = \'-Wl,-undefined,dynamic_lookup\'\n        else:\n            shared_flag = \'-shared\'\n        self.set_executables(compiler=compiler,\n                             compiler_so=compiler,\n                             compiler_cxx=compiler,\n                             archiver=\'xiar\' + \' cru\',\n                             linker_exe=compiler + \' -shared-intel\',\n                             linker_so=compiler + \' \' + shared_flag +\n                             \' -shared-intel\')\n\n\nif platform.system() == \'Windows\':\n    class IntelCCompilerW(MSVCCompiler):\n        \n        compiler_type = \'intelw\'\n        compiler_cxx = \'icl\'\n\n        def __init__(self, verbose=0, dry_run=0, force=0):\n            MSVCCompiler.__init__(self, verbose, dry_run, force)\n            version_match = simple_version_match(start=\'Intel\\(R\\).*?32,\')\n            self.__version = version_match\n\n        def initialize(self, plat_name=None):\n            MSVCCompiler.initialize(self, plat_name)\n            self.cc = self.find_exe(\'icl.exe\')\n            self.lib = self.find_exe(\'xilib\')\n            self.linker = self.find_exe(\'xilink\')\n            self.compile_options = [\'/nologo\', \'/O3\', \'/MD\', \'/W3\',\n                                    \'/Qstd=c99\', \'/QaxSSE4.2\']\n            self.compile_options_debug = [\'/nologo\', \'/Od\', \'/MDd\', \'/W3\',\n                                          \'/Qstd=c99\', \'/Z7\', \'/D_DEBUG\']\n\n    class IntelEM64TCCompilerW(IntelCCompilerW):\n        \n        compiler_type = \'intelemw\'\n\n        def __init__(self, verbose=0, dry_run=0, force=0):\n            MSVCCompiler.__init__(self, verbose, dry_run, force)\n            version_match = simple_version_match(start=\'Intel\\(R\\).*?64,\')\n            self.__version = version_match\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport numpy as np\nimport numpy.linalg as la\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\n__all__ = [\n    \'lagzero\', \'lagone\', \'lagx\', \'lagdomain\', \'lagline\', \'lagadd\',\n    \'lagsub\', \'lagmulx\', \'lagmul\', \'lagdiv\', \'lagpow\', \'lagval\', \'lagder\',\n    \'lagint\', \'lag2poly\', \'poly2lag\', \'lagfromroots\', \'lagvander\',\n    \'lagfit\', \'lagtrim\', \'lagroots\', \'Laguerre\', \'lagval2d\', \'lagval3d\',\n    \'laggrid2d\', \'laggrid3d\', \'lagvander2d\', \'lagvander3d\', \'lagcompanion\',\n    \'laggauss\', \'lagweight\']\n\nlagtrim = pu.trimcoef\n\n\ndef poly2lag(pol):\n    \n    [pol] = pu.as_series([pol])\n    deg = len(pol) - 1\n    res = 0\n    for i in range(deg, -1, -1):\n        res = lagadd(lagmulx(res), pol[i])\n    return res\n\n\ndef lag2poly(c):\n    \n    from .polynomial import polyadd, polysub, polymulx\n\n    [c] = pu.as_series([c])\n    n = len(c)\n    if n == 1:\n        return c\n    else:\n        c0 = c[-2]\n        c1 = c[-1]\n                for i in range(n - 1, 1, -1):\n            tmp = c0\n            c0 = polysub(c[i - 2], (c1*(i - 1))/i)\n            c1 = polyadd(tmp, polysub((2*i - 1)*c1, polymulx(c1))/i)\n        return polyadd(c0, polysub(c1, polymulx(c1)))\n\n\nlagdomain = np.array([0, 1])\n\nlagzero = np.array([0])\n\nlagone = np.array([1])\n\nlagx = np.array([1, -1])\n\n\ndef lagline(off, scl):\n    \n    if scl != 0:\n        return np.array([off + scl, -scl])\n    else:\n        return np.array([off])\n\n\ndef lagfromroots(roots):\n    \n    if len(roots) == 0:\n        return np.ones(1)\n    else:\n        [roots] = pu.as_series([roots], trim=False)\n        roots.sort()\n        p = [lagline(-r, 1) for r in roots]\n        n = len(p)\n        while n > 1:\n            m, r = divmod(n, 2)\n            tmp = [lagmul(p[i], p[i+m]) for i in range(m)]\n            if r:\n                tmp[0] = lagmul(tmp[0], p[-1])\n            p = tmp\n            n = m\n        return p[0]\n\n\ndef lagadd(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] += c2\n        ret = c1\n    else:\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef lagsub(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] -= c2\n        ret = c1\n    else:\n        c2 = -c2\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef lagmulx(c):\n    \n        [c] = pu.as_series([c])\n        if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]\n    prd[1] = -c[0]\n    for i in range(1, len(c)):\n        prd[i + 1] = -c[i]*(i + 1)\n        prd[i] += c[i]*(2*i + 1)\n        prd[i - 1] -= c[i]*i\n    return prd\n\n\ndef lagmul(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n\n    if len(c1) > len(c2):\n        c = c2\n        xs = c1\n    else:\n        c = c1\n        xs = c2\n\n    if len(c) == 1:\n        c0 = c[0]*xs\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]*xs\n        c1 = c[1]*xs\n    else:\n        nd = len(c)\n        c0 = c[-2]*xs\n        c1 = c[-1]*xs\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = lagsub(c[-i]*xs, (c1*(nd - 1))/nd)\n            c1 = lagadd(tmp, lagsub((2*nd - 1)*c1, lagmulx(c1))/nd)\n    return lagadd(c0, lagsub(c1, lagmulx(c1)))\n\n\ndef lagdiv(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    lc1 = len(c1)\n    lc2 = len(c2)\n    if lc1 < lc2:\n        return c1[:1]*0, c1\n    elif lc2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    else:\n        quo = np.empty(lc1 - lc2 + 1, dtype=c1.dtype)\n        rem = c1\n        for i in range(lc1 - lc2, - 1, -1):\n            p = lagmul([0]*i + [1], c2)\n            q = rem[-1]/p[-1]\n            rem = rem[:-1] - q*p[:-1]\n            quo[i] = q\n        return quo, pu.trimseq(rem)\n\n\ndef lagpow(c, pow, maxpower=16):\n    \n        [c] = pu.as_series([c])\n    power = int(pow)\n    if power != pow or power < 0:\n        raise ValueError("Power must be a non-negative integer.")\n    elif maxpower is not None and power > maxpower:\n        raise ValueError("Power is too large")\n    elif power == 0:\n        return np.array([1], dtype=c.dtype)\n    elif power == 1:\n        return c\n    else:\n                        prd = c\n        for i in range(2, power + 1):\n            prd = lagmul(prd, c)\n        return prd\n\n\ndef lagder(c, m=1, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of derivation must be integer")\n    if cnt < 0:\n        raise ValueError("The order of derivation must be non-negative")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    n = len(c)\n    if cnt >= n:\n        c = c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=c.dtype)\n            for j in range(n, 1, -1):\n                der[j - 1] = -c[j]\n                c[j - 1] += c[j]\n            der[0] = -c[1]\n            c = der\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef lagint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if not np.iterable(k):\n        k = [k]\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of integration must be integer")\n    if cnt < 0:\n        raise ValueError("The order of integration must be non-negative")\n    if len(k) > cnt:\n        raise ValueError("Too many integration constants")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    k = list(k) + [0]*(cnt - len(k))\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=c.dtype)\n            tmp[0] = c[0]\n            tmp[1] = -c[0]\n            for j in range(1, n):\n                tmp[j] += c[j]\n                tmp[j + 1] = -c[j]\n            tmp[0] += k[i] - lagval(lbnd, tmp)\n            c = tmp\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef lagval(x, c, tensor=True):\n    \n    c = np.array(c, ndmin=1, copy=0)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    if len(c) == 1:\n        c0 = c[0]\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]\n        c1 = c[1]\n    else:\n        nd = len(c)\n        c0 = c[-2]\n        c1 = c[-1]\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = c[-i] - (c1*(nd - 1))/nd\n            c1 = tmp + (c1*((2*nd - 1) - x))/nd\n    return c0 + c1*(1 - x)\n\n\ndef lagval2d(x, y, c):\n    \n    try:\n        x, y = np.array((x, y), copy=0)\n    except:\n        raise ValueError(\'x, y are incompatible\')\n\n    c = lagval(x, c)\n    c = lagval(y, c, tensor=False)\n    return c\n\n\ndef laggrid2d(x, y, c):\n    \n    c = lagval(x, c)\n    c = lagval(y, c)\n    return c\n\n\ndef lagval3d(x, y, z, c):\n    \n    try:\n        x, y, z = np.array((x, y, z), copy=0)\n    except:\n        raise ValueError(\'x, y, z are incompatible\')\n\n    c = lagval(x, c)\n    c = lagval(y, c, tensor=False)\n    c = lagval(z, c, tensor=False)\n    return c\n\n\ndef laggrid3d(x, y, z, c):\n    \n    c = lagval(x, c)\n    c = lagval(y, c)\n    c = lagval(z, c)\n    return c\n\n\ndef lagvander(x, deg):\n    \n    ideg = int(deg)\n    if ideg != deg:\n        raise ValueError("deg must be integer")\n    if ideg < 0:\n        raise ValueError("deg must be non-negative")\n\n    x = np.array(x, copy=0, ndmin=1) + 0.0\n    dims = (ideg + 1,) + x.shape\n    dtyp = x.dtype\n    v = np.empty(dims, dtype=dtyp)\n    v[0] = x*0 + 1\n    if ideg > 0:\n        v[1] = 1 - x\n        for i in range(2, ideg + 1):\n            v[i] = (v[i-1]*(2*i - 1 - x) - v[i-2]*(i - 1))/i\n    return np.rollaxis(v, 0, v.ndim)\n\n\ndef lagvander2d(x, y, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy = ideg\n    x, y = np.array((x, y), copy=0) + 0.0\n\n    vx = lagvander(x, degx)\n    vy = lagvander(y, degy)\n    v = vx[..., None]*vy[..., None,:]\n    return v.reshape(v.shape[:-2] + (-1,))\n\n\ndef lagvander3d(x, y, z, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy, degz = ideg\n    x, y, z = np.array((x, y, z), copy=0) + 0.0\n\n    vx = lagvander(x, degx)\n    vy = lagvander(y, degy)\n    vz = lagvander(z, degz)\n    v = vx[..., None, None]*vy[..., None,:, None]*vz[..., None, None,:]\n    return v.reshape(v.shape[:-3] + (-1,))\n\n\ndef lagfit(x, y, deg, rcond=None, full=False, w=None):\n    \n    order = int(deg) + 1\n    x = np.asarray(x) + 0.0\n    y = np.asarray(y) + 0.0\n\n        if deg < 0:\n        raise ValueError("expected deg >= 0")\n    if x.ndim != 1:\n        raise TypeError("expected 1D vector for x")\n    if x.size == 0:\n        raise TypeError("expected non-empty vector for x")\n    if y.ndim < 1 or y.ndim > 2:\n        raise TypeError("expected 1D or 2D array for y")\n    if len(x) != len(y):\n        raise TypeError("expected x and y to have same length")\n\n        lhs = lagvander(x, deg).T\n    rhs = y.T\n    if w is not None:\n        w = np.asarray(w) + 0.0\n        if w.ndim != 1:\n            raise TypeError("expected 1D vector for w")\n        if len(x) != len(w):\n            raise TypeError("expected x and w to have same length")\n                        lhs = lhs * w\n        rhs = rhs * w\n\n        if rcond is None:\n        rcond = len(x)*np.finfo(x.dtype).eps\n\n        if issubclass(lhs.dtype.type, np.complexfloating):\n        scl = np.sqrt((np.square(lhs.real) + np.square(lhs.imag)).sum(1))\n    else:\n        scl = np.sqrt(np.square(lhs).sum(1))\n    scl[scl == 0] = 1\n\n        c, resids, rank, s = la.lstsq(lhs.T/scl, rhs.T, rcond)\n    c = (c.T/scl).T\n\n        if rank != order and not full:\n        msg = "The fit may be poorly conditioned"\n        warnings.warn(msg, pu.RankWarning)\n\n    if full:\n        return c, [resids, rank, s, rcond]\n    else:\n        return c\n\n\ndef lagcompanion(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        raise ValueError(\'Series must have maximum degree of at least 1.\')\n    if len(c) == 2:\n        return np.array([[1 + c[0]/c[1]]])\n\n    n = len(c) - 1\n    mat = np.zeros((n, n), dtype=c.dtype)\n    top = mat.reshape(-1)[1::n+1]\n    mid = mat.reshape(-1)[0::n+1]\n    bot = mat.reshape(-1)[n::n+1]\n    top[...] = -np.arange(1, n)\n    mid[...] = 2.*np.arange(n) + 1.\n    bot[...] = top\n    mat[:, -1] += (c[:-1]/c[-1])*n\n    return mat\n\n\ndef lagroots(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) <= 1:\n        return np.array([], dtype=c.dtype)\n    if len(c) == 2:\n        return np.array([1 + c[0]/c[1]])\n\n    m = lagcompanion(c)\n    r = la.eigvals(m)\n    r.sort()\n    return r\n\n\ndef laggauss(deg):\n    \n    ideg = int(deg)\n    if ideg != deg or ideg < 1:\n        raise ValueError("deg must be a non-negative integer")\n\n            c = np.array([0]*deg + [1])\n    m = lagcompanion(c)\n    x = la.eigvalsh(m)\n\n        dy = lagval(x, c)\n    df = lagval(x, lagder(c))\n    x -= dy/df\n\n            fm = lagval(x, c[1:])\n    fm /= np.abs(fm).max()\n    df /= np.abs(df).max()\n    w = 1/(fm * df)\n\n        w /= w.sum()\n\n    return x, w\n\n\ndef lagweight(x):\n    \n    w = np.exp(-x)\n    return w\n\n\nclass Laguerre(ABCPolyBase):\n    \n        _add = staticmethod(lagadd)\n    _sub = staticmethod(lagsub)\n    _mul = staticmethod(lagmul)\n    _div = staticmethod(lagdiv)\n    _pow = staticmethod(lagpow)\n    _val = staticmethod(lagval)\n    _int = staticmethod(lagint)\n    _der = staticmethod(lagder)\n    _fit = staticmethod(lagfit)\n    _line = staticmethod(lagline)\n    _roots = staticmethod(lagroots)\n    _fromroots = staticmethod(lagfromroots)\n\n        nickname = \'lag\'\n    domain = np.array(lagdomain)\n    window = np.array(lagdomain)\nfrom __future__ import division, absolute_import, print_function\n\nimport os\n\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'LaheyFCompiler\']\n\nclass LaheyFCompiler(FCompiler):\n\n    compiler_type = \'lahey\'\n    description = \'Lahey/Fujitsu Fortran 95 Compiler\'\n    version_pattern =  r\'Lahey/Fujitsu Fortran 95 Compiler Release (?P<version>[^\\s*]*)\'\n\n    executables = {\n        \'version_cmd\'  : ["<F90>", "--version"],\n        \'compiler_f77\' : ["lf95", "--fix"],\n        \'compiler_fix\' : ["lf95", "--fix"],\n        \'compiler_f90\' : ["lf95"],\n        \'linker_so\'    : ["lf95", "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    module_dir_switch = None      module_include_switch = None \n    def get_flags_opt(self):\n        return [\'-O\']\n    def get_flags_debug(self):\n        return [\'-g\', \'--chk\', \'--chkglobal\']\n    def get_library_dirs(self):\n        opt = []\n        d = os.environ.get(\'LAHEY\')\n        if d:\n            opt.append(os.path.join(d, \'lib\'))\n        return opt\n    def get_libraries(self):\n        opt = []\n        opt.extend([\'fj9f6\', \'fj9i6\', \'fj9ipp\', \'fj9e6\'])\n        return opt\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'lahey\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport numpy as np\nimport numpy.linalg as la\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\n__all__ = [\n    \'legzero\', \'legone\', \'legx\', \'legdomain\', \'legline\', \'legadd\',\n    \'legsub\', \'legmulx\', \'legmul\', \'legdiv\', \'legpow\', \'legval\', \'legder\',\n    \'legint\', \'leg2poly\', \'poly2leg\', \'legfromroots\', \'legvander\',\n    \'legfit\', \'legtrim\', \'legroots\', \'Legendre\', \'legval2d\', \'legval3d\',\n    \'leggrid2d\', \'leggrid3d\', \'legvander2d\', \'legvander3d\', \'legcompanion\',\n    \'leggauss\', \'legweight\']\n\nlegtrim = pu.trimcoef\n\n\ndef poly2leg(pol):\n    \n    [pol] = pu.as_series([pol])\n    deg = len(pol) - 1\n    res = 0\n    for i in range(deg, -1, -1):\n        res = legadd(legmulx(res), pol[i])\n    return res\n\n\ndef leg2poly(c):\n    \n    from .polynomial import polyadd, polysub, polymulx\n\n    [c] = pu.as_series([c])\n    n = len(c)\n    if n < 3:\n        return c\n    else:\n        c0 = c[-2]\n        c1 = c[-1]\n                for i in range(n - 1, 1, -1):\n            tmp = c0\n            c0 = polysub(c[i - 2], (c1*(i - 1))/i)\n            c1 = polyadd(tmp, (polymulx(c1)*(2*i - 1))/i)\n        return polyadd(c0, polymulx(c1))\n\n\nlegdomain = np.array([-1, 1])\n\nlegzero = np.array([0])\n\nlegone = np.array([1])\n\nlegx = np.array([0, 1])\n\n\ndef legline(off, scl):\n    \n    if scl != 0:\n        return np.array([off, scl])\n    else:\n        return np.array([off])\n\n\ndef legfromroots(roots):\n    \n    if len(roots) == 0:\n        return np.ones(1)\n    else:\n        [roots] = pu.as_series([roots], trim=False)\n        roots.sort()\n        p = [legline(-r, 1) for r in roots]\n        n = len(p)\n        while n > 1:\n            m, r = divmod(n, 2)\n            tmp = [legmul(p[i], p[i+m]) for i in range(m)]\n            if r:\n                tmp[0] = legmul(tmp[0], p[-1])\n            p = tmp\n            n = m\n        return p[0]\n\n\ndef legadd(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] += c2\n        ret = c1\n    else:\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef legsub(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] -= c2\n        ret = c1\n    else:\n        c2 = -c2\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef legmulx(c):\n    \n        [c] = pu.as_series([c])\n        if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]*0\n    prd[1] = c[0]\n    for i in range(1, len(c)):\n        j = i + 1\n        k = i - 1\n        s = i + j\n        prd[j] = (c[i]*j)/s\n        prd[k] += (c[i]*i)/s\n    return prd\n\n\ndef legmul(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n\n    if len(c1) > len(c2):\n        c = c2\n        xs = c1\n    else:\n        c = c1\n        xs = c2\n\n    if len(c) == 1:\n        c0 = c[0]*xs\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]*xs\n        c1 = c[1]*xs\n    else:\n        nd = len(c)\n        c0 = c[-2]*xs\n        c1 = c[-1]*xs\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = legsub(c[-i]*xs, (c1*(nd - 1))/nd)\n            c1 = legadd(tmp, (legmulx(c1)*(2*nd - 1))/nd)\n    return legadd(c0, legmulx(c1))\n\n\ndef legdiv(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    lc1 = len(c1)\n    lc2 = len(c2)\n    if lc1 < lc2:\n        return c1[:1]*0, c1\n    elif lc2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    else:\n        quo = np.empty(lc1 - lc2 + 1, dtype=c1.dtype)\n        rem = c1\n        for i in range(lc1 - lc2, - 1, -1):\n            p = legmul([0]*i + [1], c2)\n            q = rem[-1]/p[-1]\n            rem = rem[:-1] - q*p[:-1]\n            quo[i] = q\n        return quo, pu.trimseq(rem)\n\n\ndef legpow(c, pow, maxpower=16):\n    \n        [c] = pu.as_series([c])\n    power = int(pow)\n    if power != pow or power < 0:\n        raise ValueError("Power must be a non-negative integer.")\n    elif maxpower is not None and power > maxpower:\n        raise ValueError("Power is too large")\n    elif power == 0:\n        return np.array([1], dtype=c.dtype)\n    elif power == 1:\n        return c\n    else:\n                        prd = c\n        for i in range(2, power + 1):\n            prd = legmul(prd, c)\n        return prd\n\n\ndef legder(c, m=1, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of derivation must be integer")\n    if cnt < 0:\n        raise ValueError("The order of derivation must be non-negative")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    n = len(c)\n    if cnt >= n:\n        c = c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=c.dtype)\n            for j in range(n, 2, -1):\n                der[j - 1] = (2*j - 1)*c[j]\n                c[j - 2] += c[j]\n            if n > 1:\n                der[1] = 3*c[2]\n            der[0] = c[1]\n            c = der\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef legint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if not np.iterable(k):\n        k = [k]\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of integration must be integer")\n    if cnt < 0:\n        raise ValueError("The order of integration must be non-negative")\n    if len(k) > cnt:\n        raise ValueError("Too many integration constants")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    k = list(k) + [0]*(cnt - len(k))\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=c.dtype)\n            tmp[0] = c[0]*0\n            tmp[1] = c[0]\n            if n > 1:\n                tmp[2] = c[1]/3\n            for j in range(2, n):\n                t = c[j]/(2*j + 1)\n                tmp[j + 1] = t\n                tmp[j - 1] -= t\n            tmp[0] += k[i] - legval(lbnd, tmp)\n            c = tmp\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef legval(x, c, tensor=True):\n    \n    c = np.array(c, ndmin=1, copy=0)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n        c = c.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    if len(c) == 1:\n        c0 = c[0]\n        c1 = 0\n    elif len(c) == 2:\n        c0 = c[0]\n        c1 = c[1]\n    else:\n        nd = len(c)\n        c0 = c[-2]\n        c1 = c[-1]\n        for i in range(3, len(c) + 1):\n            tmp = c0\n            nd = nd - 1\n            c0 = c[-i] - (c1*(nd - 1))/nd\n            c1 = tmp + (c1*x*(2*nd - 1))/nd\n    return c0 + c1*x\n\n\ndef legval2d(x, y, c):\n    \n    try:\n        x, y = np.array((x, y), copy=0)\n    except:\n        raise ValueError(\'x, y are incompatible\')\n\n    c = legval(x, c)\n    c = legval(y, c, tensor=False)\n    return c\n\n\ndef leggrid2d(x, y, c):\n    \n    c = legval(x, c)\n    c = legval(y, c)\n    return c\n\n\ndef legval3d(x, y, z, c):\n    \n    try:\n        x, y, z = np.array((x, y, z), copy=0)\n    except:\n        raise ValueError(\'x, y, z are incompatible\')\n\n    c = legval(x, c)\n    c = legval(y, c, tensor=False)\n    c = legval(z, c, tensor=False)\n    return c\n\n\ndef leggrid3d(x, y, z, c):\n    \n    c = legval(x, c)\n    c = legval(y, c)\n    c = legval(z, c)\n    return c\n\n\ndef legvander(x, deg):\n    \n    ideg = int(deg)\n    if ideg != deg:\n        raise ValueError("deg must be integer")\n    if ideg < 0:\n        raise ValueError("deg must be non-negative")\n\n    x = np.array(x, copy=0, ndmin=1) + 0.0\n    dims = (ideg + 1,) + x.shape\n    dtyp = x.dtype\n    v = np.empty(dims, dtype=dtyp)\n            v[0] = x*0 + 1\n    if ideg > 0:\n        v[1] = x\n        for i in range(2, ideg + 1):\n            v[i] = (v[i-1]*x*(2*i - 1) - v[i-2]*(i - 1))/i\n    return np.rollaxis(v, 0, v.ndim)\n\n\ndef legvander2d(x, y, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy = ideg\n    x, y = np.array((x, y), copy=0) + 0.0\n\n    vx = legvander(x, degx)\n    vy = legvander(y, degy)\n    v = vx[..., None]*vy[..., None,:]\n    return v.reshape(v.shape[:-2] + (-1,))\n\n\ndef legvander3d(x, y, z, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy, degz = ideg\n    x, y, z = np.array((x, y, z), copy=0) + 0.0\n\n    vx = legvander(x, degx)\n    vy = legvander(y, degy)\n    vz = legvander(z, degz)\n    v = vx[..., None, None]*vy[..., None,:, None]*vz[..., None, None,:]\n    return v.reshape(v.shape[:-3] + (-1,))\n\n\ndef legfit(x, y, deg, rcond=None, full=False, w=None):\n    \n    order = int(deg) + 1\n    x = np.asarray(x) + 0.0\n    y = np.asarray(y) + 0.0\n\n        if deg < 0:\n        raise ValueError("expected deg >= 0")\n    if x.ndim != 1:\n        raise TypeError("expected 1D vector for x")\n    if x.size == 0:\n        raise TypeError("expected non-empty vector for x")\n    if y.ndim < 1 or y.ndim > 2:\n        raise TypeError("expected 1D or 2D array for y")\n    if len(x) != len(y):\n        raise TypeError("expected x and y to have same length")\n\n        lhs = legvander(x, deg).T\n    rhs = y.T\n    if w is not None:\n        w = np.asarray(w) + 0.0\n        if w.ndim != 1:\n            raise TypeError("expected 1D vector for w")\n        if len(x) != len(w):\n            raise TypeError("expected x and w to have same length")\n                        lhs = lhs * w\n        rhs = rhs * w\n\n        if rcond is None:\n        rcond = len(x)*np.finfo(x.dtype).eps\n\n        if issubclass(lhs.dtype.type, np.complexfloating):\n        scl = np.sqrt((np.square(lhs.real) + np.square(lhs.imag)).sum(1))\n    else:\n        scl = np.sqrt(np.square(lhs).sum(1))\n    scl[scl == 0] = 1\n\n        c, resids, rank, s = la.lstsq(lhs.T/scl, rhs.T, rcond)\n    c = (c.T/scl).T\n\n        if rank != order and not full:\n        msg = "The fit may be poorly conditioned"\n        warnings.warn(msg, pu.RankWarning)\n\n    if full:\n        return c, [resids, rank, s, rcond]\n    else:\n        return c\n\n\ndef legcompanion(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        raise ValueError(\'Series must have maximum degree of at least 1.\')\n    if len(c) == 2:\n        return np.array([[-c[0]/c[1]]])\n\n    n = len(c) - 1\n    mat = np.zeros((n, n), dtype=c.dtype)\n    scl = 1./np.sqrt(2*np.arange(n) + 1)\n    top = mat.reshape(-1)[1::n+1]\n    bot = mat.reshape(-1)[n::n+1]\n    top[...] = np.arange(1, n)*scl[:n-1]*scl[1:n]\n    bot[...] = top\n    mat[:, -1] -= (c[:-1]/c[-1])*(scl/scl[-1])*(n/(2*n - 1))\n    return mat\n\n\ndef legroots(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        return np.array([], dtype=c.dtype)\n    if len(c) == 2:\n        return np.array([-c[0]/c[1]])\n\n    m = legcompanion(c)\n    r = la.eigvals(m)\n    r.sort()\n    return r\n\n\ndef leggauss(deg):\n    \n    ideg = int(deg)\n    if ideg != deg or ideg < 1:\n        raise ValueError("deg must be a non-negative integer")\n\n            c = np.array([0]*deg + [1])\n    m = legcompanion(c)\n    x = la.eigvalsh(m)\n\n        dy = legval(x, c)\n    df = legval(x, legder(c))\n    x -= dy/df\n\n            fm = legval(x, c[1:])\n    fm /= np.abs(fm).max()\n    df /= np.abs(df).max()\n    w = 1/(fm * df)\n\n        w = (w + w[::-1])/2\n    x = (x - x[::-1])/2\n\n        w *= 2. / w.sum()\n\n    return x, w\n\n\ndef legweight(x):\n    \n    w = x*0.0 + 1.0\n    return w\n\n\nclass Legendre(ABCPolyBase):\n    \n        _add = staticmethod(legadd)\n    _sub = staticmethod(legsub)\n    _mul = staticmethod(legmul)\n    _div = staticmethod(legdiv)\n    _pow = staticmethod(legpow)\n    _val = staticmethod(legval)\n    _int = staticmethod(legint)\n    _der = staticmethod(legder)\n    _fit = staticmethod(legfit)\n    _line = staticmethod(legline)\n    _roots = staticmethod(legroots)\n    _fromroots = staticmethod(legfromroots)\n\n        nickname = \'leg\'\n    domain = np.array(legdomain)\n    window = np.array(legdomain)\nfrom __future__ import division, absolute_import, print_function\n\nimport re\nimport sys\nimport os\nimport subprocess\n\n__doc__ = \n\n__version__ = \'0.1a\'\n\npy_ver = "%d%d" % tuple(sys.version_info[:2])\n\nDEFAULT_NM = \'nm -Cs\'\n\nDEF_HEADER =  % py_ver\n\nFUNC_RE = re.compile(r"^(.*) in python%s\\.dll" % py_ver, re.MULTILINE)\nDATA_RE = re.compile(r"^_imp__(.*) in python%s\\.dll" % py_ver, re.MULTILINE)\n\ndef parse_cmd():\n    \n    if len(sys.argv) == 3:\n        if sys.argv[1][-4:] == \'.lib\' and sys.argv[2][-4:] == \'.def\':\n            libfile, deffile = sys.argv[1:]\n        elif sys.argv[1][-4:] == \'.def\' and sys.argv[2][-4:] == \'.lib\':\n            deffile, libfile = sys.argv[1:]\n        else:\n            print("I\'m assuming that your first argument is the library")\n            print("and the second is the DEF file.")\n    elif len(sys.argv) == 2:\n        if sys.argv[1][-4:] == \'.def\':\n            deffile = sys.argv[1]\n            libfile = \'python%s.lib\' % py_ver\n        elif sys.argv[1][-4:] == \'.lib\':\n            deffile = None\n            libfile = sys.argv[1]\n    else:\n        libfile = \'python%s.lib\' % py_ver\n        deffile = None\n    return libfile, deffile\n\ndef getnm(nm_cmd = [\'nm\', \'-Cs\', \'python%s.lib\' % py_ver]):\n    \n    f = subprocess.Popen(nm_cmd, shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n    nm_output = f.stdout.read()\n    f.stdout.close()\n    return nm_output\n\ndef parse_nm(nm_output):\n    \n    data = DATA_RE.findall(nm_output)\n    func = FUNC_RE.findall(nm_output)\n\n    flist = []\n    for sym in data:\n        if sym in func and (sym[:2] == \'Py\' or sym[:3] == \'_Py\' or sym[:4] == \'init\'):\n            flist.append(sym)\n\n    dlist = []\n    for sym in data:\n        if sym not in flist and (sym[:2] == \'Py\' or sym[:3] == \'_Py\'):\n            dlist.append(sym)\n\n    dlist.sort()\n    flist.sort()\n    return dlist, flist\n\ndef output_def(dlist, flist, header, file = sys.stdout):\n    \n    for data_sym in dlist:\n        header = header + \'\\t%s DATA\\n\' % data_sym\n    header = header + \'\\n\'     for func_sym in flist:\n        header = header + \'\\t%s\\n\' % func_sym\n    file.write(header)\n\nif __name__ == \'__main__\':\n    libfile, deffile = parse_cmd()\n    if deffile is None:\n        deffile = sys.stdout\n    else:\n        deffile = open(deffile, \'w\')\n    nm_cmd = [str(DEFAULT_NM), str(libfile)]\n    nm_output = getnm(nm_cmd)\n    dlist, flist = parse_nm(nm_output)\n    output_def(dlist, flist, DEF_HEADER, deffile)\n\nfrom __future__ import division, absolute_import, print_function\n\n\n__all__ = [\'matrix_power\', \'solve\', \'tensorsolve\', \'tensorinv\', \'inv\',\n           \'cholesky\', \'eigvals\', \'eigvalsh\', \'pinv\', \'slogdet\', \'det\',\n           \'svd\', \'eig\', \'eigh\', \'lstsq\', \'norm\', \'qr\', \'cond\', \'matrix_rank\',\n           \'LinAlgError\', \'multi_dot\']\n\nimport warnings\n\nfrom numpy.core import (\n    array, asarray, zeros, empty, empty_like, transpose, intc, single, double,\n    csingle, cdouble, inexact, complexfloating, newaxis, ravel, all, Inf, dot,\n    add, multiply, sqrt, maximum, fastCopyAndTranspose, sum, isfinite, size,\n    finfo, errstate, geterrobj, longdouble, rollaxis, amin, amax, product, abs,\n    broadcast, atleast_2d, intp, asanyarray, isscalar\n    )\nfrom numpy.lib import triu, asfarray\nfrom numpy.linalg import lapack_lite, _umath_linalg\nfrom numpy.matrixlib.defmatrix import matrix_power\nfrom numpy.compat import asbytes\n\n_N = asbytes(\'N\')\n_V = asbytes(\'V\')\n_A = asbytes(\'A\')\n_S = asbytes(\'S\')\n_L = asbytes(\'L\')\n\nfortran_int = intc\n\nclass LinAlgError(Exception):\n    \n    pass\n\n\n_linalg_error_extobj = None\n\ndef _determine_error_states():\n    global _linalg_error_extobj\n    errobj = geterrobj()\n    bufsize = errobj[0]\n\n    with errstate(invalid=\'call\', over=\'ignore\',\n                  divide=\'ignore\', under=\'ignore\'):\n        invalid_call_errmask = geterrobj()[1]\n\n    _linalg_error_extobj = [bufsize, invalid_call_errmask, None]\n\n_determine_error_states()\n\ndef _raise_linalgerror_singular(err, flag):\n    raise LinAlgError("Singular matrix")\n\ndef _raise_linalgerror_nonposdef(err, flag):\n    raise LinAlgError("Matrix is not positive definite")\n\ndef _raise_linalgerror_eigenvalues_nonconvergence(err, flag):\n    raise LinAlgError("Eigenvalues did not converge")\n\ndef _raise_linalgerror_svd_nonconvergence(err, flag):\n    raise LinAlgError("SVD did not converge")\n\ndef get_linalg_error_extobj(callback):\n    extobj = list(_linalg_error_extobj)\n    extobj[2] = callback\n    return extobj\n\ndef _makearray(a):\n    new = asarray(a)\n    wrap = getattr(a, "__array_prepare__", new.__array_wrap__)\n    return new, wrap\n\ndef isComplexType(t):\n    return issubclass(t, complexfloating)\n\n_real_types_map = {single : single,\n                   double : double,\n                   csingle : single,\n                   cdouble : double}\n\n_complex_types_map = {single : csingle,\n                      double : cdouble,\n                      csingle : csingle,\n                      cdouble : cdouble}\n\ndef _realType(t, default=double):\n    return _real_types_map.get(t, default)\n\ndef _complexType(t, default=cdouble):\n    return _complex_types_map.get(t, default)\n\ndef _linalgRealType(t):\n    \n    return double\n\n_complex_types_map = {single : csingle,\n                      double : cdouble,\n                      csingle : csingle,\n                      cdouble : cdouble}\n\ndef _commonType(*arrays):\n        result_type = single\n    is_complex = False\n    for a in arrays:\n        if issubclass(a.dtype.type, inexact):\n            if isComplexType(a.dtype.type):\n                is_complex = True\n            rt = _realType(a.dtype.type, default=None)\n            if rt is None:\n                                raise TypeError("array type %s is unsupported in linalg" %\n                        (a.dtype.name,))\n        else:\n            rt = double\n        if rt is double:\n            result_type = double\n    if is_complex:\n        t = cdouble\n        result_type = _complex_types_map[result_type]\n    else:\n        t = double\n    return t, result_type\n\n\n\n_fastCT = fastCopyAndTranspose\n\ndef _to_native_byte_order(*arrays):\n    ret = []\n    for arr in arrays:\n        if arr.dtype.byteorder not in (\'=\', \'|\'):\n            ret.append(asarray(arr, dtype=arr.dtype.newbyteorder(\'=\')))\n        else:\n            ret.append(arr)\n    if len(ret) == 1:\n        return ret[0]\n    else:\n        return ret\n\ndef _fastCopyAndTranspose(type, *arrays):\n    cast_arrays = ()\n    for a in arrays:\n        if a.dtype.type is type:\n            cast_arrays = cast_arrays + (_fastCT(a),)\n        else:\n            cast_arrays = cast_arrays + (_fastCT(a.astype(type)),)\n    if len(cast_arrays) == 1:\n        return cast_arrays[0]\n    else:\n        return cast_arrays\n\ndef _assertRank2(*arrays):\n    for a in arrays:\n        if len(a.shape) != 2:\n            raise LinAlgError(\'%d-dimensional array given. Array must be \'\n                    \'two-dimensional\' % len(a.shape))\n\ndef _assertRankAtLeast2(*arrays):\n    for a in arrays:\n        if len(a.shape) < 2:\n            raise LinAlgError(\'%d-dimensional array given. Array must be \'\n                    \'at least two-dimensional\' % len(a.shape))\n\ndef _assertSquareness(*arrays):\n    for a in arrays:\n        if max(a.shape) != min(a.shape):\n            raise LinAlgError(\'Array must be square\')\n\ndef _assertNdSquareness(*arrays):\n    for a in arrays:\n        if max(a.shape[-2:]) != min(a.shape[-2:]):\n            raise LinAlgError(\'Last 2 dimensions of the array must be square\')\n\ndef _assertFinite(*arrays):\n    for a in arrays:\n        if not (isfinite(a).all()):\n            raise LinAlgError("Array must not contain infs or NaNs")\n\ndef _assertNoEmpty2d(*arrays):\n    for a in arrays:\n        if a.size == 0 and product(a.shape[-2:]) == 0:\n            raise LinAlgError("Arrays cannot be empty")\n\n\n\ndef tensorsolve(a, b, axes=None):\n    \n    a, wrap = _makearray(a)\n    b = asarray(b)\n    an = a.ndim\n\n    if axes is not None:\n        allaxes = list(range(0, an))\n        for k in axes:\n            allaxes.remove(k)\n            allaxes.insert(an, k)\n        a = a.transpose(allaxes)\n\n    oldshape = a.shape[-(an-b.ndim):]\n    prod = 1\n    for k in oldshape:\n        prod *= k\n\n    a = a.reshape(-1, prod)\n    b = b.ravel()\n    res = wrap(solve(a, b))\n    res.shape = oldshape\n    return res\n\ndef solve(a, b):\n    \n    a, _ = _makearray(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    b, wrap = _makearray(b)\n    t, result_t = _commonType(a, b)\n\n            if b.ndim == a.ndim - 1:\n        if a.shape[-1] == 0 and b.shape[-1] == 0:\n                                    a = a.reshape(a.shape[:-1])\n            bc = broadcast(a, b)\n            return wrap(empty(bc.shape, dtype=result_t))\n\n        gufunc = _umath_linalg.solve1\n    else:\n        if b.size == 0:\n            if (a.shape[-1] == 0 and b.shape[-2] == 0) or b.shape[-1] == 0:\n                a = a[:,:1].reshape(a.shape[:-1] + (1,))\n                bc = broadcast(a, b)\n                return wrap(empty(bc.shape, dtype=result_t))\n\n        gufunc = _umath_linalg.solve\n\n    signature = \'DD->D\' if isComplexType(t) else \'dd->d\'\n    extobj = get_linalg_error_extobj(_raise_linalgerror_singular)\n    r = gufunc(a, b, signature=signature, extobj=extobj)\n\n    return wrap(r.astype(result_t, copy=False))\n\n\ndef tensorinv(a, ind=2):\n    \n    a = asarray(a)\n    oldshape = a.shape\n    prod = 1\n    if ind > 0:\n        invshape = oldshape[ind:] + oldshape[:ind]\n        for k in oldshape[ind:]:\n            prod *= k\n    else:\n        raise ValueError("Invalid ind argument.")\n    a = a.reshape(prod, -1)\n    ia = inv(a)\n    return ia.reshape(*invshape)\n\n\n\ndef inv(a):\n    \n    a, wrap = _makearray(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n\n    if a.shape[-1] == 0:\n                return wrap(empty_like(a, dtype=result_t))\n\n    signature = \'D->D\' if isComplexType(t) else \'d->d\'\n    extobj = get_linalg_error_extobj(_raise_linalgerror_singular)\n    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n    return wrap(ainv.astype(result_t, copy=False))\n\n\n\ndef cholesky(a):\n    \n    extobj = get_linalg_error_extobj(_raise_linalgerror_nonposdef)\n    gufunc = _umath_linalg.cholesky_lo\n    a, wrap = _makearray(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n    signature = \'D->D\' if isComplexType(t) else \'d->d\'\n    r = gufunc(a, signature=signature, extobj=extobj)\n    return wrap(r.astype(result_t, copy=False))\n\n\ndef qr(a, mode=\'reduced\'):\n    \n    if mode not in (\'reduced\', \'complete\', \'r\', \'raw\'):\n        if mode in (\'f\', \'full\'):\n                        msg = "".join((\n                    "The \'full\' option is deprecated in favor of \'reduced\'.\\n",\n                    "For backward compatibility let mode default."))\n            warnings.warn(msg, DeprecationWarning)\n            mode = \'reduced\'\n        elif mode in (\'e\', \'economic\'):\n                        msg = "The \'economic\' option is deprecated.",\n            warnings.warn(msg, DeprecationWarning)\n            mode = \'economic\'\n        else:\n            raise ValueError("Unrecognized mode \'%s\'" % mode)\n\n    a, wrap = _makearray(a)\n    _assertRank2(a)\n    _assertNoEmpty2d(a)\n    m, n = a.shape\n    t, result_t = _commonType(a)\n    a = _fastCopyAndTranspose(t, a)\n    a = _to_native_byte_order(a)\n    mn = min(m, n)\n    tau = zeros((mn,), t)\n    if isComplexType(t):\n        lapack_routine = lapack_lite.zgeqrf\n        routine_name = \'zgeqrf\'\n    else:\n        lapack_routine = lapack_lite.dgeqrf\n        routine_name = \'dgeqrf\'\n\n        lwork = 1\n    work = zeros((lwork,), t)\n    results = lapack_routine(m, n, a, m, tau, work, -1, 0)\n    if results[\'info\'] != 0:\n        raise LinAlgError(\'%s returns %d\' % (routine_name, results[\'info\']))\n\n        lwork = int(abs(work[0]))\n    work = zeros((lwork,), t)\n    results = lapack_routine(m, n, a, m, tau, work, lwork, 0)\n    if results[\'info\'] != 0:\n        raise LinAlgError(\'%s returns %d\' % (routine_name, results[\'info\']))\n\n        if mode == \'r\':\n        r = _fastCopyAndTranspose(result_t, a[:, :mn])\n        return wrap(triu(r))\n\n    if mode == \'raw\':\n        return a, tau\n\n    if mode == \'economic\':\n        if t != result_t :\n            a = a.astype(result_t, copy=False)\n        return wrap(a.T)\n\n        if mode == \'complete\' and m > n:\n        mc = m\n        q = empty((m, m), t)\n    else:\n        mc = mn\n        q = empty((n, m), t)\n    q[:n] = a\n\n    if isComplexType(t):\n        lapack_routine = lapack_lite.zungqr\n        routine_name = \'zungqr\'\n    else:\n        lapack_routine = lapack_lite.dorgqr\n        routine_name = \'dorgqr\'\n\n        lwork = 1\n    work = zeros((lwork,), t)\n    results = lapack_routine(m, mc, mn, q, m, tau, work, -1, 0)\n    if results[\'info\'] != 0:\n        raise LinAlgError(\'%s returns %d\' % (routine_name, results[\'info\']))\n\n        lwork = int(abs(work[0]))\n    work = zeros((lwork,), t)\n    results = lapack_routine(m, mc, mn, q, m, tau, work, lwork, 0)\n    if results[\'info\'] != 0:\n        raise LinAlgError(\'%s returns %d\' % (routine_name, results[\'info\']))\n\n    q = _fastCopyAndTranspose(result_t, q[:mc])\n    r = _fastCopyAndTranspose(result_t, a[:, :mc])\n\n    return wrap(q), wrap(triu(r))\n\n\n\n\ndef eigvals(a):\n    \n    a, wrap = _makearray(a)\n    _assertNoEmpty2d(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    _assertFinite(a)\n    t, result_t = _commonType(a)\n\n    extobj = get_linalg_error_extobj(\n        _raise_linalgerror_eigenvalues_nonconvergence)\n    signature = \'D->D\' if isComplexType(t) else \'d->D\'\n    w = _umath_linalg.eigvals(a, signature=signature, extobj=extobj)\n\n    if not isComplexType(t):\n        if all(w.imag == 0):\n            w = w.real\n            result_t = _realType(result_t)\n        else:\n            result_t = _complexType(result_t)\n\n    return w.astype(result_t, copy=False)\n\ndef eigvalsh(a, UPLO=\'L\'):\n    \n    UPLO = UPLO.upper()\n    if UPLO not in (\'L\', \'U\'):\n        raise ValueError("UPLO argument must be \'L\' or \'U\'")\n\n    extobj = get_linalg_error_extobj(\n        _raise_linalgerror_eigenvalues_nonconvergence)\n    if UPLO == \'L\':\n        gufunc = _umath_linalg.eigvalsh_lo\n    else:\n        gufunc = _umath_linalg.eigvalsh_up\n\n    a, wrap = _makearray(a)\n    _assertNoEmpty2d(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n    signature = \'D->d\' if isComplexType(t) else \'d->d\'\n    w = gufunc(a, signature=signature, extobj=extobj)\n    return w.astype(_realType(result_t), copy=False)\n\ndef _convertarray(a):\n    t, result_t = _commonType(a)\n    a = _fastCT(a.astype(t))\n    return a, t, result_t\n\n\n\n\ndef eig(a):\n    \n    a, wrap = _makearray(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    _assertFinite(a)\n    t, result_t = _commonType(a)\n\n    extobj = get_linalg_error_extobj(\n        _raise_linalgerror_eigenvalues_nonconvergence)\n    signature = \'D->DD\' if isComplexType(t) else \'d->DD\'\n    w, vt = _umath_linalg.eig(a, signature=signature, extobj=extobj)\n\n    if not isComplexType(t) and all(w.imag == 0.0):\n        w = w.real\n        vt = vt.real\n        result_t = _realType(result_t)\n    else:\n        result_t = _complexType(result_t)\n\n    vt = vt.astype(result_t, copy=False)\n    return w.astype(result_t, copy=False), wrap(vt)\n\n\ndef eigh(a, UPLO=\'L\'):\n    \n    UPLO = UPLO.upper()\n    if UPLO not in (\'L\', \'U\'):\n        raise ValueError("UPLO argument must be \'L\' or \'U\'")\n\n    a, wrap = _makearray(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n\n    extobj = get_linalg_error_extobj(\n        _raise_linalgerror_eigenvalues_nonconvergence)\n    if UPLO == \'L\':\n        gufunc = _umath_linalg.eigh_lo\n    else:\n        gufunc = _umath_linalg.eigh_up\n\n    signature = \'D->dD\' if isComplexType(t) else \'d->dd\'\n    w, vt = gufunc(a, signature=signature, extobj=extobj)\n    w = w.astype(_realType(result_t), copy=False)\n    vt = vt.astype(result_t, copy=False)\n    return w, wrap(vt)\n\n\n\ndef svd(a, full_matrices=1, compute_uv=1):\n    \n    a, wrap = _makearray(a)\n    _assertNoEmpty2d(a)\n    _assertRankAtLeast2(a)\n    t, result_t = _commonType(a)\n\n    extobj = get_linalg_error_extobj(_raise_linalgerror_svd_nonconvergence)\n\n    m = a.shape[-2]\n    n = a.shape[-1]\n    if compute_uv:\n        if full_matrices:\n            if m < n:\n                gufunc = _umath_linalg.svd_m_f\n            else:\n                gufunc = _umath_linalg.svd_n_f\n        else:\n            if m < n:\n                gufunc = _umath_linalg.svd_m_s\n            else:\n                gufunc = _umath_linalg.svd_n_s\n\n        signature = \'D->DdD\' if isComplexType(t) else \'d->ddd\'\n        u, s, vt = gufunc(a, signature=signature, extobj=extobj)\n        u = u.astype(result_t, copy=False)\n        s = s.astype(_realType(result_t), copy=False)\n        vt = vt.astype(result_t, copy=False)\n        return wrap(u), s, wrap(vt)\n    else:\n        if m < n:\n            gufunc = _umath_linalg.svd_m\n        else:\n            gufunc = _umath_linalg.svd_n\n\n        signature = \'D->d\' if isComplexType(t) else \'d->d\'\n        s = gufunc(a, signature=signature, extobj=extobj)\n        s = s.astype(_realType(result_t), copy=False)\n        return s\n\ndef cond(x, p=None):\n    \n    x = asarray(x)      if p is None:\n        s = svd(x, compute_uv=False)\n        return s[..., 0]/s[..., -1]\n    else:\n        return norm(x, p, axis=(-2, -1)) * norm(inv(x), p, axis=(-2, -1))\n\n\ndef matrix_rank(M, tol=None):\n    \n    M = asarray(M)\n    if M.ndim > 2:\n        raise TypeError(\'array should have 2 or fewer dimensions\')\n    if M.ndim < 2:\n        return int(not all(M==0))\n    S = svd(M, compute_uv=False)\n    if tol is None:\n        tol = S.max() * max(M.shape) * finfo(S.dtype).eps\n    return sum(S > tol)\n\n\n\ndef pinv(a, rcond=1e-15 ):\n    \n    a, wrap = _makearray(a)\n    _assertNoEmpty2d(a)\n    a = a.conjugate()\n    u, s, vt = svd(a, 0)\n    m = u.shape[0]\n    n = vt.shape[1]\n    cutoff = rcond*maximum.reduce(s)\n    for i in range(min(n, m)):\n        if s[i] > cutoff:\n            s[i] = 1./s[i]\n        else:\n            s[i] = 0.;\n    res = dot(transpose(vt), multiply(s[:, newaxis], transpose(u)))\n    return wrap(res)\n\n\ndef slogdet(a):\n    \n    a = asarray(a)\n    _assertNoEmpty2d(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n    real_t = _realType(result_t)\n    signature = \'D->Dd\' if isComplexType(t) else \'d->dd\'\n    sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n    if isscalar(sign):\n        sign = sign.astype(result_t)\n    else:\n        sign = sign.astype(result_t, copy=False)\n    if isscalar(logdet):\n        logdet = logdet.astype(real_t)\n    else:\n        logdet = logdet.astype(real_t, copy=False)\n    return sign, logdet\n\ndef det(a):\n    \n    a = asarray(a)\n    _assertNoEmpty2d(a)\n    _assertRankAtLeast2(a)\n    _assertNdSquareness(a)\n    t, result_t = _commonType(a)\n    signature = \'D->D\' if isComplexType(t) else \'d->d\'\n    r = _umath_linalg.det(a, signature=signature)\n    if isscalar(r):\n        r = r.astype(result_t)\n    else:\n        r = r.astype(result_t, copy=False)\n    return r\n\n\ndef lstsq(a, b, rcond=-1):\n    \n    import math\n    a, _ = _makearray(a)\n    b, wrap = _makearray(b)\n    is_1d = len(b.shape) == 1\n    if is_1d:\n        b = b[:, newaxis]\n    _assertRank2(a, b)\n    m  = a.shape[0]\n    n  = a.shape[1]\n    n_rhs = b.shape[1]\n    ldb = max(n, m)\n    if m != b.shape[0]:\n        raise LinAlgError(\'Incompatible dimensions\')\n    t, result_t = _commonType(a, b)\n    result_real_t = _realType(result_t)\n    real_t = _linalgRealType(t)\n    bstar = zeros((ldb, n_rhs), t)\n    bstar[:b.shape[0], :n_rhs] = b.copy()\n    a, bstar = _fastCopyAndTranspose(t, a, bstar)\n    a, bstar = _to_native_byte_order(a, bstar)\n    s = zeros((min(m, n),), real_t)\n    nlvl = max( 0, int( math.log( float(min(m, n))/2. ) ) + 1 )\n    iwork = zeros((3*min(m, n)*nlvl+11*min(m, n),), fortran_int)\n    if isComplexType(t):\n        lapack_routine = lapack_lite.zgelsd\n        lwork = 1\n        rwork = zeros((lwork,), real_t)\n        work = zeros((lwork,), t)\n        results = lapack_routine(m, n, n_rhs, a, m, bstar, ldb, s, rcond,\n                                 0, work, -1, rwork, iwork, 0)\n        lwork = int(abs(work[0]))\n        rwork = zeros((lwork,), real_t)\n        a_real = zeros((m, n), real_t)\n        bstar_real = zeros((ldb, n_rhs,), real_t)\n        results = lapack_lite.dgelsd(m, n, n_rhs, a_real, m,\n                                     bstar_real, ldb, s, rcond,\n                                     0, rwork, -1, iwork, 0)\n        lrwork = int(rwork[0])\n        work = zeros((lwork,), t)\n        rwork = zeros((lrwork,), real_t)\n        results = lapack_routine(m, n, n_rhs, a, m, bstar, ldb, s, rcond,\n                                 0, work, lwork, rwork, iwork, 0)\n    else:\n        lapack_routine = lapack_lite.dgelsd\n        lwork = 1\n        work = zeros((lwork,), t)\n        results = lapack_routine(m, n, n_rhs, a, m, bstar, ldb, s, rcond,\n                                 0, work, -1, iwork, 0)\n        lwork = int(work[0])\n        work = zeros((lwork,), t)\n        results = lapack_routine(m, n, n_rhs, a, m, bstar, ldb, s, rcond,\n                                 0, work, lwork, iwork, 0)\n    if results[\'info\'] > 0:\n        raise LinAlgError(\'SVD did not converge in Linear Least Squares\')\n    resids = array([], result_real_t)\n    if is_1d:\n        x = array(ravel(bstar)[:n], dtype=result_t, copy=True)\n        if results[\'rank\'] == n and m > n:\n            if isComplexType(t):\n                resids = array([sum(abs(ravel(bstar)[n:])**2)],\n                               dtype=result_real_t)\n            else:\n                resids = array([sum((ravel(bstar)[n:])**2)],\n                               dtype=result_real_t)\n    else:\n        x = array(transpose(bstar)[:n,:], dtype=result_t, copy=True)\n        if results[\'rank\'] == n and m > n:\n            if isComplexType(t):\n                resids = sum(abs(transpose(bstar)[n:,:])**2, axis=0).astype(\n                    result_real_t, copy=False)\n            else:\n                resids = sum((transpose(bstar)[n:,:])**2, axis=0).astype(\n                    result_real_t, copy=False)\n\n    st = s[:min(n, m)].astype(result_real_t, copy=True)\n    return wrap(x), wrap(resids), results[\'rank\'], st\n\n\ndef _multi_svd_norm(x, row_axis, col_axis, op):\n    \n    if row_axis > col_axis:\n        row_axis -= 1\n    y = rollaxis(rollaxis(x, col_axis, x.ndim), row_axis, -1)\n    result = op(svd(y, compute_uv=0), axis=-1)\n    return result\n\n\ndef norm(x, ord=None, axis=None, keepdims=False):\n    \n    x = asarray(x)\n\n        if axis is None:\n        ndim = x.ndim\n        if ((ord is None) or\n            (ord in (\'f\', \'fro\') and ndim == 2) or\n            (ord == 2 and ndim == 1)):\n\n            x = x.ravel(order=\'K\')\n            if isComplexType(x.dtype.type):\n                sqnorm = dot(x.real, x.real) + dot(x.imag, x.imag)\n            else:\n                sqnorm = dot(x, x)\n            ret = sqrt(sqnorm)\n            if keepdims:\n                ret = ret.reshape(ndim*[1])\n            return ret\n\n        nd = x.ndim\n    if axis is None:\n        axis = tuple(range(nd))\n    elif not isinstance(axis, tuple):\n        try:\n            axis = int(axis)\n        except:\n            raise TypeError("\'axis\' must be None, an integer or a tuple of integers")\n        axis = (axis,)\n\n    if len(axis) == 1:\n        if ord == Inf:\n            return abs(x).max(axis=axis, keepdims=keepdims)\n        elif ord == -Inf:\n            return abs(x).min(axis=axis, keepdims=keepdims)\n        elif ord == 0:\n                        return (x != 0).sum(axis=axis, keepdims=keepdims)\n        elif ord == 1:\n                        return add.reduce(abs(x), axis=axis, keepdims=keepdims)\n        elif ord is None or ord == 2:\n                        s = (x.conj() * x).real\n            return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n        else:\n            try:\n                ord + 1\n            except TypeError:\n                raise ValueError("Invalid norm order for vectors.")\n            if x.dtype.type is longdouble:\n                                                                absx = abs(x)\n            else:\n                absx = x if isComplexType(x.dtype.type) else asfarray(x)\n                if absx.dtype is x.dtype:\n                    absx = abs(absx)\n                else:\n                                        abs(absx, out=absx)\n            absx **= ord\n            return add.reduce(absx, axis=axis, keepdims=keepdims) ** (1.0 / ord)\n    elif len(axis) == 2:\n        row_axis, col_axis = axis\n        if row_axis < 0:\n            row_axis += nd\n        if col_axis < 0:\n            col_axis += nd\n        if not (0 <= row_axis < nd and 0 <= col_axis < nd):\n            raise ValueError(\'Invalid axis %r for an array with shape %r\' %\n                             (axis, x.shape))\n        if row_axis == col_axis:\n            raise ValueError(\'Duplicate axes given.\')\n        if ord == 2:\n            ret =  _multi_svd_norm(x, row_axis, col_axis, amax)\n        elif ord == -2:\n            ret = _multi_svd_norm(x, row_axis, col_axis, amin)\n        elif ord == 1:\n            if col_axis > row_axis:\n                col_axis -= 1\n            ret = add.reduce(abs(x), axis=row_axis).max(axis=col_axis)\n        elif ord == Inf:\n            if row_axis > col_axis:\n                row_axis -= 1\n            ret = add.reduce(abs(x), axis=col_axis).max(axis=row_axis)\n        elif ord == -1:\n            if col_axis > row_axis:\n                col_axis -= 1\n            ret = add.reduce(abs(x), axis=row_axis).min(axis=col_axis)\n        elif ord == -Inf:\n            if row_axis > col_axis:\n                row_axis -= 1\n            ret = add.reduce(abs(x), axis=col_axis).min(axis=row_axis)\n        elif ord in [None, \'fro\', \'f\']:\n            ret = sqrt(add.reduce((x.conj() * x).real, axis=axis))\n        elif ord == \'nuc\':\n            ret = _multi_svd_norm(x, row_axis, col_axis, sum)\n        else:\n            raise ValueError("Invalid norm order for matrices.")\n        if keepdims:\n            ret_shape = list(x.shape)\n            ret_shape[axis[0]] = 1\n            ret_shape[axis[1]] = 1\n            ret = ret.reshape(ret_shape)\n        return ret\n    else:\n        raise ValueError("Improper number of dimensions to norm.")\n\n\n\ndef multi_dot(arrays):\n    \n    n = len(arrays)\n        if n < 2:\n        raise ValueError("Expecting at least two arrays.")\n    elif n == 2:\n        return dot(arrays[0], arrays[1])\n\n    arrays = [asanyarray(a) for a in arrays]\n\n        ndim_first, ndim_last = arrays[0].ndim, arrays[-1].ndim\n            if arrays[0].ndim == 1:\n        arrays[0] = atleast_2d(arrays[0])\n    if arrays[-1].ndim == 1:\n        arrays[-1] = atleast_2d(arrays[-1]).T\n    _assertRank2(*arrays)\n\n        if n == 3:\n        result = _multi_dot_three(arrays[0], arrays[1], arrays[2])\n    else:\n        order = _multi_dot_matrix_chain_order(arrays)\n        result = _multi_dot(arrays, order, 0, n - 1)\n\n        if ndim_first == 1 and ndim_last == 1:\n        return result[0, 0]      elif ndim_first == 1 or ndim_last == 1:\n        return result.ravel()      else:\n        return result\n\n\ndef _multi_dot_three(A, B, C):\n    \n        cost1 = (A.shape[0] * A.shape[1] * B.shape[1] +               A.shape[0] * B.shape[1] * C.shape[1])           cost2 = (B.shape[0] * B.shape[1] * C.shape[1] +               A.shape[0] * A.shape[1] * C.shape[1])   \n    if cost1 < cost2:\n        return dot(dot(A, B), C)\n    else:\n        return dot(A, dot(B, C))\n\n\ndef _multi_dot_matrix_chain_order(arrays, return_costs=False):\n    \n    n = len(arrays)\n            p = [a.shape[0] for a in arrays] + [arrays[-1].shape[1]]\n            m = zeros((n, n), dtype=double)\n            s = empty((n, n), dtype=intp)\n\n    for l in range(1, n):\n        for i in range(n - l):\n            j = i + l\n            m[i, j] = Inf\n            for k in range(i, j):\n                q = m[i, k] + m[k+1, j] + p[i]*p[k+1]*p[j+1]\n                if q < m[i, j]:\n                    m[i, j] = q\n                    s[i, j] = k  \n    return (s, m) if return_costs else s\n\n\ndef _multi_dot(arrays, order, i, j):\n    \n    if i == j:\n        return arrays[i]\n    else:\n        return dot(_multi_dot(arrays, order, i, order[i, j]),\n                   _multi_dot(arrays, order, order[i, j] + 1, j))\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys, re, os\n\ndef dos2unix(file):\n    "Replace CRLF with LF in argument files.  Print names of changed files."\n    if os.path.isdir(file):\n        print(file, "Directory!")\n        return\n\n    data = open(file, "rb").read()\n    if \'\\0\' in data:\n        print(file, "Binary!")\n        return\n\n    newdata = re.sub("\\r\\n", "\\n", data)\n    if newdata != data:\n        print(\'dos2unix:\', file)\n        f = open(file, "wb")\n        f.write(newdata)\n        f.close()\n        return file\n    else:\n        print(file, \'ok\')\n\ndef dos2unix_one_dir(modified_files, dir_name, file_names):\n    for file in file_names:\n        full_path = os.path.join(dir_name, file)\n        file = dos2unix(full_path)\n        if file is not None:\n            modified_files.append(file)\n\ndef dos2unix_dir(dir_name):\n    modified_files = []\n    os.path.walk(dir_name, dos2unix_one_dir, modified_files)\n    return modified_files\n\ndef unix2dos(file):\n    "Replace LF with CRLF in argument files.  Print names of changed files."\n    if os.path.isdir(file):\n        print(file, "Directory!")\n        return\n\n    data = open(file, "rb").read()\n    if \'\\0\' in data:\n        print(file, "Binary!")\n        return\n    newdata = re.sub("\\r\\n", "\\n", data)\n    newdata = re.sub("\\n", "\\r\\n", newdata)\n    if newdata != data:\n        print(\'unix2dos:\', file)\n        f = open(file, "wb")\n        f.write(newdata)\n        f.close()\n        return file\n    else:\n        print(file, \'ok\')\n\ndef unix2dos_one_dir(modified_files, dir_name, file_names):\n    for file in file_names:\n        full_path = os.path.join(dir_name, file)\n        unix2dos(full_path)\n        if file is not None:\n            modified_files.append(file)\n\ndef unix2dos_dir(dir_name):\n    modified_files = []\n    os.path.walk(dir_name, unix2dos_one_dir, modified_files)\n    return modified_files\n\nif __name__ == "__main__":\n    dos2unix_dir(sys.argv[1])\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nfrom distutils.log import *\nfrom distutils.log import Log as old_Log\nfrom distutils.log import _global_log\n\nif sys.version_info[0] < 3:\n    from .misc_util import (red_text, default_text, cyan_text, green_text,\n            is_sequence, is_string)\nelse:\n    from numpy.distutils.misc_util import (red_text, default_text, cyan_text,\n            green_text, is_sequence, is_string)\n\n\ndef _fix_args(args,flag=1):\n    if is_string(args):\n        return args.replace(\'%\', \'%%\')\n    if flag and is_sequence(args):\n        return tuple([_fix_args(a, flag=0) for a in args])\n    return args\n\n\nclass Log(old_Log):\n    def _log(self, level, msg, args):\n        if level >= self.threshold:\n            if args:\n                msg = msg % _fix_args(args)\n            if 0:\n                if msg.startswith(\'copying \') and msg.find(\' -> \') != -1:\n                    return\n                if msg.startswith(\'byte-compiling \'):\n                    return\n            print(_global_color_map[level](msg))\n            sys.stdout.flush()\n\n    def good(self, msg, *args):\n        \n        if WARN >= self.threshold:\n            if args:\n                print(green_text(msg % _fix_args(args)))\n            else:\n                print(green_text(msg))\n            sys.stdout.flush()\n\n\n_global_log.__class__ = Log\n\ngood = _global_log.good\n\ndef set_threshold(level, force=False):\n    prev_level = _global_log.threshold\n    if prev_level > DEBUG or force:\n                        _global_log.threshold = level\n        if level <= DEBUG:\n            info(\'set_threshold: setting threshold to DEBUG level,\'\n                    \' it can be changed only with force argument\')\n    else:\n        info(\'set_threshold: not changing threshold from DEBUG level\'\n                \' %s to %s\' % (prev_level, level))\n    return prev_level\n\n\ndef set_verbosity(v, force=False):\n    prev_level = _global_log.threshold\n    if v < 0:\n        set_threshold(ERROR, force)\n    elif v == 0:\n        set_threshold(WARN, force)\n    elif v == 1:\n        set_threshold(INFO, force)\n    elif v >= 2:\n        set_threshold(DEBUG, force)\n    return {FATAL:-2,ERROR:-1,WARN:0,INFO:1,DEBUG:2}.get(prev_level, 1)\n\n\n_global_color_map = {\n    DEBUG:cyan_text,\n    INFO:default_text,\n    WARN:red_text,\n    ERROR:red_text,\n    FATAL:red_text\n}\n\nset_verbosity(0, force=True)\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'MachAr\']\n\nfrom numpy.core.fromnumeric import any\nfrom numpy.core.numeric import errstate\n\n\nclass MachAr(object):\n    \n\n    def __init__(self, float_conv=float,int_conv=int,\n                 float_to_float=float,\n                 float_to_str=lambda v:\'%24.16e\' % v,\n                 title=\'Python floating point number\'):\n        \n                        with errstate(under=\'ignore\'):\n            self._do_init(float_conv, int_conv, float_to_float, float_to_str, title)\n\n    def _do_init(self, float_conv, int_conv, float_to_float, float_to_str, title):\n        max_iterN = 10000\n        msg = "Did not converge after %d tries with %s"\n        one = float_conv(1)\n        two = one + one\n        zero = one - one\n\n                        a = one\n        for _ in range(max_iterN):\n            a = a + a\n            temp = a + one\n            temp1 = temp - a\n            if any(temp1 - one != zero):\n                break\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        b = one\n        for _ in range(max_iterN):\n            b = b + b\n            temp = a + b\n            itemp = int_conv(temp-a)\n            if any(itemp != 0):\n                break\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        ibeta = itemp\n        beta = float_conv(ibeta)\n\n                it = -1\n        b = one\n        for _ in range(max_iterN):\n            it = it + 1\n            b = b * beta\n            temp = b + one\n            temp1 = temp - b\n            if any(temp1 - one != zero):\n                break\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n\n        betah = beta / two\n        a = one\n        for _ in range(max_iterN):\n            a = a + a\n            temp = a + one\n            temp1 = temp - a\n            if any(temp1 - one != zero):\n                break\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        temp = a + betah\n        irnd = 0\n        if any(temp-a != zero):\n            irnd = 1\n        tempa = a + beta\n        temp = tempa + betah\n        if irnd == 0 and any(temp-tempa != zero):\n            irnd = 2\n\n                negep = it + 3\n        betain = one / beta\n        a = one\n        for i in range(negep):\n            a = a * betain\n        b = a\n        for _ in range(max_iterN):\n            temp = one - a\n            if any(temp-one != zero):\n                break\n            a = a * beta\n            negep = negep - 1\n                        if negep < 0:\n                raise RuntimeError("could not determine machine tolerance "\n                                   "for \'negep\', locals() -> %s" % (locals()))\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        negep = -negep\n        epsneg = a\n\n                machep = - it - 3\n        a = b\n\n        for _ in range(max_iterN):\n            temp = one + a\n            if any(temp-one != zero):\n                break\n            a = a * beta\n            machep = machep + 1\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        eps = a\n\n                ngrd = 0\n        temp = one + eps\n        if irnd == 0 and any(temp*one - one != zero):\n            ngrd = 1\n\n                i = 0\n        k = 1\n        z = betain\n        t = one + eps\n        nxres = 0\n        for _ in range(max_iterN):\n            y = z\n            z = y*y\n            a = z*one              temp = z*t\n            if any(a+a == zero) or any(abs(z) >= y):\n                break\n            temp1 = temp * betain\n            if any(temp1*beta == z):\n                break\n            i = i + 1\n            k = k + k\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        if ibeta != 10:\n            iexp = i + 1\n            mx = k + k\n        else:\n            iexp = 2\n            iz = ibeta\n            while k >= iz:\n                iz = iz * ibeta\n                iexp = iexp + 1\n            mx = iz + iz - 1\n\n                for _ in range(max_iterN):\n            xmin = y\n            y = y * betain\n            a = y * one\n            temp = y * t\n            if any((a + a) != zero) and any(abs(y) < xmin):\n                k = k + 1\n                temp1 = temp * betain\n                if any(temp1*beta == y) and any(temp != y):\n                    nxres = 3\n                    xmin = y\n                    break\n            else:\n                break\n        else:\n            raise RuntimeError(msg % (_, one.dtype))\n        minexp = -k\n\n                if mx <= k + k - 3 and ibeta != 10:\n            mx = mx + mx\n            iexp = iexp + 1\n        maxexp = mx + minexp\n        irnd = irnd + nxres\n        if irnd >= 2:\n            maxexp = maxexp - 2\n        i = maxexp + minexp\n        if ibeta == 2 and not i:\n            maxexp = maxexp - 1\n        if i > 20:\n            maxexp = maxexp - 1\n        if any(a != y):\n            maxexp = maxexp - 2\n        xmax = one - epsneg\n        if any(xmax*one != xmax):\n            xmax = one - beta*epsneg\n        xmax = xmax / (xmin*beta*beta*beta)\n        i = maxexp + minexp + 3\n        for j in range(i):\n            if ibeta == 2:\n                xmax = xmax + xmax\n            else:\n                xmax = xmax * beta\n\n        self.ibeta = ibeta\n        self.it = it\n        self.negep = negep\n        self.epsneg = float_to_float(epsneg)\n        self._str_epsneg = float_to_str(epsneg)\n        self.machep = machep\n        self.eps = float_to_float(eps)\n        self._str_eps = float_to_str(eps)\n        self.ngrd = ngrd\n        self.iexp = iexp\n        self.minexp = minexp\n        self.xmin = float_to_float(xmin)\n        self._str_xmin = float_to_str(xmin)\n        self.maxexp = maxexp\n        self.xmax = float_to_float(xmax)\n        self._str_xmax = float_to_str(xmax)\n        self.irnd = irnd\n\n        self.title = title\n                self.epsilon = self.eps\n        self.tiny = self.xmin\n        self.huge = self.xmax\n\n        import math\n        self.precision = int(-math.log10(float_to_float(self.eps)))\n        ten = two + two + two + two + two\n        resolution = ten ** (-self.precision)\n        self.resolution = float_to_float(resolution)\n        self._str_resolution = float_to_str(resolution)\n\n    def __str__(self):\n        fmt = (\n           \'Machine parameters for %(title)s\\n\'\n           \'---------------------------------------------------------------------\\n\'\n           \'ibeta=%(ibeta)s it=%(it)s iexp=%(iexp)s ngrd=%(ngrd)s irnd=%(irnd)s\\n\'\n           \'machep=%(machep)s     eps=%(_str_eps)s (beta**machep == epsilon)\\n\'\n           \'negep =%(negep)s  epsneg=%(_str_epsneg)s (beta**epsneg)\\n\'\n           \'minexp=%(minexp)s   xmin=%(_str_xmin)s (beta**minexp == tiny)\\n\'\n           \'maxexp=%(maxexp)s    xmax=%(_str_xmax)s ((1-epsneg)*beta**maxexp == huge)\\n\'\n           \'---------------------------------------------------------------------\\n\'\n           )\n        return fmt % self.__dict__\n\n\nif __name__ == \'__main__\':\n    print(MachAr())\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\nfrom numpy.matrixlib.defmatrix import matrix, asmatrix\nfrom numpy import *\n\n__version__ = np.__version__\n\n__all__ = np.__all__[:] __all__ += [\'rand\', \'randn\', \'repmat\']\n\ndef empty(shape, dtype=None, order=\'C\'):\n    \n    return ndarray.__new__(matrix, shape, dtype, order=order)\n\ndef ones(shape, dtype=None, order=\'C\'):\n    \n    a = ndarray.__new__(matrix, shape, dtype, order=order)\n    a.fill(1)\n    return a\n\ndef zeros(shape, dtype=None, order=\'C\'):\n    \n    a = ndarray.__new__(matrix, shape, dtype, order=order)\n    a.fill(0)\n    return a\n\ndef identity(n,dtype=None):\n    \n    a = array([1]+n*[0], dtype=dtype)\n    b = empty((n, n), dtype=dtype)\n    b.flat = a\n    return b\n\ndef eye(n,M=None, k=0, dtype=float):\n    \n    return asmatrix(np.eye(n, M, k, dtype))\n\ndef rand(*args):\n    \n    if isinstance(args[0], tuple):\n        args = args[0]\n    return asmatrix(np.random.rand(*args))\n\ndef randn(*args):\n    \n    if isinstance(args[0], tuple):\n        args = args[0]\n    return asmatrix(np.random.randn(*args))\n\ndef repmat(a, m, n):\n    \n    a = asanyarray(a)\n    ndim = a.ndim\n    if ndim == 0:\n        origrows, origcols = (1, 1)\n    elif ndim == 1:\n        origrows, origcols = (1, a.shape[0])\n    else:\n        origrows, origcols = a.shape\n    rows = origrows * m\n    cols = origcols * n\n    c = a.reshape(1, a.size).repeat(m, 0).reshape(rows, origcols).repeat(n, 0)\n    return c.reshape(rows, cols)\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\nfrom .numeric import uint8, ndarray, dtype\nfrom numpy.compat import long, basestring\n\n__all__ = [\'memmap\']\n\ndtypedescr = dtype\nvalid_filemodes = ["r", "c", "r+", "w+"]\nwriteable_filemodes = ["r+", "w+"]\n\nmode_equivalents = {\n    "readonly":"r",\n    "copyonwrite":"c",\n    "readwrite":"r+",\n    "write":"w+"\n    }\n\nclass memmap(ndarray):\n    \n\n    __array_priority__ = -100.0\n\n    def __new__(subtype, filename, dtype=uint8, mode=\'r+\', offset=0,\n                shape=None, order=\'C\'):\n                import mmap\n        import os.path\n        try:\n            mode = mode_equivalents[mode]\n        except KeyError:\n            if mode not in valid_filemodes:\n                raise ValueError("mode must be one of %s" %\n                                 (valid_filemodes + list(mode_equivalents.keys())))\n\n        if hasattr(filename, \'read\'):\n            fid = filename\n            own_file = False\n        else:\n            fid = open(filename, (mode == \'c\' and \'r\' or mode)+\'b\')\n            own_file = True\n\n        if (mode == \'w+\') and shape is None:\n            raise ValueError("shape must be given")\n\n        fid.seek(0, 2)\n        flen = fid.tell()\n        descr = dtypedescr(dtype)\n        _dbytes = descr.itemsize\n\n        if shape is None:\n            bytes = flen - offset\n            if (bytes % _dbytes):\n                fid.close()\n                raise ValueError("Size of available data is not a "\n                        "multiple of the data-type size.")\n            size = bytes // _dbytes\n            shape = (size,)\n        else:\n            if not isinstance(shape, tuple):\n                shape = (shape,)\n            size = 1\n            for k in shape:\n                size *= k\n\n        bytes = long(offset + size*_dbytes)\n\n        if mode == \'w+\' or (mode == \'r+\' and flen < bytes):\n            fid.seek(bytes - 1, 0)\n            fid.write(np.compat.asbytes(\'\\0\'))\n            fid.flush()\n\n        if mode == \'c\':\n            acc = mmap.ACCESS_COPY\n        elif mode == \'r\':\n            acc = mmap.ACCESS_READ\n        else:\n            acc = mmap.ACCESS_WRITE\n\n        start = offset - offset % mmap.ALLOCATIONGRANULARITY\n        bytes -= start\n        offset -= start\n        mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)\n\n        self = ndarray.__new__(subtype, shape, dtype=descr, buffer=mm,\n            offset=offset, order=order)\n        self._mmap = mm\n        self.offset = offset\n        self.mode = mode\n\n        if isinstance(filename, basestring):\n            self.filename = os.path.abspath(filename)\n                elif (hasattr(filename, "name") and\n              isinstance(filename.name, basestring)):\n            self.filename = os.path.abspath(filename.name)\n                else:\n            self.filename = None\n\n        if own_file:\n            fid.close()\n\n        return self\n\n    def __array_finalize__(self, obj):\n        if hasattr(obj, \'_mmap\') and np.may_share_memory(self, obj):\n            self._mmap = obj._mmap\n            self.filename = obj.filename\n            self.offset = obj.offset\n            self.mode = obj.mode\n        else:\n            self._mmap = None\n            self.filename = None\n            self.offset = None\n            self.mode = None\n\n    def flush(self):\n        \n        if self.base is not None and hasattr(self.base, \'flush\'):\n            self.base.flush()\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport sys\nimport subprocess\nimport re\n\nimport numpy.distutils.ccompiler\n\nif sys.version_info[0] < 3:\n    from . import log\nelse:\n    from numpy.distutils import log\n\nimport distutils.cygwinccompiler\nfrom distutils.version import StrictVersion\nfrom numpy.distutils.ccompiler import gen_preprocess_options, gen_lib_options\nfrom distutils.unixccompiler import UnixCCompiler\nfrom distutils.msvccompiler import get_build_version as get_build_msvc_version\nfrom distutils.errors import (DistutilsExecError, CompileError,\n                              UnknownFileError)\nfrom numpy.distutils.misc_util import (msvc_runtime_library,\n                                       get_build_architecture)\n\n_START = re.compile(r\'\\[Ordinal/Name Pointer\\] Table\')\n_TABLE = re.compile(r\'^\\s+\\[([\\s*[0-9]*)\\] ([a-zA-Z0-9_]*)\')\n\nclass Mingw32CCompiler(distutils.cygwinccompiler.CygwinCCompiler):\n    \n\n    compiler_type = \'mingw32\'\n\n    def __init__ (self,\n                  verbose=0,\n                  dry_run=0,\n                  force=0):\n\n        distutils.cygwinccompiler.CygwinCCompiler.__init__ (self, verbose,\n                                                            dry_run, force)\n\n                        if self.gcc_version is None:\n            import re\n            p = subprocess.Popen([\'gcc\', \'-dumpversion\'], shell=True,\n                                 stdout=subprocess.PIPE)\n            out_string = p.stdout.read()\n            p.stdout.close()\n            result = re.search(\'(\\d+\\.\\d+)\', out_string)\n            if result:\n                self.gcc_version = StrictVersion(result.group(1))\n\n                        if self.gcc_version <= "2.91.57":\n            entry_point = \'--entry _DllMain@12\'\n        else:\n            entry_point = \'\'\n\n        if self.linker_dll == \'dllwrap\':\n                                                                                    self.linker = \'dllwrap\'         elif self.linker_dll == \'gcc\':\n            self.linker = \'g++\'\n\n        p = subprocess.Popen([\'gcc\', \'--version\'], shell=True,\n                             stdout=subprocess.PIPE)\n        out_string = p.stdout.read()\n        p.stdout.close()\n\n                                        \n        if \'MinGW-W64\' not in str(out_string) and \'mingwpy\' not in str(out_string):\n\n                                                build_import_library()\n\n                                    msvcr_success = build_msvcr_library()\n            msvcr_dbg_success = build_msvcr_library(debug=True)\n            if msvcr_success or msvcr_dbg_success:\n                                self.define_macro(\'NPY_MINGW_USE_CUSTOM_MSVCR\')\n\n                msvcr_version = \'0x%03i0\' % int(msvc_runtime_library().lstrip(\'msvcr\'))\n        self.define_macro(\'__MSVCRT_VERSION__\', msvcr_version)\n\n                                        if get_build_architecture() == \'AMD64\':\n            if self.gcc_version < "4.0":\n                self.set_executables(\n                    compiler=\'gcc -g -DDEBUG -DMS_WIN64 -mno-cygwin -O0 -Wall\',\n                    compiler_so=\'gcc -g -DDEBUG -DMS_WIN64 -mno-cygwin -O0\'\n                                \' -Wall -Wstrict-prototypes\',\n                    linker_exe=\'gcc -g -mno-cygwin\',\n                    linker_so=\'gcc -g -mno-cygwin -shared\')\n            else:\n                                self.set_executables(\n                    compiler=\'gcc -O2 -march=x86-64 -mtune=generic -DMS_WIN64\'\n                             \' -msse2 -mlong-double-64 -Wall\',\n                    compiler_so=\'gcc -O2 -march=x86-64 -mtune=generic -DMS_WIN64\'\n                                \' -msse2 -mlong-double-64 -Wall -Wstrict-prototypes\',\n                    linker_exe=\'gcc\',\n                    linker_so=\'gcc -shared -Wl,-gc-sections -Wl,-s\')\n        else:\n            if self.gcc_version <= "3.0.0":\n                self.set_executables(\n                    compiler=\'gcc -mno-cygwin -O2 -w\',\n                    compiler_so=\'gcc -mno-cygwin -mdll -O2 -w\'\n                                \' -Wstrict-prototypes\',\n                    linker_exe=\'g++ -mno-cygwin\',\n                    linker_so=\'%s -mno-cygwin -mdll -static %s\' %\n                              (self.linker, entry_point))\n            elif self.gcc_version < "4.0":\n                self.set_executables(\n                    compiler=\'gcc -mno-cygwin -O2 -Wall\',\n                    compiler_so=\'gcc -mno-cygwin -O2 -Wall\'\n                                \' -Wstrict-prototypes\',\n                    linker_exe=\'g++ -mno-cygwin\',\n                    linker_so=\'g++ -mno-cygwin -shared\')\n            else:\n                                                                self.set_executables(\n                    compiler=\'gcc -O2 -march=pentium4 -mtune=generic\'\n                             \' -mfpmath=sse -msse2 -mlong-double-64\'\n                             \' -mincoming-stack-boundary=2 -Wall\',\n                    compiler_so=\'gcc -O2 -march=pentium4 -mtune=generic\'\n                                \' -mfpmath=sse -msse2 -mlong-double-64\'\n                                \' -mincoming-stack-boundary=2 -Wall\'\n                                \' -Wstrict-prototypes\',\n                    linker_exe=\'g++ \',\n                    linker_so=\'g++ -shared -Wl,-gc-sections -Wl,-s\')\n                        self.compiler_cxx = [\'g++\']\n\n                        \n                        return\n\n    \n    def link(self,\n             target_desc,\n             objects,\n             output_filename,\n             output_dir,\n             libraries,\n             library_dirs,\n             runtime_library_dirs,\n             export_symbols = None,\n             debug=0,\n             extra_preargs=None,\n             extra_postargs=None,\n             build_temp=None,\n             target_lang=None):\n                        runtime_library = msvc_runtime_library()\n        if runtime_library:\n            if not libraries:\n                libraries = []\n            libraries.append(runtime_library)\n        args = (self,\n                target_desc,\n                objects,\n                output_filename,\n                output_dir,\n                libraries,\n                library_dirs,\n                runtime_library_dirs,\n                None,                 debug,\n                extra_preargs,\n                extra_postargs,\n                build_temp,\n                target_lang)\n        if self.gcc_version < "3.0.0":\n            func = distutils.cygwinccompiler.CygwinCCompiler.link\n        else:\n            func = UnixCCompiler.link\n        func(*args[:func.__code__.co_argcount])\n        return\n\n    def object_filenames (self,\n                          source_filenames,\n                          strip_dir=0,\n                          output_dir=\'\'):\n        if output_dir is None: output_dir = \'\'\n        obj_names = []\n        for src_name in source_filenames:\n                        (base, ext) = os.path.splitext (os.path.normcase(src_name))\n\n                                                drv, base = os.path.splitdrive(base)\n            if drv:\n                base = base[1:]\n\n            if ext not in (self.src_extensions + [\'.rc\', \'.res\']):\n                raise UnknownFileError(\n                      "unknown file type \'%s\' (from \'%s\')" % \\\n                      (ext, src_name))\n            if strip_dir:\n                base = os.path.basename (base)\n            if ext == \'.res\' or ext == \'.rc\':\n                                obj_names.append (os.path.join (output_dir,\n                                                base + ext + self.obj_extension))\n            else:\n                obj_names.append (os.path.join (output_dir,\n                                                base + self.obj_extension))\n        return obj_names\n\n    \n\ndef find_python_dll():\n    maj, min, micro = [int(i) for i in sys.version_info[:3]]\n    dllname = \'python%d%d.dll\' % (maj, min)\n    print("Looking for %s" % dllname)\n\n                    lib_dirs = []\n    lib_dirs.append(sys.prefix)\n    lib_dirs.append(os.path.join(sys.prefix, \'lib\'))\n    try:\n        lib_dirs.append(os.path.join(os.environ[\'SYSTEMROOT\'], \'system32\'))\n    except KeyError:\n        pass\n\n    for d in lib_dirs:\n        dll = os.path.join(d, dllname)\n        if os.path.exists(dll):\n            return dll\n\n    raise ValueError("%s not found in %s" % (dllname, lib_dirs))\n\ndef dump_table(dll):\n    st = subprocess.Popen(["objdump.exe", "-p", dll], stdout=subprocess.PIPE)\n    return st.stdout.readlines()\n\ndef generate_def(dll, dfile):\n    \n    dump = dump_table(dll)\n    for i in range(len(dump)):\n        if _START.match(dump[i].decode()):\n            break\n    else:\n        raise ValueError("Symbol table not found")\n\n    syms = []\n    for j in range(i+1, len(dump)):\n        m = _TABLE.match(dump[j].decode())\n        if m:\n            syms.append((int(m.group(1).strip()), m.group(2)))\n        else:\n            break\n\n    if len(syms) == 0:\n        log.warn(\'No symbols found in %s\' % dll)\n\n    d = open(dfile, \'w\')\n    d.write(\'LIBRARY        %s\\n\' % os.path.basename(dll))\n    d.write(\';CODE          PRELOAD MOVEABLE DISCARDABLE\\n\')\n    d.write(\';DATA          PRELOAD SINGLE\\n\')\n    d.write(\'\\nEXPORTS\\n\')\n    for s in syms:\n                d.write(\'%s\\n\' % s[1])\n    d.close()\n\ndef find_dll(dll_name):\n\n    arch = {\'AMD64\' : \'amd64\',\n            \'Intel\' : \'x86\'}[get_build_architecture()]\n\n    def _find_dll_in_winsxs(dll_name):\n                winsxs_path = os.path.join(os.environ[\'WINDIR\'], \'winsxs\')\n        if not os.path.exists(winsxs_path):\n            return None\n        for root, dirs, files in os.walk(winsxs_path):\n            if dll_name in files and arch in root:\n                return os.path.join(root, dll_name)\n        return None\n\n    def _find_dll_in_path(dll_name):\n                        for path in [sys.prefix] + os.environ[\'PATH\'].split(\';\'):\n            filepath = os.path.join(path, dll_name)\n            if os.path.exists(filepath):\n                return os.path.abspath(filepath)\n\n    return _find_dll_in_winsxs(dll_name) or _find_dll_in_path(dll_name)\n\ndef build_msvcr_library(debug=False):\n    if os.name != \'nt\':\n        return False\n\n    msvcr_name = msvc_runtime_library()\n\n        if int(msvcr_name.lstrip(\'msvcr\')) < 80:\n        log.debug(\'Skip building msvcr library:\'\n                  \' custom functionality not present\')\n        return False\n\n    if debug:\n        msvcr_name += \'d\'\n\n        out_name = "lib%s.a" % msvcr_name\n    out_file = os.path.join(sys.prefix, \'libs\', out_name)\n    if os.path.isfile(out_file):\n        log.debug(\'Skip building msvcr library: "%s" exists\' %\n                  (out_file,))\n        return True\n\n        msvcr_dll_name = msvcr_name + \'.dll\'\n    dll_file = find_dll(msvcr_dll_name)\n    if not dll_file:\n        log.warn(\'Cannot build msvcr library: "%s" not found\' %\n                 msvcr_dll_name)\n        return False\n\n    def_name = "lib%s.def" % msvcr_name\n    def_file = os.path.join(sys.prefix, \'libs\', def_name)\n\n    log.info(\'Building msvcr library: "%s" (from %s)\' \\\n             % (out_file, dll_file))\n\n        generate_def(dll_file, def_file)\n\n        cmd = [\'dlltool\', \'-d\', def_file, \'-l\', out_file]\n    retcode = subprocess.call(cmd)\n\n        os.remove(def_file)\n\n    return (not retcode)\n\ndef build_import_library():\n    if os.name != \'nt\':\n        return\n\n    arch = get_build_architecture()\n    if arch == \'AMD64\':\n        return _build_import_library_amd64()\n    elif arch == \'Intel\':\n        return _build_import_library_x86()\n    else:\n        raise ValueError("Unhandled arch %s" % arch)\n\ndef _build_import_library_amd64():\n    dll_file = find_python_dll()\n\n    out_name = "libpython%d%d.a" % tuple(sys.version_info[:2])\n    out_file = os.path.join(sys.prefix, \'libs\', out_name)\n    if os.path.isfile(out_file):\n        log.debug(\'Skip building import library: "%s" exists\' %\n                  (out_file))\n        return\n\n    def_name = "python%d%d.def" % tuple(sys.version_info[:2])\n    def_file = os.path.join(sys.prefix, \'libs\', def_name)\n\n    log.info(\'Building import library (arch=AMD64): "%s" (from %s)\' %\n             (out_file, dll_file))\n\n    generate_def(dll_file, def_file)\n\n    cmd = [\'dlltool\', \'-d\', def_file, \'-l\', out_file]\n    subprocess.Popen(cmd)\n\ndef _build_import_library_x86():\n    \n    lib_name = "python%d%d.lib" % tuple(sys.version_info[:2])\n    lib_file = os.path.join(sys.prefix, \'libs\', lib_name)\n    out_name = "libpython%d%d.a" % tuple(sys.version_info[:2])\n    out_file = os.path.join(sys.prefix, \'libs\', out_name)\n    if not os.path.isfile(lib_file):\n        log.warn(\'Cannot build import library: "%s" not found\' % (lib_file))\n        return\n    if os.path.isfile(out_file):\n        log.debug(\'Skip building import library: "%s" exists\' % (out_file))\n        return\n    log.info(\'Building import library (ARCH=x86): "%s"\' % (out_file))\n\n    from numpy.distutils import lib2def\n\n    def_name = "python%d%d.def" % tuple(sys.version_info[:2])\n    def_file = os.path.join(sys.prefix, \'libs\', def_name)\n    nm_cmd = \'%s %s\' % (lib2def.DEFAULT_NM, lib_file)\n    nm_output = lib2def.getnm(nm_cmd)\n    dlist, flist = lib2def.parse_nm(nm_output)\n    lib2def.output_def(dlist, flist, lib2def.DEF_HEADER, open(def_file, \'w\'))\n\n    dll_name = "python%d%d.dll" % tuple(sys.version_info[:2])\n    args = (dll_name, def_file, out_file)\n    cmd = \'dlltool --dllname %s --def %s --output-lib %s\' % args\n    status = os.system(cmd)\n        if status:\n        log.warn(\'Failed to build import library for gcc. Linking will fail.\')\n    return\n\n\n\n_MSVCRVER_TO_FULLVER = {}\nif sys.platform == \'win32\':\n    try:\n        import msvcrt\n                        _MSVCRVER_TO_FULLVER[\'80\'] = "8.0.50727.42"\n        _MSVCRVER_TO_FULLVER[\'90\'] = "9.0.21022.8"\n                        _MSVCRVER_TO_FULLVER[\'100\'] = "10.0.30319.460"\n        if hasattr(msvcrt, "CRT_ASSEMBLY_VERSION"):\n            major, minor, rest = msvcrt.CRT_ASSEMBLY_VERSION.split(".", 2)\n            _MSVCRVER_TO_FULLVER[major + minor] = msvcrt.CRT_ASSEMBLY_VERSION\n            del major, minor, rest\n    except ImportError:\n                                log.warn(\'Cannot import msvcrt: using manifest will not be possible\')\n\ndef msvc_manifest_xml(maj, min):\n    \n    try:\n        fullver = _MSVCRVER_TO_FULLVER[str(maj * 10 + min)]\n    except KeyError:\n        raise ValueError("Version %d,%d of MSVCRT not supported yet" %\n                         (maj, min))\n                            template = \n\n    return template % {\'fullver\': fullver, \'maj\': maj, \'min\': min}\n\ndef manifest_rc(name, type=\'dll\'):\n    \n    if type == \'dll\':\n        rctype = 2\n    elif type == \'exe\':\n        rctype = 1\n    else:\n        raise ValueError("Type %s not supported" % type)\n\n    return  % (rctype, name)\n\ndef check_embedded_msvcr_match_linked(msver):\n    \n            msvcv = msvc_runtime_library()\n    if msvcv:\n        assert msvcv.startswith("msvcr"), msvcv\n                        maj = int(msvcv[5:-1])\n        if not maj == int(msver):\n            raise ValueError(\n                  "Discrepancy between linked msvcr " \\\n                  "(%d) and the one about to be embedded " \\\n                  "(%d)" % (int(msver), maj))\n\ndef configtest_name(config):\n    base = os.path.basename(config._gen_temp_sourcefile("yo", [], "c"))\n    return os.path.splitext(base)[0]\n\ndef manifest_name(config):\n        root = configtest_name(config)\n    exext = config.compiler.exe_extension\n    return root + exext + ".manifest"\n\ndef rc_name(config):\n        root = configtest_name(config)\n    return root + ".rc"\n\ndef generate_manifest(config):\n    msver = get_build_msvc_version()\n    if msver is not None:\n        if msver >= 8:\n            check_embedded_msvcr_match_linked(msver)\n            ma = int(msver)\n            mi = int((msver - ma) * 10)\n                        manxml = msvc_manifest_xml(ma, mi)\n            man = open(manifest_name(config), "w")\n            config.temp_files.append(manifest_name(config))\n            man.write(manxml)\n            man.close()\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.cpuinfo import cpu\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'MIPSFCompiler\']\n\nclass MIPSFCompiler(FCompiler):\n\n    compiler_type = \'mips\'\n    description = \'MIPSpro Fortran Compiler\'\n    version_pattern =  r\'MIPSpro Compilers: Version (?P<version>[^\\s*,]*)\'\n\n    executables = {\n        \'version_cmd\'  : ["<F90>", "-version"],\n        \'compiler_f77\' : ["f77", "-f77"],\n        \'compiler_fix\' : ["f90", "-fixedform"],\n        \'compiler_f90\' : ["f90"],\n        \'linker_so\'    : ["f90", "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : None\n        }\n    module_dir_switch = None     module_include_switch = None     pic_flags = [\'-KPIC\']\n\n    def get_flags(self):\n        return self.pic_flags + [\'-n32\']\n    def get_flags_opt(self):\n        return [\'-O3\']\n    def get_flags_arch(self):\n        opt = []\n        for a in \'19 20 21 22_4k 22_5k 24 25 26 27 28 30 32_5k 32_10k\'.split():\n            if getattr(cpu, \'is_IP%s\'%a)():\n                opt.append(\'-TARG:platform=IP%s\' % a)\n                break\n        return opt\n    def get_flags_arch_f77(self):\n        r = None\n        if cpu.is_r10000(): r = 10000\n        elif cpu.is_r12000(): r = 12000\n        elif cpu.is_r8000(): r = 8000\n        elif cpu.is_r5000(): r = 5000\n        elif cpu.is_r4000(): r = 4000\n        if r is not None:\n            return [\'r%s\' % (r)]\n        return []\n    def get_flags_arch_f90(self):\n        r = self.get_flags_arch_f77()\n        if r:\n            r[0] = \'-\' + r[0]\n        return r\n\nif __name__ == \'__main__\':\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'mips\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport re\nimport sys\nimport imp\nimport copy\nimport glob\nimport atexit\nimport tempfile\nimport subprocess\nimport shutil\n\nimport distutils\nfrom distutils.errors import DistutilsError\ntry:\n    from threading import local as tlocal\nexcept ImportError:\n    from dummy_threading import local as tlocal\n\ntry:\n    set\nexcept NameError:\n    from sets import Set as set\n\nfrom numpy.distutils.compat import get_exception\n\n__all__ = [\'Configuration\', \'get_numpy_include_dirs\', \'default_config_dict\',\n           \'dict_append\', \'appendpath\', \'generate_config_py\',\n           \'get_cmd\', \'allpath\', \'get_mathlibs\',\n           \'terminal_has_colors\', \'red_text\', \'green_text\', \'yellow_text\',\n           \'blue_text\', \'cyan_text\', \'cyg2win32\', \'mingw32\', \'all_strings\',\n           \'has_f_sources\', \'has_cxx_sources\', \'filter_sources\',\n           \'get_dependencies\', \'is_local_src_dir\', \'get_ext_source_files\',\n           \'get_script_files\', \'get_lib_source_files\', \'get_data_files\',\n           \'dot_join\', \'get_frame\', \'minrelpath\', \'njoin\',\n           \'is_sequence\', \'is_string\', \'as_list\', \'gpaths\', \'get_language\',\n           \'quote_args\', \'get_build_architecture\', \'get_info\', \'get_pkg_info\',\n           \'get_num_build_jobs\']\n\nclass InstallableLib(object):\n    \n    def __init__(self, name, build_info, target_dir):\n        self.name = name\n        self.build_info = build_info\n        self.target_dir = target_dir\n\n\ndef get_num_build_jobs():\n    \n    from numpy.distutils.core import get_distribution\n    envjobs = int(os.environ.get("NPY_NUM_BUILD_JOBS", 1))\n    dist = get_distribution()\n        if dist is None:\n        return envjobs\n\n        cmdattr = (getattr(dist.get_command_obj(\'build\'), \'parallel\', None),\n               getattr(dist.get_command_obj(\'build_ext\'), \'parallel\', None),\n               getattr(dist.get_command_obj(\'build_clib\'), \'parallel\', None))\n    if all(x is None for x in cmdattr):\n        return envjobs\n    else:\n        return max(x for x in cmdattr if x is not None)\n\ndef quote_args(args):\n            args = list(args)\n    for i in range(len(args)):\n        a = args[i]\n        if \' \' in a and a[0] not in \'"\\\'\':\n            args[i] = \'"%s"\' % (a)\n    return args\n\ndef allpath(name):\n    "Convert a /-separated pathname to one using the OS\'s path separator."\n    splitted = name.split(\'/\')\n    return os.path.join(*splitted)\n\ndef rel_path(path, parent_path):\n    \n    pd = os.path.abspath(parent_path)\n    apath = os.path.abspath(path)\n    if len(apath)<len(pd):\n        return path\n    if apath==pd:\n        return \'\'\n    if pd == apath[:len(pd)]:\n        assert apath[len(pd)] in [os.sep], repr((path, apath[len(pd)]))\n        path = apath[len(pd)+1:]\n    return path\n\ndef get_path_from_frame(frame, parent_path=None):\n    \n\n        try:\n        caller_file = eval(\'__file__\', frame.f_globals, frame.f_locals)\n        d = os.path.dirname(os.path.abspath(caller_file))\n    except NameError:\n                                caller_name = eval(\'__name__\', frame.f_globals, frame.f_locals)\n        __import__(caller_name)\n        mod = sys.modules[caller_name]\n        if hasattr(mod, \'__file__\'):\n            d = os.path.dirname(os.path.abspath(mod.__file__))\n        else:\n                                    d = os.path.abspath(\'.\')\n            \n    if parent_path is not None:\n        d = rel_path(d, parent_path)\n\n    return d or \'.\'\n\ndef njoin(*path):\n    \n    paths = []\n    for p in path:\n        if is_sequence(p):\n                        paths.append(njoin(*p))\n        else:\n            assert is_string(p)\n            paths.append(p)\n    path = paths\n    if not path:\n                joined = \'\'\n    else:\n                joined = os.path.join(*path)\n    if os.path.sep != \'/\':\n        joined = joined.replace(\'/\', os.path.sep)\n    return minrelpath(joined)\n\ndef get_mathlibs(path=None):\n    \n    if path is not None:\n        config_file = os.path.join(path, \'_numpyconfig.h\')\n    else:\n                dirs = get_numpy_include_dirs()\n        for path in dirs:\n            fn = os.path.join(path, \'_numpyconfig.h\')\n            if os.path.exists(fn):\n                config_file = fn\n                break\n        else:\n            raise DistutilsError(\'_numpyconfig.h not found in numpy include \'\n                \'dirs %r\' % (dirs,))\n\n    fid = open(config_file)\n    mathlibs = []\n    s = \'    for line in fid:\n        if line.startswith(s):\n            value = line[len(s):].strip()\n            if value:\n                mathlibs.extend(value.split(\',\'))\n    fid.close()\n    return mathlibs\n\ndef minrelpath(path):\n    \n    if not is_string(path):\n        return path\n    if \'.\' not in path:\n        return path\n    l = path.split(os.sep)\n    while l:\n        try:\n            i = l.index(\'.\', 1)\n        except ValueError:\n            break\n        del l[i]\n    j = 1\n    while l:\n        try:\n            i = l.index(\'..\', j)\n        except ValueError:\n            break\n        if l[i-1]==\'..\':\n            j += 1\n        else:\n            del l[i], l[i-1]\n            j = 1\n    if not l:\n        return \'\'\n    return os.sep.join(l)\n\ndef _fix_paths(paths, local_path, include_non_existing):\n    assert is_sequence(paths), repr(type(paths))\n    new_paths = []\n    assert not is_string(paths), repr(paths)\n    for n in paths:\n        if is_string(n):\n            if \'*\' in n or \'?\' in n:\n                p = glob.glob(n)\n                p2 = glob.glob(njoin(local_path, n))\n                if p2:\n                    new_paths.extend(p2)\n                elif p:\n                    new_paths.extend(p)\n                else:\n                    if include_non_existing:\n                        new_paths.append(n)\n                    print(\'could not resolve pattern in %r: %r\' %\n                            (local_path, n))\n            else:\n                n2 = njoin(local_path, n)\n                if os.path.exists(n2):\n                    new_paths.append(n2)\n                else:\n                    if os.path.exists(n):\n                        new_paths.append(n)\n                    elif include_non_existing:\n                        new_paths.append(n)\n                    if not os.path.exists(n):\n                        print(\'non-existing path in %r: %r\' %\n                                (local_path, n))\n\n        elif is_sequence(n):\n            new_paths.extend(_fix_paths(n, local_path, include_non_existing))\n        else:\n            new_paths.append(n)\n    return [minrelpath(p) for p in new_paths]\n\ndef gpaths(paths, local_path=\'\', include_non_existing=True):\n    \n    if is_string(paths):\n        paths = (paths,)\n    return _fix_paths(paths, local_path, include_non_existing)\n\n\ndef clean_up_temporary_directory():\n    tdata = tlocal()\n    _temporary_directory = getattr(tdata, \'tempdir\', None)\n    if not _temporary_directory:\n        return\n    try:\n        shutil.rmtree(_temporary_directory)\n    except OSError:\n        pass\n    _temporary_directory = None\n\ndef make_temp_file(suffix=\'\', prefix=\'\', text=True):\n    tdata = tlocal()\n    if not hasattr(tdata, \'tempdir\'):\n        tdata.tempdir = tempfile.mkdtemp()\n        atexit.register(clean_up_temporary_directory)\n    fid, name = tempfile.mkstemp(suffix=suffix,\n                                 prefix=prefix,\n                                 dir=tdata.tempdir,\n                                 text=text)\n    fo = os.fdopen(fid, \'w\')\n    return fo, name\n\ndef terminal_has_colors():\n    if sys.platform==\'cygwin\' and \'USE_COLOR\' not in os.environ:\n                                                                        return 0\n    if hasattr(sys.stdout, \'isatty\') and sys.stdout.isatty():\n        try:\n            import curses\n            curses.setupterm()\n            if (curses.tigetnum("colors") >= 0\n                and curses.tigetnum("pairs") >= 0\n                and ((curses.tigetstr("setf") is not None\n                      and curses.tigetstr("setb") is not None)\n                     or (curses.tigetstr("setaf") is not None\n                         and curses.tigetstr("setab") is not None)\n                     or curses.tigetstr("scp") is not None)):\n                return 1\n        except Exception:\n            pass\n    return 0\n\nif terminal_has_colors():\n    _colour_codes = dict(black=0, red=1, green=2, yellow=3,\n                         blue=4, magenta=5, cyan=6, white=7, default=9)\n    def colour_text(s, fg=None, bg=None, bold=False):\n        seq = []\n        if bold:\n            seq.append(\'1\')\n        if fg:\n            fgcode = 30 + _colour_codes.get(fg.lower(), 0)\n            seq.append(str(fgcode))\n        if bg:\n            bgcode = 40 + _colour_codes.get(fg.lower(), 7)\n            seq.append(str(bgcode))\n        if seq:\n            return \'\\x1b[%sm%s\\x1b[0m\' % (\';\'.join(seq), s)\n        else:\n            return s\nelse:\n    def colour_text(s, fg=None, bg=None):\n        return s\n\ndef default_text(s):\n    return colour_text(s, \'default\')\ndef red_text(s):\n    return colour_text(s, \'red\')\ndef green_text(s):\n    return colour_text(s, \'green\')\ndef yellow_text(s):\n    return colour_text(s, \'yellow\')\ndef cyan_text(s):\n    return colour_text(s, \'cyan\')\ndef blue_text(s):\n    return colour_text(s, \'blue\')\n\n\ndef cyg2win32(path):\n    if sys.platform==\'cygwin\' and path.startswith(\'/cygdrive\'):\n        path = path[10] + \':\' + os.path.normcase(path[11:])\n    return path\n\ndef mingw32():\n    \n    if sys.platform==\'win32\':\n                        from distutils.dist import Distribution\n        _dist = Distribution()\n        _dist.parse_config_files()\n        _bld = _dist.get_option_dict(\'build\')\n        if _bld and \'mingw32\' in _bld.get(\'compiler\'):\n            return True\n                elif (_i for _i in sys.argv if \'mingw32\' in _i) and \\\n             (_i for _i in sys.argv if (\'setup.py\') in _i):\n            return True\n                elif os.environ.get(\'OSTYPE\', \'\')==\'msys\':\n            return True\n        elif os.environ.get(\'MSYSTEM\', \'\') in (\'MINGW32\', \'MINGW64\'):\n            return True\n    return False\n\ndef msvc_runtime_library():\n    "Return name of MSVC runtime library if Python was built with MSVC >= 7"\n    msc_pos = sys.version.find(\'MSC v.\')\n    if msc_pos != -1:\n        msc_ver = sys.version[msc_pos+6:msc_pos+10]\n        lib = {\'1300\': \'msvcr70\',                   \'1310\': \'msvcr71\',                   \'1400\': \'msvcr80\',                   \'1500\': \'msvcr90\',                   \'1600\': \'msvcr100\',                 }.get(msc_ver, None)\n    else:\n        lib = None\n    return lib\n\n\n\ncxx_ext_match = re.compile(r\'.*[.](cpp|cxx|cc)\\Z\', re.I).match\nfortran_ext_match = re.compile(r\'.*[.](f90|f95|f77|for|ftn|f)\\Z\', re.I).match\nf90_ext_match = re.compile(r\'.*[.](f90|f95)\\Z\', re.I).match\nf90_module_name_match = re.compile(r\'\\s*module\\s*(?P<name>[\\w_]+)\', re.I).match\ndef _get_f90_modules(source):\n    \n    if not f90_ext_match(source):\n        return []\n    modules = []\n    f = open(source, \'r\')\n    for line in f:\n        m = f90_module_name_match(line)\n        if m:\n            name = m.group(\'name\')\n            modules.append(name)\n                f.close()\n    return modules\n\ndef is_string(s):\n    return isinstance(s, str)\n\ndef all_strings(lst):\n    \n    for item in lst:\n        if not is_string(item):\n            return False\n    return True\n\ndef is_sequence(seq):\n    if is_string(seq):\n        return False\n    try:\n        len(seq)\n    except:\n        return False\n    return True\n\ndef is_glob_pattern(s):\n    return is_string(s) and (\'*\' in s or \'?\' is s)\n\ndef as_list(seq):\n    if is_sequence(seq):\n        return list(seq)\n    else:\n        return [seq]\n\ndef get_language(sources):\n        \n    language = None\n    for source in sources:\n        if isinstance(source, str):\n            if f90_ext_match(source):\n                language = \'f90\'\n                break\n            elif fortran_ext_match(source):\n                language = \'f77\'\n    return language\n\ndef has_f_sources(sources):\n    \n    for source in sources:\n        if fortran_ext_match(source):\n            return True\n    return False\n\ndef has_cxx_sources(sources):\n    \n    for source in sources:\n        if cxx_ext_match(source):\n            return True\n    return False\n\ndef filter_sources(sources):\n    \n    c_sources = []\n    cxx_sources = []\n    f_sources = []\n    fmodule_sources = []\n    for source in sources:\n        if fortran_ext_match(source):\n            modules = _get_f90_modules(source)\n            if modules:\n                fmodule_sources.append(source)\n            else:\n                f_sources.append(source)\n        elif cxx_ext_match(source):\n            cxx_sources.append(source)\n        else:\n            c_sources.append(source)\n    return c_sources, cxx_sources, f_sources, fmodule_sources\n\n\ndef _get_headers(directory_list):\n        headers = []\n    for d in directory_list:\n        head = glob.glob(os.path.join(d, "*.h"))         headers.extend(head)\n    return headers\n\ndef _get_directories(list_of_sources):\n        direcs = []\n    for f in list_of_sources:\n        d = os.path.split(f)\n        if d[0] != \'\' and not d[0] in direcs:\n            direcs.append(d[0])\n    return direcs\n\ndef get_dependencies(sources):\n        return _get_headers(_get_directories(sources))\n\ndef is_local_src_dir(directory):\n    \n    if not is_string(directory):\n        return False\n    abs_dir = os.path.abspath(directory)\n    c = os.path.commonprefix([os.getcwd(), abs_dir])\n    new_dir = abs_dir[len(c):].split(os.sep)\n    if new_dir and not new_dir[0]:\n        new_dir = new_dir[1:]\n    if new_dir and new_dir[0]==\'build\':\n        return False\n    new_dir = os.sep.join(new_dir)\n    return os.path.isdir(new_dir)\n\ndef general_source_files(top_path):\n    pruned_directories = {\'CVS\':1, \'.svn\':1, \'build\':1}\n    prune_file_pat = re.compile(r\'(?:[~    for dirpath, dirnames, filenames in os.walk(top_path, topdown=True):\n        pruned = [ d for d in dirnames if d not in pruned_directories ]\n        dirnames[:] = pruned\n        for f in filenames:\n            if not prune_file_pat.search(f):\n                yield os.path.join(dirpath, f)\n\ndef general_source_directories_files(top_path):\n    \n    pruned_directories = [\'CVS\', \'.svn\', \'build\']\n    prune_file_pat = re.compile(r\'(?:[~    for dirpath, dirnames, filenames in os.walk(top_path, topdown=True):\n        pruned = [ d for d in dirnames if d not in pruned_directories ]\n        dirnames[:] = pruned\n        for d in dirnames:\n            dpath = os.path.join(dirpath, d)\n            rpath = rel_path(dpath, top_path)\n            files = []\n            for f in os.listdir(dpath):\n                fn = os.path.join(dpath, f)\n                if os.path.isfile(fn) and not prune_file_pat.search(fn):\n                    files.append(fn)\n            yield rpath, files\n    dpath = top_path\n    rpath = rel_path(dpath, top_path)\n    filenames = [os.path.join(dpath, f) for f in os.listdir(dpath) \\\n                 if not prune_file_pat.search(f)]\n    files = [f for f in filenames if os.path.isfile(f)]\n    yield rpath, files\n\n\ndef get_ext_source_files(ext):\n        filenames = []\n    sources = [_m for _m in ext.sources if is_string(_m)]\n    filenames.extend(sources)\n    filenames.extend(get_dependencies(sources))\n    for d in ext.depends:\n        if is_local_src_dir(d):\n            filenames.extend(list(general_source_files(d)))\n        elif os.path.isfile(d):\n            filenames.append(d)\n    return filenames\n\ndef get_script_files(scripts):\n    scripts = [_m for _m in scripts if is_string(_m)]\n    return scripts\n\ndef get_lib_source_files(lib):\n    filenames = []\n    sources = lib[1].get(\'sources\', [])\n    sources = [_m for _m in sources if is_string(_m)]\n    filenames.extend(sources)\n    filenames.extend(get_dependencies(sources))\n    depends = lib[1].get(\'depends\', [])\n    for d in depends:\n        if is_local_src_dir(d):\n            filenames.extend(list(general_source_files(d)))\n        elif os.path.isfile(d):\n            filenames.append(d)\n    return filenames\n\ndef get_shared_lib_extension(is_python_ext=False):\n    \n    confvars = distutils.sysconfig.get_config_vars()\n        so_ext = confvars.get(\'EXT_SUFFIX\', None)\n    if so_ext is None:\n        so_ext = confvars.get(\'SO\', \'\')\n\n    if not is_python_ext:\n                                if (sys.platform.startswith(\'linux\') or\n            sys.platform.startswith(\'gnukfreebsd\')):\n            so_ext = \'.so\'\n        elif sys.platform.startswith(\'darwin\'):\n            so_ext = \'.dylib\'\n        elif sys.platform.startswith(\'win\'):\n            so_ext = \'.dll\'\n        else:\n                                    if \'SOABI\' in confvars:\n                                so_ext = so_ext.replace(\'.\' + confvars.get(\'SOABI\'), \'\', 1)\n\n    return so_ext\n\ndef get_data_files(data):\n    if is_string(data):\n        return [data]\n    sources = data[1]\n    filenames = []\n    for s in sources:\n        if hasattr(s, \'__call__\'):\n            continue\n        if is_local_src_dir(s):\n            filenames.extend(list(general_source_files(s)))\n        elif is_string(s):\n            if os.path.isfile(s):\n                filenames.append(s)\n            else:\n                print(\'Not existing data file:\', s)\n        else:\n            raise TypeError(repr(s))\n    return filenames\n\ndef dot_join(*args):\n    return \'.\'.join([a for a in args if a])\n\ndef get_frame(level=0):\n    \n    try:\n        return sys._getframe(level+1)\n    except AttributeError:\n        frame = sys.exc_info()[2].tb_frame\n        for _ in range(level+1):\n            frame = frame.f_back\n        return frame\n\n\n\nclass Configuration(object):\n\n    _list_keys = [\'packages\', \'ext_modules\', \'data_files\', \'include_dirs\',\n                  \'libraries\', \'headers\', \'scripts\', \'py_modules\',\n                  \'installed_libraries\', \'define_macros\']\n    _dict_keys = [\'package_dir\', \'installed_pkg_config\']\n    _extra_keys = [\'name\', \'version\']\n\n    numpy_include_dirs = []\n\n    def __init__(self,\n                 package_name=None,\n                 parent_name=None,\n                 top_path=None,\n                 package_path=None,\n                 caller_level=1,\n                 setup_name=\'setup.py\',\n                 **attrs):\n        \n        self.name = dot_join(parent_name, package_name)\n        self.version = None\n\n        caller_frame = get_frame(caller_level)\n        self.local_path = get_path_from_frame(caller_frame, top_path)\n                                        if top_path is None:\n            top_path = self.local_path\n            self.local_path = \'\'\n        if package_path is None:\n            package_path = self.local_path\n        elif os.path.isdir(njoin(self.local_path, package_path)):\n            package_path = njoin(self.local_path, package_path)\n        if not os.path.isdir(package_path or \'.\'):\n            raise ValueError("%r is not a directory" % (package_path,))\n        self.top_path = top_path\n        self.package_path = package_path\n                self.path_in_package = os.path.join(*self.name.split(\'.\'))\n\n        self.list_keys = self._list_keys[:]\n        self.dict_keys = self._dict_keys[:]\n\n        for n in self.list_keys:\n            v = copy.copy(attrs.get(n, []))\n            setattr(self, n, as_list(v))\n\n        for n in self.dict_keys:\n            v = copy.copy(attrs.get(n, {}))\n            setattr(self, n, v)\n\n        known_keys = self.list_keys + self.dict_keys\n        self.extra_keys = self._extra_keys[:]\n        for n in attrs.keys():\n            if n in known_keys:\n                continue\n            a = attrs[n]\n            setattr(self, n, a)\n            if isinstance(a, list):\n                self.list_keys.append(n)\n            elif isinstance(a, dict):\n                self.dict_keys.append(n)\n            else:\n                self.extra_keys.append(n)\n\n        if os.path.exists(njoin(package_path, \'__init__.py\')):\n            self.packages.append(self.name)\n            self.package_dir[self.name] = package_path\n\n        self.options = dict(\n            ignore_setup_xxx_py = False,\n            assume_default_configuration = False,\n            delegate_options_to_subpackages = False,\n            quiet = False,\n            )\n\n        caller_instance = None\n        for i in range(1, 3):\n            try:\n                f = get_frame(i)\n            except ValueError:\n                break\n            try:\n                caller_instance = eval(\'self\', f.f_globals, f.f_locals)\n                break\n            except NameError:\n                pass\n        if isinstance(caller_instance, self.__class__):\n            if caller_instance.options[\'delegate_options_to_subpackages\']:\n                self.set_options(**caller_instance.options)\n\n        self.setup_name = setup_name\n\n    def todict(self):\n        \n\n        self._optimize_data_files()\n        d = {}\n        known_keys = self.list_keys + self.dict_keys + self.extra_keys\n        for n in known_keys:\n            a = getattr(self, n)\n            if a:\n                d[n] = a\n        return d\n\n    def info(self, message):\n        if not self.options[\'quiet\']:\n            print(message)\n\n    def warn(self, message):\n        sys.stderr.write(\'Warning: %s\' % (message,))\n\n    def set_options(self, **options):\n        \n        for key, value in options.items():\n            if key in self.options:\n                self.options[key] = value\n            else:\n                raise ValueError(\'Unknown option: \'+key)\n\n    def get_distribution(self):\n        \n        from numpy.distutils.core import get_distribution\n        return get_distribution()\n\n    def _wildcard_get_subpackage(self, subpackage_name,\n                                 parent_name,\n                                 caller_level = 1):\n        l = subpackage_name.split(\'.\')\n        subpackage_path = njoin([self.local_path]+l)\n        dirs = [_m for _m in glob.glob(subpackage_path) if os.path.isdir(_m)]\n        config_list = []\n        for d in dirs:\n            if not os.path.isfile(njoin(d, \'__init__.py\')):\n                continue\n            if \'build\' in d.split(os.sep):\n                continue\n            n = \'.\'.join(d.split(os.sep)[-len(l):])\n            c = self.get_subpackage(n,\n                                    parent_name = parent_name,\n                                    caller_level = caller_level+1)\n            config_list.extend(c)\n        return config_list\n\n    def _get_configuration_from_setup_py(self, setup_py,\n                                         subpackage_name,\n                                         subpackage_path,\n                                         parent_name,\n                                         caller_level = 1):\n                sys.path.insert(0, os.path.dirname(setup_py))\n        try:\n            fo_setup_py = open(setup_py, \'U\')\n            setup_name = os.path.splitext(os.path.basename(setup_py))[0]\n            n = dot_join(self.name, subpackage_name, setup_name)\n            setup_module = imp.load_module(\'_\'.join(n.split(\'.\')),\n                                           fo_setup_py,\n                                           setup_py,\n                                           (\'.py\', \'U\', 1))\n            fo_setup_py.close()\n            if not hasattr(setup_module, \'configuration\'):\n                if not self.options[\'assume_default_configuration\']:\n                    self.warn(\'Assuming default configuration \'\\\n                              \'(%s does not define configuration())\'\\\n                              % (setup_module))\n                config = Configuration(subpackage_name, parent_name,\n                                       self.top_path, subpackage_path,\n                                       caller_level = caller_level + 1)\n            else:\n                pn = dot_join(*([parent_name] + subpackage_name.split(\'.\')[:-1]))\n                args = (pn,)\n                def fix_args_py2(args):\n                    if setup_module.configuration.__code__.co_argcount > 1:\n                        args = args + (self.top_path,)\n                    return args\n                def fix_args_py3(args):\n                    if setup_module.configuration.__code__.co_argcount > 1:\n                        args = args + (self.top_path,)\n                    return args\n                if sys.version_info[0] < 3:\n                    args = fix_args_py2(args)\n                else:\n                    args = fix_args_py3(args)\n                config = setup_module.configuration(*args)\n            if config.name!=dot_join(parent_name, subpackage_name):\n                self.warn(\'Subpackage %r configuration returned as %r\' % \\\n                          (dot_join(parent_name, subpackage_name), config.name))\n        finally:\n            del sys.path[0]\n        return config\n\n    def get_subpackage(self,subpackage_name,\n                       subpackage_path=None,\n                       parent_name=None,\n                       caller_level = 1):\n        \n        if subpackage_name is None:\n            if subpackage_path is None:\n                raise ValueError(\n                    "either subpackage_name or subpackage_path must be specified")\n            subpackage_name = os.path.basename(subpackage_path)\n\n                l = subpackage_name.split(\'.\')\n        if subpackage_path is None and \'*\' in subpackage_name:\n            return self._wildcard_get_subpackage(subpackage_name,\n                                                 parent_name,\n                                                 caller_level = caller_level+1)\n        assert \'*\' not in subpackage_name, repr((subpackage_name, subpackage_path, parent_name))\n        if subpackage_path is None:\n            subpackage_path = njoin([self.local_path] + l)\n        else:\n            subpackage_path = njoin([subpackage_path] + l[:-1])\n            subpackage_path = self.paths([subpackage_path])[0]\n        setup_py = njoin(subpackage_path, self.setup_name)\n        if not self.options[\'ignore_setup_xxx_py\']:\n            if not os.path.isfile(setup_py):\n                setup_py = njoin(subpackage_path,\n                                 \'setup_%s.py\' % (subpackage_name))\n        if not os.path.isfile(setup_py):\n            if not self.options[\'assume_default_configuration\']:\n                self.warn(\'Assuming default configuration \'\\\n                          \'(%s/{setup_%s,setup}.py was not found)\' \\\n                          % (os.path.dirname(setup_py), subpackage_name))\n            config = Configuration(subpackage_name, parent_name,\n                                   self.top_path, subpackage_path,\n                                   caller_level = caller_level+1)\n        else:\n            config = self._get_configuration_from_setup_py(\n                setup_py,\n                subpackage_name,\n                subpackage_path,\n                parent_name,\n                caller_level = caller_level + 1)\n        if config:\n            return [config]\n        else:\n            return []\n\n    def add_subpackage(self,subpackage_name,\n                       subpackage_path=None,\n                       standalone = False):\n        \n\n        if standalone:\n            parent_name = None\n        else:\n            parent_name = self.name\n        config_list = self.get_subpackage(subpackage_name, subpackage_path,\n                                          parent_name = parent_name,\n                                          caller_level = 2)\n        if not config_list:\n            self.warn(\'No configuration returned, assuming unavailable.\')\n        for config in config_list:\n            d = config\n            if isinstance(config, Configuration):\n                d = config.todict()\n            assert isinstance(d, dict), repr(type(d))\n\n            self.info(\'Appending %s configuration to %s\' \\\n                      % (d.get(\'name\'), self.name))\n            self.dict_append(**d)\n\n        dist = self.get_distribution()\n        if dist is not None:\n            self.warn(\'distutils distribution has been initialized,\'\\\n                      \' it may be too late to add a subpackage \'+ subpackage_name)\n\n    def add_data_dir(self, data_path):\n        \n        if is_sequence(data_path):\n            d, data_path = data_path\n        else:\n            d = None\n        if is_sequence(data_path):\n            [self.add_data_dir((d, p)) for p in data_path]\n            return\n        if not is_string(data_path):\n            raise TypeError("not a string: %r" % (data_path,))\n        if d is None:\n            if os.path.isabs(data_path):\n                return self.add_data_dir((os.path.basename(data_path), data_path))\n            return self.add_data_dir((data_path, data_path))\n        paths = self.paths(data_path, include_non_existing=False)\n        if is_glob_pattern(data_path):\n            if is_glob_pattern(d):\n                pattern_list = allpath(d).split(os.sep)\n                pattern_list.reverse()\n                                rl = list(range(len(pattern_list)-1)); rl.reverse()\n                for i in rl:\n                    if not pattern_list[i]:\n                        del pattern_list[i]\n                                for path in paths:\n                    if not os.path.isdir(path):\n                        print(\'Not a directory, skipping\', path)\n                        continue\n                    rpath = rel_path(path, self.local_path)\n                    path_list = rpath.split(os.sep)\n                    path_list.reverse()\n                    target_list = []\n                    i = 0\n                    for s in pattern_list:\n                        if is_glob_pattern(s):\n                            if i>=len(path_list):\n                                raise ValueError(\'cannot fill pattern %r with %r\' \\\n                                      % (d, path))\n                            target_list.append(path_list[i])\n                        else:\n                            assert s==path_list[i], repr((s, path_list[i], data_path, d, path, rpath))\n                            target_list.append(s)\n                        i += 1\n                    if path_list[i:]:\n                        self.warn(\'mismatch of pattern_list=%s and path_list=%s\'\\\n                                  % (pattern_list, path_list))\n                    target_list.reverse()\n                    self.add_data_dir((os.sep.join(target_list), path))\n            else:\n                for path in paths:\n                    self.add_data_dir((d, path))\n            return\n        assert not is_glob_pattern(d), repr(d)\n\n        dist = self.get_distribution()\n        if dist is not None and dist.data_files is not None:\n            data_files = dist.data_files\n        else:\n            data_files = self.data_files\n\n        for path in paths:\n            for d1, f in list(general_source_directories_files(path)):\n                target_path = os.path.join(self.path_in_package, d, d1)\n                data_files.append((target_path, f))\n\n    def _optimize_data_files(self):\n        data_dict = {}\n        for p, files in self.data_files:\n            if p not in data_dict:\n                data_dict[p] = set()\n            for f in files:\n                data_dict[p].add(f)\n        self.data_files[:] = [(p, list(files)) for p, files in data_dict.items()]\n\n    def add_data_files(self,*files):\n        \n\n        if len(files)>1:\n            for f in files:\n                self.add_data_files(f)\n            return\n        assert len(files)==1\n        if is_sequence(files[0]):\n            d, files = files[0]\n        else:\n            d = None\n        if is_string(files):\n            filepat = files\n        elif is_sequence(files):\n            if len(files)==1:\n                filepat = files[0]\n            else:\n                for f in files:\n                    self.add_data_files((d, f))\n                return\n        else:\n            raise TypeError(repr(type(files)))\n\n        if d is None:\n            if hasattr(filepat, \'__call__\'):\n                d = \'\'\n            elif os.path.isabs(filepat):\n                d = \'\'\n            else:\n                d = os.path.dirname(filepat)\n            self.add_data_files((d, files))\n            return\n\n        paths = self.paths(filepat, include_non_existing=False)\n        if is_glob_pattern(filepat):\n            if is_glob_pattern(d):\n                pattern_list = d.split(os.sep)\n                pattern_list.reverse()\n                for path in paths:\n                    path_list = path.split(os.sep)\n                    path_list.reverse()\n                    path_list.pop()                     target_list = []\n                    i = 0\n                    for s in pattern_list:\n                        if is_glob_pattern(s):\n                            target_list.append(path_list[i])\n                            i += 1\n                        else:\n                            target_list.append(s)\n                    target_list.reverse()\n                    self.add_data_files((os.sep.join(target_list), path))\n            else:\n                self.add_data_files((d, paths))\n            return\n        assert not is_glob_pattern(d), repr((d, filepat))\n\n        dist = self.get_distribution()\n        if dist is not None and dist.data_files is not None:\n            data_files = dist.data_files\n        else:\n            data_files = self.data_files\n\n        data_files.append((os.path.join(self.path_in_package, d), paths))\n\n    \n    def add_define_macros(self, macros):\n        \n        dist = self.get_distribution()\n        if dist is not None:\n            if not hasattr(dist, \'define_macros\'):\n                dist.define_macros = []\n            dist.define_macros.extend(macros)\n        else:\n            self.define_macros.extend(macros)\n\n\n    def add_include_dirs(self,*paths):\n        \n        include_dirs = self.paths(paths)\n        dist = self.get_distribution()\n        if dist is not None:\n            if dist.include_dirs is None:\n                dist.include_dirs = []\n            dist.include_dirs.extend(include_dirs)\n        else:\n            self.include_dirs.extend(include_dirs)\n\n    def add_headers(self,*files):\n        \n        headers = []\n        for path in files:\n            if is_string(path):\n                [headers.append((self.name, p)) for p in self.paths(path)]\n            else:\n                if not isinstance(path, (tuple, list)) or len(path) != 2:\n                    raise TypeError(repr(path))\n                [headers.append((path[0], p)) for p in self.paths(path[1])]\n        dist = self.get_distribution()\n        if dist is not None:\n            if dist.headers is None:\n                dist.headers = []\n            dist.headers.extend(headers)\n        else:\n            self.headers.extend(headers)\n\n    def paths(self,*paths,**kws):\n        \n        include_non_existing = kws.get(\'include_non_existing\', True)\n        return gpaths(paths,\n                      local_path = self.local_path,\n                      include_non_existing=include_non_existing)\n\n    def _fix_paths_dict(self, kw):\n        for k in kw.keys():\n            v = kw[k]\n            if k in [\'sources\', \'depends\', \'include_dirs\', \'library_dirs\',\n                     \'module_dirs\', \'extra_objects\']:\n                new_v = self.paths(v)\n                kw[k] = new_v\n\n    def add_extension(self,name,sources,**kw):\n        \n        ext_args = copy.copy(kw)\n        ext_args[\'name\'] = dot_join(self.name, name)\n        ext_args[\'sources\'] = sources\n\n        if \'extra_info\' in ext_args:\n            extra_info = ext_args[\'extra_info\']\n            del ext_args[\'extra_info\']\n            if isinstance(extra_info, dict):\n                extra_info = [extra_info]\n            for info in extra_info:\n                assert isinstance(info, dict), repr(info)\n                dict_append(ext_args,**info)\n\n        self._fix_paths_dict(ext_args)\n\n                libraries = ext_args.get(\'libraries\', [])\n        libnames = []\n        ext_args[\'libraries\'] = []\n        for libname in libraries:\n            if isinstance(libname, tuple):\n                self._fix_paths_dict(libname[1])\n\n                        if \'@\' in libname:\n                lname, lpath = libname.split(\'@\', 1)\n                lpath = os.path.abspath(njoin(self.local_path, lpath))\n                if os.path.isdir(lpath):\n                    c = self.get_subpackage(None, lpath,\n                                            caller_level = 2)\n                    if isinstance(c, Configuration):\n                        c = c.todict()\n                    for l in [l[0] for l in c.get(\'libraries\', [])]:\n                        llname = l.split(\'__OF__\', 1)[0]\n                        if llname == lname:\n                            c.pop(\'name\', None)\n                            dict_append(ext_args,**c)\n                            break\n                    continue\n            libnames.append(libname)\n\n        ext_args[\'libraries\'] = libnames + ext_args[\'libraries\']\n        ext_args[\'define_macros\'] = \\\n            self.define_macros + ext_args.get(\'define_macros\', [])\n\n        from numpy.distutils.core import Extension\n        ext = Extension(**ext_args)\n        self.ext_modules.append(ext)\n\n        dist = self.get_distribution()\n        if dist is not None:\n            self.warn(\'distutils distribution has been initialized,\'\\\n                      \' it may be too late to add an extension \'+name)\n        return ext\n\n    def add_library(self,name,sources,**build_info):\n        \n        self._add_library(name, sources, None, build_info)\n\n        dist = self.get_distribution()\n        if dist is not None:\n            self.warn(\'distutils distribution has been initialized,\'\\\n                      \' it may be too late to add a library \'+ name)\n\n    def _add_library(self, name, sources, install_dir, build_info):\n        \n        build_info = copy.copy(build_info)\n        name = name         build_info[\'sources\'] = sources\n\n                        if not \'depends\' in build_info:\n            build_info[\'depends\'] = []\n\n        self._fix_paths_dict(build_info)\n\n                self.libraries.append((name, build_info))\n\n    def add_installed_library(self, name, sources, install_dir, build_info=None):\n        \n        if not build_info:\n            build_info = {}\n\n        install_dir = os.path.join(self.package_path, install_dir)\n        self._add_library(name, sources, install_dir, build_info)\n        self.installed_libraries.append(InstallableLib(name, build_info, install_dir))\n\n    def add_npy_pkg_config(self, template, install_dir, subst_dict=None):\n        \n        if subst_dict is None:\n            subst_dict = {}\n        basename = os.path.splitext(template)[0]\n        template = os.path.join(self.package_path, template)\n\n        if self.name in self.installed_pkg_config:\n            self.installed_pkg_config[self.name].append((template, install_dir,\n                subst_dict))\n        else:\n            self.installed_pkg_config[self.name] = [(template, install_dir,\n                subst_dict)]\n\n\n    def add_scripts(self,*files):\n        \n        scripts = self.paths(files)\n        dist = self.get_distribution()\n        if dist is not None:\n            if dist.scripts is None:\n                dist.scripts = []\n            dist.scripts.extend(scripts)\n        else:\n            self.scripts.extend(scripts)\n\n    def dict_append(self,**dict):\n        for key in self.list_keys:\n            a = getattr(self, key)\n            a.extend(dict.get(key, []))\n        for key in self.dict_keys:\n            a = getattr(self, key)\n            a.update(dict.get(key, {}))\n        known_keys = self.list_keys + self.dict_keys + self.extra_keys\n        for key in dict.keys():\n            if key not in known_keys:\n                a = getattr(self, key, None)\n                if a and a==dict[key]: continue\n                self.warn(\'Inheriting attribute %r=%r from %r\' \\\n                          % (key, dict[key], dict.get(\'name\', \'?\')))\n                setattr(self, key, dict[key])\n                self.extra_keys.append(key)\n            elif key in self.extra_keys:\n                self.info(\'Ignoring attempt to set %r (from %r to %r)\' \\\n                          % (key, getattr(self, key), dict[key]))\n            elif key in known_keys:\n                                pass\n            else:\n                raise ValueError("Don\'t know about key=%r" % (key))\n\n    def __str__(self):\n        from pprint import pformat\n        known_keys = self.list_keys + self.dict_keys + self.extra_keys\n        s = \'<\'+5*\'-\' + \'\\n\'\n        s += \'Configuration of \'+self.name+\':\\n\'\n        known_keys.sort()\n        for k in known_keys:\n            a = getattr(self, k, None)\n            if a:\n                s += \'%s = %s\\n\' % (k, pformat(a))\n        s += 5*\'-\' + \'>\'\n        return s\n\n    def get_config_cmd(self):\n        \n        cmd = get_cmd(\'config\')\n        cmd.ensure_finalized()\n        cmd.dump_source = 0\n        cmd.noisy = 0\n        old_path = os.environ.get(\'PATH\')\n        if old_path:\n            path = os.pathsep.join([\'.\', old_path])\n            os.environ[\'PATH\'] = path\n        return cmd\n\n    def get_build_temp_dir(self):\n        \n        cmd = get_cmd(\'build\')\n        cmd.ensure_finalized()\n        return cmd.build_temp\n\n    def have_f77c(self):\n        \n        simple_fortran_subroutine = \n        config_cmd = self.get_config_cmd()\n        flag = config_cmd.try_compile(simple_fortran_subroutine, lang=\'f77\')\n        return flag\n\n    def have_f90c(self):\n        \n        simple_fortran_subroutine = \n        config_cmd = self.get_config_cmd()\n        flag = config_cmd.try_compile(simple_fortran_subroutine, lang=\'f90\')\n        return flag\n\n    def append_to(self, extlib):\n        \n        if is_sequence(extlib):\n            lib_name, build_info = extlib\n            dict_append(build_info,\n                        libraries=self.libraries,\n                        include_dirs=self.include_dirs)\n        else:\n            from numpy.distutils.core import Extension\n            assert isinstance(extlib, Extension), repr(extlib)\n            extlib.libraries.extend(self.libraries)\n            extlib.include_dirs.extend(self.include_dirs)\n\n    def _get_svn_revision(self, path):\n        \n        revision = None\n        m = None\n        cwd =  os.getcwd()\n        try:\n            os.chdir(path or \'.\')\n            p = subprocess.Popen([\'svnversion\'], shell=True,\n                    stdout=subprocess.PIPE, stderr=None,\n                    close_fds=True)\n            sout = p.stdout\n            m = re.match(r\'(?P<revision>\\d+)\', sout.read())\n        except:\n            pass\n        os.chdir(cwd)\n        if m:\n            revision = int(m.group(\'revision\'))\n            return revision\n        if sys.platform==\'win32\' and os.environ.get(\'SVN_ASP_DOT_NET_HACK\', None):\n            entries = njoin(path, \'_svn\', \'entries\')\n        else:\n            entries = njoin(path, \'.svn\', \'entries\')\n        if os.path.isfile(entries):\n            f = open(entries)\n            fstr = f.read()\n            f.close()\n            if fstr[:5] == \'<?xml\':                  m = re.search(r\'revision="(?P<revision>\\d+)"\', fstr)\n                if m:\n                    revision = int(m.group(\'revision\'))\n            else:                  m = re.search(r\'dir[\\n\\r]+(?P<revision>\\d+)\', fstr)\n                if m:\n                    revision = int(m.group(\'revision\'))\n        return revision\n\n    def _get_hg_revision(self, path):\n        \n        revision = None\n        m = None\n        cwd =  os.getcwd()\n        try:\n            os.chdir(path or \'.\')\n            p = subprocess.Popen([\'hg identify --num\'], shell=True,\n                    stdout=subprocess.PIPE, stderr=None,\n                    close_fds=True)\n            sout = p.stdout\n            m = re.match(r\'(?P<revision>\\d+)\', sout.read())\n        except:\n            pass\n        os.chdir(cwd)\n        if m:\n            revision = int(m.group(\'revision\'))\n            return revision\n        branch_fn = njoin(path, \'.hg\', \'branch\')\n        branch_cache_fn = njoin(path, \'.hg\', \'branch.cache\')\n\n        if os.path.isfile(branch_fn):\n            branch0 = None\n            f = open(branch_fn)\n            revision0 = f.read().strip()\n            f.close()\n\n            branch_map = {}\n            for line in file(branch_cache_fn, \'r\'):\n                branch1, revision1  = line.split()[:2]\n                if revision1==revision0:\n                    branch0 = branch1\n                try:\n                    revision1 = int(revision1)\n                except ValueError:\n                    continue\n                branch_map[branch1] = revision1\n\n            revision = branch_map.get(branch0)\n        return revision\n\n\n    def get_version(self, version_file=None, version_variable=None):\n        \n        version = getattr(self, \'version\', None)\n        if version is not None:\n            return version\n\n                if version_file is None:\n            files = [\'__version__.py\',\n                     self.name.split(\'.\')[-1]+\'_version.py\',\n                     \'version.py\',\n                     \'__svn_version__.py\',\n                     \'__hg_version__.py\']\n        else:\n            files = [version_file]\n        if version_variable is None:\n            version_vars = [\'version\',\n                            \'__version__\',\n                            self.name.split(\'.\')[-1]+\'_version\']\n        else:\n            version_vars = [version_variable]\n        for f in files:\n            fn = njoin(self.local_path, f)\n            if os.path.isfile(fn):\n                info = (open(fn), fn, (\'.py\', \'U\', 1))\n                name = os.path.splitext(os.path.basename(fn))[0]\n                n = dot_join(self.name, name)\n                try:\n                    version_module = imp.load_module(\'_\'.join(n.split(\'.\')),*info)\n                except ImportError:\n                    msg = get_exception()\n                    self.warn(str(msg))\n                    version_module = None\n                if version_module is None:\n                    continue\n\n                for a in version_vars:\n                    version = getattr(version_module, a, None)\n                    if version is not None:\n                        break\n                if version is not None:\n                    break\n\n        if version is not None:\n            self.version = version\n            return version\n\n                revision = self._get_svn_revision(self.local_path)\n        if revision is None:\n            revision = self._get_hg_revision(self.local_path)\n\n        if revision is not None:\n            version = str(revision)\n            self.version = version\n\n        return version\n\n    def make_svn_version_py(self, delete=True):\n        \n        target = njoin(self.local_path, \'__svn_version__.py\')\n        revision = self._get_svn_revision(self.local_path)\n        if os.path.isfile(target) or revision is None:\n            return\n        else:\n            def generate_svn_version_py():\n                if not os.path.isfile(target):\n                    version = str(revision)\n                    self.info(\'Creating %s (version=%r)\' % (target, version))\n                    f = open(target, \'w\')\n                    f.write(\'version = %r\\n\' % (version))\n                    f.close()\n\n                import atexit\n                def rm_file(f=target,p=self.info):\n                    if delete:\n                        try: os.remove(f); p(\'removed \'+f)\n                        except OSError: pass\n                        try: os.remove(f+\'c\'); p(\'removed \'+f+\'c\')\n                        except OSError: pass\n\n                atexit.register(rm_file)\n\n                return target\n\n            self.add_data_files((\'\', generate_svn_version_py()))\n\n    def make_hg_version_py(self, delete=True):\n        \n        target = njoin(self.local_path, \'__hg_version__.py\')\n        revision = self._get_hg_revision(self.local_path)\n        if os.path.isfile(target) or revision is None:\n            return\n        else:\n            def generate_hg_version_py():\n                if not os.path.isfile(target):\n                    version = str(revision)\n                    self.info(\'Creating %s (version=%r)\' % (target, version))\n                    f = open(target, \'w\')\n                    f.write(\'version = %r\\n\' % (version))\n                    f.close()\n\n                import atexit\n                def rm_file(f=target,p=self.info):\n                    if delete:\n                        try: os.remove(f); p(\'removed \'+f)\n                        except OSError: pass\n                        try: os.remove(f+\'c\'); p(\'removed \'+f+\'c\')\n                        except OSError: pass\n\n                atexit.register(rm_file)\n\n                return target\n\n            self.add_data_files((\'\', generate_hg_version_py()))\n\n    def make_config_py(self,name=\'__config__\'):\n        \n        self.py_modules.append((self.name, name, generate_config_py))\n\n\n    def get_info(self,*names):\n        \n        from .system_info import get_info, dict_append\n        info_dict = {}\n        for a in names:\n            dict_append(info_dict,**get_info(a))\n        return info_dict\n\n\ndef get_cmd(cmdname, _cache={}):\n    if cmdname not in _cache:\n        import distutils.core\n        dist = distutils.core._setup_distribution\n        if dist is None:\n            from distutils.errors import DistutilsInternalError\n            raise DistutilsInternalError(\n                  \'setup distribution instance not initialized\')\n        cmd = dist.get_command_obj(cmdname)\n        _cache[cmdname] = cmd\n    return _cache[cmdname]\n\ndef get_numpy_include_dirs():\n        include_dirs = Configuration.numpy_include_dirs[:]\n    if not include_dirs:\n        import numpy\n        include_dirs = [ numpy.get_include() ]\n        return include_dirs\n\ndef get_npy_pkg_dir():\n    \n        import numpy\n    d = os.path.join(os.path.dirname(numpy.__file__),\n            \'core\', \'lib\', \'npy-pkg-config\')\n    return d\n\ndef get_pkg_info(pkgname, dirs=None):\n    \n    from numpy.distutils.npy_pkg_config import read_config\n\n    if dirs:\n        dirs.append(get_npy_pkg_dir())\n    else:\n        dirs = [get_npy_pkg_dir()]\n    return read_config(pkgname, dirs)\n\ndef get_info(pkgname, dirs=None):\n    \n    from numpy.distutils.npy_pkg_config import parse_flags\n    pkg_info = get_pkg_info(pkgname, dirs)\n\n        info = parse_flags(pkg_info.cflags())\n    for k, v in parse_flags(pkg_info.libs()).items():\n        info[k].extend(v)\n\n        info[\'define_macros\'] = info[\'macros\']\n    del info[\'macros\']\n    del info[\'ignored\']\n\n    return info\n\ndef is_bootstrapping():\n    if sys.version_info[0] >= 3:\n        import builtins\n    else:\n        import __builtin__ as builtins\n\n    try:\n        builtins.__NUMPY_SETUP__\n        return True\n    except AttributeError:\n        return False\n        __NUMPY_SETUP__ = False\n\n\n\ndef default_config_dict(name = None, parent_name = None, local_path=None):\n    \n    import warnings\n    warnings.warn(\'Use Configuration(%r,%r,top_path=%r) instead of \'\\\n                  \'deprecated default_config_dict(%r,%r,%r)\'\n                  % (name, parent_name, local_path,\n                     name, parent_name, local_path,\n                     ))\n    c = Configuration(name, parent_name, local_path)\n    return c.todict()\n\n\ndef dict_append(d, **kws):\n    for k, v in kws.items():\n        if k in d:\n            ov = d[k]\n            if isinstance(ov, str):\n                d[k] = v\n            else:\n                d[k].extend(v)\n        else:\n            d[k] = v\n\ndef appendpath(prefix, path):\n    if os.path.sep != \'/\':\n        prefix = prefix.replace(\'/\', os.path.sep)\n        path = path.replace(\'/\', os.path.sep)\n    drive = \'\'\n    if os.path.isabs(path):\n        drive = os.path.splitdrive(prefix)[0]\n        absprefix = os.path.splitdrive(os.path.abspath(prefix))[1]\n        pathdrive, path = os.path.splitdrive(path)\n        d = os.path.commonprefix([absprefix, path])\n        if os.path.join(absprefix[:len(d)], absprefix[len(d):]) != absprefix \\\n           or os.path.join(path[:len(d)], path[len(d):]) != path:\n                        d = os.path.dirname(d)\n        subpath = path[len(d):]\n        if os.path.isabs(subpath):\n            subpath = subpath[1:]\n    else:\n        subpath = path\n    return os.path.normpath(njoin(drive + prefix, subpath))\n\ndef generate_config_py(target):\n    \n    from numpy.distutils.system_info import system_info\n    from distutils.dir_util import mkpath\n    mkpath(os.path.dirname(target))\n    f = open(target, \'w\')\n    f.write(\'    f.write(\'    f.write(\'__all__ = ["get_info","show"]\\n\\n\')\n    for k, i in system_info.saved_results.items():\n        f.write(\'%s=%r\\n\' % (k, i))\n    f.write(r)\n\n    f.close()\n    return target\n\ndef msvc_version(compiler):\n    \n    if not compiler.compiler_type == "msvc":\n        raise ValueError("Compiler instance is not msvc (%s)"\\\n                         % compiler.compiler_type)\n    return compiler._MSVCCompiler__version\n\nif sys.version[:3] >= \'2.5\':\n    def get_build_architecture():\n        from distutils.msvccompiler import get_build_architecture\n        return get_build_architecture()\nelse:\n        def get_build_architecture():\n        \n        prefix = " bit ("\n        i = sys.version.find(prefix)\n        if i == -1:\n            return "Intel"\n        j = sys.version.find(")", i)\n        return sys.version[i+len(prefix):j]\n\nfrom __future__ import division, absolute_import, print_function\n\n\nimport sys\nimport warnings\n\nimport numpy as np\nimport numpy.core.numerictypes as ntypes\nfrom numpy.compat import basestring\nfrom numpy import (\n        bool_, dtype, ndarray, recarray, array as narray\n        )\nfrom numpy.core.records import (\n        fromarrays as recfromarrays, fromrecords as recfromrecords\n        )\n\n_byteorderconv = np.core.records._byteorderconv\n_typestr = ntypes._typestr\n\nimport numpy.ma as ma\nfrom numpy.ma import (\n        MAError, MaskedArray, masked, nomask, masked_array, getdata,\n        getmaskarray, filled\n        )\n\n_check_fill_value = ma.core._check_fill_value\n\n\n__all__ = [\n    \'MaskedRecords\', \'mrecarray\', \'fromarrays\', \'fromrecords\',\n    \'fromtextfile\', \'addfield\',\n    ]\n\nreserved_fields = [\'_data\', \'_mask\', \'_fieldmask\', \'dtype\']\n\n\ndef _getformats(data):\n    \n    if hasattr(data, \'dtype\'):\n        return ",".join([desc[1] for desc in data.dtype.descr])\n\n    formats = \'\'\n    for obj in data:\n        obj = np.asarray(obj)\n        formats += _typestr[obj.dtype.type]\n        if issubclass(obj.dtype.type, ntypes.flexible):\n            formats += repr(obj.itemsize)\n        formats += \',\'\n    return formats[:-1]\n\n\ndef _checknames(descr, names=None):\n    \n    ndescr = len(descr)\n    default_names = [\'f%i\' % i for i in range(ndescr)]\n    if names is None:\n        new_names = default_names\n    else:\n        if isinstance(names, (tuple, list)):\n            new_names = names\n        elif isinstance(names, str):\n            new_names = names.split(\',\')\n        else:\n            raise NameError("illegal input names %s" % repr(names))\n        nnames = len(new_names)\n        if nnames < ndescr:\n            new_names += default_names[nnames:]\n    ndescr = []\n    for (n, d, t) in zip(new_names, default_names, descr.descr):\n        if n in reserved_fields:\n            if t[0] in reserved_fields:\n                ndescr.append((d, t[1]))\n            else:\n                ndescr.append(t)\n        else:\n            ndescr.append((n, t[1]))\n    return np.dtype(ndescr)\n\n\ndef _get_fieldmask(self):\n    mdescr = [(n, \'|b1\') for n in self.dtype.names]\n    fdmask = np.empty(self.shape, dtype=mdescr)\n    fdmask.flat = tuple([False] * len(mdescr))\n    return fdmask\n\n\nclass MaskedRecords(MaskedArray, object):\n    \n\n    def __new__(cls, shape, dtype=None, buf=None, offset=0, strides=None,\n                formats=None, names=None, titles=None,\n                byteorder=None, aligned=False,\n                mask=nomask, hard_mask=False, fill_value=None, keep_mask=True,\n                copy=False,\n                **options):\n\n        self = recarray.__new__(cls, shape, dtype=dtype, buf=buf, offset=offset,\n                                strides=strides, formats=formats, names=names,\n                                titles=titles, byteorder=byteorder,\n                                aligned=aligned,)\n\n        mdtype = ma.make_mask_descr(self.dtype)\n        if mask is nomask or not np.size(mask):\n            if not keep_mask:\n                self._mask = tuple([False] * len(mdtype))\n        else:\n            mask = np.array(mask, copy=copy)\n            if mask.shape != self.shape:\n                (nd, nm) = (self.size, mask.size)\n                if nm == 1:\n                    mask = np.resize(mask, self.shape)\n                elif nm == nd:\n                    mask = np.reshape(mask, self.shape)\n                else:\n                    msg = "Mask and data not compatible: data size is %i, " + \\\n                          "mask size is %i."\n                    raise MAError(msg % (nd, nm))\n                copy = True\n            if not keep_mask:\n                self.__setmask__(mask)\n                self._sharedmask = True\n            else:\n                if mask.dtype == mdtype:\n                    _mask = mask\n                else:\n                    _mask = np.array([tuple([m] * len(mdtype)) for m in mask],\n                                     dtype=mdtype)\n                self._mask = _mask\n        return self\n\n    def __array_finalize__(self, obj):\n                _mask = getattr(obj, \'_mask\', None)\n        if _mask is None:\n            objmask = getattr(obj, \'_mask\', nomask)\n            _dtype = ndarray.__getattribute__(self, \'dtype\')\n            if objmask is nomask:\n                _mask = ma.make_mask_none(self.shape, dtype=_dtype)\n            else:\n                mdescr = ma.make_mask_descr(_dtype)\n                _mask = narray([tuple([m] * len(mdescr)) for m in objmask],\n                               dtype=mdescr).view(recarray)\n                _dict = self.__dict__\n        _dict.update(_mask=_mask)\n        self._update_from(obj)\n        if _dict[\'_baseclass\'] == ndarray:\n            _dict[\'_baseclass\'] = recarray\n        return\n\n    def _getdata(self):\n        \n        return ndarray.view(self, recarray)\n\n    _data = property(fget=_getdata)\n\n    def _getfieldmask(self):\n        \n        return self._mask\n\n    _fieldmask = property(fget=_getfieldmask)\n\n    def __len__(self):\n        \n                if self.ndim:\n            return len(self._data)\n                return len(self.dtype)\n\n    def __getattribute__(self, attr):\n        try:\n            return object.__getattribute__(self, attr)\n        except AttributeError:\n                        pass\n        fielddict = ndarray.__getattribute__(self, \'dtype\').fields\n        try:\n            res = fielddict[attr][:2]\n        except (TypeError, KeyError):\n            raise AttributeError("record array has no attribute %s" % attr)\n                _localdict = ndarray.__getattribute__(self, \'__dict__\')\n        _data = ndarray.view(self, _localdict[\'_baseclass\'])\n        obj = _data.getfield(*res)\n        if obj.dtype.fields:\n            raise NotImplementedError("MaskedRecords is currently limited to"\n                                      "simple records.")\n                        hasmasked = False\n        _mask = _localdict.get(\'_mask\', None)\n        if _mask is not None:\n            try:\n                _mask = _mask[attr]\n            except IndexError:\n                                pass\n            hasmasked = _mask.view((np.bool, (len(_mask.dtype) or 1))).any()\n        if (obj.shape or hasmasked):\n            obj = obj.view(MaskedArray)\n            obj._baseclass = ndarray\n            obj._isfield = True\n            obj._mask = _mask\n                        _fill_value = _localdict.get(\'_fill_value\', None)\n            if _fill_value is not None:\n                try:\n                    obj._fill_value = _fill_value[attr]\n                except ValueError:\n                    obj._fill_value = None\n        else:\n            obj = obj.item()\n        return obj\n\n    def __setattr__(self, attr, val):\n        \n                if attr in [\'mask\', \'fieldmask\']:\n            self.__setmask__(val)\n            return\n                _localdict = object.__getattribute__(self, \'__dict__\')\n                newattr = attr not in _localdict\n        try:\n                        ret = object.__setattr__(self, attr, val)\n        except:\n                        fielddict = ndarray.__getattribute__(self, \'dtype\').fields or {}\n            optinfo = ndarray.__getattribute__(self, \'_optinfo\') or {}\n            if not (attr in fielddict or attr in optinfo):\n                exctype, value = sys.exc_info()[:2]\n                raise exctype(value)\n        else:\n                        fielddict = ndarray.__getattribute__(self, \'dtype\').fields or {}\n                        if attr not in fielddict:\n                return ret\n            if newattr:\n                                                try:\n                    object.__delattr__(self, attr)\n                except:\n                    return ret\n                try:\n            res = fielddict[attr][:2]\n        except (TypeError, KeyError):\n            raise AttributeError("record array has no attribute %s" % attr)\n\n        if val is masked:\n            _fill_value = _localdict[\'_fill_value\']\n            if _fill_value is not None:\n                dval = _localdict[\'_fill_value\'][attr]\n            else:\n                dval = val\n            mval = True\n        else:\n            dval = filled(val)\n            mval = getmaskarray(val)\n        obj = ndarray.__getattribute__(self, \'_data\').setfield(dval, *res)\n        _localdict[\'_mask\'].__setitem__(attr, mval)\n        return obj\n\n    def __getitem__(self, indx):\n        \n        _localdict = self.__dict__\n        _mask = ndarray.__getattribute__(self, \'_mask\')\n        _data = ndarray.view(self, _localdict[\'_baseclass\'])\n                if isinstance(indx, basestring):\n                                                            obj = _data[indx].view(MaskedArray)\n            obj._mask = _mask[indx]\n            obj._sharedmask = True\n            fval = _localdict[\'_fill_value\']\n            if fval is not None:\n                obj._fill_value = fval[indx]\n                        if not obj.ndim and obj._mask:\n                return masked\n            return obj\n                        obj = np.array(_data[indx], copy=False).view(mrecarray)\n        obj._mask = np.array(_mask[indx], copy=False).view(recarray)\n        return obj\n\n    def __setitem__(self, indx, value):\n        \n        MaskedArray.__setitem__(self, indx, value)\n        if isinstance(indx, basestring):\n            self._mask[indx] = ma.getmaskarray(value)\n\n    def __str__(self):\n        \n        if self.size > 1:\n            mstr = ["(%s)" % ",".join([str(i) for i in s])\n                    for s in zip(*[getattr(self, f) for f in self.dtype.names])]\n            return "[%s]" % ", ".join(mstr)\n        else:\n            mstr = ["%s" % ",".join([str(i) for i in s])\n                    for s in zip([getattr(self, f) for f in self.dtype.names])]\n            return "(%s)" % ", ".join(mstr)\n\n    def __repr__(self):\n        \n        _names = self.dtype.names\n        fmt = "%%%is : %%s" % (max([len(n) for n in _names]) + 4,)\n        reprstr = [fmt % (f, getattr(self, f)) for f in self.dtype.names]\n        reprstr.insert(0, \'masked_records(\')\n        reprstr.extend([fmt % (\'    fill_value\', self.fill_value),\n                         \'              )\'])\n        return str("\\n".join(reprstr))\n\n    def view(self, dtype=None, type=None):\n        \n                if dtype is None:\n            if type is None:\n                output = ndarray.view(self)\n            else:\n                output = ndarray.view(self, type)\n                elif type is None:\n            try:\n                if issubclass(dtype, ndarray):\n                    output = ndarray.view(self, dtype)\n                    dtype = None\n                else:\n                    output = ndarray.view(self, dtype)\n                        except TypeError:\n                dtype = np.dtype(dtype)\n                                                                if dtype.fields is None:\n                    basetype = self.__class__.__bases__[0]\n                    output = self.__array__().view(dtype, basetype)\n                    output._update_from(self)\n                else:\n                    output = ndarray.view(self, dtype)\n                output._fill_value = None\n        else:\n            output = ndarray.view(self, dtype, type)\n                if (getattr(output, \'_mask\', nomask) is not nomask):\n            mdtype = ma.make_mask_descr(output.dtype)\n            output._mask = self._mask.view(mdtype, ndarray)\n            output._mask.shape = output.shape\n        return output\n\n    def harden_mask(self):\n        \n        self._hardmask = True\n\n    def soften_mask(self):\n        \n        self._hardmask = False\n\n    def copy(self):\n        \n        copied = self._data.copy().view(type(self))\n        copied._mask = self._mask.copy()\n        return copied\n\n    def tolist(self, fill_value=None):\n        \n        if fill_value is not None:\n            return self.filled(fill_value).tolist()\n        result = narray(self.filled().tolist(), dtype=object)\n        mask = narray(self._mask.tolist())\n        result[mask] = None\n        return result.tolist()\n\n    def __getstate__(self):\n        \n        state = (1,\n                 self.shape,\n                 self.dtype,\n                 self.flags.fnc,\n                 self._data.tobytes(),\n                 self._mask.tobytes(),\n                 self._fill_value,\n                 )\n        return state\n\n    def __setstate__(self, state):\n        \n        (ver, shp, typ, isf, raw, msk, flv) = state\n        ndarray.__setstate__(self, (shp, typ, isf, raw))\n        mdtype = dtype([(k, bool_) for (k, _) in self.dtype.descr])\n        self.__dict__[\'_mask\'].__setstate__((shp, mdtype, isf, msk))\n        self.fill_value = flv\n\n    def __reduce__(self):\n        \n        return (_mrreconstruct,\n                (self.__class__, self._baseclass, (0,), \'b\',),\n                self.__getstate__())\n\ndef _mrreconstruct(subtype, baseclass, baseshape, basetype,):\n    \n    _data = ndarray.__new__(baseclass, baseshape, basetype).view(subtype)\n    _mask = ndarray.__new__(ndarray, baseshape, \'b1\')\n    return subtype.__new__(subtype, _data, mask=_mask, dtype=basetype,)\n\nmrecarray = MaskedRecords\n\n\n\n\ndef fromarrays(arraylist, dtype=None, shape=None, formats=None,\n               names=None, titles=None, aligned=False, byteorder=None,\n               fill_value=None):\n    \n    datalist = [getdata(x) for x in arraylist]\n    masklist = [np.atleast_1d(getmaskarray(x)) for x in arraylist]\n    _array = recfromarrays(datalist,\n                           dtype=dtype, shape=shape, formats=formats,\n                           names=names, titles=titles, aligned=aligned,\n                           byteorder=byteorder).view(mrecarray)\n    _array._mask.flat = list(zip(*masklist))\n    if fill_value is not None:\n        _array.fill_value = fill_value\n    return _array\n\n\ndef fromrecords(reclist, dtype=None, shape=None, formats=None, names=None,\n                titles=None, aligned=False, byteorder=None,\n                fill_value=None, mask=nomask):\n    \n        _mask = getattr(reclist, \'_mask\', None)\n        if isinstance(reclist, ndarray):\n                if isinstance(reclist, MaskedArray):\n            reclist = reclist.filled().view(ndarray)\n                if dtype is None:\n            dtype = reclist.dtype\n        reclist = reclist.tolist()\n    mrec = recfromrecords(reclist, dtype=dtype, shape=shape, formats=formats,\n                          names=names, titles=titles,\n                          aligned=aligned, byteorder=byteorder).view(mrecarray)\n        if fill_value is not None:\n        mrec.fill_value = fill_value\n        if mask is not nomask:\n        mask = np.array(mask, copy=False)\n        maskrecordlength = len(mask.dtype)\n        if maskrecordlength:\n            mrec._mask.flat = mask\n        elif len(mask.shape) == 2:\n            mrec._mask.flat = [tuple(m) for m in mask]\n        else:\n            mrec.__setmask__(mask)\n    if _mask is not None:\n        mrec._mask[:] = _mask\n    return mrec\n\n\ndef _guessvartypes(arr):\n    \n    vartypes = []\n    arr = np.asarray(arr)\n    if len(arr.shape) == 2:\n        arr = arr[0]\n    elif len(arr.shape) > 2:\n        raise ValueError("The array should be 2D at most!")\n        for f in arr:\n        try:\n            int(f)\n        except ValueError:\n            try:\n                float(f)\n            except ValueError:\n                try:\n                    complex(f)\n                except ValueError:\n                    vartypes.append(arr.dtype)\n                else:\n                    vartypes.append(np.dtype(complex))\n            else:\n                vartypes.append(np.dtype(float))\n        else:\n            vartypes.append(np.dtype(int))\n    return vartypes\n\n\ndef openfile(fname):\n    \n        if hasattr(fname, \'readline\'):\n        return fname\n        try:\n        f = open(fname)\n    except IOError:\n        raise IOError("No such file: \'%s\'" % fname)\n    if f.readline()[:2] != "\\\\x":\n        f.seek(0, 0)\n        return f\n    f.close()\n    raise NotImplementedError("Wow, binary file")\n\n\ndef fromtextfile(fname, delimitor=None, commentchar=\'                 varnames=None, vartypes=None):\n    \n        ftext = openfile(fname)\n\n        while True:\n        line = ftext.readline()\n        firstline = line[:line.find(commentchar)].strip()\n        _varnames = firstline.split(delimitor)\n        if len(_varnames) > 1:\n            break\n    if varnames is None:\n        varnames = _varnames\n\n        _variables = masked_array([line.strip().split(delimitor) for line in ftext\n                               if line[0] != commentchar and len(line) > 1])\n    (_, nfields) = _variables.shape\n    ftext.close()\n\n        if vartypes is None:\n        vartypes = _guessvartypes(_variables[0])\n    else:\n        vartypes = [np.dtype(v) for v in vartypes]\n        if len(vartypes) != nfields:\n            msg = "Attempting to %i dtypes for %i fields!"\n            msg += " Reverting to default."\n            warnings.warn(msg % (len(vartypes), nfields))\n            vartypes = _guessvartypes(_variables[0])\n\n        mdescr = [(n, f) for (n, f) in zip(varnames, vartypes)]\n    mfillv = [ma.default_fill_value(f) for f in vartypes]\n\n            _mask = (_variables.T == missingchar)\n    _datalist = [masked_array(a, mask=m, dtype=t, fill_value=f)\n                 for (a, m, t, f) in zip(_variables.T, _mask, vartypes, mfillv)]\n\n    return fromarrays(_datalist, dtype=mdescr)\n\n\ndef addfield(mrecord, newfield, newfieldname=None):\n    \n    _data = mrecord._data\n    _mask = mrecord._mask\n    if newfieldname is None or newfieldname in reserved_fields:\n        newfieldname = \'f%i\' % len(_data.dtype)\n    newfield = ma.array(newfield)\n            newdtype = np.dtype(_data.dtype.descr + [(newfieldname, newfield.dtype)])\n    newdata = recarray(_data.shape, newdtype)\n        [newdata.setfield(_data.getfield(*f), *f)\n         for f in _data.dtype.fields.values()]\n        newdata.setfield(newfield._data, *newdata.dtype.fields[newfieldname])\n    newdata = newdata.view(MaskedRecords)\n            newmdtype = np.dtype([(n, bool_) for n in newdtype.names])\n    newmask = recarray(_data.shape, newmdtype)\n        [newmask.setfield(_mask.getfield(*f), *f)\n         for f in _mask.dtype.fields.values()]\n        newmask.setfield(getmaskarray(newfield),\n                     *newmask.dtype.fields[newfieldname])\n    newdata._mask = newmask\n    return newdata\nimport os\nimport distutils.msvc9compiler\nfrom distutils.msvc9compiler import *\n\n\nclass MSVCCompiler(distutils.msvc9compiler.MSVCCompiler):\n    def __init__(self, verbose=0, dry_run=0, force=0):\n        distutils.msvc9compiler.MSVCCompiler.__init__(self, verbose, dry_run, force)\n\n    def initialize(self, plat_name=None):\n        environ_lib = os.getenv(\'lib\')\n        environ_include = os.getenv(\'include\')\n        distutils.msvc9compiler.MSVCCompiler.initialize(self, plat_name)\n        if environ_lib is not None:\n            os.environ[\'lib\'] = environ_lib + os.environ[\'lib\']\n        if environ_include is not None:\n            os.environ[\'include\'] = environ_include + os.environ[\'include\']\n\n    def manifest_setup_ldargs(self, output_filename, build_temp, ld_args):\n        ld_args.append(\'/MANIFEST\')\n        distutils.msvc9compiler.MSVCCompiler.manifest_setup_ldargs(self,\n                                                                   output_filename,\n                                                                   build_temp, ld_args)\nimport os\nimport distutils.msvccompiler\nfrom distutils.msvccompiler import *\n\nfrom .system_info import platform_bits\n\n\nclass MSVCCompiler(distutils.msvccompiler.MSVCCompiler):\n    def __init__(self, verbose=0, dry_run=0, force=0):\n        distutils.msvccompiler.MSVCCompiler.__init__(self, verbose, dry_run, force)\n\n    def initialize(self, plat_name=None):\n        environ_lib = os.getenv(\'lib\')\n        environ_include = os.getenv(\'include\')\n        distutils.msvccompiler.MSVCCompiler.initialize(self, plat_name)\n        if environ_lib is not None:\n            os.environ[\'lib\'] = environ_lib + os.environ[\'lib\']\n        if environ_include is not None:\n            os.environ[\'include\'] = environ_include + os.environ[\'include\']\n        if platform_bits == 32:\n                                    self.compile_options += [\'/arch:SSE2\']\n            self.compile_options_debug += [\'/arch:SSE2\']\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'NAGFCompiler\']\n\nclass NAGFCompiler(FCompiler):\n\n    compiler_type = \'nag\'\n    description = \'NAGWare Fortran 95 Compiler\'\n    version_pattern =  r\'NAGWare Fortran 95 compiler Release (?P<version>[^\\s]*)\'\n\n    executables = {\n        \'version_cmd\'  : ["<F90>", "-V"],\n        \'compiler_f77\' : ["f95", "-fixed"],\n        \'compiler_fix\' : ["f95", "-fixed"],\n        \'compiler_f90\' : ["f95"],\n        \'linker_so\'    : ["<F90>"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n\n    def get_flags_linker_so(self):\n        if sys.platform==\'darwin\':\n            return [\'-unsharedf95\', \'-Wl,-bundle,-flat_namespace,-undefined,suppress\']\n        return ["-Wl,-shared"]\n    def get_flags_opt(self):\n        return [\'-O4\']\n    def get_flags_arch(self):\n        version = self.get_version()\n        if version and version < \'5.1\':\n            return [\'-target=native\']\n        else:\n            return [\'\']\n    def get_flags_debug(self):\n        return [\'-g\', \'-gline\', \'-g90\', \'-nan\', \'-C\']\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'nag\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport numpy as np\nfrom numpy.lib.function_base import _ureduce as _ureduce\n\n__all__ = [\n    \'nansum\', \'nanmax\', \'nanmin\', \'nanargmax\', \'nanargmin\', \'nanmean\',\n    \'nanmedian\', \'nanpercentile\', \'nanvar\', \'nanstd\', \'nanprod\',\n    ]\n\n\ndef _replace_nan(a, val):\n    \n    is_new = not isinstance(a, np.ndarray)\n    if is_new:\n        a = np.array(a)\n    if not issubclass(a.dtype.type, np.inexact):\n        return a, None\n    if not is_new:\n                a = np.array(a, subok=True)\n\n    mask = np.isnan(a)\n    np.copyto(a, val, where=mask)\n    return a, mask\n\n\ndef _copyto(a, val, mask):\n    \n    if isinstance(a, np.ndarray):\n        np.copyto(a, val, where=mask, casting=\'unsafe\')\n    else:\n        a = a.dtype.type(val)\n    return a\n\n\ndef _divide_by_count(a, b, out=None):\n    \n    with np.errstate(invalid=\'ignore\'):\n        if isinstance(a, np.ndarray):\n            if out is None:\n                return np.divide(a, b, out=a, casting=\'unsafe\')\n            else:\n                return np.divide(a, b, out=out, casting=\'unsafe\')\n        else:\n            if out is None:\n                return a.dtype.type(a / b)\n            else:\n                                                return np.divide(a, b, out=out, casting=\'unsafe\')\n\n\ndef nanmin(a, axis=None, out=None, keepdims=False):\n    \n    if not isinstance(a, np.ndarray) or type(a) is np.ndarray:\n                res = np.fmin.reduce(a, axis=axis, out=out, keepdims=keepdims)\n        if np.isnan(res).any():\n            warnings.warn("All-NaN axis encountered", RuntimeWarning)\n    else:\n                a, mask = _replace_nan(a, +np.inf)\n        res = np.amin(a, axis=axis, out=out, keepdims=keepdims)\n        if mask is None:\n            return res\n\n                mask = np.all(mask, axis=axis, keepdims=keepdims)\n        if np.any(mask):\n            res = _copyto(res, np.nan, mask)\n            warnings.warn("All-NaN axis encountered", RuntimeWarning)\n    return res\n\n\ndef nanmax(a, axis=None, out=None, keepdims=False):\n    \n    if not isinstance(a, np.ndarray) or type(a) is np.ndarray:\n                res = np.fmax.reduce(a, axis=axis, out=out, keepdims=keepdims)\n        if np.isnan(res).any():\n            warnings.warn("All-NaN slice encountered", RuntimeWarning)\n    else:\n                a, mask = _replace_nan(a, -np.inf)\n        res = np.amax(a, axis=axis, out=out, keepdims=keepdims)\n        if mask is None:\n            return res\n\n                mask = np.all(mask, axis=axis, keepdims=keepdims)\n        if np.any(mask):\n            res = _copyto(res, np.nan, mask)\n            warnings.warn("All-NaN axis encountered", RuntimeWarning)\n    return res\n\n\ndef nanargmin(a, axis=None):\n    \n    a, mask = _replace_nan(a, np.inf)\n    res = np.argmin(a, axis=axis)\n    if mask is not None:\n        mask = np.all(mask, axis=axis)\n        if np.any(mask):\n            raise ValueError("All-NaN slice encountered")\n    return res\n\n\ndef nanargmax(a, axis=None):\n    \n    a, mask = _replace_nan(a, -np.inf)\n    res = np.argmax(a, axis=axis)\n    if mask is not None:\n        mask = np.all(mask, axis=axis)\n        if np.any(mask):\n            raise ValueError("All-NaN slice encountered")\n    return res\n\n\ndef nansum(a, axis=None, dtype=None, out=None, keepdims=0):\n    \n    a, mask = _replace_nan(a, 0)\n    return np.sum(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n\ndef nanprod(a, axis=None, dtype=None, out=None, keepdims=0):\n    \n    a, mask = _replace_nan(a, 1)\n    return np.prod(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n\ndef nanmean(a, axis=None, dtype=None, out=None, keepdims=False):\n    \n    arr, mask = _replace_nan(a, 0)\n    if mask is None:\n        return np.mean(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n\n    if dtype is not None:\n        dtype = np.dtype(dtype)\n    if dtype is not None and not issubclass(dtype.type, np.inexact):\n        raise TypeError("If a is inexact, then dtype must be inexact")\n    if out is not None and not issubclass(out.dtype.type, np.inexact):\n        raise TypeError("If a is inexact, then out must be inexact")\n\n        with warnings.catch_warnings():\n        warnings.simplefilter(\'ignore\')\n        cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims)\n        tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n        avg = _divide_by_count(tot, cnt, out=out)\n\n    isbad = (cnt == 0)\n    if isbad.any():\n        warnings.warn("Mean of empty slice", RuntimeWarning)\n                    return avg\n\n\ndef _nanmedian1d(arr1d, overwrite_input=False):\n    \n    c = np.isnan(arr1d)\n    s = np.where(c)[0]\n    if s.size == arr1d.size:\n        warnings.warn("All-NaN slice encountered", RuntimeWarning)\n        return np.nan\n    elif s.size == 0:\n        return np.median(arr1d, overwrite_input=overwrite_input)\n    else:\n        if overwrite_input:\n            x = arr1d\n        else:\n            x = arr1d.copy()\n                enonan = arr1d[-s.size:][~c[-s.size:]]\n                x[s[:enonan.size]] = enonan\n                return np.median(x[:-s.size], overwrite_input=True)\n\n\ndef _nanmedian(a, axis=None, out=None, overwrite_input=False):\n    \n    if axis is None or a.ndim == 1:\n        part = a.ravel()\n        if out is None:\n            return _nanmedian1d(part, overwrite_input)\n        else:\n            out[...] = _nanmedian1d(part, overwrite_input)\n            return out\n    else:\n                        if a.shape[axis] < 400:\n            return _nanmedian_small(a, axis, out, overwrite_input)\n        result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n        if out is not None:\n            out[...] = result\n        return result\n\ndef _nanmedian_small(a, axis=None, out=None, overwrite_input=False):\n    \n    a = np.ma.masked_array(a, np.isnan(a))\n    m = np.ma.median(a, axis=axis, overwrite_input=overwrite_input)\n    for i in range(np.count_nonzero(m.mask.ravel())):\n        warnings.warn("All-NaN slice encountered", RuntimeWarning)\n    if out is not None:\n        out[...] = m.filled(np.nan)\n        return out\n    return m.filled(np.nan)\n\ndef nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \n    a = np.asanyarray(a)\n            if a.size == 0:\n        return np.nanmean(a, axis, out=out, keepdims=keepdims)\n\n    r, k = _ureduce(a, func=_nanmedian, axis=axis, out=out,\n                    overwrite_input=overwrite_input)\n    if keepdims:\n        return r.reshape(k)\n    else:\n        return r\n\n\ndef nanpercentile(a, q, axis=None, out=None, overwrite_input=False,\n                  interpolation=\'linear\', keepdims=False):\n    \n\n    a = np.asanyarray(a)\n    q = np.asanyarray(q)\n            if a.size == 0:\n        return np.nanmean(a, axis, out=out, keepdims=keepdims)\n\n    r, k = _ureduce(a, func=_nanpercentile, q=q, axis=axis, out=out,\n                    overwrite_input=overwrite_input,\n                    interpolation=interpolation)\n    if keepdims:\n        if q.ndim == 0:\n            return r.reshape(k)\n        else:\n            return r.reshape([len(q)] + k)\n    else:\n        return r\n\n\ndef _nanpercentile(a, q, axis=None, out=None, overwrite_input=False,\n                   interpolation=\'linear\', keepdims=False):\n    \n    if axis is None:\n        part = a.ravel()\n        result = _nanpercentile1d(part, q, overwrite_input, interpolation)\n    else:\n        result = np.apply_along_axis(_nanpercentile1d, axis, a, q,\n                                     overwrite_input, interpolation)\n\n    if out is not None:\n        out[...] = result\n    return result\n\n\ndef _nanpercentile1d(arr1d, q, overwrite_input=False, interpolation=\'linear\'):\n    \n    c = np.isnan(arr1d)\n    s = np.where(c)[0]\n    if s.size == arr1d.size:\n        warnings.warn("All-NaN slice encountered", RuntimeWarning)\n        return np.nan\n    elif s.size == 0:\n        return np.percentile(arr1d, q, overwrite_input=overwrite_input,\n                             interpolation=interpolation)\n    else:\n        if overwrite_input:\n            x = arr1d\n        else:\n            x = arr1d.copy()\n                enonan = arr1d[-s.size:][~c[-s.size:]]\n                x[s[:enonan.size]] = enonan\n                return np.percentile(x[:-s.size], q, overwrite_input=True,\n                             interpolation=interpolation)\n\n\ndef nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \n    arr, mask = _replace_nan(a, 0)\n    if mask is None:\n        return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                      keepdims=keepdims)\n\n    if dtype is not None:\n        dtype = np.dtype(dtype)\n    if dtype is not None and not issubclass(dtype.type, np.inexact):\n        raise TypeError("If a is inexact, then dtype must be inexact")\n    if out is not None and not issubclass(out.dtype.type, np.inexact):\n        raise TypeError("If a is inexact, then out must be inexact")\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\'ignore\')\n\n                cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=True)\n        avg = np.sum(arr, axis=axis, dtype=dtype, keepdims=True)\n        avg = _divide_by_count(avg, cnt)\n\n                np.subtract(arr, avg, out=arr, casting=\'unsafe\')\n        arr = _copyto(arr, 0, mask)\n        if issubclass(arr.dtype.type, np.complexfloating):\n            sqr = np.multiply(arr, arr.conj(), out=arr).real\n        else:\n            sqr = np.multiply(arr, arr, out=arr)\n\n                var = np.sum(sqr, axis=axis, dtype=dtype, out=out, keepdims=keepdims)\n        if var.ndim < cnt.ndim:\n                        cnt = cnt.squeeze(axis)\n        dof = cnt - ddof\n        var = _divide_by_count(var, dof)\n\n    isbad = (dof <= 0)\n    if np.any(isbad):\n        warnings.warn("Degrees of freedom <= 0 for slice.", RuntimeWarning)\n                        var = _copyto(var, np.nan, isbad)\n    return var\n\n\ndef nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n    \n    var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                 keepdims=keepdims)\n    if isinstance(var, np.ndarray):\n        std = np.sqrt(var, out=var)\n    else:\n        std = var.dtype.type(np.sqrt(var))\n    return std\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'NoneFCompiler\']\n\nclass NoneFCompiler(FCompiler):\n\n    compiler_type = \'none\'\n    description = \'Fake Fortran compiler\'\n\n    executables = {\'compiler_f77\': None,\n                   \'compiler_f90\': None,\n                   \'compiler_fix\': None,\n                   \'linker_so\': None,\n                   \'linker_exe\': None,\n                   \'archiver\': None,\n                   \'ranlib\': None,\n                   \'version_cmd\': None,\n                   }\n\n    def find_executables(self):\n        pass\n\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    compiler = NoneFCompiler()\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport doctest\n\nimport nose\nfrom nose.plugins import doctests as npd\nfrom nose.plugins.errorclass import ErrorClass, ErrorClassPlugin\nfrom nose.plugins.base import Plugin\nfrom nose.util import src\nimport numpy\nfrom .nosetester import get_package_name\nimport inspect\n\n\nclass NumpyDocTestFinder(doctest.DocTestFinder):\n\n    def _from_module(self, module, object):\n        \n        if module is None:\n                        return True\n        elif inspect.isfunction(object):\n                        return module.__dict__ is object.__globals__\n        elif inspect.isbuiltin(object):\n                        return module.__name__ == object.__module__\n        elif inspect.isclass(object):\n                        return module.__name__ == object.__module__\n        elif inspect.ismethod(object):\n                                                                        return module.__name__ == object.__self__.__class__.__module__\n        elif inspect.getmodule(object) is not None:\n                                    return module is inspect.getmodule(object)\n        elif hasattr(object, \'__module__\'):\n                        return module.__name__ == object.__module__\n        elif isinstance(object, property):\n                        return True          else:\n            raise ValueError("object must be a class or function")\n\n    def _find(self, tests, obj, name, module, source_lines, globs, seen):\n        \n\n        doctest.DocTestFinder._find(self, tests, obj, name, module,\n                                    source_lines, globs, seen)\n\n                        \n                from inspect import (\n            isroutine, isclass, ismodule, isfunction, ismethod\n            )\n\n                if ismodule(obj) and self._recurse:\n            for valname, val in obj.__dict__.items():\n                valname1 = \'%s.%s\' % (name, valname)\n                if ( (isroutine(val) or isclass(val))\n                     and self._from_module(module, val)):\n\n                    self._find(tests, val, valname1, module, source_lines,\n                               globs, seen)\n\n                if isclass(obj) and self._recurse:\n                        for valname, val in obj.__dict__.items():\n                                                                if isinstance(val, staticmethod):\n                    val = getattr(obj, valname)\n                if isinstance(val, classmethod):\n                    val = getattr(obj, valname).__func__\n\n                                if ((isfunction(val) or isclass(val) or\n                     ismethod(val) or isinstance(val, property)) and\n                      self._from_module(module, val)):\n                    valname = \'%s.%s\' % (name, valname)\n                    self._find(tests, val, valname, module, source_lines,\n                               globs, seen)\n\n\nclass NumpyOutputChecker(doctest.OutputChecker):\n    def check_output(self, want, got, optionflags):\n        ret = doctest.OutputChecker.check_output(self, want, got,\n                                                 optionflags)\n        if not ret:\n            if "                return True\n\n                                                            got = got.replace("\'>", "\'<")\n            want = want.replace("\'>", "\'<")\n\n                        for sz in [4, 8]:\n                got = got.replace("\'<i%d\'" % sz, "int")\n                want = want.replace("\'<i%d\'" % sz, "int")\n\n            ret = doctest.OutputChecker.check_output(self, want,\n                    got, optionflags)\n\n        return ret\n\n\nclass NumpyDocTestCase(npd.DocTestCase):\n    def __init__(self, test, optionflags=0, setUp=None, tearDown=None,\n                 checker=None, obj=None, result_var=\'_\'):\n        self._result_var = result_var\n        self._nose_obj = obj\n        doctest.DocTestCase.__init__(self, test,\n                                     optionflags=optionflags,\n                                     setUp=setUp, tearDown=tearDown,\n                                     checker=checker)\n\n\nprint_state = numpy.get_printoptions()\n\nclass NumpyDoctest(npd.Doctest):\n    name = \'numpydoctest\'       score = 1000  \n        doctest_optflags = doctest.NORMALIZE_WHITESPACE | doctest.ELLIPSIS\n\n        doctest_ignore = [\'generate_numpy_api.py\',\n                      \'setup.py\']\n\n        doctest_case_class = NumpyDocTestCase\n    out_check_class = NumpyOutputChecker\n    test_finder_class = NumpyDocTestFinder\n\n        def options(self, parser, env=os.environ):\n        Plugin.options(self, parser, env)\n                        self.doctest_tests = True\n                        self.doctest_result_var = None\n\n    def configure(self, options, config):\n                Plugin.configure(self, options, config)\n        self.finder = self.test_finder_class()\n        self.parser = doctest.DocTestParser()\n        if self.enabled:\n                                                            config.plugins.plugins = [p for p in config.plugins.plugins\n                                      if p.name != \'doctest\']\n\n    def set_test_context(self, test):\n        \n                pkg_name = get_package_name(os.path.dirname(test.filename))\n\n                                                                        test.globs = {\'__builtins__\':__builtins__,\n                      \'__file__\':\'__main__\',\n                      \'__name__\':\'__main__\',\n                      \'np\':numpy}\n                if \'scipy\' in pkg_name:\n            p = pkg_name.split(\'.\')\n            p2 = p[-1]\n            test.globs[p2] = __import__(pkg_name, test.globs, {}, [p2])\n\n                def loadTestsFromModule(self, module):\n        if not self.matches(module.__name__):\n            npd.log.debug("Doctest doesn\'t want module %s", module)\n            return\n        try:\n            tests = self.finder.find(module)\n        except AttributeError:\n                                    return\n        if not tests:\n            return\n        tests.sort()\n        module_file = src(module.__file__)\n        for test in tests:\n            if not test.examples:\n                continue\n            if not test.filename:\n                test.filename = module_file\n                        self.set_test_context(test)\n            yield self.doctest_case_class(test,\n                                          optionflags=self.doctest_optflags,\n                                          checker=self.out_check_class(),\n                                          result_var=self.doctest_result_var)\n\n            def afterContext(self):\n        numpy.set_printoptions(**print_state)\n\n        def wantFile(self, file):\n        bn = os.path.basename(file)\n        if bn in self.doctest_ignore:\n            return False\n        return npd.Doctest.wantFile(self, file)\n\n\nclass Unplugger(object):\n    \n    name = \'unplugger\'\n    enabled = True      score = 4000  \n    def __init__(self, to_unplug=\'doctest\'):\n        self.to_unplug = to_unplug\n\n    def options(self, parser, env):\n        pass\n\n    def configure(self, options, config):\n                config.plugins.plugins = [p for p in config.plugins.plugins\n                                  if p.name != self.to_unplug]\n\n\nclass KnownFailureTest(Exception):\n    \n    pass\n\n\nclass KnownFailure(ErrorClassPlugin):\n    \n    enabled = True\n    knownfail = ErrorClass(KnownFailureTest,\n                           label=\'KNOWNFAIL\',\n                           isfailure=False)\n\n    def options(self, parser, env=os.environ):\n        env_opt = \'NOSE_WITHOUT_KNOWNFAIL\'\n        parser.add_option(\'--no-knownfail\', action=\'store_true\',\n                          dest=\'noKnownFail\', default=env.get(env_opt, False),\n                          help=\'Disable special handling of KnownFailureTest \'\n                               \'exceptions\')\n\n    def configure(self, options, conf):\n        if not self.can_configure:\n            return\n        self.conf = conf\n        disable = getattr(options, \'noKnownFail\', False)\n        if disable:\n            self.enabled = False\n\n\nclass NumpyTestProgram(nose.core.TestProgram):\n    def runTests(self):\n        \n        if self.testRunner is None:\n            self.testRunner = nose.core.TextTestRunner(stream=self.config.stream,\n                                                       verbosity=self.config.verbosity,\n                                                       config=self.config)\n        plug_runner = self.config.plugins.prepareTestRunner(self.testRunner)\n        if plug_runner is not None:\n            self.testRunner = plug_runner\n        self.result = self.testRunner.run(self.test)\n        self.success = self.result.wasSuccessful()\n        return self.success\n\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport sys\nimport warnings\nfrom numpy.compat import basestring\nimport numpy as np\n\n\ndef get_package_name(filepath):\n    \n\n    fullpath = filepath[:]\n    pkg_name = []\n    while \'site-packages\' in filepath or \'dist-packages\' in filepath:\n        filepath, p2 = os.path.split(filepath)\n        if p2 in (\'site-packages\', \'dist-packages\'):\n            break\n        pkg_name.append(p2)\n\n        if not pkg_name:\n        if \'scipy\' in fullpath:\n            return \'scipy\'\n        else:\n            return \'numpy\'\n\n        pkg_name.reverse()\n\n        if pkg_name[0].endswith(\'.egg\'):\n        pkg_name.pop(0)\n\n    return \'.\'.join(pkg_name)\n\ndef import_nose():\n    \n    fine_nose = True\n    minimum_nose_version = (0, 10, 0)\n    try:\n        import nose\n    except ImportError:\n        fine_nose = False\n    else:\n        if nose.__versioninfo__ < minimum_nose_version:\n            fine_nose = False\n\n    if not fine_nose:\n        msg = (\'Need nose >= %d.%d.%d for tests - see \'\n               \'http://somethingaboutorange.com/mrl/projects/nose\' %\n               minimum_nose_version)\n        raise ImportError(msg)\n\n    return nose\n\ndef run_module_suite(file_to_run=None, argv=None):\n    \n    if file_to_run is None:\n        f = sys._getframe(1)\n        file_to_run = f.f_locals.get(\'__file__\', None)\n        if file_to_run is None:\n            raise AssertionError\n\n    if argv is None:\n        argv = sys.argv + [file_to_run]\n    else:\n        argv = argv + [file_to_run]\n\n    nose = import_nose()\n    from .noseclasses import KnownFailure\n    nose.run(argv=argv, addplugins=[KnownFailure()])\n\n\nclass NoseTester(object):\n    \n        excludes = [\'f2py_ext\',\n                \'f2py_f90_ext\',\n                \'gen_ext\',\n                \'pyrex_ext\',\n                \'swig_ext\']\n\n    def __init__(self, package=None, raise_warnings=None):\n        if raise_warnings is None and \'.dev0\' in np.__version__:\n            raise_warnings = "develop"\n        elif raise_warnings is None:\n            raise_warnings = "release"\n\n        package_name = None\n        if package is None:\n            f = sys._getframe(1)\n            package_path = f.f_locals.get(\'__file__\', None)\n            if package_path is None:\n                raise AssertionError\n            package_path = os.path.dirname(package_path)\n            package_name = f.f_locals.get(\'__name__\', None)\n        elif isinstance(package, type(os)):\n            package_path = os.path.dirname(package.__file__)\n            package_name = getattr(package, \'__name__\', None)\n        else:\n            package_path = str(package)\n\n        self.package_path = package_path\n\n                        if package_name is None:\n            package_name = get_package_name(package_path)\n        self.package_name = package_name\n\n                self.raise_warnings = raise_warnings\n\n    def _test_argv(self, label, verbose, extra_argv):\n        \n        argv = [__file__, self.package_path, \'-s\']\n        if label and label != \'full\':\n            if not isinstance(label, basestring):\n                raise TypeError(\'Selection label should be a string\')\n            if label == \'fast\':\n                label = \'not slow\'\n            argv += [\'-A\', label]\n        argv += [\'--verbosity\', str(verbose)]\n\n                                                argv += [\'--exe\']\n\n        if extra_argv:\n            argv += extra_argv\n        return argv\n\n    def _show_system_info(self):\n        nose = import_nose()\n\n        import numpy\n        print("NumPy version %s" % numpy.__version__)\n        relaxed_strides = numpy.ones((10, 1), order="C").flags.f_contiguous\n        print("NumPy relaxed strides checking option:", relaxed_strides)\n        npdir = os.path.dirname(numpy.__file__)\n        print("NumPy is installed in %s" % npdir)\n\n        if \'scipy\' in self.package_name:\n            import scipy\n            print("SciPy version %s" % scipy.__version__)\n            spdir = os.path.dirname(scipy.__file__)\n            print("SciPy is installed in %s" % spdir)\n\n        pyversion = sys.version.replace(\'\\n\', \'\')\n        print("Python version %s" % pyversion)\n        print("nose version %d.%d.%d" % nose.__versioninfo__)\n\n    def _get_custom_doctester(self):\n        \n        from .noseclasses import NumpyDoctest\n        return NumpyDoctest()\n\n    def prepare_test_args(self, label=\'fast\', verbose=1, extra_argv=None,\n                          doctests=False, coverage=False):\n        \n                import_nose()\n                argv = self._test_argv(label, verbose, extra_argv)\n                for ename in self.excludes:\n            argv += [\'--exclude\', ename]\n                if coverage:\n            argv += [\'--cover-package=%s\' % self.package_name, \'--with-coverage\',\n                   \'--cover-tests\', \'--cover-erase\']\n                import nose.plugins.builtin\n        from .noseclasses import KnownFailure, Unplugger\n        plugins = [KnownFailure()]\n        plugins += [p() for p in nose.plugins.builtin.plugins]\n                doctest_argv = \'--with-doctest\' in argv\n        if doctests == False and doctest_argv:\n            doctests = True\n        plug = self._get_custom_doctester()\n        if plug is None:\n                        if doctests and not doctest_argv:\n                argv += [\'--with-doctest\']\n        else:              if doctest_argv:                  argv.remove(\'--with-doctest\')\n            plugins += [Unplugger(\'doctest\'), plug]\n            if doctests:\n                argv += [\'--with-\' + plug.name]\n        return argv, plugins\n\n    def test(self, label=\'fast\', verbose=1, extra_argv=None,\n            doctests=False, coverage=False,\n            raise_warnings=None):\n        \n\n                verbose = min(verbose, 3)\n\n        from . import utils\n        utils.verbose = verbose\n\n        if doctests:\n            print("Running unit tests and doctests for %s" % self.package_name)\n        else:\n            print("Running unit tests for %s" % self.package_name)\n\n        self._show_system_info()\n\n                import doctest\n        doctest.master = None\n\n        if raise_warnings is None:\n            raise_warnings = self.raise_warnings\n\n        _warn_opts = dict(develop=(DeprecationWarning, RuntimeWarning),\n                          release=())\n        if isinstance(raise_warnings, basestring):\n            raise_warnings = _warn_opts[raise_warnings]\n\n        with warnings.catch_warnings():\n                                    warnings.resetwarnings()\n                                    warnings.filterwarnings(\'always\')\n                        for warningtype in raise_warnings:\n                warnings.filterwarnings(\'error\', category=warningtype)\n                        warnings.filterwarnings(\'ignore\', message=\'Not importing directory\')\n            warnings.filterwarnings("ignore", message="numpy.dtype size changed")\n            warnings.filterwarnings("ignore", message="numpy.ufunc size changed")\n            warnings.filterwarnings("ignore", category=np.ModuleDeprecationWarning)\n            warnings.filterwarnings("ignore", category=FutureWarning)\n                                    warnings.filterwarnings("ignore", message=".*boolean negative.*")\n            warnings.filterwarnings("ignore", message=".*boolean subtract.*")\n                                                warnings.filterwarnings("ignore", message=".*getargspec.*",\n                                    category=DeprecationWarning,\n                                    module="nose\\.")\n\n            from .noseclasses import NumpyTestProgram\n\n            argv, plugins = self.prepare_test_args(\n                    label, verbose, extra_argv, doctests, coverage)\n            t = NumpyTestProgram(argv=argv, exit=False, plugins=plugins)\n\n        return t.result\n\n    def bench(self, label=\'fast\', verbose=1, extra_argv=None):\n        \n\n        print("Running benchmarks for %s" % self.package_name)\n        self._show_system_info()\n\n        argv = self._test_argv(label, verbose, extra_argv)\n        argv += [\'--match\', r\'(?:^|[\\\\b_\\\\.%s-])[Bb]ench\' % os.sep]\n\n                nose = import_nose()\n\n                from .noseclasses import Unplugger\n        add_plugins = [Unplugger(\'doctest\')]\n\n        return nose.run(argv=argv, addplugins=add_plugins)\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport re\nimport os\n\nif sys.version_info[0] < 3:\n    from ConfigParser import SafeConfigParser, NoOptionError\nelse:\n    from configparser import ConfigParser, SafeConfigParser, NoOptionError\n\n__all__ = [\'FormatError\', \'PkgNotFound\', \'LibraryInfo\', \'VariableSet\',\n        \'read_config\', \'parse_flags\']\n\n_VAR = re.compile(\'\\$\\{([a-zA-Z0-9_-]+)\\}\')\n\nclass FormatError(IOError):\n    \n    def __init__(self, msg):\n        self.msg = msg\n\n    def __str__(self):\n        return self.msg\n\nclass PkgNotFound(IOError):\n    \n    def __init__(self, msg):\n        self.msg = msg\n\n    def __str__(self):\n        return self.msg\n\ndef parse_flags(line):\n    \n    d = {\'include_dirs\': [], \'library_dirs\': [], \'libraries\': [],\n         \'macros\': [], \'ignored\': []}\n\n    flags = (\' \' + line).split(\' -\')\n    for flag in flags:\n        flag = \'-\' + flag\n        if len(flag) > 0:\n            if flag.startswith(\'-I\'):\n                d[\'include_dirs\'].append(flag[2:].strip())\n            elif flag.startswith(\'-L\'):\n                d[\'library_dirs\'].append(flag[2:].strip())\n            elif flag.startswith(\'-l\'):\n                d[\'libraries\'].append(flag[2:].strip())\n            elif flag.startswith(\'-D\'):\n                d[\'macros\'].append(flag[2:].strip())\n            else:\n                d[\'ignored\'].append(flag)\n\n    return d\n\ndef _escape_backslash(val):\n    return val.replace(\'\\\\\', \'\\\\\\\\\')\n\nclass LibraryInfo(object):\n    \n    def __init__(self, name, description, version, sections, vars, requires=None):\n        self.name = name\n        self.description = description\n        if requires:\n            self.requires = requires\n        else:\n            self.requires = []\n        self.version = version\n        self._sections = sections\n        self.vars = vars\n\n    def sections(self):\n        \n        return list(self._sections.keys())\n\n    def cflags(self, section="default"):\n        val = self.vars.interpolate(self._sections[section][\'cflags\'])\n        return _escape_backslash(val)\n\n    def libs(self, section="default"):\n        val = self.vars.interpolate(self._sections[section][\'libs\'])\n        return _escape_backslash(val)\n\n    def __str__(self):\n        m = [\'Name: %s\' % self.name]\n        m.append(\'Description: %s\' % self.description)\n        if self.requires:\n            m.append(\'Requires:\')\n        else:\n            m.append(\'Requires: %s\' % ",".join(self.requires))\n        m.append(\'Version: %s\' % self.version)\n\n        return "\\n".join(m)\n\nclass VariableSet(object):\n    \n    def __init__(self, d):\n        self._raw_data = dict([(k, v) for k, v in d.items()])\n\n        self._re = {}\n        self._re_sub = {}\n\n        self._init_parse()\n\n    def _init_parse(self):\n        for k, v in self._raw_data.items():\n            self._init_parse_var(k, v)\n\n    def _init_parse_var(self, name, value):\n        self._re[name] = re.compile(r\'\\$\\{%s\\}\' % name)\n        self._re_sub[name] = value\n\n    def interpolate(self, value):\n                        def _interpolate(value):\n            for k in self._re.keys():\n                value = self._re[k].sub(self._re_sub[k], value)\n            return value\n        while _VAR.search(value):\n            nvalue = _interpolate(value)\n            if nvalue == value:\n                break\n            value = nvalue\n\n        return value\n\n    def variables(self):\n        \n        return list(self._raw_data.keys())\n\n        def __getitem__(self, name):\n        return self._raw_data[name]\n\n    def __setitem__(self, name, value):\n        self._raw_data[name] = value\n        self._init_parse_var(name, value)\n\ndef parse_meta(config):\n    if not config.has_section(\'meta\'):\n        raise FormatError("No meta section found !")\n\n    d = {}\n    for name, value in config.items(\'meta\'):\n        d[name] = value\n\n    for k in [\'name\', \'description\', \'version\']:\n        if not k in d:\n            raise FormatError("Option %s (section [meta]) is mandatory, "\n                "but not found" % k)\n\n    if not \'requires\' in d:\n        d[\'requires\'] = []\n\n    return d\n\ndef parse_variables(config):\n    if not config.has_section(\'variables\'):\n        raise FormatError("No variables section found !")\n\n    d = {}\n\n    for name, value in config.items("variables"):\n        d[name] = value\n\n    return VariableSet(d)\n\ndef parse_sections(config):\n    return meta_d, r\n\ndef pkg_to_filename(pkg_name):\n    return "%s.ini" % pkg_name\n\ndef parse_config(filename, dirs=None):\n    if dirs:\n        filenames = [os.path.join(d, filename) for d in dirs]\n    else:\n        filenames = [filename]\n\n    if sys.version[:3] > \'3.1\':\n                config = ConfigParser()\n    else:\n        config = SafeConfigParser()\n\n    n = config.read(filenames)\n    if not len(n) >= 1:\n        raise PkgNotFound("Could not find file(s) %s" % str(filenames))\n\n        meta = parse_meta(config)\n\n    vars = {}\n    if config.has_section(\'variables\'):\n        for name, value in config.items("variables"):\n            vars[name] = _escape_backslash(value)\n\n        secs = [s for s in config.sections() if not s in [\'meta\', \'variables\']]\n    sections = {}\n\n    requires = {}\n    for s in secs:\n        d = {}\n        if config.has_option(s, "requires"):\n            requires[s] = config.get(s, \'requires\')\n\n        for name, value in config.items(s):\n            d[name] = value\n        sections[s] = d\n\n    return meta, vars, sections, requires\n\ndef _read_config_imp(filenames, dirs=None):\n    def _read_config(f):\n        meta, vars, sections, reqs = parse_config(f, dirs)\n                for rname, rvalue in reqs.items():\n            nmeta, nvars, nsections, nreqs = _read_config(pkg_to_filename(rvalue))\n\n                        for k, v in nvars.items():\n                if not k in vars:\n                    vars[k] = v\n\n                        for oname, ovalue in nsections[rname].items():\n                if ovalue:\n                    sections[rname][oname] += \' %s\' % ovalue\n\n        return meta, vars, sections, reqs\n\n    meta, vars, sections, reqs = _read_config(filenames)\n\n                if not \'pkgdir\' in vars and "pkgname" in vars:\n        pkgname = vars["pkgname"]\n        if not pkgname in sys.modules:\n            raise ValueError("You should import %s to get information on %s" %\n                             (pkgname, meta["name"]))\n\n        mod = sys.modules[pkgname]\n        vars["pkgdir"] = _escape_backslash(os.path.dirname(mod.__file__))\n\n    return LibraryInfo(name=meta["name"], description=meta["description"],\n            version=meta["version"], sections=sections, vars=VariableSet(vars))\n\n_CACHE = {}\ndef read_config(pkgname, dirs=None):\n    \n    try:\n        return _CACHE[pkgname]\n    except KeyError:\n        v = _read_config_imp(pkg_to_filename(pkgname), dirs)\n        _CACHE[pkgname] = v\n        return v\n\n\nif __name__ == \'__main__\':\n    import sys\n    from optparse import OptionParser\n    import glob\n\n    parser = OptionParser()\n    parser.add_option("--cflags", dest="cflags", action="store_true",\n                      help="output all preprocessor and compiler flags")\n    parser.add_option("--libs", dest="libs", action="store_true",\n                      help="output all linker flags")\n    parser.add_option("--use-section", dest="section",\n                      help="use this section instead of default for options")\n    parser.add_option("--version", dest="version", action="store_true",\n                      help="output version")\n    parser.add_option("--atleast-version", dest="min_version",\n                      help="Minimal version")\n    parser.add_option("--list-all", dest="list_all", action="store_true",\n                      help="Minimal version")\n    parser.add_option("--define-variable", dest="define_variable",\n                      help="Replace variable with the given value")\n\n    (options, args) = parser.parse_args(sys.argv)\n\n    if len(args) < 2:\n        raise ValueError("Expect package name on the command line:")\n\n    if options.list_all:\n        files = glob.glob("*.ini")\n        for f in files:\n            info = read_config(f)\n            print("%s\\t%s - %s" % (info.name, info.name, info.description))\n\n    pkg_name = args[1]\n    import os\n    d = os.environ.get(\'NPY_PKG_CONFIG_PATH\')\n    if d:\n        info = read_config(pkg_name, [\'numpy/core/lib/npy-pkg-config\', \'.\', d])\n    else:\n        info = read_config(pkg_name, [\'numpy/core/lib/npy-pkg-config\', \'.\'])\n\n    if options.section:\n        section = options.section\n    else:\n        section = "default"\n\n    if options.define_variable:\n        m = re.search(\'([\\S]+)=([\\S]+)\', options.define_variable)\n        if not m:\n            raise ValueError("--define-variable option should be of " \\\n                             "the form --define-variable=foo=bar")\n        else:\n            name = m.group(1)\n            value = m.group(2)\n        info.vars[name] = value\n\n    if options.cflags:\n        print(info.cflags(section))\n    if options.libs:\n        print(info.libs(section))\n    if options.version:\n        print(info.version)\n    if options.min_version:\n        print(info.version >= options.min_version)\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport os\nimport re\nimport itertools\nimport warnings\nimport weakref\nfrom operator import itemgetter\n\nimport numpy as np\nfrom . import format\nfrom ._datasource import DataSource\nfrom numpy.core.multiarray import packbits, unpackbits\nfrom ._iotools import (\n    LineSplitter, NameValidator, StringConverter, ConverterError,\n    ConverterLockError, ConversionWarning, _is_string_like, has_nested_fields,\n    flatten_dtype, easy_dtype, _bytes_to_name\n    )\n\nfrom numpy.compat import (\n    asbytes, asstr, asbytes_nested, bytes, basestring, unicode\n    )\n\nif sys.version_info[0] >= 3:\n    import pickle\nelse:\n    import cPickle as pickle\n    from future_builtins import map\n\nloads = pickle.loads\n\n__all__ = [\n    \'savetxt\', \'loadtxt\', \'genfromtxt\', \'ndfromtxt\', \'mafromtxt\',\n    \'recfromtxt\', \'recfromcsv\', \'load\', \'loads\', \'save\', \'savez\',\n    \'savez_compressed\', \'packbits\', \'unpackbits\', \'fromregex\', \'DataSource\'\n    ]\n\n\nclass BagObj(object):\n    \n\n    def __init__(self, obj):\n                self._obj = weakref.proxy(obj)\n\n    def __getattribute__(self, key):\n        try:\n            return object.__getattribute__(self, \'_obj\')[key]\n        except KeyError:\n            raise AttributeError(key)\n\n    def __dir__(self):\n        \n        return object.__getattribute__(self, \'_obj\').keys()\n\n\ndef zipfile_factory(*args, **kwargs):\n    import zipfile\n    kwargs[\'allowZip64\'] = True\n    return zipfile.ZipFile(*args, **kwargs)\n\n\nclass NpzFile(object):\n    \n\n    def __init__(self, fid, own_fid=False, allow_pickle=True,\n                 pickle_kwargs=None):\n                        _zip = zipfile_factory(fid)\n        self._files = _zip.namelist()\n        self.files = []\n        self.allow_pickle = allow_pickle\n        self.pickle_kwargs = pickle_kwargs\n        for x in self._files:\n            if x.endswith(\'.npy\'):\n                self.files.append(x[:-4])\n            else:\n                self.files.append(x)\n        self.zip = _zip\n        self.f = BagObj(self)\n        if own_fid:\n            self.fid = fid\n        else:\n            self.fid = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n    def close(self):\n        \n        if self.zip is not None:\n            self.zip.close()\n            self.zip = None\n        if self.fid is not None:\n            self.fid.close()\n            self.fid = None\n        self.f = None  \n    def __del__(self):\n        self.close()\n\n    def __getitem__(self, key):\n                                                                        member = 0\n        if key in self._files:\n            member = 1\n        elif key in self.files:\n            member = 1\n            key += \'.npy\'\n        if member:\n            bytes = self.zip.open(key)\n            magic = bytes.read(len(format.MAGIC_PREFIX))\n            bytes.close()\n            if magic == format.MAGIC_PREFIX:\n                bytes = self.zip.open(key)\n                return format.read_array(bytes,\n                                         allow_pickle=self.allow_pickle,\n                                         pickle_kwargs=self.pickle_kwargs)\n            else:\n                return self.zip.read(key)\n        else:\n            raise KeyError("%s is not a file in the archive" % key)\n\n    def __iter__(self):\n        return iter(self.files)\n\n    def items(self):\n        \n        return [(f, self[f]) for f in self.files]\n\n    def iteritems(self):\n        \n        for f in self.files:\n            yield (f, self[f])\n\n    def keys(self):\n        \n        return self.files\n\n    def iterkeys(self):\n        \n        return self.__iter__()\n\n    def __contains__(self, key):\n        return self.files.__contains__(key)\n\n\ndef load(file, mmap_mode=None, allow_pickle=True, fix_imports=True,\n         encoding=\'ASCII\'):\n    \n    import gzip\n\n    own_fid = False\n    if isinstance(file, basestring):\n        fid = open(file, "rb")\n        own_fid = True\n    else:\n        fid = file\n\n    if encoding not in (\'ASCII\', \'latin1\', \'bytes\'):\n                                                                                                raise ValueError("encoding must be \'ASCII\', \'latin1\', or \'bytes\'")\n\n    if sys.version_info[0] >= 3:\n        pickle_kwargs = dict(encoding=encoding, fix_imports=fix_imports)\n    else:\n                pickle_kwargs = {}\n\n    try:\n                _ZIP_PREFIX = asbytes(\'PK\\x03\\x04\')\n        N = len(format.MAGIC_PREFIX)\n        magic = fid.read(N)\n        fid.seek(-N, 1)          if magic.startswith(_ZIP_PREFIX):\n                                    tmp = own_fid\n            own_fid = False\n            return NpzFile(fid, own_fid=tmp, allow_pickle=allow_pickle,\n                           pickle_kwargs=pickle_kwargs)\n        elif magic == format.MAGIC_PREFIX:\n                        if mmap_mode:\n                return format.open_memmap(file, mode=mmap_mode)\n            else:\n                return format.read_array(fid, allow_pickle=allow_pickle,\n                                         pickle_kwargs=pickle_kwargs)\n        else:\n                        if not allow_pickle:\n                raise ValueError("allow_pickle=False, but file does not contain "\n                                 "non-pickled data")\n            try:\n                return pickle.load(fid, **pickle_kwargs)\n            except:\n                raise IOError(\n                    "Failed to interpret file %s as a pickle" % repr(file))\n    finally:\n        if own_fid:\n            fid.close()\n\n\ndef save(file, arr, allow_pickle=True, fix_imports=True):\n    \n    own_fid = False\n    if isinstance(file, basestring):\n        if not file.endswith(\'.npy\'):\n            file = file + \'.npy\'\n        fid = open(file, "wb")\n        own_fid = True\n    else:\n        fid = file\n\n    if sys.version_info[0] >= 3:\n        pickle_kwargs = dict(fix_imports=fix_imports)\n    else:\n                pickle_kwargs = None\n\n    try:\n        arr = np.asanyarray(arr)\n        format.write_array(fid, arr, allow_pickle=allow_pickle,\n                           pickle_kwargs=pickle_kwargs)\n    finally:\n        if own_fid:\n            fid.close()\n\n\ndef savez(file, *args, **kwds):\n    \n    _savez(file, args, kwds, False)\n\n\ndef savez_compressed(file, *args, **kwds):\n    \n    _savez(file, args, kwds, True)\n\n\ndef _savez(file, args, kwds, compress, allow_pickle=True, pickle_kwargs=None):\n            import zipfile\n        import tempfile\n\n    if isinstance(file, basestring):\n        if not file.endswith(\'.npz\'):\n            file = file + \'.npz\'\n\n    namedict = kwds\n    for i, val in enumerate(args):\n        key = \'arr_%d\' % i\n        if key in namedict.keys():\n            raise ValueError(\n                "Cannot use un-named variables and keyword %s" % key)\n        namedict[key] = val\n\n    if compress:\n        compression = zipfile.ZIP_DEFLATED\n    else:\n        compression = zipfile.ZIP_STORED\n\n    zipf = zipfile_factory(file, mode="w", compression=compression)\n\n        fd, tmpfile = tempfile.mkstemp(suffix=\'-numpy.npy\')\n    os.close(fd)\n    try:\n        for key, val in namedict.items():\n            fname = key + \'.npy\'\n            fid = open(tmpfile, \'wb\')\n            try:\n                format.write_array(fid, np.asanyarray(val),\n                                   allow_pickle=allow_pickle,\n                                   pickle_kwargs=pickle_kwargs)\n                fid.close()\n                fid = None\n                zipf.write(tmpfile, arcname=fname)\n            finally:\n                if fid:\n                    fid.close()\n    finally:\n        os.remove(tmpfile)\n\n    zipf.close()\n\n\ndef _getconv(dtype):\n    \n\n    def floatconv(x):\n        x.lower()\n        if b\'0x\' in x:\n            return float.fromhex(asstr(x))\n        return float(x)\n\n    typ = dtype.type\n    if issubclass(typ, np.bool_):\n        return lambda x: bool(int(x))\n    if issubclass(typ, np.uint64):\n        return np.uint64\n    if issubclass(typ, np.int64):\n        return np.int64\n    if issubclass(typ, np.integer):\n        return lambda x: int(float(x))\n    elif issubclass(typ, np.longdouble):\n        return np.longdouble\n    elif issubclass(typ, np.floating):\n        return floatconv\n    elif issubclass(typ, np.complex):\n        return lambda x: complex(asstr(x))\n    elif issubclass(typ, np.bytes_):\n        return bytes\n    else:\n        return str\n\n\ndef loadtxt(fname, dtype=float, comments=\'            converters=None, skiprows=0, usecols=None, unpack=False,\n            ndmin=0):\n    \n        if comments is not None:\n        if isinstance(comments, (basestring, bytes)):\n            comments = [asbytes(comments)]\n        else:\n            comments = [asbytes(comment) for comment in comments]\n\n                comments = (re.escape(comment) for comment in comments)\n        regex_comments = re.compile(asbytes(\'|\').join(comments))\n    user_converters = converters\n    if delimiter is not None:\n        delimiter = asbytes(delimiter)\n    if usecols is not None:\n        usecols = list(usecols)\n\n    fown = False\n    try:\n        if _is_string_like(fname):\n            fown = True\n            if fname.endswith(\'.gz\'):\n                import gzip\n                fh = iter(gzip.GzipFile(fname))\n            elif fname.endswith(\'.bz2\'):\n                import bz2\n                fh = iter(bz2.BZ2File(fname))\n            elif sys.version_info[0] == 2:\n                fh = iter(open(fname, \'U\'))\n            else:\n                fh = iter(open(fname))\n        else:\n            fh = iter(fname)\n    except TypeError:\n        raise ValueError(\'fname must be a string, file handle, or generator\')\n    X = []\n\n    def flatten_dtype(dt):\n        \n        if dt.names is None:\n                                                shape = dt.shape\n            if len(shape) == 0:\n                return ([dt.base], None)\n            else:\n                packing = [(shape[-1], list)]\n                if len(shape) > 1:\n                    for dim in dt.shape[-2::-1]:\n                        packing = [(dim*packing[0][0], packing*dim)]\n                return ([dt.base] * int(np.prod(dt.shape)), packing)\n        else:\n            types = []\n            packing = []\n            for field in dt.names:\n                tp, bytes = dt.fields[field]\n                flat_dt, flat_packing = flatten_dtype(tp)\n                types.extend(flat_dt)\n                                if len(tp.shape) > 0:\n                    packing.extend(flat_packing)\n                else:\n                    packing.append((len(flat_dt), flat_packing))\n            return (types, packing)\n\n    def pack_items(items, packing):\n        \n        if packing is None:\n            return items[0]\n        elif packing is tuple:\n            return tuple(items)\n        elif packing is list:\n            return list(items)\n        else:\n            start = 0\n            ret = []\n            for length, subpacking in packing:\n                ret.append(pack_items(items[start:start+length], subpacking))\n                start += length\n            return tuple(ret)\n\n    def split_line(line):\n        \n        line = asbytes(line)\n        if comments is not None:\n            line = regex_comments.split(asbytes(line), maxsplit=1)[0]\n        line = line.strip(asbytes(\'\\r\\n\'))\n        if line:\n            return line.split(delimiter)\n        else:\n            return []\n\n    try:\n                dtype = np.dtype(dtype)\n        defconv = _getconv(dtype)\n\n                for i in range(skiprows):\n            next(fh)\n\n                        first_vals = None\n        try:\n            while not first_vals:\n                first_line = next(fh)\n                first_vals = split_line(first_line)\n        except StopIteration:\n                        first_line = \'\'\n            first_vals = []\n            warnings.warn(\'loadtxt: Empty input file: "%s"\' % fname)\n        N = len(usecols or first_vals)\n\n        dtype_types, packing = flatten_dtype(dtype)\n        if len(dtype_types) > 1:\n                                    converters = [_getconv(dt) for dt in dtype_types]\n        else:\n                        converters = [defconv for i in range(N)]\n            if N > 1:\n                packing = [(N, tuple)]\n\n                for i, conv in (user_converters or {}).items():\n            if usecols:\n                try:\n                    i = usecols.index(i)\n                except ValueError:\n                                        continue\n            converters[i] = conv\n\n                for i, line in enumerate(itertools.chain([first_line], fh)):\n            vals = split_line(line)\n            if len(vals) == 0:\n                continue\n            if usecols:\n                vals = [vals[i] for i in usecols]\n            if len(vals) != N:\n                line_num = i + skiprows + 1\n                raise ValueError("Wrong number of columns at line %d"\n                                 % line_num)\n\n                        items = [conv(val) for (conv, val) in zip(converters, vals)]\n                        items = pack_items(items, packing)\n            X.append(items)\n    finally:\n        if fown:\n            fh.close()\n\n    X = np.array(X, dtype)\n            if X.ndim == 3 and X.shape[:2] == (1, 1):\n        X.shape = (1, -1)\n\n            if ndmin not in [0, 1, 2]:\n        raise ValueError(\'Illegal value of ndmin keyword: %s\' % ndmin)\n        if X.ndim > ndmin:\n        X = np.squeeze(X)\n            if X.ndim < ndmin:\n        if ndmin == 1:\n            X = np.atleast_1d(X)\n        elif ndmin == 2:\n            X = np.atleast_2d(X).T\n\n    if unpack:\n        if len(dtype_types) > 1:\n                        return [X[field] for field in dtype.names]\n        else:\n            return X.T\n    else:\n        return X\n\n\ndef savetxt(fname, X, fmt=\'%.18e\', delimiter=\' \', newline=\'\\n\', header=\'\',\n            footer=\'\', comments=\'    \n\n        if isinstance(fmt, bytes):\n        fmt = asstr(fmt)\n    delimiter = asstr(delimiter)\n\n    own_fh = False\n    if _is_string_like(fname):\n        own_fh = True\n        if fname.endswith(\'.gz\'):\n            import gzip\n            fh = gzip.open(fname, \'wb\')\n        else:\n            if sys.version_info[0] >= 3:\n                fh = open(fname, \'wb\')\n            else:\n                fh = open(fname, \'w\')\n    elif hasattr(fname, \'write\'):\n        fh = fname\n    else:\n        raise ValueError(\'fname must be a string or file handle\')\n\n    try:\n        X = np.asarray(X)\n\n                if X.ndim == 1:\n                        if X.dtype.names is None:\n                X = np.atleast_2d(X).T\n                ncol = 1\n\n                        else:\n                ncol = len(X.dtype.descr)\n        else:\n            ncol = X.shape[1]\n\n        iscomplex_X = np.iscomplexobj(X)\n                        if type(fmt) in (list, tuple):\n            if len(fmt) != ncol:\n                raise AttributeError(\'fmt has wrong shape.  %s\' % str(fmt))\n            format = asstr(delimiter).join(map(asstr, fmt))\n        elif isinstance(fmt, str):\n            n_fmt_chars = fmt.count(\'%\')\n            error = ValueError(\'fmt has wrong number of %% formats:  %s\' % fmt)\n            if n_fmt_chars == 1:\n                if iscomplex_X:\n                    fmt = [\' (%s+%sj)\' % (fmt, fmt), ] * ncol\n                else:\n                    fmt = [fmt, ] * ncol\n                format = delimiter.join(fmt)\n            elif iscomplex_X and n_fmt_chars != (2 * ncol):\n                raise error\n            elif ((not iscomplex_X) and n_fmt_chars != ncol):\n                raise error\n            else:\n                format = fmt\n        else:\n            raise ValueError(\'invalid fmt: %r\' % (fmt,))\n\n        if len(header) > 0:\n            header = header.replace(\'\\n\', \'\\n\' + comments)\n            fh.write(asbytes(comments + header + newline))\n        if iscomplex_X:\n            for row in X:\n                row2 = []\n                for number in row:\n                    row2.append(number.real)\n                    row2.append(number.imag)\n                fh.write(asbytes(format % tuple(row2) + newline))\n        else:\n            for row in X:\n                try:\n                    fh.write(asbytes(format % tuple(row) + newline))\n                except TypeError:\n                    raise TypeError("Mismatch between array dtype (\'%s\') and "\n                                    "format specifier (\'%s\')"\n                                    % (str(X.dtype), format))\n        if len(footer) > 0:\n            footer = footer.replace(\'\\n\', \'\\n\' + comments)\n            fh.write(asbytes(comments + footer + newline))\n    finally:\n        if own_fh:\n            fh.close()\n\n\ndef fromregex(file, regexp, dtype):\n    \n    own_fh = False\n    if not hasattr(file, "read"):\n        file = open(file, \'rb\')\n        own_fh = True\n\n    try:\n        if not hasattr(regexp, \'match\'):\n            regexp = re.compile(asbytes(regexp))\n        if not isinstance(dtype, np.dtype):\n            dtype = np.dtype(dtype)\n\n        seq = regexp.findall(file.read())\n        if seq and not isinstance(seq[0], tuple):\n                                                newdtype = np.dtype(dtype[dtype.names[0]])\n            output = np.array(seq, dtype=newdtype)\n            output.dtype = dtype\n        else:\n            output = np.array(seq, dtype=dtype)\n\n        return output\n    finally:\n        if own_fh:\n            file.close()\n\n\n\n\ndef genfromtxt(fname, dtype=float, comments=\'               skip_header=0, skip_footer=0, converters=None,\n               missing_values=None, filling_values=None, usecols=None,\n               names=None, excludelist=None, deletechars=None,\n               replace_space=\'_\', autostrip=False, case_sensitive=True,\n               defaultfmt="f%i", unpack=None, usemask=False, loose=True,\n               invalid_raise=True, max_rows=None):\n    \n    if max_rows is not None:\n        if skip_footer:\n            raise ValueError(\n                    "The keywords \'skip_footer\' and \'max_rows\' can not be "\n                    "specified at the same time.")\n        if max_rows < 1:\n            raise ValueError("\'max_rows\' must be at least 1.")\n\n        if comments is not None:\n        comments = asbytes(comments)\n    if isinstance(delimiter, unicode):\n        delimiter = asbytes(delimiter)\n    if isinstance(missing_values, (unicode, list, tuple)):\n        missing_values = asbytes_nested(missing_values)\n\n        if usemask:\n        from numpy.ma import MaskedArray, make_mask_descr\n        user_converters = converters or {}\n    if not isinstance(user_converters, dict):\n        raise TypeError(\n            "The input argument \'converter\' should be a valid dictionary "\n            "(got \'%s\' instead)" % type(user_converters))\n\n        own_fhd = False\n    try:\n        if isinstance(fname, basestring):\n            if sys.version_info[0] == 2:\n                fhd = iter(np.lib._datasource.open(fname, \'rbU\'))\n            else:\n                fhd = iter(np.lib._datasource.open(fname, \'rb\'))\n            own_fhd = True\n        else:\n            fhd = iter(fname)\n    except TypeError:\n        raise TypeError(\n            "fname must be a string, filehandle, list of strings, "\n            "or generator. Got %s instead." % type(fname))\n\n    split_line = LineSplitter(delimiter=delimiter, comments=comments,\n                              autostrip=autostrip)._handyman\n    validate_names = NameValidator(excludelist=excludelist,\n                                   deletechars=deletechars,\n                                   case_sensitive=case_sensitive,\n                                   replace_space=replace_space)\n\n        for i in range(skip_header):\n        next(fhd)\n\n        first_values = None\n    try:\n        while not first_values:\n            first_line = next(fhd)\n            if names is True:\n                if comments in first_line:\n                    first_line = (\n                        asbytes(\'\').join(first_line.split(comments)[1:]))\n            first_values = split_line(first_line)\n    except StopIteration:\n                first_line = asbytes(\'\')\n        first_values = []\n        warnings.warn(\'genfromtxt: Empty input file: "%s"\' % fname)\n\n        if names is True:\n        fval = first_values[0].strip()\n        if fval in comments:\n            del first_values[0]\n\n        if usecols is not None:\n        try:\n            usecols = [_.strip() for _ in usecols.split(",")]\n        except AttributeError:\n            try:\n                usecols = list(usecols)\n            except TypeError:\n                usecols = [usecols, ]\n    nbcols = len(usecols or first_values)\n\n        if names is True:\n        names = validate_names([_bytes_to_name(_.strip())\n                                for _ in first_values])\n        first_line = asbytes(\'\')\n    elif _is_string_like(names):\n        names = validate_names([_.strip() for _ in names.split(\',\')])\n    elif names:\n        names = validate_names(names)\n        if dtype is not None:\n        dtype = easy_dtype(dtype, defaultfmt=defaultfmt, names=names,\n                           excludelist=excludelist,\n                           deletechars=deletechars,\n                           case_sensitive=case_sensitive,\n                           replace_space=replace_space)\n        if names is not None:\n        names = list(names)\n\n    if usecols:\n        for (i, current) in enumerate(usecols):\n                        if _is_string_like(current):\n                usecols[i] = names.index(current)\n            elif current < 0:\n                usecols[i] = current + len(first_values)\n                if (dtype is not None) and (len(dtype) > nbcols):\n            descr = dtype.descr\n            dtype = np.dtype([descr[_] for _ in usecols])\n            names = list(dtype.names)\n                elif (names is not None) and (len(names) > nbcols):\n            names = [names[_] for _ in usecols]\n    elif (names is not None) and (dtype is not None):\n        names = list(dtype.names)\n\n            user_missing_values = missing_values or ()\n\n        missing_values = [list([asbytes(\'\')]) for _ in range(nbcols)]\n\n        if isinstance(user_missing_values, dict):\n                for (key, val) in user_missing_values.items():\n                        if _is_string_like(key):\n                try:\n                                        key = names.index(key)\n                except ValueError:\n                                        continue\n                        if usecols:\n                try:\n                    key = usecols.index(key)\n                except ValueError:\n                    pass\n                        if isinstance(val, (list, tuple)):\n                val = [str(_) for _ in val]\n            else:\n                val = [str(val), ]\n                        if key is None:\n                                for miss in missing_values:\n                    miss.extend(val)\n            else:\n                missing_values[key].extend(val)\n        elif isinstance(user_missing_values, (list, tuple)):\n        for (value, entry) in zip(user_missing_values, missing_values):\n            value = str(value)\n            if value not in entry:\n                entry.append(value)\n        elif isinstance(user_missing_values, bytes):\n        user_value = user_missing_values.split(asbytes(","))\n        for entry in missing_values:\n            entry.extend(user_value)\n        else:\n        for entry in missing_values:\n            entry.extend([str(user_missing_values)])\n\n            user_filling_values = filling_values\n    if user_filling_values is None:\n        user_filling_values = []\n        filling_values = [None] * nbcols\n        if isinstance(user_filling_values, dict):\n        for (key, val) in user_filling_values.items():\n            if _is_string_like(key):\n                try:\n                                        key = names.index(key)\n                except ValueError:\n                                        continue\n                        if usecols:\n                try:\n                    key = usecols.index(key)\n                except ValueError:\n                    pass\n                        filling_values[key] = val\n        elif isinstance(user_filling_values, (list, tuple)):\n        n = len(user_filling_values)\n        if (n <= nbcols):\n            filling_values[:n] = user_filling_values\n        else:\n            filling_values = user_filling_values[:nbcols]\n        else:\n        filling_values = [user_filling_values] * nbcols\n\n        if dtype is None:\n                        converters = [StringConverter(None, missing_values=miss, default=fill)\n                      for (miss, fill) in zip(missing_values, filling_values)]\n    else:\n        dtype_flat = flatten_dtype(dtype, flatten_base=True)\n                if len(dtype_flat) > 1:\n                        zipit = zip(dtype_flat, missing_values, filling_values)\n            converters = [StringConverter(dt, locked=True,\n                                          missing_values=miss, default=fill)\n                          for (dt, miss, fill) in zipit]\n        else:\n                        zipit = zip(missing_values, filling_values)\n            converters = [StringConverter(dtype, locked=True,\n                                          missing_values=miss, default=fill)\n                          for (miss, fill) in zipit]\n        uc_update = []\n    for (j, conv) in user_converters.items():\n                if _is_string_like(j):\n            try:\n                j = names.index(j)\n                i = j\n            except ValueError:\n                continue\n        elif usecols:\n            try:\n                i = usecols.index(j)\n            except ValueError:\n                                continue\n        else:\n            i = j\n                if len(first_line):\n            testing_value = first_values[j]\n        else:\n            testing_value = None\n        converters[i].update(conv, locked=True,\n                             testing_value=testing_value,\n                             default=filling_values[i],\n                             missing_values=missing_values[i],)\n        uc_update.append((i, conv))\n        user_converters.update(uc_update)\n\n        \n            rows = []\n    append_to_rows = rows.append\n        if usemask:\n        masks = []\n        append_to_masks = masks.append\n        invalid = []\n    append_to_invalid = invalid.append\n\n        for (i, line) in enumerate(itertools.chain([first_line, ], fhd)):\n        values = split_line(line)\n        nbvalues = len(values)\n                if nbvalues == 0:\n            continue\n        if usecols:\n                        try:\n                values = [values[_] for _ in usecols]\n            except IndexError:\n                append_to_invalid((i + skip_header + 1, nbvalues))\n                continue\n        elif nbvalues != nbcols:\n            append_to_invalid((i + skip_header + 1, nbvalues))\n            continue\n                append_to_rows(tuple(values))\n        if usemask:\n            append_to_masks(tuple([v.strip() in m\n                                   for (v, m) in zip(values,\n                                                     missing_values)]))\n        if len(rows) == max_rows:\n            break\n\n    if own_fhd:\n        fhd.close()\n\n        if dtype is None:\n        for (i, converter) in enumerate(converters):\n            current_column = [itemgetter(i)(_m) for _m in rows]\n            try:\n                converter.iterupgrade(current_column)\n            except ConverterLockError:\n                errmsg = "Converter                 current_column = map(itemgetter(i), rows)\n                for (j, value) in enumerate(current_column):\n                    try:\n                        converter.upgrade(value)\n                    except (ConverterError, ValueError):\n                        errmsg += "(occurred line                         errmsg %= (j + 1 + skip_header, value)\n                        raise ConverterError(errmsg)\n\n        nbinvalid = len(invalid)\n    if nbinvalid > 0:\n        nbrows = len(rows) + nbinvalid - skip_footer\n                template = "    Line         if skip_footer > 0:\n            nbinvalid_skipped = len([_ for _ in invalid\n                                     if _[0] > nbrows + skip_header])\n            invalid = invalid[:nbinvalid - nbinvalid_skipped]\n            skip_footer -= nbinvalid_skipped\n        errmsg = [template % (i, nb)\n                  for (i, nb) in invalid]\n        if len(errmsg):\n            errmsg.insert(0, "Some errors were detected !")\n            errmsg = "\\n".join(errmsg)\n                        if invalid_raise:\n                raise ValueError(errmsg)\n                        else:\n                warnings.warn(errmsg, ConversionWarning)\n\n        if skip_footer > 0:\n        rows = rows[:-skip_footer]\n        if usemask:\n            masks = masks[:-skip_footer]\n\n            if loose:\n        rows = list(\n            zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n                  for (i, conv) in enumerate(converters)]))\n    else:\n        rows = list(\n            zip(*[[conv._strict_call(_r) for _r in map(itemgetter(i), rows)]\n                  for (i, conv) in enumerate(converters)]))\n\n        data = rows\n    if dtype is None:\n                column_types = [conv.type for conv in converters]\n                strcolidx = [i for (i, v) in enumerate(column_types)\n                     if v in (type(\'S\'), np.string_)]\n                for i in strcolidx:\n            column_types[i] = "|S%i" % max(len(row[i]) for row in data)\n                if names is None:\n                        base = set([c.type for c in converters if c._checked])\n            if len(base) == 1:\n                (ddtype, mdtype) = (list(base)[0], np.bool)\n            else:\n                ddtype = [(defaultfmt % i, dt)\n                          for (i, dt) in enumerate(column_types)]\n                if usemask:\n                    mdtype = [(defaultfmt % i, np.bool)\n                              for (i, dt) in enumerate(column_types)]\n        else:\n            ddtype = list(zip(names, column_types))\n            mdtype = list(zip(names, [np.bool] * len(column_types)))\n        output = np.array(data, dtype=ddtype)\n        if usemask:\n            outputmask = np.array(masks, dtype=mdtype)\n    else:\n                if names and dtype.names:\n            dtype.names = names\n                if len(dtype_flat) > 1:\n                                                            if \'O\' in (_.char for _ in dtype_flat):\n                if has_nested_fields(dtype):\n                    raise NotImplementedError(\n                        "Nested fields involving objects are not supported...")\n                else:\n                    output = np.array(data, dtype=dtype)\n            else:\n                rows = np.array(data, dtype=[(\'\', _) for _ in dtype_flat])\n                output = rows.view(dtype)\n                        if usemask:\n                rowmasks = np.array(\n                    masks, dtype=np.dtype([(\'\', np.bool) for t in dtype_flat]))\n                                mdtype = make_mask_descr(dtype)\n                outputmask = rowmasks.view(mdtype)\n                else:\n                        if user_converters:\n                ishomogeneous = True\n                descr = []\n                for i, ttype in enumerate([conv.type for conv in converters]):\n                                        if i in user_converters:\n                        ishomogeneous &= (ttype == dtype.type)\n                        if ttype == np.string_:\n                            ttype = "|S%i" % max(len(row[i]) for row in data)\n                        descr.append((\'\', ttype))\n                    else:\n                        descr.append((\'\', dtype))\n                                if not ishomogeneous:\n                                        if len(descr) > 1:\n                        dtype = np.dtype(descr)\n                                        else:\n                        dtype = np.dtype(ttype)\n                        output = np.array(data, dtype)\n            if usemask:\n                if dtype.names:\n                    mdtype = [(_, np.bool) for _ in dtype.names]\n                else:\n                    mdtype = np.bool\n                outputmask = np.array(masks, dtype=mdtype)\n        names = output.dtype.names\n    if usemask and names:\n        for (name, conv) in zip(names or (), converters):\n            missing_values = [conv(_) for _ in conv.missing_values\n                              if _ != asbytes(\'\')]\n            for mval in missing_values:\n                outputmask[name] |= (output[name] == mval)\n        if usemask:\n        output = output.view(MaskedArray)\n        output._mask = outputmask\n    if unpack:\n        return output.squeeze().T\n    return output.squeeze()\n\n\ndef ndfromtxt(fname, **kwargs):\n    \n    kwargs[\'usemask\'] = False\n    return genfromtxt(fname, **kwargs)\n\n\ndef mafromtxt(fname, **kwargs):\n    \n    kwargs[\'usemask\'] = True\n    return genfromtxt(fname, **kwargs)\n\n\ndef recfromtxt(fname, **kwargs):\n    \n    kwargs.setdefault("dtype", None)\n    usemask = kwargs.get(\'usemask\', False)\n    output = genfromtxt(fname, **kwargs)\n    if usemask:\n        from numpy.ma.mrecords import MaskedRecords\n        output = output.view(MaskedRecords)\n    else:\n        output = output.view(np.recarray)\n    return output\n\n\ndef recfromcsv(fname, **kwargs):\n    \n        kwargs.setdefault("case_sensitive", "lower")\n    kwargs.setdefault("names", True)\n    kwargs.setdefault("delimiter", ",")\n    kwargs.setdefault("dtype", None)\n    output = genfromtxt(fname, **kwargs)\n\n    usemask = kwargs.get("usemask", False)\n    if usemask:\n        from numpy.ma.mrecords import MaskedRecords\n        output = output.view(MaskedRecords)\n    else:\n        output = output.view(np.recarray)\n    return output\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport warnings\nimport collections\nfrom numpy.core import multiarray\nfrom . import umath\nfrom .umath import (invert, sin, UFUNC_BUFSIZE_DEFAULT, ERR_IGNORE,\n                    ERR_WARN, ERR_RAISE, ERR_CALL, ERR_PRINT, ERR_LOG,\n                    ERR_DEFAULT, PINF, NAN)\nfrom . import numerictypes\nfrom .numerictypes import longlong, intc, int_, float_, complex_, bool_\nfrom ._internal import TooHardError\n\nif sys.version_info[0] >= 3:\n    import pickle\n    basestring = str\nelse:\n    import cPickle as pickle\n\nloads = pickle.loads\n\n\n__all__ = [\n    \'newaxis\', \'ndarray\', \'flatiter\', \'nditer\', \'nested_iters\', \'ufunc\',\n    \'arange\', \'array\', \'zeros\', \'count_nonzero\', \'empty\', \'broadcast\',\n    \'dtype\', \'fromstring\', \'fromfile\', \'frombuffer\', \'int_asbuffer\',\n    \'where\', \'argwhere\', \'copyto\', \'concatenate\', \'fastCopyAndTranspose\',\n    \'lexsort\', \'set_numeric_ops\', \'can_cast\', \'promote_types\',\n    \'min_scalar_type\', \'result_type\', \'asarray\', \'asanyarray\',\n    \'ascontiguousarray\', \'asfortranarray\', \'isfortran\', \'empty_like\',\n    \'zeros_like\', \'ones_like\', \'correlate\', \'convolve\', \'inner\', \'dot\',\n    \'einsum\', \'outer\', \'vdot\', \'alterdot\', \'restoredot\', \'roll\',\n    \'rollaxis\', \'cross\', \'tensordot\', \'array2string\', \'get_printoptions\',\n    \'set_printoptions\', \'array_repr\', \'array_str\', \'set_string_function\',\n    \'little_endian\', \'require\', \'fromiter\', \'array_equal\', \'array_equiv\',\n    \'indices\', \'fromfunction\', \'isclose\', \'load\', \'loads\', \'isscalar\',\n    \'binary_repr\', \'base_repr\', \'ones\', \'identity\', \'allclose\',\n    \'compare_chararrays\', \'putmask\', \'seterr\', \'geterr\', \'setbufsize\',\n    \'getbufsize\', \'seterrcall\', \'geterrcall\', \'errstate\', \'flatnonzero\',\n    \'Inf\', \'inf\', \'infty\', \'Infinity\', \'nan\', \'NaN\', \'False_\', \'True_\',\n    \'bitwise_not\', \'CLIP\', \'RAISE\', \'WRAP\', \'MAXDIMS\', \'BUFSIZE\',\n    \'ALLOW_THREADS\', \'ComplexWarning\', \'full\', \'full_like\', \'matmul\',\n    \'shares_memory\', \'MAY_SHARE_BOUNDS\', \'MAY_SHARE_EXACT\', \'TooHardError\',\n    ]\n\nif sys.version_info[0] < 3:\n    __all__.extend([\'getbuffer\', \'newbuffer\'])\n\n\nclass ComplexWarning(RuntimeWarning):\n    \n    pass\n\nbitwise_not = invert\n\nCLIP = multiarray.CLIP\nWRAP = multiarray.WRAP\nRAISE = multiarray.RAISE\nMAXDIMS = multiarray.MAXDIMS\nALLOW_THREADS = multiarray.ALLOW_THREADS\nBUFSIZE = multiarray.BUFSIZE\nMAY_SHARE_BOUNDS = multiarray.MAY_SHARE_BOUNDS\nMAY_SHARE_EXACT = multiarray.MAY_SHARE_EXACT\n\nndarray = multiarray.ndarray\nflatiter = multiarray.flatiter\nnditer = multiarray.nditer\nnested_iters = multiarray.nested_iters\nbroadcast = multiarray.broadcast\ndtype = multiarray.dtype\ncopyto = multiarray.copyto\nufunc = type(sin)\n\n\ndef zeros_like(a, dtype=None, order=\'K\', subok=True):\n    \n    res = empty_like(a, dtype=dtype, order=order, subok=subok)\n        z = zeros(1, dtype=res.dtype)\n    multiarray.copyto(res, z, casting=\'unsafe\')\n    return res\n\ndef ones(shape, dtype=None, order=\'C\'):\n    \n    a = empty(shape, dtype, order)\n    multiarray.copyto(a, 1, casting=\'unsafe\')\n    return a\n\ndef ones_like(a, dtype=None, order=\'K\', subok=True):\n    \n    res = empty_like(a, dtype=dtype, order=order, subok=subok)\n    multiarray.copyto(res, 1, casting=\'unsafe\')\n    return res\n\ndef full(shape, fill_value, dtype=None, order=\'C\'):\n    \n    a = empty(shape, dtype, order)\n    if dtype is None and array(fill_value).dtype != a.dtype:\n        warnings.warn(\n            "in the future, full({0}, {1!r}) will return an array of {2!r}".\n            format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n    multiarray.copyto(a, fill_value, casting=\'unsafe\')\n    return a\n\ndef full_like(a, fill_value, dtype=None, order=\'K\', subok=True):\n    \n    res = empty_like(a, dtype=dtype, order=order, subok=subok)\n    multiarray.copyto(res, fill_value, casting=\'unsafe\')\n    return res\n\n\ndef extend_all(module):\n    adict = {}\n    for a in __all__:\n        adict[a] = 1\n    try:\n        mall = getattr(module, \'__all__\')\n    except AttributeError:\n        mall = [k for k in module.__dict__.keys() if not k.startswith(\'_\')]\n    for a in mall:\n        if a not in adict:\n            __all__.append(a)\n\nnewaxis = None\n\n\narange = multiarray.arange\narray = multiarray.array\nzeros = multiarray.zeros\ncount_nonzero = multiarray.count_nonzero\nempty = multiarray.empty\nempty_like = multiarray.empty_like\nfromstring = multiarray.fromstring\nfromiter = multiarray.fromiter\nfromfile = multiarray.fromfile\nfrombuffer = multiarray.frombuffer\nshares_memory = multiarray.shares_memory\nif sys.version_info[0] < 3:\n    newbuffer = multiarray.newbuffer\n    getbuffer = multiarray.getbuffer\nint_asbuffer = multiarray.int_asbuffer\nwhere = multiarray.where\nconcatenate = multiarray.concatenate\nfastCopyAndTranspose = multiarray._fastCopyAndTranspose\nset_numeric_ops = multiarray.set_numeric_ops\ncan_cast = multiarray.can_cast\npromote_types = multiarray.promote_types\nmin_scalar_type = multiarray.min_scalar_type\nresult_type = multiarray.result_type\nlexsort = multiarray.lexsort\ncompare_chararrays = multiarray.compare_chararrays\nputmask = multiarray.putmask\neinsum = multiarray.einsum\ndot = multiarray.dot\ninner = multiarray.inner\nvdot = multiarray.vdot\nmatmul = multiarray.matmul\n\n\ndef asarray(a, dtype=None, order=None):\n    \n    return array(a, dtype, copy=False, order=order)\n\ndef asanyarray(a, dtype=None, order=None):\n    \n    return array(a, dtype, copy=False, order=order, subok=True)\n\ndef ascontiguousarray(a, dtype=None):\n    \n    return array(a, dtype, copy=False, order=\'C\', ndmin=1)\n\ndef asfortranarray(a, dtype=None):\n    \n    return array(a, dtype, copy=False, order=\'F\', ndmin=1)\n\ndef require(a, dtype=None, requirements=None):\n    \n    possible_flags = {\'C\':\'C\', \'C_CONTIGUOUS\':\'C\', \'CONTIGUOUS\':\'C\',\n                      \'F\':\'F\', \'F_CONTIGUOUS\':\'F\', \'FORTRAN\':\'F\',\n                      \'A\':\'A\', \'ALIGNED\':\'A\',\n                      \'W\':\'W\', \'WRITEABLE\':\'W\',\n                      \'O\':\'O\', \'OWNDATA\':\'O\',\n                      \'E\':\'E\', \'ENSUREARRAY\':\'E\'}\n    if not requirements:\n        return asanyarray(a, dtype=dtype)\n    else:\n        requirements = set(possible_flags[x.upper()] for x in requirements)\n\n    if \'E\' in requirements:\n        requirements.remove(\'E\')\n        subok = False\n    else:\n        subok = True\n\n    order = \'A\'\n    if requirements >= set([\'C\', \'F\']):\n        raise ValueError(\'Cannot specify both "C" and "F" order\')\n    elif \'F\' in requirements:\n        order = \'F\'\n        requirements.remove(\'F\')\n    elif \'C\' in requirements:\n        order = \'C\'\n        requirements.remove(\'C\')\n\n    arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n\n    for prop in requirements:\n        if not arr.flags[prop]:\n            arr = arr.copy(order)\n            break\n    return arr\n\ndef isfortran(a):\n    \n    return a.flags.fnc\n\ndef argwhere(a):\n    \n    return transpose(nonzero(a))\n\ndef flatnonzero(a):\n    \n    return a.ravel().nonzero()[0]\n\n_mode_from_name_dict = {\'v\': 0,\n                        \'s\': 1,\n                        \'f\': 2}\n\ndef _mode_from_name(mode):\n    if isinstance(mode, basestring):\n        return _mode_from_name_dict[mode.lower()[0]]\n    return mode\n\ndef correlate(a, v, mode=\'valid\'):\n    \n    mode = _mode_from_name(mode)\n    return multiarray.correlate2(a, v, mode)\n\ndef convolve(a,v,mode=\'full\'):\n    \n    a, v = array(a, copy=False, ndmin=1), array(v, copy=False, ndmin=1)\n    if (len(v) > len(a)):\n        a, v = v, a\n    if len(a) == 0:\n        raise ValueError(\'a cannot be empty\')\n    if len(v) == 0:\n        raise ValueError(\'v cannot be empty\')\n    mode = _mode_from_name(mode)\n    return multiarray.correlate(a, v[::-1], mode)\n\ndef outer(a, b, out=None):\n    \n    a = asarray(a)\n    b = asarray(b)\n    return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis,:], out)\n\n\ndef alterdot():\n    \n        warnings.warn("alterdot no longer does anything.", DeprecationWarning)\n\n\ndef restoredot():\n    \n        warnings.warn("restoredot no longer does anything.", DeprecationWarning)\n\n\ndef tensordot(a, b, axes=2):\n    \n    try:\n        iter(axes)\n    except:\n        axes_a = list(range(-axes, 0))\n        axes_b = list(range(0, axes))\n    else:\n        axes_a, axes_b = axes\n    try:\n        na = len(axes_a)\n        axes_a = list(axes_a)\n    except TypeError:\n        axes_a = [axes_a]\n        na = 1\n    try:\n        nb = len(axes_b)\n        axes_b = list(axes_b)\n    except TypeError:\n        axes_b = [axes_b]\n        nb = 1\n\n    a, b = asarray(a), asarray(b)\n    as_ = a.shape\n    nda = len(a.shape)\n    bs = b.shape\n    ndb = len(b.shape)\n    equal = True\n    if na != nb:\n        equal = False\n    else:\n        for k in range(na):\n            if as_[axes_a[k]] != bs[axes_b[k]]:\n                equal = False\n                break\n            if axes_a[k] < 0:\n                axes_a[k] += nda\n            if axes_b[k] < 0:\n                axes_b[k] += ndb\n    if not equal:\n        raise ValueError("shape-mismatch for sum")\n\n            notin = [k for k in range(nda) if k not in axes_a]\n    newaxes_a = notin + axes_a\n    N2 = 1\n    for axis in axes_a:\n        N2 *= as_[axis]\n    newshape_a = (-1, N2)\n    olda = [as_[axis] for axis in notin]\n\n    notin = [k for k in range(ndb) if k not in axes_b]\n    newaxes_b = axes_b + notin\n    N2 = 1\n    for axis in axes_b:\n        N2 *= bs[axis]\n    newshape_b = (N2, -1)\n    oldb = [bs[axis] for axis in notin]\n\n    at = a.transpose(newaxes_a).reshape(newshape_a)\n    bt = b.transpose(newaxes_b).reshape(newshape_b)\n    res = dot(at, bt)\n    return res.reshape(olda + oldb)\n\ndef roll(a, shift, axis=None):\n    \n    a = asanyarray(a)\n    if axis is None:\n        n = a.size\n        reshape = True\n    else:\n        try:\n            n = a.shape[axis]\n        except IndexError:\n            raise ValueError(\'axis must be >= 0 and < %d\' % a.ndim)\n        reshape = False\n    if n == 0:\n        return a\n    shift %= n\n    indexes = concatenate((arange(n - shift, n), arange(n - shift)))\n    res = a.take(indexes, axis)\n    if reshape:\n        res = res.reshape(a.shape)\n    return res\n\n\ndef rollaxis(a, axis, start=0):\n    \n    n = a.ndim\n    if axis < 0:\n        axis += n\n    if start < 0:\n        start += n\n    msg = \'rollaxis: %s (%d) must be >=0 and < %d\'\n    if not (0 <= axis < n):\n        raise ValueError(msg % (\'axis\', axis, n))\n    if not (0 <= start < n + 1):\n        raise ValueError(msg % (\'start\', start, n + 1))\n    if (axis < start):\n                start -= 1\n    if axis == start:\n        return a[...]\n    axes = list(range(0, n))\n    axes.remove(axis)\n    axes.insert(start, axis)\n    return a.transpose(axes)\n\n\ndef _move_axis_to_0(a, axis):\n    return rollaxis(a, axis, 0)\n\ndef cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None):\n    \n    if axis is not None:\n        axisa, axisb, axisc = (axis,) * 3\n    a = asarray(a)\n    b = asarray(b)\n        axis_msg = "\'axis{0}\' out of bounds"\n    if axisa < -a.ndim or axisa >= a.ndim:\n        raise ValueError(axis_msg.format(\'a\'))\n    if axisb < -b.ndim or axisb >= b.ndim:\n        raise ValueError(axis_msg.format(\'b\'))\n        a = rollaxis(a, axisa, a.ndim)\n    b = rollaxis(b, axisb, b.ndim)\n    msg = ("incompatible dimensions for cross product\\n"\n           "(dimension must be 2 or 3)")\n    if a.shape[-1] not in (2, 3) or b.shape[-1] not in (2, 3):\n        raise ValueError(msg)\n\n        shape = broadcast(a[..., 0], b[..., 0]).shape\n    if a.shape[-1] == 3 or b.shape[-1] == 3:\n        shape += (3,)\n                if axisc < -len(shape) or axisc >= len(shape):\n            raise ValueError(axis_msg.format(\'c\'))\n    dtype = promote_types(a.dtype, b.dtype)\n    cp = empty(shape, dtype)\n\n        a0 = a[..., 0]\n    a1 = a[..., 1]\n    if a.shape[-1] == 3:\n        a2 = a[..., 2]\n    b0 = b[..., 0]\n    b1 = b[..., 1]\n    if b.shape[-1] == 3:\n        b2 = b[..., 2]\n    if cp.ndim != 0 and cp.shape[-1] == 3:\n        cp0 = cp[..., 0]\n        cp1 = cp[..., 1]\n        cp2 = cp[..., 2]\n\n    if a.shape[-1] == 2:\n        if b.shape[-1] == 2:\n                        multiply(a0, b1, out=cp)\n            cp -= a1 * b0\n            return cp\n        else:\n            assert b.shape[-1] == 3\n                                                multiply(a1, b2, out=cp0)\n            multiply(a0, b2, out=cp1)\n            negative(cp1, out=cp1)\n            multiply(a0, b1, out=cp2)\n            cp2 -= a1 * b0\n    else:\n        assert a.shape[-1] == 3\n        if b.shape[-1] == 3:\n                                                multiply(a1, b2, out=cp0)\n            tmp = array(a2 * b1)\n            cp0 -= tmp\n            multiply(a2, b0, out=cp1)\n            multiply(a0, b2, out=tmp)\n            cp1 -= tmp\n            multiply(a0, b1, out=cp2)\n            multiply(a1, b0, out=tmp)\n            cp2 -= tmp\n        else:\n            assert b.shape[-1] == 2\n                                                multiply(a2, b1, out=cp0)\n            negative(cp0, out=cp0)\n            multiply(a2, b0, out=cp1)\n            multiply(a0, b1, out=cp2)\n            cp2 -= a1 * b0\n\n        return rollaxis(cp, -1, axisc)\n\nfrom .arrayprint import array2string, get_printoptions, set_printoptions\n\n_typelessdata = [int_, float_, complex_]\nif issubclass(intc, int):\n    _typelessdata.append(intc)\n\nif issubclass(longlong, int):\n    _typelessdata.append(longlong)\n\ndef array_repr(arr, max_line_width=None, precision=None, suppress_small=None):\n    \n    if arr.size > 0 or arr.shape == (0,):\n        lst = array2string(arr, max_line_width, precision, suppress_small,\n                           \', \', "array(")\n    else:          lst = "[], shape=%s" % (repr(arr.shape),)\n\n    if arr.__class__ is not ndarray:\n        cName = arr.__class__.__name__\n    else:\n        cName = "array"\n\n    skipdtype = (arr.dtype.type in _typelessdata) and arr.size > 0\n\n    if skipdtype:\n        return "%s(%s)" % (cName, lst)\n    else:\n        typename = arr.dtype.name\n                if typename and not (typename[0].isalpha() and typename.isalnum()):\n            typename = "\'%s\'" % typename\n\n        lf = \'\'\n        if issubclass(arr.dtype.type, flexible):\n            if arr.dtype.names:\n                typename = "%s" % str(arr.dtype)\n            else:\n                typename = "\'%s\'" % str(arr.dtype)\n            lf = \'\\n\'+\' \'*len("array(")\n        return cName + "(%s, %sdtype=%s)" % (lst, lf, typename)\n\ndef array_str(a, max_line_width=None, precision=None, suppress_small=None):\n    \n    return array2string(a, max_line_width, precision, suppress_small, \' \', "", str)\n\ndef set_string_function(f, repr=True):\n    \n    if f is None:\n        if repr:\n            return multiarray.set_string_function(array_repr, 1)\n        else:\n            return multiarray.set_string_function(array_str, 0)\n    else:\n        return multiarray.set_string_function(f, repr)\n\nset_string_function(array_str, 0)\nset_string_function(array_repr, 1)\n\nlittle_endian = (sys.byteorder == \'little\')\n\n\ndef indices(dimensions, dtype=int):\n    \n    dimensions = tuple(dimensions)\n    N = len(dimensions)\n    if N == 0:\n        return array([], dtype=dtype)\n    res = empty((N,)+dimensions, dtype=dtype)\n    for i, dim in enumerate(dimensions):\n        tmp = arange(dim, dtype=dtype)\n        tmp.shape = (1,)*i + (dim,)+(1,)*(N-i-1)\n        newdim = dimensions[:i] + (1,) + dimensions[i+1:]\n        val = zeros(newdim, dtype)\n        add(tmp, val, res[i])\n    return res\n\ndef fromfunction(function, shape, **kwargs):\n    \n    dtype = kwargs.pop(\'dtype\', float)\n    args = indices(shape, dtype=dtype)\n    return function(*args,**kwargs)\n\ndef isscalar(num):\n    \n    if isinstance(num, generic):\n        return True\n    else:\n        return type(num) in ScalarType\n\n_lkup = {\n    \'0\':\'0000\',\n    \'1\':\'0001\',\n    \'2\':\'0010\',\n    \'3\':\'0011\',\n    \'4\':\'0100\',\n    \'5\':\'0101\',\n    \'6\':\'0110\',\n    \'7\':\'0111\',\n    \'8\':\'1000\',\n    \'9\':\'1001\',\n    \'a\':\'1010\',\n    \'b\':\'1011\',\n    \'c\':\'1100\',\n    \'d\':\'1101\',\n    \'e\':\'1110\',\n    \'f\':\'1111\',\n    \'A\':\'1010\',\n    \'B\':\'1011\',\n    \'C\':\'1100\',\n    \'D\':\'1101\',\n    \'E\':\'1110\',\n    \'F\':\'1111\',\n    \'L\':\'\'}\n\ndef binary_repr(num, width=None):\n    \n        sign = \'\'\n    if num < 0:\n        if width is None:\n            sign = \'-\'\n            num = -num\n        else:\n                        num = 2**width + num\n    elif num == 0:\n        return \'0\'*(width or 1)\n    ostr = hex(num)\n    bin = \'\'.join([_lkup[ch] for ch in ostr[2:]])\n    bin = bin.lstrip(\'0\')\n    if width is not None:\n        bin = bin.zfill(width)\n    return sign + bin\n\ndef base_repr(number, base=2, padding=0):\n    \n    digits = \'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\'\n    if base > len(digits):\n        raise ValueError("Bases greater than 36 not handled in base_repr.")\n\n    num = abs(number)\n    res = []\n    while num:\n        res.append(digits[num % base])\n        num //= base\n    if padding:\n        res.append(\'0\' * padding)\n    if number < 0:\n        res.append(\'-\')\n    return \'\'.join(reversed(res or \'0\'))\n\n\ndef load(file):\n    \n    if isinstance(file, type("")):\n        file = open(file, "rb")\n    return pickle.load(file)\n\n\ndef _maketup(descr, val):\n    dt = dtype(descr)\n        fields = dt.fields\n    if fields is None:\n        return val\n    else:\n        res = [_maketup(fields[name][0], val) for name in dt.names]\n        return tuple(res)\n\ndef identity(n, dtype=None):\n    \n    from numpy import eye\n    return eye(n, dtype=dtype)\n\ndef allclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):\n    \n    return all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n\ndef isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):\n    \n    def within_tol(x, y, atol, rtol):\n        with errstate(invalid=\'ignore\'):\n            result = less_equal(abs(x-y), atol + rtol * abs(y))\n        if isscalar(a) and isscalar(b):\n            result = bool(result)\n        return result\n\n    x = array(a, copy=False, subok=True, ndmin=1)\n    y = array(b, copy=False, subok=True, ndmin=1)\n\n                dt = multiarray.result_type(y, 1.)\n    y = array(y, dtype=dt, copy=False, subok=True)\n\n    xfin = isfinite(x)\n    yfin = isfinite(y)\n    if all(xfin) and all(yfin):\n        return within_tol(x, y, atol, rtol)\n    else:\n        finite = xfin & yfin\n        cond = zeros_like(finite, subok=True)\n                                x = x * ones_like(cond)\n        y = y * ones_like(cond)\n                cond[finite] = within_tol(x[finite], y[finite], atol, rtol)\n                cond[~finite] = (x[~finite] == y[~finite])\n        if equal_nan:\n                        both_nan = isnan(x) & isnan(y)\n            cond[both_nan] = both_nan[both_nan]\n        return cond\n\ndef array_equal(a1, a2):\n    \n    try:\n        a1, a2 = asarray(a1), asarray(a2)\n    except:\n        return False\n    if a1.shape != a2.shape:\n        return False\n    return bool(asarray(a1 == a2).all())\n\ndef array_equiv(a1, a2):\n    \n    try:\n        a1, a2 = asarray(a1), asarray(a2)\n    except:\n        return False\n    try:\n        multiarray.broadcast(a1, a2)\n    except:\n        return False\n\n    return bool(asarray(a1 == a2).all())\n\n\n_errdict = {"ignore":ERR_IGNORE,\n            "warn":ERR_WARN,\n            "raise":ERR_RAISE,\n            "call":ERR_CALL,\n            "print":ERR_PRINT,\n            "log":ERR_LOG}\n\n_errdict_rev = {}\nfor key in _errdict.keys():\n    _errdict_rev[_errdict[key]] = key\ndel key\n\ndef seterr(all=None, divide=None, over=None, under=None, invalid=None):\n    \n\n    pyvals = umath.geterrobj()\n    old = geterr()\n\n    if divide is None:\n        divide = all or old[\'divide\']\n    if over is None:\n        over = all or old[\'over\']\n    if under is None:\n        under = all or old[\'under\']\n    if invalid is None:\n        invalid = all or old[\'invalid\']\n\n    maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n                 (_errdict[over] << SHIFT_OVERFLOW) +\n                 (_errdict[under] << SHIFT_UNDERFLOW) +\n                 (_errdict[invalid] << SHIFT_INVALID))\n\n    pyvals[1] = maskvalue\n    umath.seterrobj(pyvals)\n    return old\n\n\ndef geterr():\n    \n    maskvalue = umath.geterrobj()[1]\n    mask = 7\n    res = {}\n    val = (maskvalue >> SHIFT_DIVIDEBYZERO) & mask\n    res[\'divide\'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_OVERFLOW) & mask\n    res[\'over\'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_UNDERFLOW) & mask\n    res[\'under\'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_INVALID) & mask\n    res[\'invalid\'] = _errdict_rev[val]\n    return res\n\ndef setbufsize(size):\n    \n    if size > 10e6:\n        raise ValueError("Buffer size, %s, is too big." % size)\n    if size < 5:\n        raise ValueError("Buffer size, %s, is too small." % size)\n    if size % 16 != 0:\n        raise ValueError("Buffer size, %s, is not a multiple of 16." % size)\n\n    pyvals = umath.geterrobj()\n    old = getbufsize()\n    pyvals[0] = size\n    umath.seterrobj(pyvals)\n    return old\n\ndef getbufsize():\n    \n    return umath.geterrobj()[0]\n\ndef seterrcall(func):\n    \n    if func is not None and not isinstance(func, collections.Callable):\n        if not hasattr(func, \'write\') or not isinstance(func.write, collections.Callable):\n            raise ValueError("Only callable can be used as callback")\n    pyvals = umath.geterrobj()\n    old = geterrcall()\n    pyvals[2] = func\n    umath.seterrobj(pyvals)\n    return old\n\ndef geterrcall():\n    \n    return umath.geterrobj()[2]\n\nclass _unspecified(object):\n    pass\n_Unspecified = _unspecified()\n\nclass errstate(object):\n    \n        \n    def __init__(self, **kwargs):\n        self.call = kwargs.pop(\'call\', _Unspecified)\n        self.kwargs = kwargs\n\n    def __enter__(self):\n        self.oldstate = seterr(**self.kwargs)\n        if self.call is not _Unspecified:\n            self.oldcall = seterrcall(self.call)\n\n    def __exit__(self, *exc_info):\n        seterr(**self.oldstate)\n        if self.call is not _Unspecified:\n            seterrcall(self.oldcall)\n\n\ndef _setdef():\n    defval = [UFUNC_BUFSIZE_DEFAULT, ERR_DEFAULT, None]\n    umath.seterrobj(defval)\n\n_setdef()\n\nInf = inf = infty = Infinity = PINF\nnan = NaN = NAN\nFalse_ = bool_(False)\nTrue_ = bool_(True)\n\nfrom .umath import *\nfrom .numerictypes import *\nfrom . import fromnumeric\nfrom .fromnumeric import *\nextend_all(fromnumeric)\nextend_all(umath)\nextend_all(numerictypes)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport types as _types\nimport sys\nimport numbers\n\nfrom numpy.compat import bytes, long\nfrom numpy.core.multiarray import (\n        typeinfo, ndarray, array, empty, dtype, datetime_data,\n        datetime_as_string, busday_offset, busday_count, is_busday,\n        busdaycalendar\n        )\n\n\n__all__ = [\'sctypeDict\', \'sctypeNA\', \'typeDict\', \'typeNA\', \'sctypes\',\n           \'ScalarType\', \'obj2sctype\', \'cast\', \'nbytes\', \'sctype2char\',\n           \'maximum_sctype\', \'issctype\', \'typecodes\', \'find_common_type\',\n           \'issubdtype\', \'datetime_data\', \'datetime_as_string\',\n           \'busday_offset\', \'busday_count\', \'is_busday\', \'busdaycalendar\',\n           ]\n\n\nif sys.version_info[0] >= 3:\n    from builtins import bool, int, float, complex, object, str\n    unicode = str\nelse:\n    from __builtin__ import bool, int, float, complex, object, unicode, str\n\n\n\n_all_chars = [chr(_m) for _m in range(256)]\n_ascii_upper = _all_chars[65:65+26]\n_ascii_lower = _all_chars[97:97+26]\nLOWER_TABLE = "".join(_all_chars[:65] + _ascii_lower + _all_chars[65+26:])\nUPPER_TABLE = "".join(_all_chars[:97] + _ascii_upper + _all_chars[97+26:])\n\n\ndef english_lower(s):\n    \n    lowered = s.translate(LOWER_TABLE)\n    return lowered\n\ndef english_upper(s):\n    \n    uppered = s.translate(UPPER_TABLE)\n    return uppered\n\ndef english_capitalize(s):\n    \n    if s:\n        return english_upper(s[0]) + s[1:]\n    else:\n        return s\n\n\nsctypeDict = {}      sctypeNA = {}        allTypes = {}      \ndef _evalname(name):\n    k = 0\n    for ch in name:\n        if ch in \'0123456789\':\n            break\n        k += 1\n    try:\n        bits = int(name[k:])\n    except ValueError:\n        bits = 0\n    base = name[:k]\n    return base, bits\n\ndef bitname(obj):\n    \n    name = obj.__name__\n    base = \'\'\n    char = \'\'\n    try:\n        if name[-1] == \'_\':\n            newname = name[:-1]\n        else:\n            newname = name\n        info = typeinfo[english_upper(newname)]\n        assert(info[-1] == obj)          bits = info[2]\n\n    except KeyError:             base, bits = _evalname(name)\n        char = base[0]\n\n    if name == \'bool_\':\n        char = \'b\'\n        base = \'bool\'\n    elif name == \'void\':\n        char = \'V\'\n        base = \'void\'\n    elif name == \'object_\':\n        char = \'O\'\n        base = \'object\'\n        bits = 0\n    elif name == \'datetime64\':\n        char = \'M\'\n    elif name == \'timedelta64\':\n        char = \'m\'\n\n    if sys.version_info[0] >= 3:\n        if name == \'bytes_\':\n            char = \'S\'\n            base = \'bytes\'\n        elif name == \'str_\':\n            char = \'U\'\n            base = \'str\'\n    else:\n        if name == \'string_\':\n            char = \'S\'\n            base = \'string\'\n        elif name == \'unicode_\':\n            char = \'U\'\n            base = \'unicode\'\n\n    bytes = bits // 8\n\n    if char != \'\' and bytes != 0:\n        char = "%s%d" % (char, bytes)\n\n    return base, bits, char\n\n\ndef _add_types():\n    for a in typeinfo.keys():\n        name = english_lower(a)\n        if isinstance(typeinfo[a], tuple):\n            typeobj = typeinfo[a][-1]\n\n                        allTypes[name] = typeobj\n            sctypeDict[name] = typeobj\n            sctypeDict[typeinfo[a][0]] = typeobj\n            sctypeDict[typeinfo[a][1]] = typeobj\n\n        else:              allTypes[name] = typeinfo[a]\n_add_types()\n\ndef _add_aliases():\n    for a in typeinfo.keys():\n        name = english_lower(a)\n        if not isinstance(typeinfo[a], tuple):\n            continue\n        typeobj = typeinfo[a][-1]\n                base, bit, char = bitname(typeobj)\n        if base[-3:] == \'int\' or char[0] in \'ui\':\n            continue\n        if base != \'\':\n            myname = "%s%d" % (base, bit)\n            if ((name != \'longdouble\' and name != \'clongdouble\') or\n                   myname not in allTypes.keys()):\n                allTypes[myname] = typeobj\n                sctypeDict[myname] = typeobj\n                if base == \'complex\':\n                    na_name = \'%s%d\' % (english_capitalize(base), bit//2)\n                elif base == \'bool\':\n                    na_name = english_capitalize(base)\n                    sctypeDict[na_name] = typeobj\n                else:\n                    na_name = "%s%d" % (english_capitalize(base), bit)\n                    sctypeDict[na_name] = typeobj\n                sctypeNA[na_name] = typeobj\n                sctypeDict[na_name] = typeobj\n                sctypeNA[typeobj] = na_name\n                sctypeNA[typeinfo[a][0]] = na_name\n        if char != \'\':\n            sctypeDict[char] = typeobj\n            sctypeNA[char] = na_name\n_add_aliases()\n\ndef _add_integer_aliases():\n    _ctypes = [\'LONG\', \'LONGLONG\', \'INT\', \'SHORT\', \'BYTE\']\n    for ctype in _ctypes:\n        val = typeinfo[ctype]\n        bits = val[2]\n        charname = \'i%d\' % (bits//8,)\n        ucharname = \'u%d\' % (bits//8,)\n        intname = \'int%d\' % bits\n        UIntname = \'UInt%d\' % bits\n        Intname = \'Int%d\' % bits\n        uval = typeinfo[\'U\'+ctype]\n        typeobj = val[-1]\n        utypeobj = uval[-1]\n        if intname not in allTypes.keys():\n            uintname = \'uint%d\' % bits\n            allTypes[intname] = typeobj\n            allTypes[uintname] = utypeobj\n            sctypeDict[intname] = typeobj\n            sctypeDict[uintname] = utypeobj\n            sctypeDict[Intname] = typeobj\n            sctypeDict[UIntname] = utypeobj\n            sctypeDict[charname] = typeobj\n            sctypeDict[ucharname] = utypeobj\n            sctypeNA[Intname] = typeobj\n            sctypeNA[UIntname] = utypeobj\n            sctypeNA[charname] = typeobj\n            sctypeNA[ucharname] = utypeobj\n        sctypeNA[typeobj] = Intname\n        sctypeNA[utypeobj] = UIntname\n        sctypeNA[val[0]] = Intname\n        sctypeNA[uval[0]] = UIntname\n_add_integer_aliases()\n\nvoid = allTypes[\'void\']\ngeneric = allTypes[\'generic\']\n\ndef _set_up_aliases():\n    type_pairs = [(\'complex_\', \'cdouble\'),\n                  (\'int0\', \'intp\'),\n                  (\'uint0\', \'uintp\'),\n                  (\'single\', \'float\'),\n                  (\'csingle\', \'cfloat\'),\n                  (\'singlecomplex\', \'cfloat\'),\n                  (\'float_\', \'double\'),\n                  (\'intc\', \'int\'),\n                  (\'uintc\', \'uint\'),\n                  (\'int_\', \'long\'),\n                  (\'uint\', \'ulong\'),\n                  (\'cfloat\', \'cdouble\'),\n                  (\'longfloat\', \'longdouble\'),\n                  (\'clongfloat\', \'clongdouble\'),\n                  (\'longcomplex\', \'clongdouble\'),\n                  (\'bool_\', \'bool\'),\n                  (\'unicode_\', \'unicode\'),\n                  (\'object_\', \'object\')]\n    if sys.version_info[0] >= 3:\n        type_pairs.extend([(\'bytes_\', \'string\'),\n                           (\'str_\', \'unicode\'),\n                           (\'string_\', \'string\')])\n    else:\n        type_pairs.extend([(\'str_\', \'string\'),\n                           (\'string_\', \'string\'),\n                           (\'bytes_\', \'string\')])\n    for alias, t in type_pairs:\n        allTypes[alias] = allTypes[t]\n        sctypeDict[alias] = sctypeDict[t]\n        to_remove = [\'ulong\', \'object\', \'unicode\', \'int\', \'long\', \'float\',\n                 \'complex\', \'bool\', \'string\', \'datetime\', \'timedelta\']\n    if sys.version_info[0] >= 3:\n                to_remove.append(\'bytes\')\n        to_remove.append(\'str\')\n        to_remove.remove(\'unicode\')\n        to_remove.remove(\'long\')\n    for t in to_remove:\n        try:\n            del allTypes[t]\n            del sctypeDict[t]\n        except KeyError:\n            pass\n_set_up_aliases()\n\n_sctype2char_dict = {}\ndef _construct_char_code_lookup():\n    for name in typeinfo.keys():\n        tup = typeinfo[name]\n        if isinstance(tup, tuple):\n            if tup[0] not in [\'p\', \'P\']:\n                _sctype2char_dict[tup[-1]] = tup[0]\n_construct_char_code_lookup()\n\n\nsctypes = {\'int\': [],\n           \'uint\':[],\n           \'float\':[],\n           \'complex\':[],\n           \'others\':[bool, object, str, unicode, void]}\n\ndef _add_array_type(typename, bits):\n    try:\n        t = allTypes[\'%s%d\' % (typename, bits)]\n    except KeyError:\n        pass\n    else:\n        sctypes[typename].append(t)\n\ndef _set_array_types():\n    ibytes = [1, 2, 4, 8, 16, 32, 64]\n    fbytes = [2, 4, 8, 10, 12, 16, 32, 64]\n    for bytes in ibytes:\n        bits = 8*bytes\n        _add_array_type(\'int\', bits)\n        _add_array_type(\'uint\', bits)\n    for bytes in fbytes:\n        bits = 8*bytes\n        _add_array_type(\'float\', bits)\n        _add_array_type(\'complex\', 2*bits)\n    _gi = dtype(\'p\')\n    if _gi.type not in sctypes[\'int\']:\n        indx = 0\n        sz = _gi.itemsize\n        _lst = sctypes[\'int\']\n        while (indx < len(_lst) and sz >= _lst[indx](0).itemsize):\n            indx += 1\n        sctypes[\'int\'].insert(indx, _gi.type)\n        sctypes[\'uint\'].insert(indx, dtype(\'P\').type)\n_set_array_types()\n\n\ngenericTypeRank = [\'bool\', \'int8\', \'uint8\', \'int16\', \'uint16\',\n                   \'int32\', \'uint32\', \'int64\', \'uint64\', \'int128\',\n                   \'uint128\', \'float16\',\n                   \'float32\', \'float64\', \'float80\', \'float96\', \'float128\',\n                   \'float256\',\n                   \'complex32\', \'complex64\', \'complex128\', \'complex160\',\n                   \'complex192\', \'complex256\', \'complex512\', \'object\']\n\ndef maximum_sctype(t):\n    \n    g = obj2sctype(t)\n    if g is None:\n        return t\n    t = g\n    name = t.__name__\n    base, bits = _evalname(name)\n    if bits == 0:\n        return t\n    else:\n        return sctypes[base][-1]\n\ntry:\n    buffer_type = _types.BufferType\nexcept AttributeError:\n        buffer_type = memoryview\n\n_python_types = {int: \'int_\',\n                 float: \'float_\',\n                 complex: \'complex_\',\n                 bool: \'bool_\',\n                 bytes: \'bytes_\',\n                 unicode: \'unicode_\',\n                 buffer_type: \'void\',\n                 }\n\nif sys.version_info[0] >= 3:\n    def _python_type(t):\n        \n        if not isinstance(t, type):\n            t = type(t)\n        return allTypes[_python_types.get(t, \'object_\')]\nelse:\n    def _python_type(t):\n        \n        if not isinstance(t, _types.TypeType):\n            t = type(t)\n        return allTypes[_python_types.get(t, \'object_\')]\n\ndef issctype(rep):\n    \n    if not isinstance(rep, (type, dtype)):\n        return False\n    try:\n        res = obj2sctype(rep)\n        if res and res != object_:\n            return True\n        return False\n    except:\n        return False\n\ndef obj2sctype(rep, default=None):\n    \n    try:\n        if issubclass(rep, generic):\n            return rep\n    except TypeError:\n        pass\n    if isinstance(rep, dtype):\n        return rep.type\n    if isinstance(rep, type):\n        return _python_type(rep)\n    if isinstance(rep, ndarray):\n        return rep.dtype.type\n    try:\n        res = dtype(rep)\n    except:\n        return default\n    return res.type\n\n\ndef issubclass_(arg1, arg2):\n    \n    try:\n        return issubclass(arg1, arg2)\n    except TypeError:\n        return False\n\ndef issubsctype(arg1, arg2):\n    \n    return issubclass(obj2sctype(arg1), obj2sctype(arg2))\n\ndef issubdtype(arg1, arg2):\n    \n    if issubclass_(arg2, generic):\n        return issubclass(dtype(arg1).type, arg2)\n    mro = dtype(arg2).type.mro()\n    if len(mro) > 1:\n        val = mro[1]\n    else:\n        val = mro[0]\n    return issubclass(dtype(arg1).type, val)\n\n\nclass _typedict(dict):\n    \n\n    def __getitem__(self, obj):\n        return dict.__getitem__(self, obj2sctype(obj))\n\nnbytes = _typedict()\n_alignment = _typedict()\n_maxvals = _typedict()\n_minvals = _typedict()\ndef _construct_lookups():\n    for name, val in typeinfo.items():\n        if not isinstance(val, tuple):\n            continue\n        obj = val[-1]\n        nbytes[obj] = val[2] // 8\n        _alignment[obj] = val[3]\n        if (len(val) > 5):\n            _maxvals[obj] = val[4]\n            _minvals[obj] = val[5]\n        else:\n            _maxvals[obj] = None\n            _minvals[obj] = None\n\n_construct_lookups()\n\ndef sctype2char(sctype):\n    \n    sctype = obj2sctype(sctype)\n    if sctype is None:\n        raise ValueError("unrecognized type")\n    return _sctype2char_dict[sctype]\n\n\n\ncast = _typedict()\ntry:\n    ScalarType = [_types.IntType, _types.FloatType, _types.ComplexType,\n                  _types.LongType, _types.BooleanType,\n                   _types.StringType, _types.UnicodeType, _types.BufferType]\nexcept AttributeError:\n        ScalarType = [int, float, complex, int, bool, bytes, str, memoryview]\n\nScalarType.extend(_sctype2char_dict.keys())\nScalarType = tuple(ScalarType)\nfor key in _sctype2char_dict.keys():\n    cast[key] = lambda x, k=key: array(x, copy=False).astype(k)\n\n_typestr = _typedict()\nfor key in _sctype2char_dict.keys():\n    if issubclass(key, allTypes[\'flexible\']):\n        _typestr[key] = _sctype2char_dict[key]\n    else:\n        _typestr[key] = empty((1,), key).dtype.str[1:]\n\nfor key, val in _typestr.items():\n    if val not in sctypeDict:\n        sctypeDict[val] = key\n\n\nif sys.version_info[0] >= 3:\n    _toadd = [\'int\', \'float\', \'complex\', \'bool\', \'object\',\n              \'str\', \'bytes\', \'object\', (\'a\', allTypes[\'bytes_\'])]\nelse:\n    _toadd = [\'int\', \'float\', \'complex\', \'bool\', \'object\', \'string\',\n              (\'str\', allTypes[\'string_\']),\n              \'unicode\', \'object\', (\'a\', allTypes[\'string_\'])]\n\nfor name in _toadd:\n    if isinstance(name, tuple):\n        sctypeDict[name[0]] = name[1]\n    else:\n        sctypeDict[name] = allTypes[\'%s_\' % name]\n\ndel _toadd, name\n\nfor key in allTypes:\n    globals()[key] = allTypes[key]\n    __all__.append(key)\n\ndel key\n\ntypecodes = {\'Character\':\'c\',\n             \'Integer\':\'bhilqp\',\n             \'UnsignedInteger\':\'BHILQP\',\n             \'Float\':\'efdg\',\n             \'Complex\':\'FDG\',\n             \'AllInteger\':\'bBhHiIlLqQpP\',\n             \'AllFloat\':\'efdgFDG\',\n             \'Datetime\': \'Mm\',\n             \'All\':\'?bhilqpBHILQPefdgFDGSUVOMm\'}\n\ntypeDict = sctypeDict\ntypeNA = sctypeNA\n\n_kind_list = [\'b\', \'u\', \'i\', \'f\', \'c\', \'S\', \'U\', \'V\', \'O\', \'M\', \'m\']\n\n__test_types = \'?\'+typecodes[\'AllInteger\'][:-2]+typecodes[\'AllFloat\']+\'O\'\n__len_test_types = len(__test_types)\n\ndef _find_common_coerce(a, b):\n    if a > b:\n        return a\n    try:\n        thisind = __test_types.index(a.char)\n    except ValueError:\n        return None\n    return _can_coerce_all([a, b], start=thisind)\n\ndef _can_coerce_all(dtypelist, start=0):\n    N = len(dtypelist)\n    if N == 0:\n        return None\n    if N == 1:\n        return dtypelist[0]\n    thisind = start\n    while thisind < __len_test_types:\n        newdtype = dtype(__test_types[thisind])\n        numcoerce = len([x for x in dtypelist if newdtype >= x])\n        if numcoerce == N:\n            return newdtype\n        thisind += 1\n    return None\n\ndef _register_types():\n    numbers.Integral.register(integer)\n    numbers.Complex.register(inexact)\n    numbers.Real.register(floating)\n\n_register_types()\n\ndef find_common_type(array_types, scalar_types):\n    \n    array_types = [dtype(x) for x in array_types]\n    scalar_types = [dtype(x) for x in scalar_types]\n\n    maxa = _can_coerce_all(array_types)\n    maxsc = _can_coerce_all(scalar_types)\n\n    if maxa is None:\n        return maxsc\n\n    if maxsc is None:\n        return maxa\n\n    try:\n        index_a = _kind_list.index(maxa.kind)\n        index_sc = _kind_list.index(maxsc.kind)\n    except ValueError:\n        return None\n\n    if index_sc > index_a:\n        return _find_common_coerce(maxsc, maxa)\n    else:\n        return maxa\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom code_generators.genapi import StealRef, NonNull\n\nmultiarray_global_vars = {\n    \'NPY_NUMUSERTYPES\':             (7, \'int\'),\n    \'NPY_DEFAULT_ASSIGN_CASTING\':   (292, \'NPY_CASTING\'),\n}\n\nmultiarray_scalar_bool_values = {\n    \'_PyArrayScalar_BoolValues\':    (9,)\n}\n\nmultiarray_types_api = {\n    \'PyBigArray_Type\':                  (1,),\n    \'PyArray_Type\':                     (2,),\n    \'PyArrayDescr_Type\':                (3,),\n    \'PyArrayFlags_Type\':                (4,),\n    \'PyArrayIter_Type\':                 (5,),\n    \'PyArrayMultiIter_Type\':            (6,),\n    \'PyBoolArrType_Type\':               (8,),\n    \'PyGenericArrType_Type\':            (10,),\n    \'PyNumberArrType_Type\':             (11,),\n    \'PyIntegerArrType_Type\':            (12,),\n    \'PySignedIntegerArrType_Type\':      (13,),\n    \'PyUnsignedIntegerArrType_Type\':    (14,),\n    \'PyInexactArrType_Type\':            (15,),\n    \'PyFloatingArrType_Type\':           (16,),\n    \'PyComplexFloatingArrType_Type\':    (17,),\n    \'PyFlexibleArrType_Type\':           (18,),\n    \'PyCharacterArrType_Type\':          (19,),\n    \'PyByteArrType_Type\':               (20,),\n    \'PyShortArrType_Type\':              (21,),\n    \'PyIntArrType_Type\':                (22,),\n    \'PyLongArrType_Type\':               (23,),\n    \'PyLongLongArrType_Type\':           (24,),\n    \'PyUByteArrType_Type\':              (25,),\n    \'PyUShortArrType_Type\':             (26,),\n    \'PyUIntArrType_Type\':               (27,),\n    \'PyULongArrType_Type\':              (28,),\n    \'PyULongLongArrType_Type\':          (29,),\n    \'PyFloatArrType_Type\':              (30,),\n    \'PyDoubleArrType_Type\':             (31,),\n    \'PyLongDoubleArrType_Type\':         (32,),\n    \'PyCFloatArrType_Type\':             (33,),\n    \'PyCDoubleArrType_Type\':            (34,),\n    \'PyCLongDoubleArrType_Type\':        (35,),\n    \'PyObjectArrType_Type\':             (36,),\n    \'PyStringArrType_Type\':             (37,),\n    \'PyUnicodeArrType_Type\':            (38,),\n    \'PyVoidArrType_Type\':               (39,),\n        \'PyTimeIntegerArrType_Type\':        (214,),\n    \'PyDatetimeArrType_Type\':           (215,),\n    \'PyTimedeltaArrType_Type\':          (216,),\n    \'PyHalfArrType_Type\':               (217,),\n    \'NpyIter_Type\':                     (218,),\n    }\n\n\nmultiarray_funcs_api = {\n    \'PyArray_GetNDArrayCVersion\':           (0,),\n    \'PyArray_SetNumericOps\':                (40,),\n    \'PyArray_GetNumericOps\':                (41,),\n    \'PyArray_INCREF\':                       (42,),\n    \'PyArray_XDECREF\':                      (43,),\n    \'PyArray_SetStringFunction\':            (44,),\n    \'PyArray_DescrFromType\':                (45,),\n    \'PyArray_TypeObjectFromType\':           (46,),\n    \'PyArray_Zero\':                         (47,),\n    \'PyArray_One\':                          (48,),\n    \'PyArray_CastToType\':                   (49, StealRef(2), NonNull(2)),\n    \'PyArray_CastTo\':                       (50,),\n    \'PyArray_CastAnyTo\':                    (51,),\n    \'PyArray_CanCastSafely\':                (52,),\n    \'PyArray_CanCastTo\':                    (53,),\n    \'PyArray_ObjectType\':                   (54,),\n    \'PyArray_DescrFromObject\':              (55,),\n    \'PyArray_ConvertToCommonType\':          (56,),\n    \'PyArray_DescrFromScalar\':              (57,),\n    \'PyArray_DescrFromTypeObject\':          (58,),\n    \'PyArray_Size\':                         (59,),\n    \'PyArray_Scalar\':                       (60,),\n    \'PyArray_FromScalar\':                   (61, StealRef(2)),\n    \'PyArray_ScalarAsCtype\':                (62,),\n    \'PyArray_CastScalarToCtype\':            (63,),\n    \'PyArray_CastScalarDirect\':             (64,),\n    \'PyArray_ScalarFromObject\':             (65,),\n    \'PyArray_GetCastFunc\':                  (66,),\n    \'PyArray_FromDims\':                     (67,),\n    \'PyArray_FromDimsAndDataAndDescr\':      (68, StealRef(3)),\n    \'PyArray_FromAny\':                      (69, StealRef(2)),\n    \'PyArray_EnsureArray\':                  (70, StealRef(1)),\n    \'PyArray_EnsureAnyArray\':               (71, StealRef(1)),\n    \'PyArray_FromFile\':                     (72,),\n    \'PyArray_FromString\':                   (73,),\n    \'PyArray_FromBuffer\':                   (74,),\n    \'PyArray_FromIter\':                     (75, StealRef(2)),\n    \'PyArray_Return\':                       (76, StealRef(1)),\n    \'PyArray_GetField\':                     (77, StealRef(2), NonNull(2)),\n    \'PyArray_SetField\':                     (78, StealRef(2), NonNull(2)),\n    \'PyArray_Byteswap\':                     (79,),\n    \'PyArray_Resize\':                       (80,),\n    \'PyArray_MoveInto\':                     (81,),\n    \'PyArray_CopyInto\':                     (82,),\n    \'PyArray_CopyAnyInto\':                  (83,),\n    \'PyArray_CopyObject\':                   (84,),\n    \'PyArray_NewCopy\':                      (85, NonNull(1)),\n    \'PyArray_ToList\':                       (86,),\n    \'PyArray_ToString\':                     (87,),\n    \'PyArray_ToFile\':                       (88,),\n    \'PyArray_Dump\':                         (89,),\n    \'PyArray_Dumps\':                        (90,),\n    \'PyArray_ValidType\':                    (91,),\n    \'PyArray_UpdateFlags\':                  (92,),\n    \'PyArray_New\':                          (93, NonNull(1)),\n    \'PyArray_NewFromDescr\':                 (94, StealRef(2), NonNull([1, 2])),\n    \'PyArray_DescrNew\':                     (95,),\n    \'PyArray_DescrNewFromType\':             (96,),\n    \'PyArray_GetPriority\':                  (97,),\n    \'PyArray_IterNew\':                      (98,),\n    \'PyArray_MultiIterNew\':                 (99,),\n    \'PyArray_PyIntAsInt\':                   (100,),\n    \'PyArray_PyIntAsIntp\':                  (101,),\n    \'PyArray_Broadcast\':                    (102,),\n    \'PyArray_FillObjectArray\':              (103,),\n    \'PyArray_FillWithScalar\':               (104,),\n    \'PyArray_CheckStrides\':                 (105,),\n    \'PyArray_DescrNewByteorder\':            (106,),\n    \'PyArray_IterAllButAxis\':               (107,),\n    \'PyArray_CheckFromAny\':                 (108, StealRef(2)),\n    \'PyArray_FromArray\':                    (109, StealRef(2)),\n    \'PyArray_FromInterface\':                (110,),\n    \'PyArray_FromStructInterface\':          (111,),\n    \'PyArray_FromArrayAttr\':                (112,),\n    \'PyArray_ScalarKind\':                   (113,),\n    \'PyArray_CanCoerceScalar\':              (114,),\n    \'PyArray_NewFlagsObject\':               (115,),\n    \'PyArray_CanCastScalar\':                (116,),\n    \'PyArray_CompareUCS4\':                  (117,),\n    \'PyArray_RemoveSmallest\':               (118,),\n    \'PyArray_ElementStrides\':               (119,),\n    \'PyArray_Item_INCREF\':                  (120,),\n    \'PyArray_Item_XDECREF\':                 (121,),\n    \'PyArray_FieldNames\':                   (122,),\n    \'PyArray_Transpose\':                    (123,),\n    \'PyArray_TakeFrom\':                     (124,),\n    \'PyArray_PutTo\':                        (125,),\n    \'PyArray_PutMask\':                      (126,),\n    \'PyArray_Repeat\':                       (127,),\n    \'PyArray_Choose\':                       (128,),\n    \'PyArray_Sort\':                         (129,),\n    \'PyArray_ArgSort\':                      (130,),\n    \'PyArray_SearchSorted\':                 (131,),\n    \'PyArray_ArgMax\':                       (132,),\n    \'PyArray_ArgMin\':                       (133,),\n    \'PyArray_Reshape\':                      (134,),\n    \'PyArray_Newshape\':                     (135,),\n    \'PyArray_Squeeze\':                      (136,),\n    \'PyArray_View\':                         (137, StealRef(2)),\n    \'PyArray_SwapAxes\':                     (138,),\n    \'PyArray_Max\':                          (139,),\n    \'PyArray_Min\':                          (140,),\n    \'PyArray_Ptp\':                          (141,),\n    \'PyArray_Mean\':                         (142,),\n    \'PyArray_Trace\':                        (143,),\n    \'PyArray_Diagonal\':                     (144,),\n    \'PyArray_Clip\':                         (145,),\n    \'PyArray_Conjugate\':                    (146,),\n    \'PyArray_Nonzero\':                      (147,),\n    \'PyArray_Std\':                          (148,),\n    \'PyArray_Sum\':                          (149,),\n    \'PyArray_CumSum\':                       (150,),\n    \'PyArray_Prod\':                         (151,),\n    \'PyArray_CumProd\':                      (152,),\n    \'PyArray_All\':                          (153,),\n    \'PyArray_Any\':                          (154,),\n    \'PyArray_Compress\':                     (155,),\n    \'PyArray_Flatten\':                      (156,),\n    \'PyArray_Ravel\':                        (157,),\n    \'PyArray_MultiplyList\':                 (158,),\n    \'PyArray_MultiplyIntList\':              (159,),\n    \'PyArray_GetPtr\':                       (160,),\n    \'PyArray_CompareLists\':                 (161,),\n    \'PyArray_AsCArray\':                     (162, StealRef(5)),\n    \'PyArray_As1D\':                         (163,),\n    \'PyArray_As2D\':                         (164,),\n    \'PyArray_Free\':                         (165,),\n    \'PyArray_Converter\':                    (166,),\n    \'PyArray_IntpFromSequence\':             (167,),\n    \'PyArray_Concatenate\':                  (168,),\n    \'PyArray_InnerProduct\':                 (169,),\n    \'PyArray_MatrixProduct\':                (170,),\n    \'PyArray_CopyAndTranspose\':             (171,),\n    \'PyArray_Correlate\':                    (172,),\n    \'PyArray_TypestrConvert\':               (173,),\n    \'PyArray_DescrConverter\':               (174,),\n    \'PyArray_DescrConverter2\':              (175,),\n    \'PyArray_IntpConverter\':                (176,),\n    \'PyArray_BufferConverter\':              (177,),\n    \'PyArray_AxisConverter\':                (178,),\n    \'PyArray_BoolConverter\':                (179,),\n    \'PyArray_ByteorderConverter\':           (180,),\n    \'PyArray_OrderConverter\':               (181,),\n    \'PyArray_EquivTypes\':                   (182,),\n    \'PyArray_Zeros\':                        (183, StealRef(3)),\n    \'PyArray_Empty\':                        (184, StealRef(3)),\n    \'PyArray_Where\':                        (185,),\n    \'PyArray_Arange\':                       (186,),\n    \'PyArray_ArangeObj\':                    (187,),\n    \'PyArray_SortkindConverter\':            (188,),\n    \'PyArray_LexSort\':                      (189,),\n    \'PyArray_Round\':                        (190,),\n    \'PyArray_EquivTypenums\':                (191,),\n    \'PyArray_RegisterDataType\':             (192,),\n    \'PyArray_RegisterCastFunc\':             (193,),\n    \'PyArray_RegisterCanCast\':              (194,),\n    \'PyArray_InitArrFuncs\':                 (195,),\n    \'PyArray_IntTupleFromIntp\':             (196,),\n    \'PyArray_TypeNumFromName\':              (197,),\n    \'PyArray_ClipmodeConverter\':            (198,),\n    \'PyArray_OutputConverter\':              (199,),\n    \'PyArray_BroadcastToShape\':             (200,),\n    \'_PyArray_SigintHandler\':               (201,),\n    \'_PyArray_GetSigintBuf\':                (202,),\n    \'PyArray_DescrAlignConverter\':          (203,),\n    \'PyArray_DescrAlignConverter2\':         (204,),\n    \'PyArray_SearchsideConverter\':          (205,),\n    \'PyArray_CheckAxis\':                    (206,),\n    \'PyArray_OverflowMultiplyList\':         (207,),\n    \'PyArray_CompareString\':                (208,),\n    \'PyArray_MultiIterFromObjects\':         (209,),\n    \'PyArray_GetEndianness\':                (210,),\n    \'PyArray_GetNDArrayCFeatureVersion\':    (211,),\n    \'PyArray_Correlate2\':                   (212,),\n    \'PyArray_NeighborhoodIterNew\':          (213,),\n        \'PyArray_SetDatetimeParseFunction\':     (219,),\n    \'PyArray_DatetimeToDatetimeStruct\':     (220,),\n    \'PyArray_TimedeltaToTimedeltaStruct\':   (221,),\n    \'PyArray_DatetimeStructToDatetime\':     (222,),\n    \'PyArray_TimedeltaStructToTimedelta\':   (223,),\n        \'NpyIter_New\':                          (224,),\n    \'NpyIter_MultiNew\':                     (225,),\n    \'NpyIter_AdvancedNew\':                  (226,),\n    \'NpyIter_Copy\':                         (227,),\n    \'NpyIter_Deallocate\':                   (228,),\n    \'NpyIter_HasDelayedBufAlloc\':           (229,),\n    \'NpyIter_HasExternalLoop\':              (230,),\n    \'NpyIter_EnableExternalLoop\':           (231,),\n    \'NpyIter_GetInnerStrideArray\':          (232,),\n    \'NpyIter_GetInnerLoopSizePtr\':          (233,),\n    \'NpyIter_Reset\':                        (234,),\n    \'NpyIter_ResetBasePointers\':            (235,),\n    \'NpyIter_ResetToIterIndexRange\':        (236,),\n    \'NpyIter_GetNDim\':                      (237,),\n    \'NpyIter_GetNOp\':                       (238,),\n    \'NpyIter_GetIterNext\':                  (239,),\n    \'NpyIter_GetIterSize\':                  (240,),\n    \'NpyIter_GetIterIndexRange\':            (241,),\n    \'NpyIter_GetIterIndex\':                 (242,),\n    \'NpyIter_GotoIterIndex\':                (243,),\n    \'NpyIter_HasMultiIndex\':                (244,),\n    \'NpyIter_GetShape\':                     (245,),\n    \'NpyIter_GetGetMultiIndex\':             (246,),\n    \'NpyIter_GotoMultiIndex\':               (247,),\n    \'NpyIter_RemoveMultiIndex\':             (248,),\n    \'NpyIter_HasIndex\':                     (249,),\n    \'NpyIter_IsBuffered\':                   (250,),\n    \'NpyIter_IsGrowInner\':                  (251,),\n    \'NpyIter_GetBufferSize\':                (252,),\n    \'NpyIter_GetIndexPtr\':                  (253,),\n    \'NpyIter_GotoIndex\':                    (254,),\n    \'NpyIter_GetDataPtrArray\':              (255,),\n    \'NpyIter_GetDescrArray\':                (256,),\n    \'NpyIter_GetOperandArray\':              (257,),\n    \'NpyIter_GetIterView\':                  (258,),\n    \'NpyIter_GetReadFlags\':                 (259,),\n    \'NpyIter_GetWriteFlags\':                (260,),\n    \'NpyIter_DebugPrint\':                   (261,),\n    \'NpyIter_IterationNeedsAPI\':            (262,),\n    \'NpyIter_GetInnerFixedStrideArray\':     (263,),\n    \'NpyIter_RemoveAxis\':                   (264,),\n    \'NpyIter_GetAxisStrideArray\':           (265,),\n    \'NpyIter_RequiresBuffering\':            (266,),\n    \'NpyIter_GetInitialDataPtrArray\':       (267,),\n    \'NpyIter_CreateCompatibleStrides\':      (268,),\n        \'PyArray_CastingConverter\':             (269,),\n    \'PyArray_CountNonzero\':                 (270,),\n    \'PyArray_PromoteTypes\':                 (271,),\n    \'PyArray_MinScalarType\':                (272,),\n    \'PyArray_ResultType\':                   (273,),\n    \'PyArray_CanCastArrayTo\':               (274,),\n    \'PyArray_CanCastTypeTo\':                (275,),\n    \'PyArray_EinsteinSum\':                  (276,),\n    \'PyArray_NewLikeArray\':                 (277, StealRef(3), NonNull(1)),\n    \'PyArray_GetArrayParamsFromObject\':     (278,),\n    \'PyArray_ConvertClipmodeSequence\':      (279,),\n    \'PyArray_MatrixProduct2\':               (280,),\n        \'NpyIter_IsFirstVisit\':                 (281,),\n    \'PyArray_SetBaseObject\':                (282, StealRef(2)),\n    \'PyArray_CreateSortedStridePerm\':       (283,),\n    \'PyArray_RemoveAxesInPlace\':            (284,),\n    \'PyArray_DebugPrint\':                   (285,),\n    \'PyArray_FailUnlessWriteable\':          (286,),\n    \'PyArray_SetUpdateIfCopyBase\':          (287, StealRef(2)),\n    \'PyDataMem_NEW\':                        (288,),\n    \'PyDataMem_FREE\':                       (289,),\n    \'PyDataMem_RENEW\':                      (290,),\n    \'PyDataMem_SetEventHook\':               (291,),\n    \'PyArray_MapIterSwapAxes\':              (293,),\n    \'PyArray_MapIterArray\':                 (294,),\n    \'PyArray_MapIterNext\':                  (295,),\n        \'PyArray_Partition\':                    (296,),\n    \'PyArray_ArgPartition\':                 (297,),\n    \'PyArray_SelectkindConverter\':          (298,),\n    \'PyDataMem_NEW_ZEROED\':                 (299,),\n            \'PyArray_CheckAnyScalarExact\':          (300, NonNull(1)),\n    }\n\nufunc_types_api = {\n    \'PyUFunc_Type\':                             (0,)\n}\n\nufunc_funcs_api = {\n    \'PyUFunc_FromFuncAndData\':                  (1,),\n    \'PyUFunc_RegisterLoopForType\':              (2,),\n    \'PyUFunc_GenericFunction\':                  (3,),\n    \'PyUFunc_f_f_As_d_d\':                       (4,),\n    \'PyUFunc_d_d\':                              (5,),\n    \'PyUFunc_f_f\':                              (6,),\n    \'PyUFunc_g_g\':                              (7,),\n    \'PyUFunc_F_F_As_D_D\':                       (8,),\n    \'PyUFunc_F_F\':                              (9,),\n    \'PyUFunc_D_D\':                              (10,),\n    \'PyUFunc_G_G\':                              (11,),\n    \'PyUFunc_O_O\':                              (12,),\n    \'PyUFunc_ff_f_As_dd_d\':                     (13,),\n    \'PyUFunc_ff_f\':                             (14,),\n    \'PyUFunc_dd_d\':                             (15,),\n    \'PyUFunc_gg_g\':                             (16,),\n    \'PyUFunc_FF_F_As_DD_D\':                     (17,),\n    \'PyUFunc_DD_D\':                             (18,),\n    \'PyUFunc_FF_F\':                             (19,),\n    \'PyUFunc_GG_G\':                             (20,),\n    \'PyUFunc_OO_O\':                             (21,),\n    \'PyUFunc_O_O_method\':                       (22,),\n    \'PyUFunc_OO_O_method\':                      (23,),\n    \'PyUFunc_On_Om\':                            (24,),\n    \'PyUFunc_GetPyValues\':                      (25,),\n    \'PyUFunc_checkfperr\':                       (26,),\n    \'PyUFunc_clearfperr\':                       (27,),\n    \'PyUFunc_getfperr\':                         (28,),\n    \'PyUFunc_handlefperr\':                      (29,),\n    \'PyUFunc_ReplaceLoopBySignature\':           (30,),\n    \'PyUFunc_FromFuncAndDataAndSignature\':      (31,),\n    \'PyUFunc_SetUsesArraysAsData\':              (32,),\n        \'PyUFunc_e_e\':                              (33,),\n    \'PyUFunc_e_e_As_f_f\':                       (34,),\n    \'PyUFunc_e_e_As_d_d\':                       (35,),\n    \'PyUFunc_ee_e\':                             (36,),\n    \'PyUFunc_ee_e_As_ff_f\':                     (37,),\n    \'PyUFunc_ee_e_As_dd_d\':                     (38,),\n        \'PyUFunc_DefaultTypeResolver\':              (39,),\n    \'PyUFunc_ValidateCasting\':                  (40,),\n        \'PyUFunc_RegisterLoopForDescr\':             (41,),\n    }\n\nmultiarray_api = (\n        multiarray_global_vars,\n        multiarray_scalar_bool_values,\n        multiarray_types_api,\n        multiarray_funcs_api,\n)\n\nufunc_api = (\n        ufunc_funcs_api,\n        ufunc_types_api\n)\n\nfull_api = multiarray_api + ufunc_api\nfrom __future__ import division, absolute_import, print_function\n\nfrom distutils.core import Distribution\n\nclass NumpyDistribution(Distribution):\n    def __init__(self, attrs = None):\n                self.scons_data = []\n                self.installed_libraries = []\n                self.installed_pkg_config = {}\n        Distribution.__init__(self, attrs)\n\n    def has_scons_scripts(self):\n        return bool(self.scons_data)\nfrom __future__ import division, absolute_import, print_function\n\nfrom distutils.unixccompiler import UnixCCompiler\n\nclass PathScaleCCompiler(UnixCCompiler):\n\n    \n\n    compiler_type = \'pathcc\'\n    cc_exe = \'pathcc\'\n    cxx_exe = \'pathCC\'\n\n    def __init__ (self, verbose=0, dry_run=0, force=0):\n        UnixCCompiler.__init__ (self, verbose, dry_run, force)\n        cc_compiler = self.cc_exe\n        cxx_compiler = self.cxx_exe\n        self.set_executables(compiler=cc_compiler,\n                             compiler_so=cc_compiler,\n                             compiler_cxx=cxx_compiler,\n                             linker_exe=cc_compiler,\n                             linker_so=cc_compiler + \' -shared\')\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'PathScaleFCompiler\']\n\nclass PathScaleFCompiler(FCompiler):\n\n    compiler_type = \'pathf95\'\n    description = \'PathScale Fortran Compiler\'\n    version_pattern =  r\'PathScale\\(TM\\) Compiler Suite: Version (?P<version>[\\d.]+)\'\n\n    executables = {\n        \'version_cmd\'  : ["pathf95", "-version"],\n        \'compiler_f77\' : ["pathf95", "-fixedform"],\n        \'compiler_fix\' : ["pathf95", "-fixedform"],\n        \'compiler_f90\' : ["pathf95"],\n        \'linker_so\'    : ["pathf95", "-shared"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n    }\n    pic_flags = [\'-fPIC\']\n    module_dir_switch = \'-module \'     module_include_switch = \'-I\'\n\n    def get_flags_opt(self):\n        return [\'-O3\']\n    def get_flags_debug(self):\n        return [\'-g\']\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n        from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'pathf95\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.fcompiler import FCompiler\nfrom sys import platform\n\ncompilers = [\'PGroupFCompiler\']\n\nclass PGroupFCompiler(FCompiler):\n\n    compiler_type = \'pg\'\n    description = \'Portland Group Fortran Compiler\'\n    version_pattern =  r\'\\s*pg(f77|f90|hpf|fortran) (?P<version>[\\d.-]+).*\'\n\n    if platform == \'darwin\':\n        executables = {\n        \'version_cmd\'  : ["<F77>", "-V"],\n        \'compiler_f77\' : ["pgfortran", "-dynamiclib"],\n        \'compiler_fix\' : ["pgfortran", "-Mfixed", "-dynamiclib"],\n        \'compiler_f90\' : ["pgfortran", "-dynamiclib"],\n        \'linker_so\'    : ["libtool"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n        pic_flags = [\'\']\n    else:\n        executables = {\n        \'version_cmd\'  : ["<F77>", "-V"],\n        \'compiler_f77\' : ["pgfortran"],\n        \'compiler_fix\' : ["pgfortran", "-Mfixed"],\n        \'compiler_f90\' : ["pgfortran"],\n        \'linker_so\'    : ["pgfortran", "-shared", "-fpic"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n        pic_flags = [\'-fpic\']\n\n\n    module_dir_switch = \'-module \'\n    module_include_switch = \'-I\'\n\n    def get_flags(self):\n        opt = [\'-Minform=inform\', \'-Mnosecond_underscore\']\n        return self.pic_flags + opt\n    def get_flags_opt(self):\n        return [\'-fast\']\n    def get_flags_debug(self):\n        return [\'-g\']\n\n    if platform == \'darwin\':\n        def get_flags_linker_so(self):\n            return ["-dynamic", \'-undefined\', \'dynamic_lookup\']\n\n    def runtime_library_dir_option(self, dir):\n        return \'-R"%s"\' % dir\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'pg\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\n    \'polyzero\', \'polyone\', \'polyx\', \'polydomain\', \'polyline\', \'polyadd\',\n    \'polysub\', \'polymulx\', \'polymul\', \'polydiv\', \'polypow\', \'polyval\',\n    \'polyder\', \'polyint\', \'polyfromroots\', \'polyvander\', \'polyfit\',\n    \'polytrim\', \'polyroots\', \'Polynomial\', \'polyval2d\', \'polyval3d\',\n    \'polygrid2d\', \'polygrid3d\', \'polyvander2d\', \'polyvander3d\']\n\nimport warnings\nimport numpy as np\nimport numpy.linalg as la\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\npolytrim = pu.trimcoef\n\n\npolydomain = np.array([-1, 1])\n\npolyzero = np.array([0])\n\npolyone = np.array([1])\n\npolyx = np.array([0, 1])\n\n\n\ndef polyline(off, scl):\n    \n    if scl != 0:\n        return np.array([off, scl])\n    else:\n        return np.array([off])\n\n\ndef polyfromroots(roots):\n    \n    if len(roots) == 0:\n        return np.ones(1)\n    else:\n        [roots] = pu.as_series([roots], trim=False)\n        roots.sort()\n        p = [polyline(-r, 1) for r in roots]\n        n = len(p)\n        while n > 1:\n            m, r = divmod(n, 2)\n            tmp = [polymul(p[i], p[i+m]) for i in range(m)]\n            if r:\n                tmp[0] = polymul(tmp[0], p[-1])\n            p = tmp\n            n = m\n        return p[0]\n\n\ndef polyadd(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] += c2\n        ret = c1\n    else:\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef polysub(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if len(c1) > len(c2):\n        c1[:c2.size] -= c2\n        ret = c1\n    else:\n        c2 = -c2\n        c2[:c1.size] += c1\n        ret = c2\n    return pu.trimseq(ret)\n\n\ndef polymulx(c):\n    \n        [c] = pu.as_series([c])\n        if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]*0\n    prd[1:] = c\n    return prd\n\n\ndef polymul(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    ret = np.convolve(c1, c2)\n    return pu.trimseq(ret)\n\n\ndef polydiv(c1, c2):\n    \n        [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    len1 = len(c1)\n    len2 = len(c2)\n    if len2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    elif len1 < len2:\n        return c1[:1]*0, c1\n    else:\n        dlen = len1 - len2\n        scl = c2[-1]\n        c2 = c2[:-1]/scl\n        i = dlen\n        j = len1 - 1\n        while i >= 0:\n            c1[i:j] -= c2*c1[j]\n            i -= 1\n            j -= 1\n        return c1[j+1:]/scl, pu.trimseq(c1[:j+1])\n\n\ndef polypow(c, pow, maxpower=None):\n    \n        [c] = pu.as_series([c])\n    power = int(pow)\n    if power != pow or power < 0:\n        raise ValueError("Power must be a non-negative integer.")\n    elif maxpower is not None and power > maxpower:\n        raise ValueError("Power is too large")\n    elif power == 0:\n        return np.array([1], dtype=c.dtype)\n    elif power == 1:\n        return c\n    else:\n                        prd = c\n        for i in range(2, power + 1):\n            prd = np.convolve(prd, c)\n        return prd\n\n\ndef polyder(c, m=1, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n                c = c + 0.0\n    cdt = c.dtype\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of derivation must be integer")\n    if cnt < 0:\n        raise ValueError("The order of derivation must be non-negative")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    c = np.rollaxis(c, iaxis)\n    n = len(c)\n    if cnt >= n:\n        c = c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=cdt)\n            for j in range(n, 0, -1):\n                der[j - 1] = j*c[j]\n            c = der\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef polyint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \n    c = np.array(c, ndmin=1, copy=1)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n                c = c + 0.0\n    cdt = c.dtype\n    if not np.iterable(k):\n        k = [k]\n    cnt, iaxis = [int(t) for t in [m, axis]]\n\n    if cnt != m:\n        raise ValueError("The order of integration must be integer")\n    if cnt < 0:\n        raise ValueError("The order of integration must be non-negative")\n    if len(k) > cnt:\n        raise ValueError("Too many integration constants")\n    if iaxis != axis:\n        raise ValueError("The axis must be integer")\n    if not -c.ndim <= iaxis < c.ndim:\n        raise ValueError("The axis is out of range")\n    if iaxis < 0:\n        iaxis += c.ndim\n\n    if cnt == 0:\n        return c\n\n    k = list(k) + [0]*(cnt - len(k))\n    c = np.rollaxis(c, iaxis)\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=cdt)\n            tmp[0] = c[0]*0\n            tmp[1] = c[0]\n            for j in range(1, n):\n                tmp[j + 1] = c[j]/(j + 1)\n            tmp[0] += k[i] - polyval(lbnd, tmp)\n            c = tmp\n    c = np.rollaxis(c, 0, iaxis + 1)\n    return c\n\n\ndef polyval(x, c, tensor=True):\n    \n    c = np.array(c, ndmin=1, copy=0)\n    if c.dtype.char in \'?bBhHiIlLqQpP\':\n                c = c + 0.0\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    c0 = c[-1] + x*0\n    for i in range(2, len(c) + 1):\n        c0 = c[-i] + c0*x\n    return c0\n\n\ndef polyval2d(x, y, c):\n    \n    try:\n        x, y = np.array((x, y), copy=0)\n    except:\n        raise ValueError(\'x, y are incompatible\')\n\n    c = polyval(x, c)\n    c = polyval(y, c, tensor=False)\n    return c\n\n\ndef polygrid2d(x, y, c):\n    \n    c = polyval(x, c)\n    c = polyval(y, c)\n    return c\n\n\ndef polyval3d(x, y, z, c):\n    \n    try:\n        x, y, z = np.array((x, y, z), copy=0)\n    except:\n        raise ValueError(\'x, y, z are incompatible\')\n\n    c = polyval(x, c)\n    c = polyval(y, c, tensor=False)\n    c = polyval(z, c, tensor=False)\n    return c\n\n\ndef polygrid3d(x, y, z, c):\n    \n    c = polyval(x, c)\n    c = polyval(y, c)\n    c = polyval(z, c)\n    return c\n\n\ndef polyvander(x, deg):\n    \n    ideg = int(deg)\n    if ideg != deg:\n        raise ValueError("deg must be integer")\n    if ideg < 0:\n        raise ValueError("deg must be non-negative")\n\n    x = np.array(x, copy=0, ndmin=1) + 0.0\n    dims = (ideg + 1,) + x.shape\n    dtyp = x.dtype\n    v = np.empty(dims, dtype=dtyp)\n    v[0] = x*0 + 1\n    if ideg > 0:\n        v[1] = x\n        for i in range(2, ideg + 1):\n            v[i] = v[i-1]*x\n    return np.rollaxis(v, 0, v.ndim)\n\n\ndef polyvander2d(x, y, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy = ideg\n    x, y = np.array((x, y), copy=0) + 0.0\n\n    vx = polyvander(x, degx)\n    vy = polyvander(y, degy)\n    v = vx[..., None]*vy[..., None,:]\n            return v.reshape(v.shape[:-2] + (-1,))\n\n\ndef polyvander3d(x, y, z, deg):\n    \n    ideg = [int(d) for d in deg]\n    is_valid = [id == d and id >= 0 for id, d in zip(ideg, deg)]\n    if is_valid != [1, 1, 1]:\n        raise ValueError("degrees must be non-negative integers")\n    degx, degy, degz = ideg\n    x, y, z = np.array((x, y, z), copy=0) + 0.0\n\n    vx = polyvander(x, degx)\n    vy = polyvander(y, degy)\n    vz = polyvander(z, degz)\n    v = vx[..., None, None]*vy[..., None,:, None]*vz[..., None, None,:]\n            return v.reshape(v.shape[:-3] + (-1,))\n\n\ndef polyfit(x, y, deg, rcond=None, full=False, w=None):\n    \n    order = int(deg) + 1\n    x = np.asarray(x) + 0.0\n    y = np.asarray(y) + 0.0\n\n        if deg < 0:\n        raise ValueError("expected deg >= 0")\n    if x.ndim != 1:\n        raise TypeError("expected 1D vector for x")\n    if x.size == 0:\n        raise TypeError("expected non-empty vector for x")\n    if y.ndim < 1 or y.ndim > 2:\n        raise TypeError("expected 1D or 2D array for y")\n    if len(x) != len(y):\n        raise TypeError("expected x and y to have same length")\n\n        lhs = polyvander(x, deg).T\n    rhs = y.T\n    if w is not None:\n        w = np.asarray(w) + 0.0\n        if w.ndim != 1:\n            raise TypeError("expected 1D vector for w")\n        if len(x) != len(w):\n            raise TypeError("expected x and w to have same length")\n                        lhs = lhs * w\n        rhs = rhs * w\n\n        if rcond is None:\n        rcond = len(x)*np.finfo(x.dtype).eps\n\n        if issubclass(lhs.dtype.type, np.complexfloating):\n        scl = np.sqrt((np.square(lhs.real) + np.square(lhs.imag)).sum(1))\n    else:\n        scl = np.sqrt(np.square(lhs).sum(1))\n    scl[scl == 0] = 1\n\n        c, resids, rank, s = la.lstsq(lhs.T/scl, rhs.T, rcond)\n    c = (c.T/scl).T\n\n        if rank != order and not full:\n        msg = "The fit may be poorly conditioned"\n        warnings.warn(msg, pu.RankWarning)\n\n    if full:\n        return c, [resids, rank, s, rcond]\n    else:\n        return c\n\n\ndef polycompanion(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        raise ValueError(\'Series must have maximum degree of at least 1.\')\n    if len(c) == 2:\n        return np.array([[-c[0]/c[1]]])\n\n    n = len(c) - 1\n    mat = np.zeros((n, n), dtype=c.dtype)\n    bot = mat.reshape(-1)[n::n+1]\n    bot[...] = 1\n    mat[:, -1] -= c[:-1]/c[-1]\n    return mat\n\n\ndef polyroots(c):\n    \n        [c] = pu.as_series([c])\n    if len(c) < 2:\n        return np.array([], dtype=c.dtype)\n    if len(c) == 2:\n        return np.array([-c[0]/c[1]])\n\n    m = polycompanion(c)\n    r = la.eigvals(m)\n    r.sort()\n    return r\n\n\n\nclass Polynomial(ABCPolyBase):\n    \n        _add = staticmethod(polyadd)\n    _sub = staticmethod(polysub)\n    _mul = staticmethod(polymul)\n    _div = staticmethod(polydiv)\n    _pow = staticmethod(polypow)\n    _val = staticmethod(polyval)\n    _int = staticmethod(polyint)\n    _der = staticmethod(polyder)\n    _fit = staticmethod(polyfit)\n    _line = staticmethod(polyline)\n    _roots = staticmethod(polyroots)\n    _fromroots = staticmethod(polyfromroots)\n\n        nickname = \'poly\'\n    domain = np.array(polydomain)\n    window = np.array(polydomain)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\n__all__ = [\n    \'RankWarning\', \'PolyError\', \'PolyDomainError\', \'as_series\', \'trimseq\',\n    \'trimcoef\', \'getdomain\', \'mapdomain\', \'mapparms\', \'PolyBase\']\n\n\nclass RankWarning(UserWarning):\n    \n    pass\n\nclass PolyError(Exception):\n    \n    pass\n\nclass PolyDomainError(PolyError):\n    \n    pass\n\n\nclass PolyBase(object):\n    \n    pass\n\ndef trimseq(seq):\n    \n    if len(seq) == 0:\n        return seq\n    else:\n        for i in range(len(seq) - 1, -1, -1):\n            if seq[i] != 0:\n                break\n        return seq[:i+1]\n\n\ndef as_series(alist, trim=True):\n    \n    arrays = [np.array(a, ndmin=1, copy=0) for a in alist]\n    if min([a.size for a in arrays]) == 0:\n        raise ValueError("Coefficient array is empty")\n    if any([a.ndim != 1 for a in arrays]):\n        raise ValueError("Coefficient array is not 1-d")\n    if trim:\n        arrays = [trimseq(a) for a in arrays]\n\n    if any([a.dtype == np.dtype(object) for a in arrays]):\n        ret = []\n        for a in arrays:\n            if a.dtype != np.dtype(object):\n                tmp = np.empty(len(a), dtype=np.dtype(object))\n                tmp[:] = a[:]\n                ret.append(tmp)\n            else:\n                ret.append(a.copy())\n    else:\n        try:\n            dtype = np.common_type(*arrays)\n        except:\n            raise ValueError("Coefficient arrays have no common type")\n        ret = [np.array(a, copy=1, dtype=dtype) for a in arrays]\n    return ret\n\n\ndef trimcoef(c, tol=0):\n    \n    if tol < 0:\n        raise ValueError("tol must be non-negative")\n\n    [c] = as_series([c])\n    [ind] = np.where(np.abs(c) > tol)\n    if len(ind) == 0:\n        return c[:1]*0\n    else:\n        return c[:ind[-1] + 1].copy()\n\ndef getdomain(x):\n    \n    [x] = as_series([x], trim=False)\n    if x.dtype.char in np.typecodes[\'Complex\']:\n        rmin, rmax = x.real.min(), x.real.max()\n        imin, imax = x.imag.min(), x.imag.max()\n        return np.array((complex(rmin, imin), complex(rmax, imax)))\n    else:\n        return np.array((x.min(), x.max()))\n\ndef mapparms(old, new):\n    \n    oldlen = old[1] - old[0]\n    newlen = new[1] - new[0]\n    off = (old[1]*new[0] - old[0]*new[1])/oldlen\n    scl = newlen/oldlen\n    return off, scl\n\ndef mapdomain(x, old, new):\n    \n    x = np.asanyarray(x)\n    off, scl = mapparms(old, new)\n    return off + scl*x\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\nclass GenericObject(object):\n    def __init__(self, v):\n        self.v = v\n\n    def __add__(self, other):\n        return self\n\n    def __radd__(self, other):\n        return self\n\n    dtype = np.dtype(\'O\')\n\ndef print_cancast_table(ntypes):\n    print(\'X\', end=\' \')\n    for char in ntypes:\n        print(char, end=\' \')\n    print()\n    for row in ntypes:\n        print(row, end=\' \')\n        for col in ntypes:\n            print(int(np.can_cast(row, col)), end=\' \')\n        print()\n\ndef print_coercion_table(ntypes, inputfirstvalue, inputsecondvalue, firstarray, use_promote_types=False):\n    print(\'+\', end=\' \')\n    for char in ntypes:\n        print(char, end=\' \')\n    print()\n    for row in ntypes:\n        if row == \'O\':\n            rowtype = GenericObject\n        else:\n            rowtype = np.obj2sctype(row)\n\n        print(row, end=\' \')\n        for col in ntypes:\n            if col == \'O\':\n                coltype = GenericObject\n            else:\n                coltype = np.obj2sctype(col)\n            try:\n                if firstarray:\n                    rowvalue = np.array([rowtype(inputfirstvalue)], dtype=rowtype)\n                else:\n                    rowvalue = rowtype(inputfirstvalue)\n                colvalue = coltype(inputsecondvalue)\n                if use_promote_types:\n                    char = np.promote_types(rowvalue.dtype, colvalue.dtype).char\n                else:\n                    value = np.add(rowvalue, colvalue)\n                    if isinstance(value, np.ndarray):\n                        char = value.dtype.char\n                    else:\n                        char = np.dtype(type(value)).char\n            except ValueError:\n                char = \'!\'\n            except OverflowError:\n                char = \'@\'\n            except TypeError:\n                char = \'            print(char, end=\' \')\n        print()\n\nprint("can cast")\nprint_cancast_table(np.typecodes[\'All\'])\nprint()\nprint("In these tables, ValueError is \'!\', OverflowError is \'@\', TypeError is \'print()\nprint("scalar + scalar")\nprint_coercion_table(np.typecodes[\'All\'], 0, 0, False)\nprint()\nprint("scalar + neg scalar")\nprint_coercion_table(np.typecodes[\'All\'], 0, -1, False)\nprint()\nprint("array + scalar")\nprint_coercion_table(np.typecodes[\'All\'], 0, 0, True)\nprint()\nprint("array + neg scalar")\nprint_coercion_table(np.typecodes[\'All\'], 0, -1, True)\nprint()\nprint("promote_types")\nprint_coercion_table(np.typecodes[\'All\'], 0, 0, False, True)\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'bytes\', \'asbytes\', \'isfileobj\', \'getexception\', \'strchar\',\n           \'unicode\', \'asunicode\', \'asbytes_nested\', \'asunicode_nested\',\n           \'asstr\', \'open_latin1\', \'long\', \'basestring\', \'sixu\',\n           \'integer_types\']\n\nimport sys\n\nif sys.version_info[0] >= 3:\n    import io\n\n    long = int\n    integer_types = (int,)\n    basestring = str\n    unicode = str\n    bytes = bytes\n\n    def asunicode(s):\n        if isinstance(s, bytes):\n            return s.decode(\'latin1\')\n        return str(s)\n\n    def asbytes(s):\n        if isinstance(s, bytes):\n            return s\n        return str(s).encode(\'latin1\')\n\n    def asstr(s):\n        if isinstance(s, bytes):\n            return s.decode(\'latin1\')\n        return str(s)\n\n    def isfileobj(f):\n        return isinstance(f, (io.FileIO, io.BufferedReader, io.BufferedWriter))\n\n    def open_latin1(filename, mode=\'r\'):\n        return open(filename, mode=mode, encoding=\'iso-8859-1\')\n\n    def sixu(s):\n        return s\n\n    strchar = \'U\'\n\n\nelse:\n    bytes = str\n    long = long\n    basestring = basestring\n    unicode = unicode\n    integer_types = (int, long)\n    asbytes = str\n    asstr = str\n    strchar = \'S\'\n\n    def isfileobj(f):\n        return isinstance(f, file)\n\n    def asunicode(s):\n        if isinstance(s, unicode):\n            return s\n        return str(s).decode(\'ascii\')\n\n    def open_latin1(filename, mode=\'r\'):\n        return open(filename, mode=mode)\n\n    def sixu(s):\n        return unicode(s, \'unicode_escape\')\n\n\ndef getexception():\n    return sys.exc_info()[1]\n\ndef asbytes_nested(x):\n    if hasattr(x, \'__iter__\') and not isinstance(x, (bytes, unicode)):\n        return [asbytes_nested(y) for y in x]\n    else:\n        return asbytes(x)\n\ndef asunicode_nested(x):\n    if hasattr(x, \'__iter__\') and not isinstance(x, (bytes, unicode)):\n        return [asunicode_nested(y) for y in x]\n    else:\n        return asunicode(x)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport itertools\nimport numpy as np\nimport numpy.ma as ma\nfrom numpy import ndarray, recarray\nfrom numpy.ma import MaskedArray\nfrom numpy.ma.mrecords import MaskedRecords\nfrom numpy.lib._iotools import _is_string_like\nfrom numpy.compat import basestring\n\nif sys.version_info[0] < 3:\n    from future_builtins import zip\n\n_check_fill_value = np.ma.core._check_fill_value\n\n\n__all__ = [\n    \'append_fields\', \'drop_fields\', \'find_duplicates\',\n    \'get_fieldstructure\', \'join_by\', \'merge_arrays\',\n    \'rec_append_fields\', \'rec_drop_fields\', \'rec_join\',\n    \'recursive_fill_fields\', \'rename_fields\', \'stack_arrays\',\n    ]\n\n\ndef recursive_fill_fields(input, output):\n    \n    newdtype = output.dtype\n    for field in newdtype.names:\n        try:\n            current = input[field]\n        except ValueError:\n            continue\n        if current.dtype.names:\n            recursive_fill_fields(current, output[field])\n        else:\n            output[field][:len(current)] = current\n    return output\n\n\ndef get_names(adtype):\n    \n    listnames = []\n    names = adtype.names\n    for name in names:\n        current = adtype[name]\n        if current.names:\n            listnames.append((name, tuple(get_names(current))))\n        else:\n            listnames.append(name)\n    return tuple(listnames) or None\n\n\ndef get_names_flat(adtype):\n    \n    listnames = []\n    names = adtype.names\n    for name in names:\n        listnames.append(name)\n        current = adtype[name]\n        if current.names:\n            listnames.extend(get_names_flat(current))\n    return tuple(listnames) or None\n\n\ndef flatten_descr(ndtype):\n    \n    names = ndtype.names\n    if names is None:\n        return ndtype.descr\n    else:\n        descr = []\n        for field in names:\n            (typ, _) = ndtype.fields[field]\n            if typ.names:\n                descr.extend(flatten_descr(typ))\n            else:\n                descr.append((field, typ))\n        return tuple(descr)\n\n\ndef zip_descr(seqarrays, flatten=False):\n    \n    newdtype = []\n    if flatten:\n        for a in seqarrays:\n            newdtype.extend(flatten_descr(a.dtype))\n    else:\n        for a in seqarrays:\n            current = a.dtype\n            names = current.names or ()\n            if len(names) > 1:\n                newdtype.append((\'\', current.descr))\n            else:\n                newdtype.extend(current.descr)\n    return np.dtype(newdtype).descr\n\n\ndef get_fieldstructure(adtype, lastname=None, parents=None,):\n    \n    if parents is None:\n        parents = {}\n    names = adtype.names\n    for name in names:\n        current = adtype[name]\n        if current.names:\n            if lastname:\n                parents[name] = [lastname, ]\n            else:\n                parents[name] = []\n            parents.update(get_fieldstructure(current, name, parents))\n        else:\n            lastparent = [_ for _ in (parents.get(lastname, []) or [])]\n            if lastparent:\n                lastparent.append(lastname)\n            elif lastname:\n                lastparent = [lastname, ]\n            parents[name] = lastparent or []\n    return parents or None\n\n\ndef _izip_fields_flat(iterable):\n    \n    for element in iterable:\n        if isinstance(element, np.void):\n            for f in _izip_fields_flat(tuple(element)):\n                yield f\n        else:\n            yield element\n\n\ndef _izip_fields(iterable):\n    \n    for element in iterable:\n        if (hasattr(element, \'__iter__\') and\n                not isinstance(element, basestring)):\n            for f in _izip_fields(element):\n                yield f\n        elif isinstance(element, np.void) and len(tuple(element)) == 1:\n            for f in _izip_fields(element):\n                yield f\n        else:\n            yield element\n\n\ndef izip_records(seqarrays, fill_value=None, flatten=True):\n    \n        def sentinel(counter=([fill_value] * (len(seqarrays) - 1)).pop):\n        "Yields the fill_value or raises IndexError"\n        yield counter()\n        fillers = itertools.repeat(fill_value)\n    iters = [itertools.chain(it, sentinel(), fillers) for it in seqarrays]\n        if flatten:\n        zipfunc = _izip_fields_flat\n    else:\n        zipfunc = _izip_fields\n        try:\n        for tup in zip(*iters):\n            yield tuple(zipfunc(tup))\n    except IndexError:\n        pass\n\n\ndef _fix_output(output, usemask=True, asrecarray=False):\n    \n    if not isinstance(output, MaskedArray):\n        usemask = False\n    if usemask:\n        if asrecarray:\n            output = output.view(MaskedRecords)\n    else:\n        output = ma.filled(output)\n        if asrecarray:\n            output = output.view(recarray)\n    return output\n\n\ndef _fix_defaults(output, defaults=None):\n    \n    names = output.dtype.names\n    (data, mask, fill_value) = (output.data, output.mask, output.fill_value)\n    for (k, v) in (defaults or {}).items():\n        if k in names:\n            fill_value[k] = v\n            data[k][mask[k]] = v\n    return output\n\n\ndef merge_arrays(seqarrays, fill_value=-1, flatten=False,\n                 usemask=False, asrecarray=False):\n    \n        if (len(seqarrays) == 1):\n        seqarrays = np.asanyarray(seqarrays[0])\n        if isinstance(seqarrays, (ndarray, np.void)):\n        seqdtype = seqarrays.dtype\n        if (not flatten) or \\\n           (zip_descr((seqarrays,), flatten=True) == seqdtype.descr):\n                        seqarrays = seqarrays.ravel()\n                        if not seqdtype.names:\n                seqdtype = [(\'\', seqdtype)]\n                        if usemask:\n                if asrecarray:\n                    seqtype = MaskedRecords\n                else:\n                    seqtype = MaskedArray\n            elif asrecarray:\n                seqtype = recarray\n            else:\n                seqtype = ndarray\n            return seqarrays.view(dtype=seqdtype, type=seqtype)\n        else:\n            seqarrays = (seqarrays,)\n    else:\n                seqarrays = [np.asanyarray(_m) for _m in seqarrays]\n        sizes = tuple(a.size for a in seqarrays)\n    maxlength = max(sizes)\n        newdtype = zip_descr(seqarrays, flatten=flatten)\n        seqdata = []\n    seqmask = []\n        if usemask:\n        for (a, n) in zip(seqarrays, sizes):\n            nbmissing = (maxlength - n)\n                        data = a.ravel().__array__()\n            mask = ma.getmaskarray(a).ravel()\n                        if nbmissing:\n                fval = _check_fill_value(fill_value, a.dtype)\n                if isinstance(fval, (ndarray, np.void)):\n                    if len(fval.dtype) == 1:\n                        fval = fval.item()[0]\n                        fmsk = True\n                    else:\n                        fval = np.array(fval, dtype=a.dtype, ndmin=1)\n                        fmsk = np.ones((1,), dtype=mask.dtype)\n            else:\n                fval = None\n                fmsk = True\n                        seqdata.append(itertools.chain(data, [fval] * nbmissing))\n            seqmask.append(itertools.chain(mask, [fmsk] * nbmissing))\n                data = tuple(izip_records(seqdata, flatten=flatten))\n        output = ma.array(np.fromiter(data, dtype=newdtype, count=maxlength),\n                          mask=list(izip_records(seqmask, flatten=flatten)))\n        if asrecarray:\n            output = output.view(MaskedRecords)\n    else:\n                for (a, n) in zip(seqarrays, sizes):\n            nbmissing = (maxlength - n)\n            data = a.ravel().__array__()\n            if nbmissing:\n                fval = _check_fill_value(fill_value, a.dtype)\n                if isinstance(fval, (ndarray, np.void)):\n                    if len(fval.dtype) == 1:\n                        fval = fval.item()[0]\n                    else:\n                        fval = np.array(fval, dtype=a.dtype, ndmin=1)\n            else:\n                fval = None\n            seqdata.append(itertools.chain(data, [fval] * nbmissing))\n        output = np.fromiter(tuple(izip_records(seqdata, flatten=flatten)),\n                             dtype=newdtype, count=maxlength)\n        if asrecarray:\n            output = output.view(recarray)\n        return output\n\n\ndef drop_fields(base, drop_names, usemask=True, asrecarray=False):\n    \n    if _is_string_like(drop_names):\n        drop_names = [drop_names, ]\n    else:\n        drop_names = set(drop_names)\n\n    def _drop_descr(ndtype, drop_names):\n        names = ndtype.names\n        newdtype = []\n        for name in names:\n            current = ndtype[name]\n            if name in drop_names:\n                continue\n            if current.names:\n                descr = _drop_descr(current, drop_names)\n                if descr:\n                    newdtype.append((name, descr))\n            else:\n                newdtype.append((name, current))\n        return newdtype\n\n    newdtype = _drop_descr(base.dtype, drop_names)\n    if not newdtype:\n        return None\n\n    output = np.empty(base.shape, dtype=newdtype)\n    output = recursive_fill_fields(base, output)\n    return _fix_output(output, usemask=usemask, asrecarray=asrecarray)\n\n\ndef rec_drop_fields(base, drop_names):\n    \n    return drop_fields(base, drop_names, usemask=False, asrecarray=True)\n\n\ndef rename_fields(base, namemapper):\n    \n    def _recursive_rename_fields(ndtype, namemapper):\n        newdtype = []\n        for name in ndtype.names:\n            newname = namemapper.get(name, name)\n            current = ndtype[name]\n            if current.names:\n                newdtype.append(\n                    (newname, _recursive_rename_fields(current, namemapper))\n                    )\n            else:\n                newdtype.append((newname, current))\n        return newdtype\n    newdtype = _recursive_rename_fields(base.dtype, namemapper)\n    return base.view(newdtype)\n\n\ndef append_fields(base, names, data, dtypes=None,\n                  fill_value=-1, usemask=True, asrecarray=False):\n    \n        if isinstance(names, (tuple, list)):\n        if len(names) != len(data):\n            msg = "The number of arrays does not match the number of names"\n            raise ValueError(msg)\n    elif isinstance(names, basestring):\n        names = [names, ]\n        data = [data, ]\n        if dtypes is None:\n        data = [np.array(a, copy=False, subok=True) for a in data]\n        data = [a.view([(name, a.dtype)]) for (name, a) in zip(names, data)]\n    else:\n        if not isinstance(dtypes, (tuple, list)):\n            dtypes = [dtypes, ]\n        if len(data) != len(dtypes):\n            if len(dtypes) == 1:\n                dtypes = dtypes * len(data)\n            else:\n                msg = "The dtypes argument must be None, a dtype, or a list."\n                raise ValueError(msg)\n        data = [np.array(a, copy=False, subok=True, dtype=d).view([(n, d)])\n                for (a, n, d) in zip(data, names, dtypes)]\n        base = merge_arrays(base, usemask=usemask, fill_value=fill_value)\n    if len(data) > 1:\n        data = merge_arrays(data, flatten=True, usemask=usemask,\n                            fill_value=fill_value)\n    else:\n        data = data.pop()\n        output = ma.masked_all(max(len(base), len(data)),\n                           dtype=base.dtype.descr + data.dtype.descr)\n    output = recursive_fill_fields(base, output)\n    output = recursive_fill_fields(data, output)\n        return _fix_output(output, usemask=usemask, asrecarray=asrecarray)\n\n\ndef rec_append_fields(base, names, data, dtypes=None):\n    \n    return append_fields(base, names, data=data, dtypes=dtypes,\n                         asrecarray=True, usemask=False)\n\n\ndef stack_arrays(arrays, defaults=None, usemask=True, asrecarray=False,\n                 autoconvert=False):\n    \n    if isinstance(arrays, ndarray):\n        return arrays\n    elif len(arrays) == 1:\n        return arrays[0]\n    seqarrays = [np.asanyarray(a).ravel() for a in arrays]\n    nrecords = [len(a) for a in seqarrays]\n    ndtype = [a.dtype for a in seqarrays]\n    fldnames = [d.names for d in ndtype]\n        dtype_l = ndtype[0]\n    newdescr = dtype_l.descr\n    names = [_[0] for _ in newdescr]\n    for dtype_n in ndtype[1:]:\n        for descr in dtype_n.descr:\n            name = descr[0] or \'\'\n            if name not in names:\n                newdescr.append(descr)\n                names.append(name)\n            else:\n                nameidx = names.index(name)\n                current_descr = newdescr[nameidx]\n                if autoconvert:\n                    if np.dtype(descr[1]) > np.dtype(current_descr[-1]):\n                        current_descr = list(current_descr)\n                        current_descr[-1] = descr[1]\n                        newdescr[nameidx] = tuple(current_descr)\n                elif descr[1] != current_descr[-1]:\n                    raise TypeError("Incompatible type \'%s\' <> \'%s\'" %\n                                    (dict(newdescr)[name], descr[1]))\n        if len(newdescr) == 1:\n        output = ma.concatenate(seqarrays)\n    else:\n                output = ma.masked_all((np.sum(nrecords),), newdescr)\n        offset = np.cumsum(np.r_[0, nrecords])\n        seen = []\n        for (a, n, i, j) in zip(seqarrays, fldnames, offset[:-1], offset[1:]):\n            names = a.dtype.names\n            if names is None:\n                output[\'f%i\' % len(seen)][i:j] = a\n            else:\n                for name in n:\n                    output[name][i:j] = a[name]\n                    if name not in seen:\n                        seen.append(name)\n        return _fix_output(_fix_defaults(output, defaults),\n                       usemask=usemask, asrecarray=asrecarray)\n\n\ndef find_duplicates(a, key=None, ignoremask=True, return_index=False):\n    \n    a = np.asanyarray(a).ravel()\n        fields = get_fieldstructure(a.dtype)\n        base = a\n    if key:\n        for f in fields[key]:\n            base = base[f]\n        base = base[key]\n        sortidx = base.argsort()\n    sortedbase = base[sortidx]\n    sorteddata = sortedbase.filled()\n        flag = (sorteddata[:-1] == sorteddata[1:])\n        if ignoremask:\n        sortedmask = sortedbase.recordmask\n        flag[sortedmask[1:]] = False\n    flag = np.concatenate(([False], flag))\n        flag[:-1] = flag[:-1] + flag[1:]\n    duplicates = a[sortidx][flag]\n    if return_index:\n        return (duplicates, sortidx[flag])\n    else:\n        return duplicates\n\n\ndef join_by(key, r1, r2, jointype=\'inner\', r1postfix=\'1\', r2postfix=\'2\',\n                defaults=None, usemask=True, asrecarray=False):\n    \n        if jointype not in (\'inner\', \'outer\', \'leftouter\'):\n        raise ValueError(\n                "The \'jointype\' argument should be in \'inner\', "\n                "\'outer\' or \'leftouter\' (got \'%s\' instead)" % jointype\n                )\n        if isinstance(key, basestring):\n        key = (key,)\n\n        for name in key:\n        if name not in r1.dtype.names:\n            raise ValueError(\'r1 does not have key field %s\' % name)\n        if name not in r2.dtype.names:\n            raise ValueError(\'r2 does not have key field %s\' % name)\n\n        r1 = r1.ravel()\n    r2 = r2.ravel()\n            nb1 = len(r1)\n    (r1names, r2names) = (r1.dtype.names, r2.dtype.names)\n\n        if (set.intersection(set(r1names), set(r2names)).difference(key) and\n            not (r1postfix or r2postfix)):\n        msg = "r1 and r2 contain common names, r1postfix and r2postfix "\n        msg += "can\'t be empty"\n        raise ValueError(msg)\n\n        r1k = drop_fields(r1, [n for n in r1names if n not in key])\n    r2k = drop_fields(r2, [n for n in r2names if n not in key])\n\n        aux = ma.concatenate((r1k, r2k))\n    idx_sort = aux.argsort(order=key)\n    aux = aux[idx_sort]\n            flag_in = ma.concatenate(([False], aux[1:] == aux[:-1]))\n    flag_in[:-1] = flag_in[1:] + flag_in[:-1]\n    idx_in = idx_sort[flag_in]\n    idx_1 = idx_in[(idx_in < nb1)]\n    idx_2 = idx_in[(idx_in >= nb1)] - nb1\n    (r1cmn, r2cmn) = (len(idx_1), len(idx_2))\n    if jointype == \'inner\':\n        (r1spc, r2spc) = (0, 0)\n    elif jointype == \'outer\':\n        idx_out = idx_sort[~flag_in]\n        idx_1 = np.concatenate((idx_1, idx_out[(idx_out < nb1)]))\n        idx_2 = np.concatenate((idx_2, idx_out[(idx_out >= nb1)] - nb1))\n        (r1spc, r2spc) = (len(idx_1) - r1cmn, len(idx_2) - r2cmn)\n    elif jointype == \'leftouter\':\n        idx_out = idx_sort[~flag_in]\n        idx_1 = np.concatenate((idx_1, idx_out[(idx_out < nb1)]))\n        (r1spc, r2spc) = (len(idx_1) - r1cmn, 0)\n        (s1, s2) = (r1[idx_1], r2[idx_2])\n                ndtype = [list(_) for _ in r1k.dtype.descr]\n        ndtype.extend(list(_) for _ in r1.dtype.descr if _[0] not in key)\n        names = list(_[0] for _ in ndtype)\n    for desc in r2.dtype.descr:\n        desc = list(desc)\n        name = desc[0]\n                if name in names:\n            nameidx = ndtype.index(desc)\n            current = ndtype[nameidx]\n                        if name in key:\n                current[-1] = max(desc[1], current[-1])\n                        else:\n                current[0] += r1postfix\n                desc[0] += r2postfix\n                ndtype.insert(nameidx + 1, desc)\n                else:\n            names.extend(desc[0])\n            ndtype.append(desc)\n        ndtype = [tuple(_) for _ in ndtype]\n            cmn = max(r1cmn, r2cmn)\n        output = ma.masked_all((cmn + r1spc + r2spc,), dtype=ndtype)\n    names = output.dtype.names\n    for f in r1names:\n        selected = s1[f]\n        if f not in names or (f in r2names and not r2postfix and f not in key):\n            f += r1postfix\n        current = output[f]\n        current[:r1cmn] = selected[:r1cmn]\n        if jointype in (\'outer\', \'leftouter\'):\n            current[cmn:cmn + r1spc] = selected[r1cmn:]\n    for f in r2names:\n        selected = s2[f]\n        if f not in names or (f in r1names and not r1postfix and f not in key):\n            f += r2postfix\n        current = output[f]\n        current[:r2cmn] = selected[:r2cmn]\n        if (jointype == \'outer\') and r2spc:\n            current[-r2spc:] = selected[r2cmn:]\n        output.sort(order=key)\n    kwargs = dict(usemask=usemask, asrecarray=asrecarray)\n    return _fix_output(_fix_defaults(output, defaults), **kwargs)\n\n\ndef rec_join(key, r1, r2, jointype=\'inner\', r1postfix=\'1\', r2postfix=\'2\',\n             defaults=None):\n    \n    kwargs = dict(jointype=jointype, r1postfix=r1postfix, r2postfix=r2postfix,\n                  defaults=defaults, usemask=False, asrecarray=True)\n    return join_by(key, r1, r2, **kwargs)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport os\n\nfrom . import numeric as sb\nfrom . import numerictypes as nt\nfrom numpy.compat import isfileobj, bytes, long\n\n__all__ = [\'record\', \'recarray\', \'format_parser\']\n\n\nndarray = sb.ndarray\n\n_byteorderconv = {\'b\':\'>\',\n                  \'l\':\'<\',\n                  \'n\':\'=\',\n                  \'B\':\'>\',\n                  \'L\':\'<\',\n                  \'N\':\'=\',\n                  \'S\':\'s\',\n                  \'s\':\'s\',\n                  \'>\':\'>\',\n                  \'<\':\'<\',\n                  \'=\':\'=\',\n                  \'|\':\'|\',\n                  \'I\':\'|\',\n                  \'i\':\'|\'}\n\n\nnumfmt = nt.typeDict\n\ndef find_duplicate(list):\n    \n    dup = []\n    for i in range(len(list)):\n        if (list[i] in list[i + 1:]):\n            if (list[i] not in dup):\n                dup.append(list[i])\n    return dup\n\nclass format_parser:\n    \n\n    def __init__(self, formats, names, titles, aligned=False, byteorder=None):\n        self._parseFormats(formats, aligned)\n        self._setfieldnames(names, titles)\n        self._createdescr(byteorder)\n        self.dtype = self._descr\n\n    def _parseFormats(self, formats, aligned=0):\n        \n\n        if formats is None:\n            raise ValueError("Need formats argument")\n        if isinstance(formats, list):\n            if len(formats) < 2:\n                formats.append(\'\')\n            formats = \',\'.join(formats)\n        dtype = sb.dtype(formats, aligned)\n        fields = dtype.fields\n        if fields is None:\n            dtype = sb.dtype([(\'f1\', dtype)], aligned)\n            fields = dtype.fields\n        keys = dtype.names\n        self._f_formats = [fields[key][0] for key in keys]\n        self._offsets = [fields[key][1] for key in keys]\n        self._nfields = len(keys)\n\n    def _setfieldnames(self, names, titles):\n        \n\n        if (names):\n            if (type(names) in [list, tuple]):\n                pass\n            elif isinstance(names, str):\n                names = names.split(\',\')\n            else:\n                raise NameError("illegal input names %s" % repr(names))\n\n            self._names = [n.strip() for n in names[:self._nfields]]\n        else:\n            self._names = []\n\n                                        self._names += [\'f%d\' % i for i in range(len(self._names),\n                                                 self._nfields)]\n                _dup = find_duplicate(self._names)\n        if _dup:\n            raise ValueError("Duplicate field names: %s" % _dup)\n\n        if (titles):\n            self._titles = [n.strip() for n in titles[:self._nfields]]\n        else:\n            self._titles = []\n            titles = []\n\n        if (self._nfields > len(titles)):\n            self._titles += [None] * (self._nfields - len(titles))\n\n    def _createdescr(self, byteorder):\n        descr = sb.dtype({\'names\':self._names,\n                          \'formats\':self._f_formats,\n                          \'offsets\':self._offsets,\n                          \'titles\':self._titles})\n        if (byteorder is not None):\n            byteorder = _byteorderconv[byteorder[0]]\n            descr = descr.newbyteorder(byteorder)\n\n        self._descr = descr\n\nclass record(nt.void):\n    \n\n            __name__ = \'record\'\n    __module__ = \'numpy\'\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return str(self.item())\n\n    def __getattribute__(self, attr):\n        if attr in [\'setfield\', \'getfield\', \'dtype\']:\n            return nt.void.__getattribute__(self, attr)\n        try:\n            return nt.void.__getattribute__(self, attr)\n        except AttributeError:\n            pass\n        fielddict = nt.void.__getattribute__(self, \'dtype\').fields\n        res = fielddict.get(attr, None)\n        if res:\n            obj = self.getfield(*res[:2])\n                                    try:\n                dt = obj.dtype\n            except AttributeError:\n                                return obj\n            if dt.fields:\n                return obj.view((self.__class__, obj.dtype.fields))\n            return obj\n        else:\n            raise AttributeError("\'record\' object has no "\n                    "attribute \'%s\'" % attr)\n\n    def __setattr__(self, attr, val):\n        if attr in [\'setfield\', \'getfield\', \'dtype\']:\n            raise AttributeError("Cannot set \'%s\' attribute" % attr)\n        fielddict = nt.void.__getattribute__(self, \'dtype\').fields\n        res = fielddict.get(attr, None)\n        if res:\n            return self.setfield(val, *res[:2])\n        else:\n            if getattr(self, attr, None):\n                return nt.void.__setattr__(self, attr, val)\n            else:\n                raise AttributeError("\'record\' object has no "\n                        "attribute \'%s\'" % attr)\n\n    def __getitem__(self, indx):\n        obj = nt.void.__getitem__(self, indx)\n\n                if isinstance(obj, nt.void) and obj.dtype.fields:\n            return obj.view((self.__class__, obj.dtype.fields))\n        else:\n                        return obj\n\n    def pprint(self):\n        \n                names = self.dtype.names\n        maxlen = max(len(name) for name in names)\n        rows = []\n        fmt = \'%% %ds: %%s\' % maxlen\n        for name in names:\n            rows.append(fmt % (name, getattr(self, name)))\n        return "\\n".join(rows)\n\n\n\nclass recarray(ndarray):\n    \n\n            __name__ = \'recarray\'\n    __module__ = \'numpy\'\n\n    def __new__(subtype, shape, dtype=None, buf=None, offset=0, strides=None,\n                formats=None, names=None, titles=None,\n                byteorder=None, aligned=False, order=\'C\'):\n\n        if dtype is not None:\n            descr = sb.dtype(dtype)\n        else:\n            descr = format_parser(formats, names, titles, aligned, byteorder)._descr\n\n        if buf is None:\n            self = ndarray.__new__(subtype, shape, (record, descr), order=order)\n        else:\n            self = ndarray.__new__(subtype, shape, (record, descr),\n                                      buffer=buf, offset=offset,\n                                      strides=strides, order=order)\n        return self\n\n    def __array_finalize__(self, obj):\n        if self.dtype.type is not record:\n                                    self.dtype = self.dtype\n\n    def __getattribute__(self, attr):\n                                try:\n            return object.__getattribute__(self, attr)\n        except AttributeError:              pass\n\n                fielddict = ndarray.__getattribute__(self, \'dtype\').fields\n        try:\n            res = fielddict[attr][:2]\n        except (TypeError, KeyError):\n            raise AttributeError("recarray has no attribute %s" % attr)\n        obj = self.getfield(*res)\n\n                                                        if obj.dtype.fields:\n            if issubclass(obj.dtype.type, nt.void):\n                return obj.view(dtype=(self.dtype.type, obj.dtype))\n            return obj\n        else:\n            return obj.view(ndarray)\n\n                    def __setattr__(self, attr, val):\n\n                        if attr == \'dtype\' and issubclass(val.type, nt.void) and val.fields:\n            val = sb.dtype((record, val))\n\n        newattr = attr not in self.__dict__\n        try:\n            ret = object.__setattr__(self, attr, val)\n        except:\n            fielddict = ndarray.__getattribute__(self, \'dtype\').fields or {}\n            if attr not in fielddict:\n                exctype, value = sys.exc_info()[:2]\n                raise exctype(value)\n        else:\n            fielddict = ndarray.__getattribute__(self, \'dtype\').fields or {}\n            if attr not in fielddict:\n                return ret\n            if newattr:\n                                                try:\n                    object.__delattr__(self, attr)\n                except:\n                    return ret\n        try:\n            res = fielddict[attr][:2]\n        except (TypeError, KeyError):\n            raise AttributeError("record array has no attribute %s" % attr)\n        return self.setfield(val, *res)\n\n    def __getitem__(self, indx):\n        obj = ndarray.__getitem__(self, indx)\n\n                        if isinstance(obj, ndarray):\n            if obj.dtype.fields:\n                if issubclass(obj.dtype.type, nt.void):\n                    return obj.view(dtype=(self.dtype.type, obj.dtype))\n                return obj\n            else:\n                return obj.view(type=ndarray)\n        else:\n                        return obj\n\n    def __repr__(self):\n                if self.size > 0 or self.shape == (0,):\n            lst = sb.array2string(self, separator=\', \')\n        else:\n                        lst = "[], shape=%s" % (repr(self.shape),)\n\n        if (self.dtype.type is record\n                or (not issubclass(self.dtype.type, nt.void))):\n                                                                        plain_dtype = self.dtype\n            if plain_dtype.type is record:\n                plain_dtype = sb.dtype((nt.void, plain_dtype))\n            lf = \'\\n\'+\' \'*len("rec.array(")\n            return (\'rec.array(%s, %sdtype=%s)\' %\n                          (lst, lf, plain_dtype))\n        else:\n                                                lf = \'\\n\'+\' \'*len("array(")\n            return (\'array(%s, %sdtype=%s).view(numpy.recarray)\' %\n                          (lst, lf, str(self.dtype)))\n\n    def field(self, attr, val=None):\n        if isinstance(attr, int):\n            names = ndarray.__getattribute__(self, \'dtype\').names\n            attr = names[attr]\n\n        fielddict = ndarray.__getattribute__(self, \'dtype\').fields\n\n        res = fielddict[attr][:2]\n\n        if val is None:\n            obj = self.getfield(*res)\n            if obj.dtype.fields:\n                return obj\n            return obj.view(ndarray)\n        else:\n            return self.setfield(val, *res)\n\n\ndef fromarrays(arrayList, dtype=None, shape=None, formats=None,\n               names=None, titles=None, aligned=False, byteorder=None):\n    \n\n    arrayList = [sb.asarray(x) for x in arrayList]\n\n    if shape is None or shape == 0:\n        shape = arrayList[0].shape\n\n    if isinstance(shape, int):\n        shape = (shape,)\n\n    if formats is None and dtype is None:\n                        formats = []\n        for obj in arrayList:\n            if not isinstance(obj, ndarray):\n                raise ValueError("item in the array list must be an ndarray.")\n            formats.append(obj.dtype.str)\n        formats = \',\'.join(formats)\n\n    if dtype is not None:\n        descr = sb.dtype(dtype)\n        _names = descr.names\n    else:\n        parsed = format_parser(formats, names, titles, aligned, byteorder)\n        _names = parsed._names\n        descr = parsed._descr\n\n        if len(descr) != len(arrayList):\n        raise ValueError("mismatch between the number of fields "\n                "and the number of arrays")\n\n    d0 = descr[0].shape\n    nn = len(d0)\n    if nn > 0:\n        shape = shape[:-nn]\n\n    for k, obj in enumerate(arrayList):\n        nn = len(descr[k].shape)\n        testshape = obj.shape[:len(obj.shape) - nn]\n        if testshape != shape:\n            raise ValueError("array-shape mismatch in array %d" % k)\n\n    _array = recarray(shape, descr)\n\n        for i in range(len(arrayList)):\n        _array[_names[i]] = arrayList[i]\n\n    return _array\n\ndef fromrecords(recList, dtype=None, shape=None, formats=None, names=None,\n                titles=None, aligned=False, byteorder=None):\n    \n\n    nfields = len(recList[0])\n    if formats is None and dtype is None:          obj = sb.array(recList, dtype=object)\n        arrlist = [sb.array(obj[..., i].tolist()) for i in range(nfields)]\n        return fromarrays(arrlist, formats=formats, shape=shape, names=names,\n                          titles=titles, aligned=aligned, byteorder=byteorder)\n\n    if dtype is not None:\n        descr = sb.dtype((record, dtype))\n    else:\n        descr = format_parser(formats, names, titles, aligned, byteorder)._descr\n\n    try:\n        retval = sb.array(recList, dtype=descr)\n    except TypeError:          if (shape is None or shape == 0):\n            shape = len(recList)\n        if isinstance(shape, (int, long)):\n            shape = (shape,)\n        if len(shape) > 1:\n            raise ValueError("Can only deal with 1-d array.")\n        _array = recarray(shape, descr)\n        for k in range(_array.size):\n            _array[k] = tuple(recList[k])\n        return _array\n    else:\n        if shape is not None and retval.shape != shape:\n            retval.shape = shape\n\n    res = retval.view(recarray)\n\n    return res\n\n\ndef fromstring(datastring, dtype=None, shape=None, offset=0, formats=None,\n               names=None, titles=None, aligned=False, byteorder=None):\n    \n\n    if dtype is None and formats is None:\n        raise ValueError("Must have dtype= or formats=")\n\n    if dtype is not None:\n        descr = sb.dtype(dtype)\n    else:\n        descr = format_parser(formats, names, titles, aligned, byteorder)._descr\n\n    itemsize = descr.itemsize\n    if (shape is None or shape == 0 or shape == -1):\n        shape = (len(datastring) - offset) / itemsize\n\n    _array = recarray(shape, descr, buf=datastring, offset=offset)\n    return _array\n\ndef get_remaining_size(fd):\n    try:\n        fn = fd.fileno()\n    except AttributeError:\n        return os.path.getsize(fd.name) - fd.tell()\n    st = os.fstat(fn)\n    size = st.st_size - fd.tell()\n    return size\n\ndef fromfile(fd, dtype=None, shape=None, offset=0, formats=None,\n             names=None, titles=None, aligned=False, byteorder=None):\n    \n\n    if (shape is None or shape == 0):\n        shape = (-1,)\n    elif isinstance(shape, (int, long)):\n        shape = (shape,)\n\n    name = 0\n    if isinstance(fd, str):\n        name = 1\n        fd = open(fd, \'rb\')\n    if (offset > 0):\n        fd.seek(offset, 1)\n    size = get_remaining_size(fd)\n\n    if dtype is not None:\n        descr = sb.dtype(dtype)\n    else:\n        descr = format_parser(formats, names, titles, aligned, byteorder)._descr\n\n    itemsize = descr.itemsize\n\n    shapeprod = sb.array(shape).prod()\n    shapesize = shapeprod * itemsize\n    if shapesize < 0:\n        shape = list(shape)\n        shape[shape.index(-1)] = size / -shapesize\n        shape = tuple(shape)\n        shapeprod = sb.array(shape).prod()\n\n    nbytes = shapeprod * itemsize\n\n    if nbytes > size:\n        raise ValueError(\n                "Not enough bytes left in file for specified shape and type")\n\n        _array = recarray(shape, descr)\n    nbytesread = fd.readinto(_array.data)\n    if nbytesread != nbytes:\n        raise IOError("Didn\'t read as many bytes as expected")\n    if name:\n        fd.close()\n\n    return _array\n\ndef array(obj, dtype=None, shape=None, offset=0, strides=None, formats=None,\n          names=None, titles=None, aligned=False, byteorder=None, copy=True):\n    \n\n    if ((isinstance(obj, (type(None), str)) or isfileobj(obj)) and\n           (formats is None) and (dtype is None)):\n        raise ValueError("Must define formats (or dtype) if object is "\n                         "None, string, or an open file")\n\n    kwds = {}\n    if dtype is not None:\n        dtype = sb.dtype(dtype)\n    elif formats is not None:\n        dtype = format_parser(formats, names, titles,\n                              aligned, byteorder)._descr\n    else:\n        kwds = {\'formats\': formats,\n                \'names\': names,\n                \'titles\': titles,\n                \'aligned\': aligned,\n                \'byteorder\': byteorder\n                }\n\n    if obj is None:\n        if shape is None:\n            raise ValueError("Must define a shape if obj is None")\n        return recarray(shape, dtype, buf=obj, offset=offset, strides=strides)\n\n    elif isinstance(obj, bytes):\n        return fromstring(obj, dtype, shape=shape, offset=offset, **kwds)\n\n    elif isinstance(obj, (list, tuple)):\n        if isinstance(obj[0], (tuple, list)):\n            return fromrecords(obj, dtype=dtype, shape=shape, **kwds)\n        else:\n            return fromarrays(obj, dtype=dtype, shape=shape, **kwds)\n\n    elif isinstance(obj, recarray):\n        if dtype is not None and (obj.dtype != dtype):\n            new = obj.view(dtype)\n        else:\n            new = obj\n        if copy:\n            new = new.copy()\n        return new\n\n    elif isfileobj(obj):\n        return fromfile(obj, dtype=dtype, shape=shape, offset=offset)\n\n    elif isinstance(obj, ndarray):\n        if dtype is not None and (obj.dtype != dtype):\n            new = obj.view(dtype)\n        else:\n            new = obj\n        if copy:\n            new = new.copy()\n        return new.view(recarray)\n\n    else:\n        interface = getattr(obj, "__array_interface__", None)\n        if interface is None or not isinstance(interface, dict):\n            raise ValueError("Unknown input type")\n        obj = sb.array(obj)\n        if dtype is not None and (obj.dtype != dtype):\n            obj = obj.view(dtype)\n        return obj.view(recarray)\n\nfrom __future__ import division, absolute_import, print_function\n\n__version__ = "$Revision: 1.129 $"[10:-1]\n\nfrom . import __version__\nf2py_version = __version__.version\n\nimport os\nimport time\nimport copy\n\nfrom .auxfuncs import (\n    applyrules, debugcapi, dictappend, errmess, gentitle, getargs2,\n    hascallstatement, hasexternals, hasinitvalue, hasnote, hasresultnote,\n    isarray, isarrayofstrings, iscomplex, iscomplexarray,\n    iscomplexfunction, iscomplexfunction_warn, isdummyroutine, isexternal,\n    isfunction, isfunction_wrap, isint1array, isintent_aux, isintent_c,\n    isintent_callback, isintent_copy, isintent_hide, isintent_inout,\n    isintent_nothide, isintent_out, isintent_overwrite, islogical,\n    islong_complex, islong_double, islong_doublefunction, islong_long,\n    islong_longfunction, ismoduleroutine, isoptional, isrequired, isscalar,\n    issigned_long_longarray, isstring, isstringarray, isstringfunction,\n    issubroutine, issubroutine_wrap, isthreadsafe, isunsigned,\n    isunsigned_char, isunsigned_chararray, isunsigned_long_long,\n    isunsigned_long_longarray, isunsigned_short, isunsigned_shortarray,\n    l_and, l_not, l_or, outmess, replace, stripcomma,\n)\n\nfrom . import capi_maps\nfrom . import cfuncs\nfrom . import common_rules\nfrom . import use_rules\nfrom . import f90mod_rules\nfrom . import func2subr\n\noptions = {}\nsepdict = {}\nfor k in [\'decl\',\n          \'frompyobj\',\n          \'cleanupfrompyobj\',\n          \'topyarr\', \'method\',\n          \'pyobjfrom\', \'closepyobjfrom\',\n          \'freemem\',\n          \'userincludes\',\n          \'includes0\', \'includes\', \'typedefs\', \'typedefs_generated\',\n          \'cppmacros\', \'cfuncs\', \'callbacks\',\n          \'latexdoc\',\n          \'restdoc\',\n          \'routine_defs\', \'externroutines\',\n          \'initf2pywraphooks\',\n          \'commonhooks\', \'initcommonhooks\',\n          \'f90modhooks\', \'initf90modhooks\']:\n    sepdict[k] = \'\\n\'\n\n\nmodule_rules = {\n    \'modulebody\':  + time.asctime(time.localtime(time.time())) +  +  +  + gentitle("See f2py2e/cfuncs.py: includes") +  + gentitle("See f2py2e/rules.py: mod_rules[\'modulebody\']") +  + gentitle("See f2py2e/cfuncs.py: typedefs") +  + gentitle("See f2py2e/cfuncs.py: typedefs_generated") +  + gentitle("See f2py2e/cfuncs.py: cppmacros") +  + gentitle("See f2py2e/cfuncs.py: cfuncs") +  + gentitle("See f2py2e/cfuncs.py: userincludes") +  + gentitle("See f2py2e/capi_rules.py: usercode") +  + gentitle("See f2py2e/capi_rules.py: usercode1") +  + gentitle("See f2py2e/cb_rules.py: buildcallback") +  + gentitle("See f2py2e/rules.py: buildapi") +  + gentitle("See f2py2e/f90mod_rules.py: buildhooks") +  + gentitle("See f2py2e/rules.py: module_rules[\'modulebody\']") +  + gentitle("See f2py2e/common_rules.py: buildhooks") +  + gentitle("See f2py2e/rules.py") +  + ,\n    \'separatorsfor\': {\'latexdoc\': \'\\n\\n\',\n                      \'restdoc\': \'\\n\\n\'},\n    \'latexdoc\': [\'\\\\section{Module \\\\texttt{                 \'                 \'    \'restdoc\': [\'Module                 \'\\n}\n\ndefmod_rules = [\n    {\'body\': \'/*eof body*/\',\n     \'method\': \'/*eof method*/\',\n     \'externroutines\': \'/*eof externroutines*/\',\n     \'routine_defs\': \'/*eof routine_defs*/\',\n     \'initf90modhooks\': \'/*eof initf90modhooks*/\',\n     \'initf2pywraphooks\': \'/*eof initf2pywraphooks*/\',\n     \'initcommonhooks\': \'/*eof initcommonhooks*/\',\n     \'latexdoc\': \'\',\n     \'restdoc\': \'\',\n     \'modnote\': {hasnote: \'     }\n]\n\nroutine_rules = {\n    \'separatorsfor\': sepdict,\n    \'body\': ,\n    \'routine_defs\': \'    \'initf2pywraphooks\': \'    \'externroutines\': \'    \'doc\': \'    \'docshort\': \'    \'docs\': \'"\\t    \'need\': [\'arrayobject.h\', \'CFUNCSMESS\', \'MINMAX\'],\n    \'cppmacros\': {debugcapi: \'    \'latexdoc\': [\'\\\\subsection{Wrapper function \\\\texttt{                 ],\n    \'restdoc\': [\'Wrapped function ``\n                ]\n}\n\n\nrout_rules = [\n    {          \'separatorsfor\': {\'callfortranroutine\': \'\\n\', \'routdebugenter\': \'\\n\', \'decl\': \'\\n\',\n                          \'routdebugleave\': \'\\n\', \'routdebugfailure\': \'\\n\',\n                          \'setjmpbuf\': \' || \',\n                          \'docstrreq\': \'\\n\', \'docstropt\': \'\\n\', \'docstrout\': \'\\n\',\n                          \'docstrcbs\': \'\\n\', \'docstrsigns\': \'\\\\n"\\n"\',\n                          \'latexdocstrsigns\': \'\\n\',\n                          \'latexdocstrreq\': \'\\n\', \'latexdocstropt\': \'\\n\',\n                          \'latexdocstrout\': \'\\n\', \'latexdocstrcbs\': \'\\n\',\n                          },\n        \'kwlist\': \'\', \'kwlistopt\': \'\', \'callfortran\': \'\', \'callfortranappend\': \'\',\n        \'docsign\': \'\', \'docsignopt\': \'\', \'decl\': \'/*decl*/\',\n        \'freemem\': \'/*freemem*/\',\n        \'docsignshort\': \'\', \'docsignoptshort\': \'\',\n        \'docstrsigns\': \'\', \'latexdocstrsigns\': \'\',\n        \'docstrreq\': \'\\\\nParameters\\\\n----------\',\n        \'docstropt\': \'\\\\nOther Parameters\\\\n----------------\',\n        \'docstrout\': \'\\\\nReturns\\\\n-------\',\n        \'docstrcbs\': \'\\\\nNotes\\\\n-----\\\\nCall-back functions::\\\\n\',\n        \'latexdocstrreq\': \'\\\\noindent Required arguments:\',\n        \'latexdocstropt\': \'\\\\noindent Optional arguments:\',\n        \'latexdocstrout\': \'\\\\noindent Return objects:\',\n        \'latexdocstrcbs\': \'\\\\noindent Call-back functions:\',\n        \'args_capi\': \'\', \'keys_capi\': \'\', \'functype\': \'\',\n        \'frompyobj\': \'/*frompyobj*/\',\n                \'cleanupfrompyobj\': [\'/*end of cleanupfrompyobj*/\'],\n        \'pyobjfrom\': \'/*pyobjfrom*/\',\n                \'closepyobjfrom\': [\'/*end of closepyobjfrom*/\'],\n        \'topyarr\': \'/*topyarr*/\', \'routdebugleave\': \'/*routdebugleave*/\',\n        \'routdebugenter\': \'/*routdebugenter*/\',\n        \'routdebugfailure\': \'/*routdebugfailure*/\',\n        \'callfortranroutine\': \'/*callfortranroutine*/\',\n        \'argformat\': \'\', \'keyformat\': \'\', \'need_cfuncs\': \'\',\n        \'docreturn\': \'\', \'return\': \'\', \'returnformat\': \'\', \'rformat\': \'\',\n        \'kwlistxa\': \'\', \'keys_xa\': \'\', \'xaformat\': \'\', \'docsignxa\': \'\', \'docsignxashort\': \'\',\n        \'initf2pywraphook\': \'\',\n        \'routnote\': {hasnote: \'---     }, {\n        \'apiname\': \'f2py_rout_        \'pyname\': \'        \'decl\': \'\',\n        \'_check\': l_not(ismoduleroutine)\n    }, {\n        \'apiname\': \'f2py_rout_        \'pyname\': \'        \'decl\': \'\',\n        \'_check\': ismoduleroutine\n    }, {          \'functype\': \'void\',\n        \'declfortranroutine\': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): \'extern void                                l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'extern void                                ismoduleroutine: \'\',\n                               isdummyroutine: \'\'\n                               },\n        \'routine_def\': {l_not(l_or(ismoduleroutine, isintent_c, isdummyroutine)): \'\\t{\\"                        l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'\\t{\\"                        l_and(l_not(ismoduleroutine), isdummyroutine): \'\\t{\\"                        },\n        \'need\': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): \'F_FUNC\'},\n        \'callfortranroutine\': [\n            {debugcapi: [\n                ]},\n            {hasexternals: },\n            {isthreadsafe: \'\\t\\t\\tPy_BEGIN_ALLOW_THREADS\'},\n            {hascallstatement: },\n            {l_not(l_or(hascallstatement, isdummyroutine))\n                   : \'\\t\\t\\t\\t(*f2py_func)(            {isthreadsafe: \'\\t\\t\\tPy_END_ALLOW_THREADS\'},\n            {hasexternals: }\n        ],\n        \'_check\': l_and(issubroutine, l_not(issubroutine_wrap)),\n    }, {          \'functype\': \'void\',\n        \'declfortranroutine\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'extern void                                isdummyroutine: \'\',\n                               },\n\n        \'routine_def\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'\\t{\\"                        isdummyroutine: \'\\t{\\"                        },\n        \'initf2pywraphook\': {l_not(l_or(ismoduleroutine, isdummyroutine)): },\n        \'need\': {l_not(l_or(ismoduleroutine, isdummyroutine)): [\'F_WRAPPEDFUNC\', \'F_FUNC\']},\n        \'callfortranroutine\': [\n            {debugcapi: [\n                ]},\n            {hasexternals: },\n            {isthreadsafe: \'\\tPy_BEGIN_ALLOW_THREADS\'},\n            {l_not(l_or(hascallstatement, isdummyroutine))\n                   : \'\\t(*f2py_func)(            {hascallstatement:\n                \'\\t            {isthreadsafe: \'\\tPy_END_ALLOW_THREADS\'},\n            {hasexternals: \'\\t}\'}\n        ],\n        \'_check\': isfunction_wrap,\n    }, {          \'functype\': \'void\',\n        \'declfortranroutine\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'extern void                                isdummyroutine: \'\',\n                               },\n\n        \'routine_def\': {l_not(l_or(ismoduleroutine, isdummyroutine)): \'\\t{\\"                        isdummyroutine: \'\\t{\\"                        },\n        \'initf2pywraphook\': {l_not(l_or(ismoduleroutine, isdummyroutine)): },\n        \'need\': {l_not(l_or(ismoduleroutine, isdummyroutine)): [\'F_WRAPPEDFUNC\', \'F_FUNC\']},\n        \'callfortranroutine\': [\n            {debugcapi: [\n                ]},\n            {hasexternals: },\n            {isthreadsafe: \'\\tPy_BEGIN_ALLOW_THREADS\'},\n            {l_not(l_or(hascallstatement, isdummyroutine))\n                   : \'\\t(*f2py_func)(            {hascallstatement:\n                \'\\t            {isthreadsafe: \'\\tPy_END_ALLOW_THREADS\'},\n            {hasexternals: \'\\t}\'}\n        ],\n        \'_check\': issubroutine_wrap,\n    }, {          \'functype\': \'        \'docreturn\': {l_not(isintent_hide): \'        \'docstrout\': \'        \'latexdocstrout\': [\'\\\\item[]{{}\\\\verb@                           {hasresultnote: \'---         \'callfortranroutine\': [{l_and(debugcapi, isstringfunction): },\n                               {l_and(debugcapi, l_not(isstringfunction)): }\n                               ],\n        \'_check\': l_and(isfunction, l_not(isfunction_wrap))\n    }, {          \'declfortranroutine\': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): \'extern                                l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'extern                                isdummyroutine: \'\'\n                               },\n        \'routine_def\': {l_and(l_not(l_or(ismoduleroutine, isintent_c)), l_not(isdummyroutine)): \'\\t{\\"                        l_and(l_not(ismoduleroutine), isintent_c, l_not(isdummyroutine)): \'\\t{\\"                        isdummyroutine: \'\\t{\\"                        },\n        \'decl\': [{iscomplexfunction_warn: \'\\t                  l_not(iscomplexfunction): \'\\t                 {iscomplexfunction:\n                  \'\\tPyObject *                 ],\n        \'callfortranroutine\': [\n            {hasexternals: },\n            {isthreadsafe: \'\\tPy_BEGIN_ALLOW_THREADS\'},\n            {hascallstatement: },\n            {l_not(l_or(hascallstatement, isdummyroutine))\n                   : \'\\t            {isthreadsafe: \'\\tPy_END_ALLOW_THREADS\'},\n            {hasexternals: \'\\t}\'},\n            {l_and(debugcapi, iscomplexfunction)\n                   : \'\\tfprintf(stderr,"            {l_and(debugcapi, l_not(iscomplexfunction)): \'\\tfprintf(stderr,"        \'pyobjfrom\': {iscomplexfunction: \'\\t        \'need\': [{l_not(isdummyroutine): \'F_FUNC\'},\n                 {iscomplexfunction: \'pyobj_from_                 {islong_longfunction: \'long_long\'},\n                 {islong_doublefunction: \'long_double\'}],\n        \'returnformat\': {l_not(isintent_hide): \'        \'return\': {iscomplexfunction: \',                   l_not(l_or(iscomplexfunction, isintent_hide)): \',        \'_check\': l_and(isfunction, l_not(isstringfunction), l_not(isfunction_wrap))\n    }, {          \'declfortranroutine\': \'extern void         \'routine_def\': {l_not(l_or(ismoduleroutine, isintent_c)):\n                        \'\\t{\\"                        l_and(l_not(ismoduleroutine), isintent_c):\n                        \'\\t{\\"                        },\n        \'decl\': [\'\\t                 \'\\tint         \'callfortran\':\'        \'callfortranroutine\':[\'\\t                              \'\\tif ((                              \'\\t\\tPyErr_SetString(PyExc_MemoryError, \\"out of memory\\");\',\n                              \'\\t\\tf2py_success = 0;\',\n                              \'\\t} else {\',\n                              "\\t\\t(                              \'\\t}\',\n                              \'\\tif (f2py_success) {\',\n                              {hasexternals: },\n                              {isthreadsafe: \'\\t\\tPy_BEGIN_ALLOW_THREADS\'},\n                              ,\n                              {isthreadsafe: \'\\t\\tPy_END_ALLOW_THREADS\'},\n                              {hasexternals: \'\\t\\t}\'},\n                              {debugcapi:\n                                  \'\\t\\tfprintf(stderr,"                              \'\\t} /* if (f2py_success) after (string)malloc */\',\n                              ],\n        \'returnformat\': \'        \'return\': \',        \'freemem\': \'\\tSTRINGFREE(        \'need\': [\'F_FUNC\', \'        \'_check\':l_and(isstringfunction, l_not(isfunction_wrap))      },\n    {          \'routdebugenter\': \'\\tfprintf(stderr,"debug-capi:Python C/API function         \'routdebugleave\': \'\\tfprintf(stderr,"debug-capi:Python C/API function         \'routdebugfailure\': \'\\tfprintf(stderr,"debug-capi:Python C/API function         \'_check\': debugcapi\n    }\n]\n\n\ntypedef_need_dict = {islong_long: \'long_long\',\n                     islong_double: \'long_double\',\n                     islong_complex: \'complex_long_double\',\n                     isunsigned_char: \'unsigned_char\',\n                     isunsigned_short: \'unsigned_short\',\n                     isunsigned: \'unsigned\',\n                     isunsigned_long_long: \'unsigned_long_long\',\n                     isunsigned_chararray: \'unsigned_char\',\n                     isunsigned_shortarray: \'unsigned_short\',\n                     isunsigned_long_longarray: \'unsigned_long_long\',\n                     issigned_long_longarray: \'long_long\',\n                     }\n\naux_rules = [\n    {\n        \'separatorsfor\': sepdict\n    },\n    {          \'frompyobj\': [\'\\t/* Processing auxiliary variable                       {debugcapi: \'\\tfprintf(stderr,"        \'cleanupfrompyobj\': \'\\t/* End of cleaning variable         \'need\': typedef_need_dict,\n    },\n        {          \'decl\': \'\\t        \'need\': {hasinitvalue: \'math.h\'},\n        \'frompyobj\': {hasinitvalue: \'\\t        \'_check\': l_and(isscalar, l_not(iscomplex)),\n    },\n    {\n        \'return\': \',        \'docstrout\': \'        \'docreturn\': \'        \'returnformat\': \'        \'_check\': l_and(isscalar, l_not(iscomplex), isintent_out),\n    },\n        {          \'decl\': \'\\t        \'frompyobj\': {hasinitvalue: \'\\t        \'_check\': iscomplex\n    },\n        {          \'decl\': [\'\\t                 \'\\tint slen(                 ],\n        \'need\':[\'len..\'],\n        \'_check\':isstring\n    },\n        {          \'decl\': [\'\\t                 \'\\tnpy_intp                  \'\\tconst int                  ],\n        \'need\':[\'len..\', {hasinitvalue: \'forcomb\'}, {hasinitvalue: \'CFUNCSMESS\'}],\n        \'_check\': isarray\n    },\n        {          \'_check\': l_and(isarray, l_not(iscomplexarray))\n    }, {          \'_check\': l_and(isarray, l_not(iscomplexarray), isintent_nothide)\n    },\n        {\'need\': \'     \'_check\': isint1array,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_chararray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_shortarray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_long_longarray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': iscomplexarray,\n     \'_depend\': \'\'\n     },\n        {\n        \'callfortranappend\': {isarrayofstrings: \'flen(        \'need\': \'string\',\n        \'_check\': isstringarray\n    }\n]\n\narg_rules = [\n    {\n        \'separatorsfor\': sepdict\n    },\n    {          \'frompyobj\': [\'\\t/* Processing variable                       {debugcapi: \'\\tfprintf(stderr,"        \'cleanupfrompyobj\': \'\\t/* End of cleaning variable         \'_depend\': \'\',\n        \'need\': typedef_need_dict,\n    },\n        {\n        \'docstropt\': {l_and(isoptional, isintent_nothide): \'        \'docstrreq\': {l_and(isrequired, isintent_nothide): \'        \'docstrout\': {isintent_out: \'        \'latexdocstropt\': {l_and(isoptional, isintent_nothide): [\'\\\\item[]{{}\\\\verb@                                                                 {hasnote: \'---         \'latexdocstrreq\': {l_and(isrequired, isintent_nothide): [\'\\\\item[]{{}\\\\verb@                                                                 {hasnote: \'---         \'latexdocstrout\': {isintent_out: [\'\\\\item[]{{}\\\\verb@                                          {l_and(hasnote, isintent_hide): \'---                                            l_and(hasnote, isintent_nothide): \'--- See above.\'}]},\n        \'depend\': \'\'\n    },\n        {\n        \'kwlist\': \'"        \'docsign\': \'        \'_check\': l_and(isintent_nothide, l_not(isoptional))\n    },\n    {\n        \'kwlistopt\': \'"        \'docsignopt\': \'        \'docsignoptshort\': \'        \'_check\': l_and(isintent_nothide, isoptional)\n    },\n        {\n        \'docreturn\': \'        \'returnformat\': \'        \'_check\': isintent_out\n    },\n        {          \'docsignxa\': {isintent_nothide: \'        \'docsignxashort\': {isintent_nothide: \'        \'docstropt\': {isintent_nothide: \'        \'docstrcbs\': \'        \'latexdocstrcbs\': \'\\\\item[]         \'latexdocstropt\': {isintent_nothide: \'\\\\item[]{{}\\\\verb@        \'decl\': [\'\\tPyObject *                 \'\\tPyTupleObject *                 \'\\tPyTupleObject *                 \'\\tint                  {l_not(isintent_callback):\n                  \'\\t                 ],\n        \'kwlistxa\': {isintent_nothide: \'"        \'argformat\': {isrequired: \'O\'},\n        \'keyformat\': {isoptional: \'O\'},\n        \'xaformat\': {isintent_nothide: \'O!\'},\n        \'args_capi\': {isrequired: \',&        \'keys_capi\': {isoptional: \',&        \'keys_xa\': \',&PyTuple_Type,&        \'setjmpbuf\': \'(setjmp(        \'callfortran\': {l_not(isintent_callback): \'        \'need\': [\'        \'_check\':isexternal\n    },\n    {\n        \'frompyobj\': [{l_not(isintent_callback): }, {isintent_callback: },\n            ,\n            {debugcapi: [,\n                         {l_not(isintent_callback): }]},\n            ,\n        ],\n        \'cleanupfrompyobj\':\n        ,\n        \'need\': [\'SWAP\', \'create_cb_arglist\'],\n        \'_check\':isexternal,\n        \'_depend\':\'\'\n    },\n        {          \'decl\': \'\\t        \'pyobjfrom\': {debugcapi: \'\\tfprintf(stderr,"        \'callfortran\': {isintent_c: \'        \'return\': {isintent_out: \',        \'_check\': l_and(isscalar, l_not(iscomplex))\n    }, {\n        \'need\': {hasinitvalue: \'math.h\'},\n        \'_check\': l_and(isscalar, l_not(iscomplex)),\n    }, {          \'decl\': \'\\tPyObject *        \'argformat\': {isrequired: \'O\'},\n        \'keyformat\': {isoptional: \'O\'},\n        \'args_capi\': {isrequired: \',&        \'keys_capi\': {isoptional: \',&        \'pyobjfrom\': {isintent_inout: },\n        \'closepyobjfrom\': {isintent_inout: "\\t} /*if (f2py_success) of         \'need\': {isintent_inout: \'try_pyarr_from_        \'_check\': l_and(isscalar, l_not(iscomplex), isintent_nothide)\n    }, {\n        \'frompyobj\': [\n                                                                                                                                                                                                {hasinitvalue: \'\\tif (             \'_depend\': \'\'},\n            {l_and(isoptional, l_not(hasinitvalue)): \'\\tif (             \'_depend\': \'\'},\n            {l_not(islogical): },\n            {islogical: },\n        ],\n        \'cleanupfrompyobj\': \'\\t} /*if (f2py_success) of         \'need\': {l_not(islogical): \'        \'_check\': l_and(isscalar, l_not(iscomplex), isintent_nothide),\n        \'_depend\': \'\'\n    }, {          \'frompyobj\': {hasinitvalue: \'\\t        \'need\': typedef_need_dict,\n        \'_check\': l_and(isscalar, l_not(iscomplex), isintent_hide),\n        \'_depend\': \'\'\n    }, {          \'frompyobj\': {debugcapi: \'\\tfprintf(stderr,"        \'_check\': l_and(isscalar, l_not(iscomplex)),\n        \'_depend\': \'\'\n    },\n        {          \'decl\': \'\\t        \'callfortran\': {isintent_c: \'        \'pyobjfrom\': {debugcapi: \'\\tfprintf(stderr,"        \'return\': {isintent_out: \',        \'_check\': iscomplex\n    }, {          \'decl\': \'\\tPyObject *        \'argformat\': {isrequired: \'O\'},\n        \'keyformat\': {isoptional: \'O\'},\n        \'args_capi\': {isrequired: \',&        \'keys_capi\': {isoptional: \',&        \'need\': {isintent_inout: \'try_pyarr_from_        \'pyobjfrom\': {isintent_inout: },\n        \'closepyobjfrom\': {isintent_inout: "\\t\\t} /*if (f2py_success) of         \'_check\': l_and(iscomplex, isintent_nothide)\n    }, {\n        \'frompyobj\': [{hasinitvalue: \'\\tif (                      {l_and(isoptional, l_not(hasinitvalue))\n                             : \'\\tif (                      \'\\t\\tf2py_success =                       \'\\n\\tif (f2py_success) {\'],\n        \'cleanupfrompyobj\': \'\\t}  /*if (f2py_success) of         \'need\': [\'        \'_check\': l_and(iscomplex, isintent_nothide),\n        \'_depend\': \'\'\n    }, {          \'decl\': {isintent_out: \'\\tPyObject *        \'_check\': l_and(iscomplex, isintent_hide)\n    }, {\n        \'frompyobj\': {hasinitvalue: \'\\t        \'_check\': l_and(iscomplex, isintent_hide),\n        \'_depend\': \'\'\n    }, {          \'pyobjfrom\': {isintent_out: \'\\t        \'need\': [\'pyobj_from_        \'_check\': iscomplex\n    }, {\n        \'frompyobj\': {debugcapi: \'\\tfprintf(stderr,"        \'_check\': iscomplex,\n        \'_depend\': \'\'\n    },\n        {          \'decl\': [\'\\t                 \'\\tint slen(                 \'\\tPyObject *        \'callfortran\':\'        \'callfortranappend\':\'slen(        \'pyobjfrom\':{debugcapi: \'\\tfprintf(stderr,"        \'return\': {isintent_out: \',        \'need\': [\'len..\'],          \'_check\':isstring\n    }, {          \'frompyobj\': ,\n        \'cleanupfrompyobj\': ,\n        \'need\': [\'        \'_check\':isstring,\n        \'_depend\':\'\'\n    }, {          \'argformat\': {isrequired: \'O\'},\n        \'keyformat\': {isoptional: \'O\'},\n        \'args_capi\': {isrequired: \',&        \'keys_capi\': {isoptional: \',&        \'pyobjfrom\': {isintent_inout: },\n        \'closepyobjfrom\': {isintent_inout: \'\\t} /*if (f2py_success) of         \'need\': {isintent_inout: \'try_pyarr_from_        \'_check\': l_and(isstring, isintent_nothide)\n    }, {          \'_check\': l_and(isstring, isintent_hide)\n    }, {\n        \'frompyobj\': {debugcapi: \'\\tfprintf(stderr,"        \'_check\': isstring,\n        \'_depend\': \'\'\n    },\n        {          \'decl\': [\'\\t                 \'\\tnpy_intp                  \'\\tconst int                  \'\\tPyArrayObject *capi_                 \'\\tint capi_                 ],\n        \'callfortran\':\'        \'return\':{isintent_out: \',capi_        \'need\': \'len..\',\n        \'_check\': isarray\n    }, {          \'decl\': \'\\tint capi_overwrite_        \'kwlistxa\': \'"overwrite_        \'xaformat\': \'i\',\n        \'keys_xa\': \',&capi_overwrite_        \'docsignxa\': \'overwrite_        \'docsignxashort\': \'overwrite_        \'docstropt\': \'overwrite_        \'_check\': l_and(isarray, isintent_overwrite),\n    }, {\n        \'frompyobj\': \'\\tcapi_        \'_check\': l_and(isarray, isintent_overwrite),\n        \'_depend\': \'\',\n    },\n    {          \'decl\': \'\\tint capi_overwrite_        \'kwlistxa\': \'"overwrite_        \'xaformat\': \'i\',\n        \'keys_xa\': \',&capi_overwrite_        \'docsignxa\': \'overwrite_        \'docsignxashort\': \'overwrite_        \'docstropt\': \'overwrite_        \'_check\': l_and(isarray, isintent_copy),\n    }, {\n        \'frompyobj\': \'\\tcapi_        \'_check\': l_and(isarray, isintent_copy),\n        \'_depend\': \'\',\n    }, {\n        \'need\': [{hasinitvalue: \'forcomb\'}, {hasinitvalue: \'CFUNCSMESS\'}],\n        \'_check\': isarray,\n        \'_depend\': \'\'\n    }, {          \'decl\': \'\\tPyObject *        \'argformat\': {isrequired: \'O\'},\n        \'keyformat\': {isoptional: \'O\'},\n        \'args_capi\': {isrequired: \',&        \'keys_capi\': {isoptional: \',&        \'_check\': l_and(isarray, isintent_nothide)\n    }, {\n        \'frompyobj\': [\'\\t                      \'\\tcapi_                      {isintent_hide:\n                       \'\\tcapi_                      {isintent_nothide:\n                       \'\\tcapi_                      ,\n                      {hasinitvalue: [\n                          {isintent_nothide:\n                              \'\\tif (                          {isintent_hide: \'\\t{\'},\n                          {iscomplexarray: \'\\t\\t                          ]},\n                      ],\n        \'cleanupfrompyobj\': [              \'\\t}  /*if (capi_            {l_not(l_or(isintent_out, isintent_hide)): },\n            {l_and(isintent_hide, l_not(isintent_out))\n                   : },\n            {hasinitvalue: \'\\t}  /*if (f2py_success) of         ],\n        \'_check\': isarray,\n        \'_depend\': \'\'\n    },\n        {          \'_check\': l_and(isarray, l_not(iscomplexarray))\n    }, {          \'_check\': l_and(isarray, l_not(iscomplexarray), isintent_nothide)\n    },\n        {\'need\': \'     \'_check\': isint1array,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_chararray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_shortarray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': isunsigned_long_longarray,\n     \'_depend\': \'\'\n     },\n        {\'need\': \'     \'_check\': iscomplexarray,\n     \'_depend\': \'\'\n     },\n        {\n        \'callfortranappend\': {isarrayofstrings: \'flen(        \'need\': \'string\',\n        \'_check\': isstringarray\n    }\n]\n\n\ncheck_rules = [\n    {\n        \'frompyobj\': {debugcapi: \'\\tfprintf(stderr,\\"debug-capi:Checking `        \'need\': \'len..\'\n    }, {\n        \'frompyobj\': \'\\tCHECKSCALAR(        \'cleanupfrompyobj\': \'\\t} /*CHECKSCALAR(        \'need\': \'CHECKSCALAR\',\n        \'_check\': l_and(isscalar, l_not(iscomplex)),\n        \'_break\': \'\'\n    }, {\n        \'frompyobj\': \'\\tCHECKSTRING(        \'cleanupfrompyobj\': \'\\t} /*CHECKSTRING(        \'need\': \'CHECKSTRING\',\n        \'_check\': isstring,\n        \'_break\': \'\'\n    }, {\n        \'need\': \'CHECKARRAY\',\n        \'frompyobj\': \'\\tCHECKARRAY(        \'cleanupfrompyobj\': \'\\t} /*CHECKARRAY(        \'_check\': isarray,\n        \'_break\': \'\'\n    }, {\n        \'need\': \'CHECKGENERIC\',\n        \'frompyobj\': \'\\tCHECKGENERIC(        \'cleanupfrompyobj\': \'\\t} /*CHECKGENERIC(    }\n]\n\n\n\n\ndef buildmodule(m, um):\n    \n    global f2py_version, options\n    outmess(\'\\tBuilding module "%s"...\\n\' % (m[\'name\']))\n    ret = {}\n    mod_rules = defmod_rules[:]\n    vrd = capi_maps.modsign2map(m)\n    rd = dictappend({\'f2py_version\': f2py_version}, vrd)\n    funcwrappers = []\n    funcwrappers2 = []      for n in m[\'interfaced\']:\n        nb = None\n        for bi in m[\'body\']:\n            if not bi[\'block\'] == \'interface\':\n                errmess(\'buildmodule: Expected interface block. Skipping.\\n\')\n                continue\n            for b in bi[\'body\']:\n                if b[\'name\'] == n:\n                    nb = b\n                    break\n\n        if not nb:\n            errmess(\n                \'buildmodule: Could not found the body of interfaced routine "%s". Skipping.\\n\' % (n))\n            continue\n        nb_list = [nb]\n        if \'entry\' in nb:\n            for k, a in nb[\'entry\'].items():\n                nb1 = copy.deepcopy(nb)\n                del nb1[\'entry\']\n                nb1[\'name\'] = k\n                nb1[\'args\'] = a\n                nb_list.append(nb1)\n        for nb in nb_list:\n            api, wrap = buildapi(nb)\n            if wrap:\n                if ismoduleroutine(nb):\n                    funcwrappers2.append(wrap)\n                else:\n                    funcwrappers.append(wrap)\n            ar = applyrules(api, vrd)\n            rd = dictappend(rd, ar)\n\n        cr, wrap = common_rules.buildhooks(m)\n    if wrap:\n        funcwrappers.append(wrap)\n    ar = applyrules(cr, vrd)\n    rd = dictappend(rd, ar)\n\n        mr, wrap = f90mod_rules.buildhooks(m)\n    if wrap:\n        funcwrappers2.append(wrap)\n    ar = applyrules(mr, vrd)\n    rd = dictappend(rd, ar)\n\n    for u in um:\n        ar = use_rules.buildusevars(u, m[\'use\'][u[\'name\']])\n        rd = dictappend(rd, ar)\n\n    needs = cfuncs.get_needs()\n    code = {}\n    for n in needs.keys():\n        code[n] = []\n        for k in needs[n]:\n            c = \'\'\n            if k in cfuncs.includes0:\n                c = cfuncs.includes0[k]\n            elif k in cfuncs.includes:\n                c = cfuncs.includes[k]\n            elif k in cfuncs.userincludes:\n                c = cfuncs.userincludes[k]\n            elif k in cfuncs.typedefs:\n                c = cfuncs.typedefs[k]\n            elif k in cfuncs.typedefs_generated:\n                c = cfuncs.typedefs_generated[k]\n            elif k in cfuncs.cppmacros:\n                c = cfuncs.cppmacros[k]\n            elif k in cfuncs.cfuncs:\n                c = cfuncs.cfuncs[k]\n            elif k in cfuncs.callbacks:\n                c = cfuncs.callbacks[k]\n            elif k in cfuncs.f90modhooks:\n                c = cfuncs.f90modhooks[k]\n            elif k in cfuncs.commonhooks:\n                c = cfuncs.commonhooks[k]\n            else:\n                errmess(\'buildmodule: unknown need %s.\\n\' % (repr(k)))\n                continue\n            code[n].append(c)\n    mod_rules.append(code)\n    for r in mod_rules:\n        if (\'_check\' in r and r[\'_check\'](m)) or (\'_check\' not in r):\n            ar = applyrules(r, vrd, m)\n            rd = dictappend(rd, ar)\n    ar = applyrules(module_rules, rd)\n\n    fn = os.path.join(options[\'buildpath\'], vrd[\'coutput\'])\n    ret[\'csrc\'] = fn\n    f = open(fn, \'w\')\n    f.write(ar[\'modulebody\'].replace(\'\\t\', 2 * \' \'))\n    f.close()\n    outmess(\'\\tWrote C/API module "%s" to file "%s"\\n\' % (m[\'name\'], fn))\n\n    if options[\'dorestdoc\']:\n        fn = os.path.join(\n            options[\'buildpath\'], vrd[\'modulename\'] + \'module.rest\')\n        f = open(fn, \'w\')\n        f.write(\'.. -*- rest -*-\\n\')\n        f.write(\'\\n\'.join(ar[\'restdoc\']))\n        f.close()\n        outmess(\'\\tReST Documentation is saved to file "%s/%smodule.rest"\\n\' %\n                (options[\'buildpath\'], vrd[\'modulename\']))\n    if options[\'dolatexdoc\']:\n        fn = os.path.join(\n            options[\'buildpath\'], vrd[\'modulename\'] + \'module.tex\')\n        ret[\'ltx\'] = fn\n        f = open(fn, \'w\')\n        f.write(\n            \'%% This file is auto-generated with f2py (version:%s)\\n\' % (f2py_version))\n        if \'shortlatex\' not in options:\n            f.write(\n                \'\\\\documentclass{article}\\n\\\\usepackage{a4wide}\\n\\\\begin{document}\\n\\\\tableofcontents\\n\\n\')\n        f.write(\'\\n\'.join(ar[\'latexdoc\']))\n        if \'shortlatex\' not in options:\n            f.write(\'\\\\end{document}\')\n        f.close()\n        outmess(\'\\tDocumentation is saved to file "%s/%smodule.tex"\\n\' %\n                (options[\'buildpath\'], vrd[\'modulename\']))\n    if funcwrappers:\n        wn = os.path.join(options[\'buildpath\'], vrd[\'f2py_wrapper_output\'])\n        ret[\'fsrc\'] = wn\n        f = open(wn, \'w\')\n        f.write(\'C     -*- fortran -*-\\n\')\n        f.write(\n            \'C     This file is autogenerated with f2py (version:%s)\\n\' % (f2py_version))\n        f.write(\n            \'C     It contains Fortran 77 wrappers to fortran functions.\\n\')\n        lines = []\n        for l in (\'\\n\\n\'.join(funcwrappers) + \'\\n\').split(\'\\n\'):\n            if l and l[0] == \' \':\n                while len(l) >= 66:\n                    lines.append(l[:66] + \'\\n     &\')\n                    l = l[66:]\n                lines.append(l + \'\\n\')\n            else:\n                lines.append(l + \'\\n\')\n        lines = \'\'.join(lines).replace(\'\\n     &\\n\', \'\\n\')\n        f.write(lines)\n        f.close()\n        outmess(\'\\tFortran 77 wrappers are saved to "%s"\\n\' % (wn))\n    if funcwrappers2:\n        wn = os.path.join(\n            options[\'buildpath\'], \'%s-f2pywrappers2.f90\' % (vrd[\'modulename\']))\n        ret[\'fsrc\'] = wn\n        f = open(wn, \'w\')\n        f.write(\'!     -*- f90 -*-\\n\')\n        f.write(\n            \'!     This file is autogenerated with f2py (version:%s)\\n\' % (f2py_version))\n        f.write(\n            \'!     It contains Fortran 90 wrappers to fortran functions.\\n\')\n        lines = []\n        for l in (\'\\n\\n\'.join(funcwrappers2) + \'\\n\').split(\'\\n\'):\n            if len(l) > 72 and l[0] == \' \':\n                lines.append(l[:72] + \'&\\n     &\')\n                l = l[72:]\n                while len(l) > 66:\n                    lines.append(l[:66] + \'&\\n     &\')\n                    l = l[66:]\n                lines.append(l + \'\\n\')\n            else:\n                lines.append(l + \'\\n\')\n        lines = \'\'.join(lines).replace(\'\\n     &\\n\', \'\\n\')\n        f.write(lines)\n        f.close()\n        outmess(\'\\tFortran 90 wrappers are saved to "%s"\\n\' % (wn))\n    return ret\n\n\nstnd = {1: \'st\', 2: \'nd\', 3: \'rd\', 4: \'th\', 5: \'th\',\n        6: \'th\', 7: \'th\', 8: \'th\', 9: \'th\', 0: \'th\'}\n\n\ndef buildapi(rout):\n    rout, wrap = func2subr.assubr(rout)\n    args, depargs = getargs2(rout)\n    capi_maps.depargs = depargs\n    var = rout[\'vars\']\n\n    if ismoduleroutine(rout):\n        outmess(\'\\t\\t\\tConstructing wrapper function "%s.%s"...\\n\' %\n                (rout[\'modulename\'], rout[\'name\']))\n    else:\n        outmess(\'\\t\\tConstructing wrapper function "%s"...\\n\' % (rout[\'name\']))\n        vrd = capi_maps.routsign2map(rout)\n    rd = dictappend({}, vrd)\n    for r in rout_rules:\n        if (\'_check\' in r and r[\'_check\'](rout)) or (\'_check\' not in r):\n            ar = applyrules(r, vrd, rout)\n            rd = dictappend(rd, ar)\n\n        nth, nthk = 0, 0\n    savevrd = {}\n    for a in args:\n        vrd = capi_maps.sign2map(a, var[a])\n        if isintent_aux(var[a]):\n            _rules = aux_rules\n        else:\n            _rules = arg_rules\n            if not isintent_hide(var[a]):\n                if not isoptional(var[a]):\n                    nth = nth + 1\n                    vrd[\'nth\'] = repr(nth) + stnd[nth % 10] + \' argument\'\n                else:\n                    nthk = nthk + 1\n                    vrd[\'nth\'] = repr(nthk) + stnd[nthk % 10] + \' keyword\'\n            else:\n                vrd[\'nth\'] = \'hidden\'\n        savevrd[a] = vrd\n        for r in _rules:\n            if \'_depend\' in r:\n                continue\n            if (\'_check\' in r and r[\'_check\'](var[a])) or (\'_check\' not in r):\n                ar = applyrules(r, vrd, var[a])\n                rd = dictappend(rd, ar)\n                if \'_break\' in r:\n                    break\n    for a in depargs:\n        if isintent_aux(var[a]):\n            _rules = aux_rules\n        else:\n            _rules = arg_rules\n        vrd = savevrd[a]\n        for r in _rules:\n            if \'_depend\' not in r:\n                continue\n            if (\'_check\' in r and r[\'_check\'](var[a])) or (\'_check\' not in r):\n                ar = applyrules(r, vrd, var[a])\n                rd = dictappend(rd, ar)\n                if \'_break\' in r:\n                    break\n        if \'check\' in var[a]:\n            for c in var[a][\'check\']:\n                vrd[\'check\'] = c\n                ar = applyrules(check_rules, vrd, var[a])\n                rd = dictappend(rd, ar)\n    if isinstance(rd[\'cleanupfrompyobj\'], list):\n        rd[\'cleanupfrompyobj\'].reverse()\n    if isinstance(rd[\'closepyobjfrom\'], list):\n        rd[\'closepyobjfrom\'].reverse()\n    rd[\'docsignature\'] = stripcomma(replace(\'                                            {\'docsign\': rd[\'docsign\'],\n                                             \'docsignopt\': rd[\'docsignopt\'],\n                                             \'docsignxa\': rd[\'docsignxa\']}))\n    optargs = stripcomma(replace(\'                                 {\'docsignxa\': rd[\'docsignxashort\'],\n                                  \'docsignopt\': rd[\'docsignoptshort\']}\n                                 ))\n    if optargs == \'\':\n        rd[\'docsignatureshort\'] = stripcomma(\n            replace(\'    else:\n        rd[\'docsignatureshort\'] = replace(\'                                          {\'docsign\': rd[\'docsign\'],\n                                           \'docsignopt\': optargs,\n                                           })\n    rd[\'latexdocsignatureshort\'] = rd[\'docsignatureshort\'].replace(\'_\', \'\\\\_\')\n    rd[\'latexdocsignatureshort\'] = rd[\n        \'latexdocsignatureshort\'].replace(\',\', \', \')\n    cfs = stripcomma(replace(\'                     \'callfortran\': rd[\'callfortran\'], \'callfortranappend\': rd[\'callfortranappend\']}))\n    if len(rd[\'callfortranappend\']) > 1:\n        rd[\'callcompaqfortran\'] = stripcomma(replace(\'                                             \'callfortran\': rd[\'callfortran\'], \'callfortranappend\': rd[\'callfortranappend\']}))\n    else:\n        rd[\'callcompaqfortran\'] = cfs\n    rd[\'callfortran\'] = cfs\n    if isinstance(rd[\'docreturn\'], list):\n        rd[\'docreturn\'] = stripcomma(\n            replace(\'    rd[\'docstrsigns\'] = []\n    rd[\'latexdocstrsigns\'] = []\n    for k in [\'docstrreq\', \'docstropt\', \'docstrout\', \'docstrcbs\']:\n        if k in rd and isinstance(rd[k], list):\n            rd[\'docstrsigns\'] = rd[\'docstrsigns\'] + rd[k]\n        k = \'latex\' + k\n        if k in rd and isinstance(rd[k], list):\n            rd[\'latexdocstrsigns\'] = rd[\'latexdocstrsigns\'] + rd[k][0:1] +\\\n                [\'\\\\begin{description}\'] + rd[k][1:] +\\\n                [\'\\\\end{description}\']\n\n        if rd[\'keyformat\'] or rd[\'xaformat\']:\n        argformat = rd[\'argformat\']\n        if isinstance(argformat, list):\n            argformat.append(\'|\')\n        else:\n            assert isinstance(argformat, str), repr(\n                (argformat, type(argformat)))\n            rd[\'argformat\'] += \'|\'\n\n    ar = applyrules(routine_rules, rd)\n    if ismoduleroutine(rout):\n        outmess(\'\\t\\t\\t  %s\\n\' % (ar[\'docshort\']))\n    else:\n        outmess(\'\\t\\t  %s\\n\' % (ar[\'docshort\']))\n    return ar, wrap\n\n\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy.core.numeric as nx\nimport numpy.core.numerictypes as nt\nfrom numpy.core.numeric import asarray, any\nfrom numpy.lib.type_check import isreal\n\n\n__all__ = [\n    \'sqrt\', \'log\', \'log2\', \'logn\', \'log10\', \'power\', \'arccos\', \'arcsin\',\n    \'arctanh\'\n    ]\n\n\n_ln2 = nx.log(2.0)\n\n\ndef _tocomplex(arr):\n    \n    if issubclass(arr.dtype.type, (nt.single, nt.byte, nt.short, nt.ubyte,\n                                   nt.ushort, nt.csingle)):\n        return arr.astype(nt.csingle)\n    else:\n        return arr.astype(nt.cdouble)\n\ndef _fix_real_lt_zero(x):\n    \n    x = asarray(x)\n    if any(isreal(x) & (x < 0)):\n        x = _tocomplex(x)\n    return x\n\ndef _fix_int_lt_zero(x):\n    \n    x = asarray(x)\n    if any(isreal(x) & (x < 0)):\n        x = x * 1.0\n    return x\n\ndef _fix_real_abs_gt_1(x):\n    \n    x = asarray(x)\n    if any(isreal(x) & (abs(x) > 1)):\n        x = _tocomplex(x)\n    return x\n\ndef sqrt(x):\n    \n    x = _fix_real_lt_zero(x)\n    return nx.sqrt(x)\n\ndef log(x):\n    \n    x = _fix_real_lt_zero(x)\n    return nx.log(x)\n\ndef log10(x):\n    \n    x = _fix_real_lt_zero(x)\n    return nx.log10(x)\n\ndef logn(n, x):\n    \n    x = _fix_real_lt_zero(x)\n    n = _fix_real_lt_zero(n)\n    return nx.log(x)/nx.log(n)\n\ndef log2(x):\n    \n    x = _fix_real_lt_zero(x)\n    return nx.log2(x)\n\ndef power(x, p):\n    \n    x = _fix_real_lt_zero(x)\n    p = _fix_int_lt_zero(p)\n    return nx.power(x, p)\n\ndef arccos(x):\n    \n    x = _fix_real_abs_gt_1(x)\n    return nx.arccos(x)\n\ndef arcsin(x):\n    \n    x = _fix_real_abs_gt_1(x)\n    return nx.arcsin(x)\n\ndef arctanh(x):\n    \n    x = _fix_real_abs_gt_1(x)\n    return nx.arctanh(x)\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nif \'setuptools\' in sys.modules:\n    from setuptools.command.sdist import sdist as old_sdist\nelse:\n    from distutils.command.sdist import sdist as old_sdist\n\nfrom numpy.distutils.misc_util import get_data_files\n\nclass sdist(old_sdist):\n\n    def add_defaults (self):\n        old_sdist.add_defaults(self)\n\n        dist = self.distribution\n\n        if dist.has_data_files():\n            for data in dist.data_files:\n                self.filelist.extend(get_data_files(data))\n\n        if dist.has_headers():\n            headers = []\n            for h in dist.headers:\n                if isinstance(h, str): headers.append(h)\n                else: headers.append(h[1])\n            self.filelist.extend(headers)\n\n        return\nfrom __future__ import division, print_function\n\ndef configuration(parent_package=\'\',top_path=None):\n    from numpy.distutils.misc_util import Configuration\n    config = Configuration(\'ma\', parent_package, top_path)\n    config.add_data_dir(\'tests\')\n    return config\n\nif __name__ == "__main__":\n    from numpy.distutils.core import setup\n    config = configuration(top_path=\'\').todict()\n    setup(**config)\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport warnings\nimport copy\nimport binascii\n\nfrom numpy.distutils.misc_util import mingw32\n\n\n\nC_ABI_VERSION = 0x01000009\n\nC_API_VERSION = 0x0000000a\n\nclass MismatchCAPIWarning(Warning):\n    pass\n\ndef is_released(config):\n    \n    from distutils.version import LooseVersion\n\n    v = config.get_version(\'../version.py\')\n    if v is None:\n        raise ValueError("Could not get version")\n    pv = LooseVersion(vstring=v).version\n    if len(pv) > 3:\n        return False\n    return True\n\ndef get_api_versions(apiversion, codegen_dir):\n    \n            sys.path.insert(0, codegen_dir)\n    try:\n        m = __import__(\'genapi\')\n        numpy_api = __import__(\'numpy_api\')\n        curapi_hash = m.fullapi_hash(numpy_api.full_api)\n        apis_hash = m.get_versions_hash()\n    finally:\n        del sys.path[0]\n\n    return curapi_hash, apis_hash[apiversion]\n\ndef check_api_version(apiversion, codegen_dir):\n    \n    curapi_hash, api_hash = get_api_versions(apiversion, codegen_dir)\n\n                            if not curapi_hash == api_hash:\n        msg = ("API mismatch detected, the C API version "\n               "numbers have to be updated. Current C api version is %d, "\n               "with checksum %s, but recorded checksum for C API version %d in "\n               "codegen_dir/cversions.txt is %s. If functions were added in the "\n               "C API, you have to update C_API_VERSION  in %s."\n               )\n        warnings.warn(msg % (apiversion, curapi_hash, apiversion, api_hash,\n                             __file__),\n                      MismatchCAPIWarning)\nMANDATORY_FUNCS = ["sin", "cos", "tan", "sinh", "cosh", "tanh", "fabs",\n        "floor", "ceil", "sqrt", "log10", "log", "exp", "asin",\n        "acos", "atan", "fmod", \'modf\', \'frexp\', \'ldexp\']\n\nOPTIONAL_STDFUNCS = ["expm1", "log1p", "acosh", "asinh", "atanh",\n        "rint", "trunc", "exp2", "log2", "hypot", "atan2", "pow",\n        "copysign", "nextafter", "ftello", "fseeko",\n        "strtoll", "strtoull", "cbrt", "strtold_l",]\n\n\nOPTIONAL_HEADERS = [\n                "xmmintrin.h",                  "emmintrin.h",                  "features.h",  ]\n\nOPTIONAL_INTRINSICS = [("__builtin_isnan", \'5.\'),\n                       ("__builtin_isinf", \'5.\'),\n                       ("__builtin_isfinite", \'5.\'),\n                       ("__builtin_bswap32", \'5u\'),\n                       ("__builtin_bswap64", \'5u\'),\n                       ("__builtin_expect", \'5, 0\'),\n                       ("__builtin_mul_overflow", \'5, 5, (int*)5\'),\n                       ("_mm_load_ps", \'(float*)0\', "xmmintrin.h"),                         ("_mm_load_pd", \'(double*)0\', "emmintrin.h"),                         ]\n\nOPTIONAL_FUNCTION_ATTRIBUTES = [(\'__attribute__((optimize("unroll-loops")))\',\n                                \'attribute_optimize_unroll_loops\'),\n                                (\'__attribute__((optimize("O3")))\',\n                                 \'attribute_optimize_opt_3\'),\n                                (\'__attribute__((nonnull (1)))\',\n                                 \'attribute_nonnull\'),\n                                ]\n\nOPTIONAL_VARIABLE_ATTRIBUTES = ["__thread", "__declspec(thread)"]\n\nOPTIONAL_STDFUNCS_MAYBE = [\n    "expm1", "log1p", "acosh", "atanh", "asinh", "hypot", "copysign",\n    "ftello", "fseeko"\n    ]\n\nC99_FUNCS = [\n    "sin", "cos", "tan", "sinh", "cosh", "tanh", "fabs", "floor", "ceil",\n    "rint", "trunc", "sqrt", "log10", "log", "log1p", "exp", "expm1",\n    "asin", "acos", "atan", "asinh", "acosh", "atanh", "hypot", "atan2",\n    "pow", "fmod", "modf", \'frexp\', \'ldexp\', "exp2", "log2", "copysign",\n    "nextafter", "cbrt"\n    ]\nC99_FUNCS_SINGLE = [f + \'f\' for f in C99_FUNCS]\nC99_FUNCS_EXTENDED = [f + \'l\' for f in C99_FUNCS]\nC99_COMPLEX_TYPES = [\n    \'complex double\', \'complex float\', \'complex long double\'\n    ]\nC99_COMPLEX_FUNCS = [\n    "cabs", "cacos", "cacosh", "carg", "casin", "casinh", "catan",\n    "catanh", "ccos", "ccosh", "cexp", "cimag", "clog", "conj", "cpow",\n    "cproj", "creal", "csin", "csinh", "csqrt", "ctan", "ctanh"\n    ]\n\ndef fname2def(name):\n    return "HAVE_%s" % name.upper()\n\ndef sym2def(symbol):\n    define = symbol.replace(\' \', \'\')\n    return define.upper()\n\ndef type2def(symbol):\n    define = symbol.replace(\' \', \'_\')\n    return define.upper()\n\ndef check_long_double_representation(cmd):\n    cmd._check_compiler()\n    body = LONG_DOUBLE_REPRESENTATION_SRC % {\'type\': \'long double\'}\n\n                if sys.platform == "win32" and not mingw32():\n        try:\n            cmd.compiler.compile_options.remove("/GL")\n        except ValueError:\n            pass\n\n        src, obj = cmd._compile(body, None, None, \'c\')\n    try:\n        ltype = long_double_representation(pyod(obj))\n        return ltype\n    except ValueError:\n                        body = body.replace(\'struct\', \'volatile struct\')\n        body += "int main(void) { return 0; }\\n"\n        src, obj = cmd._compile(body, None, None, \'c\')\n        cmd.temp_files.append("_configtest")\n        cmd.compiler.link_executable([obj], "_configtest")\n        ltype = long_double_representation(pyod("_configtest"))\n        return ltype\n    finally:\n        cmd._clean()\n\nLONG_DOUBLE_REPRESENTATION_SRC = r\n\ndef pyod(filename):\n    \n    def _pyod2():\n        out = []\n\n        fid = open(filename, \'rb\')\n        try:\n            yo = [int(oct(int(binascii.b2a_hex(o), 16))) for o in fid.read()]\n            for i in range(0, len(yo), 16):\n                line = [\'%07d\' % int(oct(i))]\n                line.extend([\'%03d\' % c for c in yo[i:i+16]])\n                out.append(" ".join(line))\n            return out\n        finally:\n            fid.close()\n\n    def _pyod3():\n        out = []\n\n        fid = open(filename, \'rb\')\n        try:\n            yo2 = [oct(o)[2:] for o in fid.read()]\n            for i in range(0, len(yo2), 16):\n                line = [\'%07d\' % int(oct(i)[2:])]\n                line.extend([\'%03d\' % int(c) for c in yo2[i:i+16]])\n                out.append(" ".join(line))\n            return out\n        finally:\n            fid.close()\n\n    if sys.version_info[0] < 3:\n        return _pyod2()\n    else:\n        return _pyod3()\n\n_BEFORE_SEQ = [\'000\', \'000\', \'000\', \'000\', \'000\', \'000\', \'000\', \'000\',\n              \'001\', \'043\', \'105\', \'147\', \'211\', \'253\', \'315\', \'357\']\n_AFTER_SEQ = [\'376\', \'334\', \'272\', \'230\', \'166\', \'124\', \'062\', \'020\']\n\n_IEEE_DOUBLE_BE = [\'301\', \'235\', \'157\', \'064\', \'124\', \'000\', \'000\', \'000\']\n_IEEE_DOUBLE_LE = _IEEE_DOUBLE_BE[::-1]\n_INTEL_EXTENDED_12B = [\'000\', \'000\', \'000\', \'000\', \'240\', \'242\', \'171\', \'353\',\n                       \'031\', \'300\', \'000\', \'000\']\n_INTEL_EXTENDED_16B = [\'000\', \'000\', \'000\', \'000\', \'240\', \'242\', \'171\', \'353\',\n                       \'031\', \'300\', \'000\', \'000\', \'000\', \'000\', \'000\', \'000\']\n_MOTOROLA_EXTENDED_12B = [\'300\', \'031\', \'000\', \'000\', \'353\', \'171\',\n                          \'242\', \'240\', \'000\', \'000\', \'000\', \'000\']\n_IEEE_QUAD_PREC_BE = [\'300\', \'031\', \'326\', \'363\', \'105\', \'100\', \'000\', \'000\',\n                      \'000\', \'000\', \'000\', \'000\', \'000\', \'000\', \'000\', \'000\']\n_IEEE_QUAD_PREC_LE = _IEEE_QUAD_PREC_BE[::-1]\n_DOUBLE_DOUBLE_BE = ([\'301\', \'235\', \'157\', \'064\', \'124\', \'000\', \'000\', \'000\'] +\n                     [\'000\'] * 8)\n_DOUBLE_DOUBLE_LE = ([\'000\', \'000\', \'000\', \'124\', \'064\', \'157\', \'235\', \'301\'] +\n                     [\'000\'] * 8)\n\ndef long_double_representation(lines):\n    \n\n                                read = [\'\'] * 32\n    saw = None\n    for line in lines:\n                        for w in line.split()[1:]:\n            read.pop(0)\n            read.append(w)\n\n                                    if read[-8:] == _AFTER_SEQ:\n                saw = copy.copy(read)\n                if read[:12] == _BEFORE_SEQ[4:]:\n                    if read[12:-8] == _INTEL_EXTENDED_12B:\n                        return \'INTEL_EXTENDED_12_BYTES_LE\'\n                    if read[12:-8] == _MOTOROLA_EXTENDED_12B:\n                        return \'MOTOROLA_EXTENDED_12_BYTES_BE\'\n                elif read[:8] == _BEFORE_SEQ[8:]:\n                    if read[8:-8] == _INTEL_EXTENDED_16B:\n                        return \'INTEL_EXTENDED_16_BYTES_LE\'\n                    elif read[8:-8] == _IEEE_QUAD_PREC_BE:\n                        return \'IEEE_QUAD_BE\'\n                    elif read[8:-8] == _IEEE_QUAD_PREC_LE:\n                        return \'IEEE_QUAD_LE\'\n                    elif read[8:-8] == _DOUBLE_DOUBLE_BE:\n                        return \'DOUBLE_DOUBLE_BE\'\n                    elif read[8:-8] == _DOUBLE_DOUBLE_LE:\n                        return \'DOUBLE_DOUBLE_LE\'\n                elif read[:16] == _BEFORE_SEQ:\n                    if read[16:-8] == _IEEE_DOUBLE_LE:\n                        return \'IEEE_DOUBLE_LE\'\n                    elif read[16:-8] == _IEEE_DOUBLE_BE:\n                        return \'IEEE_DOUBLE_BE\'\n\n    if saw is not None:\n        raise ValueError("Unrecognized format (%s)" % saw)\n    else:\n                raise ValueError("Could not lock sequences (%s)" % saw)\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\n\nimport numpy.core.numeric as _nx\nfrom numpy.core.numeric import (\n    asarray, zeros, outer, concatenate, isscalar, array, asanyarray\n    )\nfrom numpy.core.fromnumeric import product, reshape\nfrom numpy.core import vstack, atleast_3d\n\n\n__all__ = [\n    \'column_stack\', \'row_stack\', \'dstack\', \'array_split\', \'split\',\n    \'hsplit\', \'vsplit\', \'dsplit\', \'apply_over_axes\', \'expand_dims\',\n    \'apply_along_axis\', \'kron\', \'tile\', \'get_array_wrap\'\n    ]\n\n\ndef apply_along_axis(func1d, axis, arr, *args, **kwargs):\n    \n    arr = asarray(arr)\n    nd = arr.ndim\n    if axis < 0:\n        axis += nd\n    if (axis >= nd):\n        raise ValueError("axis must be less than arr.ndim; axis=%d, rank=%d."\n            % (axis, nd))\n    ind = [0]*(nd-1)\n    i = zeros(nd, \'O\')\n    indlist = list(range(nd))\n    indlist.remove(axis)\n    i[axis] = slice(None, None)\n    outshape = asarray(arr.shape).take(indlist)\n    i.put(indlist, ind)\n    res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n        if isscalar(res):\n        outarr = zeros(outshape, asarray(res).dtype)\n        outarr[tuple(ind)] = res\n        Ntot = product(outshape)\n        k = 1\n        while k < Ntot:\n                        ind[-1] += 1\n            n = -1\n            while (ind[n] >= outshape[n]) and (n > (1-nd)):\n                ind[n-1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(ind)] = res\n            k += 1\n        return outarr\n    else:\n        Ntot = product(outshape)\n        holdshape = outshape\n        outshape = list(arr.shape)\n        outshape[axis] = len(res)\n        outarr = zeros(outshape, asarray(res).dtype)\n        outarr[tuple(i.tolist())] = res\n        k = 1\n        while k < Ntot:\n                        ind[-1] += 1\n            n = -1\n            while (ind[n] >= holdshape[n]) and (n > (1-nd)):\n                ind[n-1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(i.tolist())] = res\n            k += 1\n        return outarr\n\n\ndef apply_over_axes(func, a, axes):\n    \n    val = asarray(a)\n    N = a.ndim\n    if array(axes).ndim == 0:\n        axes = (axes,)\n    for axis in axes:\n        if axis < 0:\n            axis = N + axis\n        args = (val, axis)\n        res = func(*args)\n        if res.ndim == val.ndim:\n            val = res\n        else:\n            res = expand_dims(res, axis)\n            if res.ndim == val.ndim:\n                val = res\n            else:\n                raise ValueError("function is not returning "\n                        "an array of the correct shape")\n    return val\n\ndef expand_dims(a, axis):\n    \n    a = asarray(a)\n    shape = a.shape\n    if axis < 0:\n        axis = axis + len(shape) + 1\n    return a.reshape(shape[:axis] + (1,) + shape[axis:])\n\nrow_stack = vstack\n\ndef column_stack(tup):\n    \n    arrays = []\n    for v in tup:\n        arr = array(v, copy=False, subok=True)\n        if arr.ndim < 2:\n            arr = array(arr, copy=False, subok=True, ndmin=2).T\n        arrays.append(arr)\n    return _nx.concatenate(arrays, 1)\n\ndef dstack(tup):\n    \n    return _nx.concatenate([atleast_3d(_m) for _m in tup], 2)\n\ndef _replace_zero_by_x_arrays(sub_arys):\n    for i in range(len(sub_arys)):\n        if len(_nx.shape(sub_arys[i])) == 0:\n            sub_arys[i] = _nx.empty(0, dtype=sub_arys[i].dtype)\n        elif _nx.sometrue(_nx.equal(_nx.shape(sub_arys[i]), 0)):\n            sub_arys[i] = _nx.empty(0, dtype=sub_arys[i].dtype)\n    return sub_arys\n\ndef array_split(ary, indices_or_sections, axis=0):\n    \n    try:\n        Ntotal = ary.shape[axis]\n    except AttributeError:\n        Ntotal = len(ary)\n    try:\n                Nsections = len(indices_or_sections) + 1\n        div_points = [0] + list(indices_or_sections) + [Ntotal]\n    except TypeError:\n                Nsections = int(indices_or_sections)\n        if Nsections <= 0:\n            raise ValueError(\'number sections must be larger than 0.\')\n        Neach_section, extras = divmod(Ntotal, Nsections)\n        section_sizes = ([0] +\n                         extras * [Neach_section+1] +\n                         (Nsections-extras) * [Neach_section])\n        div_points = _nx.array(section_sizes).cumsum()\n\n    sub_arys = []\n    sary = _nx.swapaxes(ary, axis, 0)\n    for i in range(Nsections):\n        st = div_points[i]\n        end = div_points[i + 1]\n        sub_arys.append(_nx.swapaxes(sary[st:end], axis, 0))\n\n                if any(arr.size == 0 and arr.ndim != 1 for arr in sub_arys):\n        warnings.warn("in the future np.array_split will retain the shape of "\n                      "arrays with a zero size, instead of replacing them by "\n                      "`array([])`, which always has a shape of (0,).",\n                      FutureWarning)\n        sub_arys = _replace_zero_by_x_arrays(sub_arys)\n\n    return sub_arys\n\ndef split(ary,indices_or_sections,axis=0):\n    \n    try:\n        len(indices_or_sections)\n    except TypeError:\n        sections = indices_or_sections\n        N = ary.shape[axis]\n        if N % sections:\n            raise ValueError(\n                \'array split does not result in an equal division\')\n    res = array_split(ary, indices_or_sections, axis)\n    return res\n\ndef hsplit(ary, indices_or_sections):\n    \n    if len(_nx.shape(ary)) == 0:\n        raise ValueError(\'hsplit only works on arrays of 1 or more dimensions\')\n    if len(ary.shape) > 1:\n        return split(ary, indices_or_sections, 1)\n    else:\n        return split(ary, indices_or_sections, 0)\n\ndef vsplit(ary, indices_or_sections):\n    \n    if len(_nx.shape(ary)) < 2:\n        raise ValueError(\'vsplit only works on arrays of 2 or more dimensions\')\n    return split(ary, indices_or_sections, 0)\n\ndef dsplit(ary, indices_or_sections):\n    \n    if len(_nx.shape(ary)) < 3:\n        raise ValueError(\'dsplit only works on arrays of 3 or more dimensions\')\n    return split(ary, indices_or_sections, 2)\n\ndef get_array_prepare(*args):\n    \n    wrappers = sorted((getattr(x, \'__array_priority__\', 0), -i,\n                 x.__array_prepare__) for i, x in enumerate(args)\n                                   if hasattr(x, \'__array_prepare__\'))\n    if wrappers:\n        return wrappers[-1][-1]\n    return None\n\ndef get_array_wrap(*args):\n    \n    wrappers = sorted((getattr(x, \'__array_priority__\', 0), -i,\n                 x.__array_wrap__) for i, x in enumerate(args)\n                                   if hasattr(x, \'__array_wrap__\'))\n    if wrappers:\n        return wrappers[-1][-1]\n    return None\n\ndef kron(a, b):\n    \n    b = asanyarray(b)\n    a = array(a, copy=False, subok=True, ndmin=b.ndim)\n    ndb, nda = b.ndim, a.ndim\n    if (nda == 0 or ndb == 0):\n        return _nx.multiply(a, b)\n    as_ = a.shape\n    bs = b.shape\n    if not a.flags.contiguous:\n        a = reshape(a, as_)\n    if not b.flags.contiguous:\n        b = reshape(b, bs)\n    nd = ndb\n    if (ndb != nda):\n        if (ndb > nda):\n            as_ = (1,)*(ndb-nda) + as_\n        else:\n            bs = (1,)*(nda-ndb) + bs\n            nd = nda\n    result = outer(a, b).reshape(as_+bs)\n    axis = nd-1\n    for _ in range(nd):\n        result = concatenate(result, axis=axis)\n    wrapper = get_array_prepare(a, b)\n    if wrapper is not None:\n        result = wrapper(result)\n    wrapper = get_array_wrap(a, b)\n    if wrapper is not None:\n        result = wrapper(result)\n    return result\n\n\ndef tile(A, reps):\n    \n    try:\n        tup = tuple(reps)\n    except TypeError:\n        tup = (reps,)\n    d = len(tup)\n    if all(x == 1 for x in tup) and isinstance(A, _nx.ndarray):\n                        return _nx.array(A, copy=True, subok=True, ndmin=d)\n    else:\n                        c = _nx.array(A, copy=False, subok=True, ndmin=d)\n    if (d < c.ndim):\n        tup = (1,)*(c.ndim-d) + tup\n    shape_out = tuple(s*t for s, t in zip(c.shape, tup))\n    n = c.size\n    if n > 0:\n        for dim_in, nrep in zip(c.shape, tup):\n            if nrep != 1:\n                c = c.reshape(-1, n).repeat(nrep, 0)\n            n //= dim_in\n    return c.reshape(shape_out)\n\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\n\n__all__ = [\'broadcast_to\', \'broadcast_arrays\']\n\n\nclass DummyArray(object):\n    \n\n    def __init__(self, interface, base=None):\n        self.__array_interface__ = interface\n        self.base = base\n\n\ndef _maybe_view_as_subclass(original_array, new_array):\n    if type(original_array) is not type(new_array):\n                        new_array = new_array.view(type=type(original_array))\n                                if new_array.__array_finalize__:\n            new_array.__array_finalize__(original_array)\n    return new_array\n\n\ndef as_strided(x, shape=None, strides=None, subok=False):\n    \n        x = np.array(x, copy=False, subok=subok)\n    interface = dict(x.__array_interface__)\n    if shape is not None:\n        interface[\'shape\'] = tuple(shape)\n    if strides is not None:\n        interface[\'strides\'] = tuple(strides)\n    array = np.asarray(DummyArray(interface, base=x))\n\n    if array.dtype.fields is None and x.dtype.fields is not None:\n                array.dtype = x.dtype\n\n    return _maybe_view_as_subclass(x, array)\n\n\ndef _broadcast_to(array, shape, subok, readonly):\n    shape = tuple(shape) if np.iterable(shape) else (shape,)\n    array = np.array(array, copy=False, subok=subok)\n    if not shape and array.shape:\n        raise ValueError(\'cannot broadcast a non-scalar to a scalar array\')\n    if any(size < 0 for size in shape):\n        raise ValueError(\'all elements of broadcast shape must be non-\'\n                         \'negative\')\n    broadcast = np.nditer(\n        (array,), flags=[\'multi_index\', \'refs_ok\', \'zerosize_ok\'],\n        op_flags=[\'readonly\'], itershape=shape, order=\'C\').itviews[0]\n    result = _maybe_view_as_subclass(array, broadcast)\n    if not readonly and array.flags.writeable:\n        result.flags.writeable = True\n    return result\n\n\ndef broadcast_to(array, shape, subok=False):\n    \n    return _broadcast_to(array, shape, subok=subok, readonly=True)\n\n\ndef _broadcast_shape(*args):\n    \n    if not args:\n        raise ValueError(\'must provide at least one argument\')\n    if len(args) == 1:\n                return np.asarray(args[0]).shape\n            b = np.broadcast(*args[:32])\n        for pos in range(32, len(args), 31):\n                                b = broadcast_to(0, b.shape)\n        b = np.broadcast(b, *args[pos:(pos + 31)])\n    return b.shape\n\n\ndef broadcast_arrays(*args, **kwargs):\n    \n                \n    subok = kwargs.pop(\'subok\', False)\n    if kwargs:\n        raise TypeError(\'broadcast_arrays() got an unexpected keyword \'\n                        \'argument {}\'.format(kwargs.pop()))\n    args = [np.array(_m, copy=False, subok=subok) for _m in args]\n\n    shape = _broadcast_shape(*args)\n\n    if all(array.shape == shape for array in args):\n                return args\n\n            return [_broadcast_to(array, shape, subok=subok, readonly=False)\n            for array in args]\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.distutils.ccompiler import simple_version_match\nfrom numpy.distutils.fcompiler import FCompiler\n\ncompilers = [\'SunFCompiler\']\n\nclass SunFCompiler(FCompiler):\n\n    compiler_type = \'sun\'\n    description = \'Sun or Forte Fortran 95 Compiler\'\n            version_match = simple_version_match(\n                      start=r\'f9[05]: (Sun|Forte|WorkShop).*Fortran 95\')\n\n    executables = {\n        \'version_cmd\'  : ["<F90>", "-V"],\n        \'compiler_f77\' : ["f90"],\n        \'compiler_fix\' : ["f90", "-fixed"],\n        \'compiler_f90\' : ["f90"],\n        \'linker_so\'    : ["<F90>", "-Bdynamic", "-G"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n    module_dir_switch = \'-moddir=\'\n    module_include_switch = \'-M\'\n    pic_flags = [\'-xcode=pic32\']\n\n    def get_flags_f77(self):\n        ret = ["-ftrap=%none"]\n        if (self.get_version() or \'\') >= \'7\':\n            ret.append("-f77")\n        else:\n            ret.append("-fixed")\n        return ret\n    def get_opt(self):\n        return [\'-fast\', \'-dalign\']\n    def get_arch(self):\n        return [\'-xtarget=generic\']\n    def get_libraries(self):\n        opt = []\n        opt.extend([\'fsu\', \'sunmath\', \'mvec\'])\n        return opt\n\n    def runtime_library_dir_option(self, dir):\n        return \'-R"%s"\' % dir\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'sun\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nimport os\nimport re\nimport copy\nimport warnings\nfrom glob import glob\nfrom functools import reduce\nif sys.version_info[0] < 3:\n    from ConfigParser import NoOptionError, ConfigParser\nelse:\n    from configparser import NoOptionError, ConfigParser\n\nfrom distutils.errors import DistutilsError\nfrom distutils.dist import Distribution\nimport distutils.sysconfig\nfrom distutils import log\nfrom distutils.util import get_platform\n\nfrom numpy.distutils.exec_command import \\\n    find_executable, exec_command, get_pythonexe\nfrom numpy.distutils.misc_util import is_sequence, is_string, \\\n                                      get_shared_lib_extension\nfrom numpy.distutils.command.config import config as cmd_config\nfrom numpy.distutils.compat import get_exception\nimport distutils.ccompiler\nimport tempfile\nimport shutil\n\n\nimport platform\n_bits = {\'32bit\': 32, \'64bit\': 64}\nplatform_bits = _bits[platform.architecture()[0]]\n\n\ndef libpaths(paths, bits):\n    \n    if bits not in (32, 64):\n        raise ValueError("Invalid bit size in libpaths: 32 or 64 only")\n\n        if bits == 32:\n        return paths\n\n        out = []\n    for p in paths:\n        out.extend([p + \'64\', p])\n\n    return out\n\n\nif sys.platform == \'win32\':\n    default_lib_dirs = [\'C:\\\\\',\n                        os.path.join(distutils.sysconfig.EXEC_PREFIX,\n                                     \'libs\')]\n    default_runtime_dirs = []\n    default_include_dirs = []\n    default_src_dirs = [\'.\']\n    default_x11_lib_dirs = []\n    default_x11_include_dirs = []\nelse:\n    default_lib_dirs = libpaths([\'/usr/local/lib\', \'/opt/lib\', \'/usr/lib\',\n                                 \'/opt/local/lib\', \'/sw/lib\'], platform_bits)\n    default_runtime_dirs = []\n    default_include_dirs = [\'/usr/local/include\',\n                            \'/opt/include\', \'/usr/include\',\n                                                        \'/opt/local/include/ufsparse\',\n                            \'/opt/local/include\', \'/sw/include\',\n                            \'/usr/include/suitesparse\']\n    default_src_dirs = [\'.\', \'/usr/local/src\', \'/opt/src\', \'/sw/src\']\n\n    default_x11_lib_dirs = libpaths([\'/usr/X11R6/lib\', \'/usr/X11/lib\',\n                                     \'/usr/lib\'], platform_bits)\n    default_x11_include_dirs = [\'/usr/X11R6/include\', \'/usr/X11/include\',\n                                \'/usr/include\']\n\n    if os.path.exists(\'/usr/lib/X11\'):\n        globbed_x11_dir = glob(\'/usr/lib/*/libX11.so\')\n        if globbed_x11_dir:\n            x11_so_dir = os.path.split(globbed_x11_dir[0])[0]\n            default_x11_lib_dirs.extend([x11_so_dir, \'/usr/lib/X11\'])\n            default_x11_include_dirs.extend([\'/usr/lib/X11/include\',\n                                             \'/usr/include/X11\'])\n\n    import subprocess as sp\n    tmp = None\n    try:\n                        tmp = open(os.devnull, \'w\')\n        p = sp.Popen(["gcc", "-print-multiarch"], stdout=sp.PIPE,\n                stderr=tmp)\n    except (OSError, DistutilsError):\n                        pass\n    else:\n        triplet = str(p.communicate()[0].decode().strip())\n        if p.returncode == 0:\n                        default_x11_lib_dirs += [os.path.join("/usr/lib/", triplet)]\n            default_lib_dirs += [os.path.join("/usr/lib/", triplet)]\n    finally:\n        if tmp is not None:\n            tmp.close()\n\nif os.path.join(sys.prefix, \'lib\') not in default_lib_dirs:\n    default_lib_dirs.insert(0, os.path.join(sys.prefix, \'lib\'))\n    default_include_dirs.append(os.path.join(sys.prefix, \'include\'))\n    default_src_dirs.append(os.path.join(sys.prefix, \'src\'))\n\ndefault_lib_dirs = [_m for _m in default_lib_dirs if os.path.isdir(_m)]\ndefault_runtime_dirs = [_m for _m in default_runtime_dirs if os.path.isdir(_m)]\ndefault_include_dirs = [_m for _m in default_include_dirs if os.path.isdir(_m)]\ndefault_src_dirs = [_m for _m in default_src_dirs if os.path.isdir(_m)]\n\nso_ext = get_shared_lib_extension()\n\n\ndef get_standard_file(fname):\n    \n        filenames = []\n    try:\n        f = __file__\n    except NameError:\n        f = sys.argv[0]\n    else:\n        sysfile = os.path.join(os.path.split(os.path.abspath(f))[0],\n                               fname)\n        if os.path.isfile(sysfile):\n            filenames.append(sysfile)\n\n            try:\n        f = os.path.expanduser(\'~\')\n    except KeyError:\n        pass\n    else:\n        user_file = os.path.join(f, fname)\n        if os.path.isfile(user_file):\n            filenames.append(user_file)\n\n        if os.path.isfile(fname):\n        filenames.append(os.path.abspath(fname))\n\n    return filenames\n\n\ndef get_info(name, notfound_action=0):\n    \n    cl = {\'atlas\': atlas_info,            \'atlas_threads\': atlas_threads_info,                          \'atlas_blas\': atlas_blas_info,\n          \'atlas_blas_threads\': atlas_blas_threads_info,\n          \'lapack_atlas\': lapack_atlas_info,            \'lapack_atlas_threads\': lapack_atlas_threads_info,            \'atlas_3_10\': atlas_3_10_info,            \'atlas_3_10_threads\': atlas_3_10_threads_info,                          \'atlas_3_10_blas\': atlas_3_10_blas_info,\n          \'atlas_3_10_blas_threads\': atlas_3_10_blas_threads_info,\n          \'lapack_atlas_3_10\': lapack_atlas_3_10_info,            \'lapack_atlas_3_10_threads\': lapack_atlas_3_10_threads_info,            \'mkl\': mkl_info,\n                    \'openblas\': openblas_info,                              \'openblas_lapack\': openblas_lapack_info,           \'lapack_mkl\': lapack_mkl_info,                \'blas_mkl\': blas_mkl_info,                    \'x11\': x11_info,\n          \'fft_opt\': fft_opt_info,\n          \'fftw\': fftw_info,\n          \'fftw2\': fftw2_info,\n          \'fftw3\': fftw3_info,\n          \'dfftw\': dfftw_info,\n          \'sfftw\': sfftw_info,\n          \'fftw_threads\': fftw_threads_info,\n          \'dfftw_threads\': dfftw_threads_info,\n          \'sfftw_threads\': sfftw_threads_info,\n          \'djbfft\': djbfft_info,\n          \'blas\': blas_info,                            \'lapack\': lapack_info,                        \'lapack_src\': lapack_src_info,\n          \'blas_src\': blas_src_info,\n          \'numpy\': numpy_info,\n          \'f2py\': f2py_info,\n          \'Numeric\': Numeric_info,\n          \'numeric\': Numeric_info,\n          \'numarray\': numarray_info,\n          \'numerix\': numerix_info,\n          \'lapack_opt\': lapack_opt_info,\n          \'blas_opt\': blas_opt_info,\n          \'boost_python\': boost_python_info,\n          \'agg2\': agg2_info,\n          \'wx\': wx_info,\n          \'gdk_pixbuf_xlib_2\': gdk_pixbuf_xlib_2_info,\n          \'gdk-pixbuf-xlib-2.0\': gdk_pixbuf_xlib_2_info,\n          \'gdk_pixbuf_2\': gdk_pixbuf_2_info,\n          \'gdk-pixbuf-2.0\': gdk_pixbuf_2_info,\n          \'gdk\': gdk_info,\n          \'gdk_2\': gdk_2_info,\n          \'gdk-2.0\': gdk_2_info,\n          \'gdk_x11_2\': gdk_x11_2_info,\n          \'gdk-x11-2.0\': gdk_x11_2_info,\n          \'gtkp_x11_2\': gtkp_x11_2_info,\n          \'gtk+-x11-2.0\': gtkp_x11_2_info,\n          \'gtkp_2\': gtkp_2_info,\n          \'gtk+-2.0\': gtkp_2_info,\n          \'xft\': xft_info,\n          \'freetype2\': freetype2_info,\n          \'umfpack\': umfpack_info,\n          \'amd\': amd_info,\n          }.get(name.lower(), system_info)\n    return cl().get_info(notfound_action)\n\n\nclass NotFoundError(DistutilsError):\n    \n\n\nclass AtlasNotFoundError(NotFoundError):\n    \n\n\nclass LapackNotFoundError(NotFoundError):\n    \n\n\nclass LapackSrcNotFoundError(LapackNotFoundError):\n    \n\n\nclass BlasNotFoundError(NotFoundError):\n    \n\n\nclass BlasSrcNotFoundError(BlasNotFoundError):\n    \n\n\nclass FFTWNotFoundError(NotFoundError):\n    \n\n\nclass DJBFFTNotFoundError(NotFoundError):\n    \n\n\nclass NumericNotFoundError(NotFoundError):\n    \n\n\nclass X11NotFoundError(NotFoundError):\n    \n\n\nclass UmfpackNotFoundError(NotFoundError):\n    \n\n\nclass system_info(object):\n\n    \n    section = \'ALL\'\n    dir_env_var = None\n    search_static_first = 0                                  verbosity = 1\n    saved_results = {}\n\n    notfounderror = NotFoundError\n\n    def __init__(self,\n                  default_lib_dirs=default_lib_dirs,\n                  default_include_dirs=default_include_dirs,\n                  verbosity=1,\n                  ):\n        self.__class__.info = {}\n        self.local_prefixes = []\n        defaults = {}\n        defaults[\'library_dirs\'] = os.pathsep.join(default_lib_dirs)\n        defaults[\'include_dirs\'] = os.pathsep.join(default_include_dirs)\n        defaults[\'runtime_library_dirs\'] = os.pathsep.join(default_runtime_dirs)\n        defaults[\'rpath\'] = \'\'\n        defaults[\'src_dirs\'] = os.pathsep.join(default_src_dirs)\n        defaults[\'search_static_first\'] = str(self.search_static_first)\n        defaults[\'extra_compile_args\'] = \'\'\n        defaults[\'extra_link_args\'] = \'\'\n        self.cp = ConfigParser(defaults)\n        self.files = []\n        self.files.extend(get_standard_file(\'.numpy-site.cfg\'))\n        self.files.extend(get_standard_file(\'site.cfg\'))\n        self.parse_config_files()\n        if self.section is not None:\n            self.search_static_first = self.cp.getboolean(\n                self.section, \'search_static_first\')\n        assert isinstance(self.search_static_first, int)\n\n    def parse_config_files(self):\n        self.cp.read(self.files)\n        if not self.cp.has_section(self.section):\n            if self.section is not None:\n                self.cp.add_section(self.section)\n\n    def calc_libraries_info(self):\n        libs = self.get_libraries()\n        dirs = self.get_lib_dirs()\n                r_dirs = self.get_runtime_lib_dirs() \n                        r_dirs.extend(self.get_runtime_lib_dirs(key=\'rpath\'))\n        info = {}\n        for lib in libs:\n            i = self.check_libs(dirs, [lib])\n            if i is not None:\n                dict_append(info, **i)\n            else:\n                log.info(\'Library %s was not found. Ignoring\' % (lib))\n            i = self.check_libs(r_dirs, [lib])\n            if i is not None:\n                                                                                del i[\'libraries\']\n                i[\'runtime_library_dirs\'] = i.pop(\'library_dirs\')\n                dict_append(info, **i)\n            else:\n                log.info(\'Runtime library %s was not found. Ignoring\' % (lib))\n        return info\n\n    def set_info(self, **info):\n        if info:\n            lib_info = self.calc_libraries_info()\n            dict_append(info, **lib_info)\n                        extra_info = self.calc_extra_info()\n            dict_append(info, **extra_info)\n        self.saved_results[self.__class__.__name__] = info\n\n    def has_info(self):\n        return self.__class__.__name__ in self.saved_results\n\n    def calc_extra_info(self):\n        \n        info = {}\n        for key in [\'extra_compile_args\', \'extra_link_args\']:\n                        opt = self.cp.get(self.section, key)\n            if opt:\n                tmp = {key : [opt]}\n                dict_append(info, **tmp)\n        return info\n\n    def get_info(self, notfound_action=0):\n        \n        flag = 0\n        if not self.has_info():\n            flag = 1\n            log.info(self.__class__.__name__ + \':\')\n            if hasattr(self, \'calc_info\'):\n                self.calc_info()\n            if notfound_action:\n                if not self.has_info():\n                    if notfound_action == 1:\n                        warnings.warn(self.notfounderror.__doc__)\n                    elif notfound_action == 2:\n                        raise self.notfounderror(self.notfounderror.__doc__)\n                    else:\n                        raise ValueError(repr(notfound_action))\n\n            if not self.has_info():\n                log.info(\'  NOT AVAILABLE\')\n                self.set_info()\n            else:\n                log.info(\'  FOUND:\')\n\n        res = self.saved_results.get(self.__class__.__name__)\n        if self.verbosity > 0 and flag:\n            for k, v in res.items():\n                v = str(v)\n                if k in [\'sources\', \'libraries\'] and len(v) > 270:\n                    v = v[:120] + \'...\\n...\\n...\' + v[-120:]\n                log.info(\'    %s = %s\', k, v)\n            log.info(\'\')\n\n        return copy.deepcopy(res)\n\n    def get_paths(self, section, key):\n        dirs = self.cp.get(section, key).split(os.pathsep)\n        env_var = self.dir_env_var\n        if env_var:\n            if is_sequence(env_var):\n                e0 = env_var[-1]\n                for e in env_var:\n                    if e in os.environ:\n                        e0 = e\n                        break\n                if not env_var[0] == e0:\n                    log.info(\'Setting %s=%s\' % (env_var[0], e0))\n                env_var = e0\n        if env_var and env_var in os.environ:\n            d = os.environ[env_var]\n            if d == \'None\':\n                log.info(\'Disabled %s: %s\',\n                         self.__class__.__name__, \'(%s is None)\'\n                         % (env_var,))\n                return []\n            if os.path.isfile(d):\n                dirs = [os.path.dirname(d)] + dirs\n                l = getattr(self, \'_lib_names\', [])\n                if len(l) == 1:\n                    b = os.path.basename(d)\n                    b = os.path.splitext(b)[0]\n                    if b[:3] == \'lib\':\n                        log.info(\'Replacing _lib_names[0]==%r with %r\' \\\n                              % (self._lib_names[0], b[3:]))\n                        self._lib_names[0] = b[3:]\n            else:\n                ds = d.split(os.pathsep)\n                ds2 = []\n                for d in ds:\n                    if os.path.isdir(d):\n                        ds2.append(d)\n                        for dd in [\'include\', \'lib\']:\n                            d1 = os.path.join(d, dd)\n                            if os.path.isdir(d1):\n                                ds2.append(d1)\n                dirs = ds2 + dirs\n        default_dirs = self.cp.get(self.section, key).split(os.pathsep)\n        dirs.extend(default_dirs)\n        ret = []\n        for d in dirs:\n            if not os.path.isdir(d):\n                warnings.warn(\'Specified path %s is invalid.\' % d)\n                continue\n\n            if d not in ret:\n                ret.append(d)\n\n        log.debug(\'( %s = %s )\', key, \':\'.join(ret))\n        return ret\n\n    def get_lib_dirs(self, key=\'library_dirs\'):\n        return self.get_paths(self.section, key)\n\n    def get_runtime_lib_dirs(self, key=\'runtime_library_dirs\'):\n        return self.get_paths(self.section, key)\n\n    def get_include_dirs(self, key=\'include_dirs\'):\n        return self.get_paths(self.section, key)\n\n    def get_src_dirs(self, key=\'src_dirs\'):\n        return self.get_paths(self.section, key)\n\n    def get_libs(self, key, default):\n        try:\n            libs = self.cp.get(self.section, key)\n        except NoOptionError:\n            if not default:\n                return []\n            if is_string(default):\n                return [default]\n            return default\n        return [b for b in [a.strip() for a in libs.split(\',\')] if b]\n\n    def get_libraries(self, key=\'libraries\'):\n        return self.get_libs(key, \'\')\n\n    def library_extensions(self):\n        static_exts = [\'.a\']\n        if sys.platform == \'win32\':\n            static_exts.append(\'.lib\')          if self.search_static_first:\n            exts = static_exts + [so_ext]\n        else:\n            exts = [so_ext] + static_exts\n        if sys.platform == \'cygwin\':\n            exts.append(\'.dll.a\')\n        if sys.platform == \'darwin\':\n            exts.append(\'.dylib\')\n                                                return exts\n\n    def check_libs(self, lib_dirs, libs, opt_libs=[]):\n        \n        exts = self.library_extensions()\n        info = None\n        for ext in exts:\n            info = self._check_libs(lib_dirs, libs, opt_libs, [ext])\n            if info is not None:\n                break\n        if not info:\n            log.info(\'  libraries %s not found in %s\', \',\'.join(libs),\n                     lib_dirs)\n        return info\n\n    def check_libs2(self, lib_dirs, libs, opt_libs=[]):\n        \n        exts = self.library_extensions()\n        info = self._check_libs(lib_dirs, libs, opt_libs, exts)\n        if not info:\n            log.info(\'  libraries %s not found in %s\', \',\'.join(libs),\n                     lib_dirs)\n        return info\n\n    def _lib_list(self, lib_dir, libs, exts):\n        assert is_string(lib_dir)\n        liblist = []\n                if sys.platform == \'win32\':\n            lib_prefixes = [\'\', \'lib\']\n        else:\n            lib_prefixes = [\'lib\']\n                for l in libs:\n            for ext in exts:\n                for prefix in lib_prefixes:\n                    p = self.combine_paths(lib_dir, prefix + l + ext)\n                    if p:\n                        break\n                if p:\n                    assert len(p) == 1\n                                                            if ext == \'.dll.a\':\n                        l += \'.dll\'\n                    liblist.append(l)\n                    break\n        return liblist\n\n    def _check_libs(self, lib_dirs, libs, opt_libs, exts):\n        \n                if is_sequence(lib_dirs):\n            found_libs, found_dirs = [], []\n            for dir_ in lib_dirs:\n                found_libs1 = self._lib_list(dir_, libs, exts)\n                                                                                                for found_lib in found_libs1:\n                    if found_lib not in found_libs:\n                        found_libs.append(found_lib)\n                        if dir_ not in found_dirs:\n                            found_dirs.append(dir_)\n        else:\n            found_libs = self._lib_list(lib_dirs, libs, exts)\n            found_dirs = [lib_dirs]\n        if len(found_libs) > 0 and len(found_libs) == len(libs):\n            info = {\'libraries\': found_libs, \'library_dirs\': found_dirs}\n                        if is_sequence(lib_dirs):\n                for dir_ in lib_dirs:\n                    opt_found_libs = self._lib_list(dir_, opt_libs, exts)\n                    if opt_found_libs:\n                        if dir_ not in found_dirs:\n                            found_dirs.extend(dir_)\n                        found_libs.extend(opt_found_libs)\n            else:\n                opt_found_libs = self._lib_list(lib_dirs, opt_libs, exts)\n                if opt_found_libs:\n                    found_libs.extend(opt_found_libs)\n            return info\n        else:\n            return None\n\n    def combine_paths(self, *args):\n        \n        return combine_paths(*args, **{\'verbosity\': self.verbosity})\n\n\nclass fft_opt_info(system_info):\n\n    def calc_info(self):\n        info = {}\n        fftw_info = get_info(\'fftw3\') or get_info(\'fftw2\') or get_info(\'dfftw\')\n        djbfft_info = get_info(\'djbfft\')\n        if fftw_info:\n            dict_append(info, **fftw_info)\n            if djbfft_info:\n                dict_append(info, **djbfft_info)\n            self.set_info(**info)\n            return\n\n\nclass fftw_info(system_info):\n        section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    notfounderror = FFTWNotFoundError\n    ver_info = [{\'name\':\'fftw3\',\n                    \'libs\':[\'fftw3\'],\n                    \'includes\':[\'fftw3.h\'],\n                    \'macros\':[(\'SCIPY_FFTW3_H\', None)]},\n                  {\'name\':\'fftw2\',\n                    \'libs\':[\'rfftw\', \'fftw\'],\n                    \'includes\':[\'fftw.h\', \'rfftw.h\'],\n                    \'macros\':[(\'SCIPY_FFTW_H\', None)]}]\n\n    def calc_ver_info(self, ver_param):\n        \n        lib_dirs = self.get_lib_dirs()\n        incl_dirs = self.get_include_dirs()\n        incl_dir = None\n        libs = self.get_libs(self.section + \'_libs\', ver_param[\'libs\'])\n        info = self.check_libs(lib_dirs, libs)\n        if info is not None:\n            flag = 0\n            for d in incl_dirs:\n                if len(self.combine_paths(d, ver_param[\'includes\'])) \\\n                   == len(ver_param[\'includes\']):\n                    dict_append(info, include_dirs=[d])\n                    flag = 1\n                    incl_dirs = [d]\n                    break\n            if flag:\n                dict_append(info, define_macros=ver_param[\'macros\'])\n            else:\n                info = None\n        if info is not None:\n            self.set_info(**info)\n            return True\n        else:\n            log.info(\'  %s not found\' % (ver_param[\'name\']))\n            return False\n\n    def calc_info(self):\n        for i in self.ver_info:\n            if self.calc_ver_info(i):\n                break\n\n\nclass fftw2_info(fftw_info):\n        section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    notfounderror = FFTWNotFoundError\n    ver_info = [{\'name\':\'fftw2\',\n                    \'libs\':[\'rfftw\', \'fftw\'],\n                    \'includes\':[\'fftw.h\', \'rfftw.h\'],\n                    \'macros\':[(\'SCIPY_FFTW_H\', None)]}\n                  ]\n\n\nclass fftw3_info(fftw_info):\n        section = \'fftw3\'\n    dir_env_var = \'FFTW3\'\n    notfounderror = FFTWNotFoundError\n    ver_info = [{\'name\':\'fftw3\',\n                    \'libs\':[\'fftw3\'],\n                    \'includes\':[\'fftw3.h\'],\n                    \'macros\':[(\'SCIPY_FFTW3_H\', None)]},\n                  ]\n\n\nclass dfftw_info(fftw_info):\n    section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    ver_info = [{\'name\':\'dfftw\',\n                    \'libs\':[\'drfftw\', \'dfftw\'],\n                    \'includes\':[\'dfftw.h\', \'drfftw.h\'],\n                    \'macros\':[(\'SCIPY_DFFTW_H\', None)]}]\n\n\nclass sfftw_info(fftw_info):\n    section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    ver_info = [{\'name\':\'sfftw\',\n                    \'libs\':[\'srfftw\', \'sfftw\'],\n                    \'includes\':[\'sfftw.h\', \'srfftw.h\'],\n                    \'macros\':[(\'SCIPY_SFFTW_H\', None)]}]\n\n\nclass fftw_threads_info(fftw_info):\n    section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    ver_info = [{\'name\':\'fftw threads\',\n                    \'libs\':[\'rfftw_threads\', \'fftw_threads\'],\n                    \'includes\':[\'fftw_threads.h\', \'rfftw_threads.h\'],\n                    \'macros\':[(\'SCIPY_FFTW_THREADS_H\', None)]}]\n\n\nclass dfftw_threads_info(fftw_info):\n    section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    ver_info = [{\'name\':\'dfftw threads\',\n                    \'libs\':[\'drfftw_threads\', \'dfftw_threads\'],\n                    \'includes\':[\'dfftw_threads.h\', \'drfftw_threads.h\'],\n                    \'macros\':[(\'SCIPY_DFFTW_THREADS_H\', None)]}]\n\n\nclass sfftw_threads_info(fftw_info):\n    section = \'fftw\'\n    dir_env_var = \'FFTW\'\n    ver_info = [{\'name\':\'sfftw threads\',\n                    \'libs\':[\'srfftw_threads\', \'sfftw_threads\'],\n                    \'includes\':[\'sfftw_threads.h\', \'srfftw_threads.h\'],\n                    \'macros\':[(\'SCIPY_SFFTW_THREADS_H\', None)]}]\n\n\nclass djbfft_info(system_info):\n    section = \'djbfft\'\n    dir_env_var = \'DJBFFT\'\n    notfounderror = DJBFFTNotFoundError\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend(self.combine_paths(d, [\'djbfft\']) + [d])\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        incl_dirs = self.get_include_dirs()\n        info = None\n        for d in lib_dirs:\n            p = self.combine_paths(d, [\'djbfft.a\'])\n            if p:\n                info = {\'extra_objects\': p}\n                break\n            p = self.combine_paths(d, [\'libdjbfft.a\', \'libdjbfft\' + so_ext])\n            if p:\n                info = {\'libraries\': [\'djbfft\'], \'library_dirs\': [d]}\n                break\n        if info is None:\n            return\n        for d in incl_dirs:\n            if len(self.combine_paths(d, [\'fftc8.h\', \'fftfreq.h\'])) == 2:\n                dict_append(info, include_dirs=[d],\n                            define_macros=[(\'SCIPY_DJBFFT_H\', None)])\n                self.set_info(**info)\n                return\n        return\n\n\nclass mkl_info(system_info):\n    section = \'mkl\'\n    dir_env_var = \'MKL\'\n    _lib_mkl = [\'mkl\', \'vml\', \'guide\']\n\n    def get_mkl_rootdir(self):\n        mklroot = os.environ.get(\'MKLROOT\', None)\n        if mklroot is not None:\n            return mklroot\n        paths = os.environ.get(\'LD_LIBRARY_PATH\', \'\').split(os.pathsep)\n        ld_so_conf = \'/etc/ld.so.conf\'\n        if os.path.isfile(ld_so_conf):\n            for d in open(ld_so_conf, \'r\'):\n                d = d.strip()\n                if d:\n                    paths.append(d)\n        intel_mkl_dirs = []\n        for path in paths:\n            path_atoms = path.split(os.sep)\n            for m in path_atoms:\n                if m.startswith(\'mkl\'):\n                    d = os.sep.join(path_atoms[:path_atoms.index(m) + 2])\n                    intel_mkl_dirs.append(d)\n                    break\n        for d in paths:\n            dirs = glob(os.path.join(d, \'mkl\', \'*\'))\n            dirs += glob(os.path.join(d, \'mkl*\'))\n            for d in dirs:\n                if os.path.isdir(os.path.join(d, \'lib\')):\n                    return d\n        return None\n\n    def __init__(self):\n        mklroot = self.get_mkl_rootdir()\n        if mklroot is None:\n            system_info.__init__(self)\n        else:\n            from .cpuinfo import cpu\n            l = \'mkl\'              if cpu.is_Itanium():\n                plt = \'64\'\n                            elif cpu.is_Xeon():\n                plt = \'intel64\'\n                            else:\n                plt = \'32\'\n                            if l not in self._lib_mkl:\n                self._lib_mkl.insert(0, l)\n            system_info.__init__(\n                self,\n                default_lib_dirs=[os.path.join(mklroot, \'lib\', plt)],\n                default_include_dirs=[os.path.join(mklroot, \'include\')])\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        incl_dirs = self.get_include_dirs()\n        mkl_libs = self.get_libs(\'mkl_libs\', self._lib_mkl)\n        info = self.check_libs2(lib_dirs, mkl_libs)\n        if info is None:\n            return\n        dict_append(info,\n                    define_macros=[(\'SCIPY_MKL_H\', None),\n                                   (\'HAVE_CBLAS\', None)],\n                    include_dirs=incl_dirs)\n        if sys.platform == \'win32\':\n            pass          else:\n            dict_append(info, libraries=[\'pthread\'])\n        self.set_info(**info)\n\n\nclass lapack_mkl_info(mkl_info):\n\n    def calc_info(self):\n        mkl = get_info(\'mkl\')\n        if not mkl:\n            return\n        if sys.platform == \'win32\':\n            lapack_libs = self.get_libs(\'lapack_libs\', [\'mkl_lapack\'])\n        else:\n            lapack_libs = self.get_libs(\'lapack_libs\',\n                                        [\'mkl_lapack32\', \'mkl_lapack64\'])\n\n        info = {\'libraries\': lapack_libs}\n        dict_append(info, **mkl)\n        self.set_info(**info)\n\n\nclass blas_mkl_info(mkl_info):\n    pass\n\n\nclass atlas_info(system_info):\n    section = \'atlas\'\n    dir_env_var = \'ATLAS\'\n    _lib_names = [\'f77blas\', \'cblas\']\n    if sys.platform[:7] == \'freebsd\':\n        _lib_atlas = [\'atlas_r\']\n        _lib_lapack = [\'alapack_r\']\n    else:\n        _lib_atlas = [\'atlas\']\n        _lib_lapack = [\'lapack\']\n\n    notfounderror = AtlasNotFoundError\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend(self.combine_paths(d, [\'atlas*\', \'ATLAS*\',\n                                         \'sse\', \'3dnow\', \'sse2\']) + [d])\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        info = {}\n        atlas_libs = self.get_libs(\'atlas_libs\',\n                                   self._lib_names + self._lib_atlas)\n        lapack_libs = self.get_libs(\'lapack_libs\', self._lib_lapack)\n        atlas = None\n        lapack = None\n        atlas_1 = None\n        for d in lib_dirs:\n            atlas = self.check_libs2(d, atlas_libs, [])\n            lapack_atlas = self.check_libs2(d, [\'lapack_atlas\'], [])\n            if atlas is not None:\n                lib_dirs2 = [d] + self.combine_paths(d, [\'atlas*\', \'ATLAS*\'])\n                lapack = self.check_libs2(lib_dirs2, lapack_libs, [])\n                if lapack is not None:\n                    break\n            if atlas:\n                atlas_1 = atlas\n        log.info(self.__class__)\n        if atlas is None:\n            atlas = atlas_1\n        if atlas is None:\n            return\n        include_dirs = self.get_include_dirs()\n        h = (self.combine_paths(lib_dirs + include_dirs, \'cblas.h\') or [None])\n        h = h[0]\n        if h:\n            h = os.path.dirname(h)\n            dict_append(info, include_dirs=[h])\n        info[\'language\'] = \'c\'\n        if lapack is not None:\n            dict_append(info, **lapack)\n            dict_append(info, **atlas)\n        elif \'lapack_atlas\' in atlas[\'libraries\']:\n            dict_append(info, **atlas)\n            dict_append(info,\n                        define_macros=[(\'ATLAS_WITH_LAPACK_ATLAS\', None)])\n            self.set_info(**info)\n            return\n        else:\n            dict_append(info, **atlas)\n            dict_append(info, define_macros=[(\'ATLAS_WITHOUT_LAPACK\', None)])\n            message = \n            warnings.warn(message)\n            self.set_info(**info)\n            return\n\n                lapack_dir = lapack[\'library_dirs\'][0]\n        lapack_name = lapack[\'libraries\'][0]\n        lapack_lib = None\n        lib_prefixes = [\'lib\']\n        if sys.platform == \'win32\':\n            lib_prefixes.append(\'\')\n        for e in self.library_extensions():\n            for prefix in lib_prefixes:\n                fn = os.path.join(lapack_dir, prefix + lapack_name + e)\n                if os.path.exists(fn):\n                    lapack_lib = fn\n                    break\n            if lapack_lib:\n                break\n        if lapack_lib is not None:\n            sz = os.stat(lapack_lib)[6]\n            if sz <= 4000 * 1024:\n                message =  % (lapack_lib, sz / 1024)\n                warnings.warn(message)\n            else:\n                info[\'language\'] = \'f77\'\n\n        atlas_version, atlas_extra_info = get_atlas_version(**atlas)\n        dict_append(info, **atlas_extra_info)\n\n        self.set_info(**info)\n\n\nclass atlas_blas_info(atlas_info):\n    _lib_names = [\'f77blas\', \'cblas\']\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        info = {}\n        atlas_libs = self.get_libs(\'atlas_libs\',\n                                   self._lib_names + self._lib_atlas)\n        atlas = self.check_libs2(lib_dirs, atlas_libs, [])\n        if atlas is None:\n            return\n        include_dirs = self.get_include_dirs()\n        h = (self.combine_paths(lib_dirs + include_dirs, \'cblas.h\') or [None])\n        h = h[0]\n        if h:\n            h = os.path.dirname(h)\n            dict_append(info, include_dirs=[h])\n        info[\'language\'] = \'c\'\n        info[\'define_macros\'] = [(\'HAVE_CBLAS\', None)]\n\n        atlas_version, atlas_extra_info = get_atlas_version(**atlas)\n        dict_append(atlas, **atlas_extra_info)\n\n        dict_append(info, **atlas)\n\n        self.set_info(**info)\n        return\n\n\nclass atlas_threads_info(atlas_info):\n    dir_env_var = [\'PTATLAS\', \'ATLAS\']\n    _lib_names = [\'ptf77blas\', \'ptcblas\']\n\n\nclass atlas_blas_threads_info(atlas_blas_info):\n    dir_env_var = [\'PTATLAS\', \'ATLAS\']\n    _lib_names = [\'ptf77blas\', \'ptcblas\']\n\n\nclass lapack_atlas_info(atlas_info):\n    _lib_names = [\'lapack_atlas\'] + atlas_info._lib_names\n\n\nclass lapack_atlas_threads_info(atlas_threads_info):\n    _lib_names = [\'lapack_atlas\'] + atlas_threads_info._lib_names\n\n\nclass atlas_3_10_info(atlas_info):\n    _lib_names = [\'satlas\']\n    _lib_atlas = _lib_names\n    _lib_lapack = _lib_names\n\n\nclass atlas_3_10_blas_info(atlas_3_10_info):\n    _lib_names = [\'satlas\']\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        info = {}\n        atlas_libs = self.get_libs(\'atlas_libs\',\n                                   self._lib_names)\n        atlas = self.check_libs2(lib_dirs, atlas_libs, [])\n        if atlas is None:\n            return\n        include_dirs = self.get_include_dirs()\n        h = (self.combine_paths(lib_dirs + include_dirs, \'cblas.h\') or [None])\n        h = h[0]\n        if h:\n            h = os.path.dirname(h)\n            dict_append(info, include_dirs=[h])\n        info[\'language\'] = \'c\'\n        info[\'define_macros\'] = [(\'HAVE_CBLAS\', None)]\n\n        atlas_version, atlas_extra_info = get_atlas_version(**atlas)\n        dict_append(atlas, **atlas_extra_info)\n\n        dict_append(info, **atlas)\n\n        self.set_info(**info)\n        return\n\n\nclass atlas_3_10_threads_info(atlas_3_10_info):\n    dir_env_var = [\'PTATLAS\', \'ATLAS\']\n    _lib_names = [\'tatlas\']\n                _lib_atlas = _lib_names\n    _lib_lapack = _lib_names\n\n\nclass atlas_3_10_blas_threads_info(atlas_3_10_blas_info):\n    dir_env_var = [\'PTATLAS\', \'ATLAS\']\n    _lib_names = [\'tatlas\']\n\n\nclass lapack_atlas_3_10_info(atlas_3_10_info):\n    pass\n\n\nclass lapack_atlas_3_10_threads_info(atlas_3_10_threads_info):\n    pass\n\n\nclass lapack_info(system_info):\n    section = \'lapack\'\n    dir_env_var = \'LAPACK\'\n    _lib_names = [\'lapack\']\n    notfounderror = LapackNotFoundError\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n\n        lapack_libs = self.get_libs(\'lapack_libs\', self._lib_names)\n        info = self.check_libs(lib_dirs, lapack_libs, [])\n        if info is None:\n            return\n        info[\'language\'] = \'f77\'\n        self.set_info(**info)\n\n\nclass lapack_src_info(system_info):\n    section = \'lapack_src\'\n    dir_env_var = \'LAPACK_SRC\'\n    notfounderror = LapackSrcNotFoundError\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend([d] + self.combine_paths(d, [\'LAPACK*/SRC\', \'SRC\']))\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        src_dirs = self.get_src_dirs()\n        src_dir = \'\'\n        for d in src_dirs:\n            if os.path.isfile(os.path.join(d, \'dgesv.f\')):\n                src_dir = d\n                break\n        if not src_dir:\n                        return\n                                allaux =           laux =           lasrc =           sd_lasrc =           cz_lasrc =                   sclaux = laux + \' econd \'                          dzlaux = laux + \' secnd \'                          slasrc = lasrc + sd_lasrc                          dlasrc = lasrc + sd_lasrc                          clasrc = lasrc + cz_lasrc + \' srot srscl \'          zlasrc = lasrc + cz_lasrc + \' drot drscl \'          oclasrc = \' icmax1 scsum1 \'                        ozlasrc = \' izmax1 dzsum1 \'                        sources = [\'s%s.f\' % f for f in (sclaux + slasrc).split()] \\\n                  + [\'d%s.f\' % f for f in (dzlaux + dlasrc).split()] \\\n                  + [\'c%s.f\' % f for f in (clasrc).split()] \\\n                  + [\'z%s.f\' % f for f in (zlasrc).split()] \\\n                  + [\'%s.f\' % f for f in (allaux + oclasrc + ozlasrc).split()]\n        sources = [os.path.join(src_dir, f) for f in sources]\n                src_dir2 = os.path.join(src_dir, \'..\', \'INSTALL\')\n        sources += [os.path.join(src_dir2, p + \'lamch.f\') for p in \'sdcz\']\n                sources += [os.path.join(src_dir, p + \'larfp.f\') for p in \'sdcz\']\n        sources += [os.path.join(src_dir, \'ila\' + p + \'lr.f\') for p in \'sdcz\']\n        sources += [os.path.join(src_dir, \'ila\' + p + \'lc.f\') for p in \'sdcz\']\n                                sources = [f for f in sources if os.path.isfile(f)]\n        info = {\'sources\': sources, \'language\': \'f77\'}\n        self.set_info(**info)\n\natlas_version_c_text = r\n\n_cached_atlas_version = {}\n\n\ndef get_atlas_version(**config):\n    libraries = config.get(\'libraries\', [])\n    library_dirs = config.get(\'library_dirs\', [])\n    key = (tuple(libraries), tuple(library_dirs))\n    if key in _cached_atlas_version:\n        return _cached_atlas_version[key]\n    c = cmd_config(Distribution())\n    atlas_version = None\n    info = {}\n    try:\n        s, o = c.get_output(atlas_version_c_text,\n                            libraries=libraries, library_dirs=library_dirs,\n                            use_tee=(system_info.verbosity > 0))\n        if s and re.search(r\'undefined reference to `_gfortran\', o, re.M):\n            s, o = c.get_output(atlas_version_c_text,\n                                libraries=libraries + [\'gfortran\'],\n                                library_dirs=library_dirs,\n                                use_tee=(system_info.verbosity > 0))\n            if not s:\n                warnings.warn()\n                dict_append(info, language=\'f90\',\n                            define_macros=[(\'ATLAS_REQUIRES_GFORTRAN\', None)])\n    except Exception:                  for o in library_dirs:\n            m = re.search(r\'ATLAS_(?P<version>\\d+[.]\\d+[.]\\d+)_\', o)\n            if m:\n                atlas_version = m.group(\'version\')\n            if atlas_version is not None:\n                break\n\n                        if atlas_version is None:\n            atlas_version = os.environ.get(\'ATLAS_VERSION\', None)\n        if atlas_version:\n            dict_append(info, define_macros=[(\n                \'ATLAS_INFO\', \'"\\\\"%s\\\\""\' % atlas_version)\n            ])\n        else:\n            dict_append(info, define_macros=[(\'NO_ATLAS_INFO\', -1)])\n        return atlas_version or \'?.?.?\', info\n\n    if not s:\n        m = re.search(r\'ATLAS version (?P<version>\\d+[.]\\d+[.]\\d+)\', o)\n        if m:\n            atlas_version = m.group(\'version\')\n    if atlas_version is None:\n        if re.search(r\'undefined symbol: ATL_buildinfo\', o, re.M):\n            atlas_version = \'3.2.1_pre3.3.6\'\n        else:\n            log.info(\'Status: %d\', s)\n            log.info(\'Output: %s\', o)\n\n    if atlas_version == \'3.2.1_pre3.3.6\':\n        dict_append(info, define_macros=[(\'NO_ATLAS_INFO\', -2)])\n    else:\n        dict_append(info, define_macros=[(\n            \'ATLAS_INFO\', \'"\\\\"%s\\\\""\' % atlas_version)\n        ])\n    result = _cached_atlas_version[key] = atlas_version, info\n    return result\n\n\nclass lapack_opt_info(system_info):\n\n    notfounderror = LapackNotFoundError\n\n    def calc_info(self):\n\n        openblas_info = get_info(\'openblas_lapack\')\n        if openblas_info:\n            self.set_info(**openblas_info)\n            return\n\n        lapack_mkl_info = get_info(\'lapack_mkl\')\n        if lapack_mkl_info:\n            self.set_info(**lapack_mkl_info)\n            return\n\n        atlas_info = get_info(\'atlas_3_10_threads\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas_3_10\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas_threads\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas\')\n\n        if sys.platform == \'darwin\' and not atlas_info:\n                        args = []\n            link_args = []\n            if get_platform()[-4:] == \'i386\' or \'intel\' in get_platform() or \\\n               \'x86_64\' in get_platform() or \\\n               \'i386\' in platform.platform():\n                intel = 1\n            else:\n                intel = 0\n            if os.path.exists(\'/System/Library/Frameworks\'\n                              \'/Accelerate.framework/\'):\n                if intel:\n                    args.extend([\'-msse3\'])\n                else:\n                    args.extend([\'-faltivec\'])\n                link_args.extend([\'-Wl,-framework\', \'-Wl,Accelerate\'])\n            elif os.path.exists(\'/System/Library/Frameworks\'\n                                \'/vecLib.framework/\'):\n                if intel:\n                    args.extend([\'-msse3\'])\n                else:\n                    args.extend([\'-faltivec\'])\n                link_args.extend([\'-Wl,-framework\', \'-Wl,vecLib\'])\n            if args:\n                self.set_info(extra_compile_args=args,\n                              extra_link_args=link_args,\n                              define_macros=[(\'NO_ATLAS_INFO\', 3),\n                                             (\'HAVE_CBLAS\', None)])\n                return\n\n                need_lapack = 0\n        need_blas = 0\n        info = {}\n        if atlas_info:\n            l = atlas_info.get(\'define_macros\', [])\n            if (\'ATLAS_WITH_LAPACK_ATLAS\', None) in l \\\n                   or (\'ATLAS_WITHOUT_LAPACK\', None) in l:\n                need_lapack = 1\n            info = atlas_info\n\n        else:\n            warnings.warn(AtlasNotFoundError.__doc__)\n            need_blas = 1\n            need_lapack = 1\n            dict_append(info, define_macros=[(\'NO_ATLAS_INFO\', 1)])\n\n        if need_lapack:\n            lapack_info = get_info(\'lapack\')\n                        if lapack_info:\n                dict_append(info, **lapack_info)\n            else:\n                warnings.warn(LapackNotFoundError.__doc__)\n                lapack_src_info = get_info(\'lapack_src\')\n                if not lapack_src_info:\n                    warnings.warn(LapackSrcNotFoundError.__doc__)\n                    return\n                dict_append(info, libraries=[(\'flapack_src\', lapack_src_info)])\n\n        if need_blas:\n            blas_info = get_info(\'blas\')\n                        if blas_info:\n                dict_append(info, **blas_info)\n            else:\n                warnings.warn(BlasNotFoundError.__doc__)\n                blas_src_info = get_info(\'blas_src\')\n                if not blas_src_info:\n                    warnings.warn(BlasSrcNotFoundError.__doc__)\n                    return\n                dict_append(info, libraries=[(\'fblas_src\', blas_src_info)])\n\n        self.set_info(**info)\n        return\n\n\nclass blas_opt_info(system_info):\n\n    notfounderror = BlasNotFoundError\n\n    def calc_info(self):\n\n        blas_mkl_info = get_info(\'blas_mkl\')\n        if blas_mkl_info:\n            self.set_info(**blas_mkl_info)\n            return\n\n        openblas_info = get_info(\'openblas\')\n        if openblas_info:\n            self.set_info(**openblas_info)\n            return\n\n        atlas_info = get_info(\'atlas_3_10_blas_threads\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas_3_10_blas\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas_blas_threads\')\n        if not atlas_info:\n            atlas_info = get_info(\'atlas_blas\')\n\n        if sys.platform == \'darwin\' and not atlas_info:\n                        args = []\n            link_args = []\n            if get_platform()[-4:] == \'i386\' or \'intel\' in get_platform() or \\\n               \'x86_64\' in get_platform() or \\\n               \'i386\' in platform.platform():\n                intel = 1\n            else:\n                intel = 0\n            if os.path.exists(\'/System/Library/Frameworks\'\n                              \'/Accelerate.framework/\'):\n                if intel:\n                    args.extend([\'-msse3\'])\n                else:\n                    args.extend([\'-faltivec\'])\n                args.extend([\n                    \'-I/System/Library/Frameworks/vecLib.framework/Headers\'])\n                link_args.extend([\'-Wl,-framework\', \'-Wl,Accelerate\'])\n            elif os.path.exists(\'/System/Library/Frameworks\'\n                                \'/vecLib.framework/\'):\n                if intel:\n                    args.extend([\'-msse3\'])\n                else:\n                    args.extend([\'-faltivec\'])\n                args.extend([\n                    \'-I/System/Library/Frameworks/vecLib.framework/Headers\'])\n                link_args.extend([\'-Wl,-framework\', \'-Wl,vecLib\'])\n            if args:\n                self.set_info(extra_compile_args=args,\n                              extra_link_args=link_args,\n                              define_macros=[(\'NO_ATLAS_INFO\', 3),\n                                             (\'HAVE_CBLAS\', None)])\n                return\n\n        need_blas = 0\n        info = {}\n        if atlas_info:\n            info = atlas_info\n        else:\n            warnings.warn(AtlasNotFoundError.__doc__)\n            need_blas = 1\n            dict_append(info, define_macros=[(\'NO_ATLAS_INFO\', 1)])\n\n        if need_blas:\n            blas_info = get_info(\'blas\')\n            if blas_info:\n                dict_append(info, **blas_info)\n            else:\n                warnings.warn(BlasNotFoundError.__doc__)\n                blas_src_info = get_info(\'blas_src\')\n                if not blas_src_info:\n                    warnings.warn(BlasSrcNotFoundError.__doc__)\n                    return\n                dict_append(info, libraries=[(\'fblas_src\', blas_src_info)])\n\n        self.set_info(**info)\n        return\n\n\nclass blas_info(system_info):\n    section = \'blas\'\n    dir_env_var = \'BLAS\'\n    _lib_names = [\'blas\']\n    notfounderror = BlasNotFoundError\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n        blas_libs = self.get_libs(\'blas_libs\', self._lib_names)\n        info = self.check_libs(lib_dirs, blas_libs, [])\n        if info is None:\n            return\n        info[\'language\'] = \'f77\'          self.set_info(**info)\n\n\nclass openblas_info(blas_info):\n    section = \'openblas\'\n    dir_env_var = \'OPENBLAS\'\n    _lib_names = [\'openblas\']\n    notfounderror = BlasNotFoundError\n\n    def check_embedded_lapack(self, info):\n        return True\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n\n        openblas_libs = self.get_libs(\'libraries\', self._lib_names)\n        if openblas_libs == self._lib_names:             openblas_libs = self.get_libs(\'openblas_libs\', self._lib_names)\n        info = self.check_libs(lib_dirs, openblas_libs, [])\n        if info is None:\n            return\n\n                extra_info = self.calc_extra_info()\n        dict_append(info, **extra_info)\n\n        if not self.check_embedded_lapack(info):\n            return\n\n        info[\'language\'] = \'c\'\n        info[\'define_macros\'] = [(\'HAVE_CBLAS\', None)]\n        self.set_info(**info)\n\n\nclass openblas_lapack_info(openblas_info):\n    section = \'openblas\'\n    dir_env_var = \'OPENBLAS\'\n    _lib_names = [\'openblas\']\n    notfounderror = BlasNotFoundError\n\n    def check_embedded_lapack(self, info):\n        res = False\n        c = distutils.ccompiler.new_compiler()\n        tmpdir = tempfile.mkdtemp()\n        s = \n        src = os.path.join(tmpdir, \'source.c\')\n        out = os.path.join(tmpdir, \'a.out\')\n                try:\n            extra_args = info[\'extra_link_args\']\n        except:\n            extra_args = []\n        try:\n            with open(src, \'wt\') as f:\n                f.write(s)\n            obj = c.compile([src], output_dir=tmpdir)\n            try:\n                c.link_executable(obj, out, libraries=info[\'libraries\'],\n                                  library_dirs=info[\'library_dirs\'],\n                                  extra_postargs=extra_args)\n                res = True\n            except distutils.ccompiler.LinkError:\n                res = False\n        finally:\n            shutil.rmtree(tmpdir)\n        return res\n\n\nclass blas_src_info(system_info):\n    section = \'blas_src\'\n    dir_env_var = \'BLAS_SRC\'\n    notfounderror = BlasSrcNotFoundError\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend([d] + self.combine_paths(d, [\'blas\']))\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        src_dirs = self.get_src_dirs()\n        src_dir = \'\'\n        for d in src_dirs:\n            if os.path.isfile(os.path.join(d, \'daxpy.f\')):\n                src_dir = d\n                break\n        if not src_dir:\n                        return\n        blas1 = \n        blas2 = \n        blas3 = \n        sources = [os.path.join(src_dir, f + \'.f\') \\\n                   for f in (blas1 + blas2 + blas3).split()]\n                sources = [f for f in sources if os.path.isfile(f)]\n        info = {\'sources\': sources, \'language\': \'f77\'}\n        self.set_info(**info)\n\n\nclass x11_info(system_info):\n    section = \'x11\'\n    notfounderror = X11NotFoundError\n\n    def __init__(self):\n        system_info.__init__(self,\n                             default_lib_dirs=default_x11_lib_dirs,\n                             default_include_dirs=default_x11_include_dirs)\n\n    def calc_info(self):\n        if sys.platform  in [\'win32\']:\n            return\n        lib_dirs = self.get_lib_dirs()\n        include_dirs = self.get_include_dirs()\n        x11_libs = self.get_libs(\'x11_libs\', [\'X11\'])\n        info = self.check_libs(lib_dirs, x11_libs, [])\n        if info is None:\n            return\n        inc_dir = None\n        for d in include_dirs:\n            if self.combine_paths(d, \'X11/X.h\'):\n                inc_dir = d\n                break\n        if inc_dir is not None:\n            dict_append(info, include_dirs=[inc_dir])\n        self.set_info(**info)\n\n\nclass _numpy_info(system_info):\n    section = \'Numeric\'\n    modulename = \'Numeric\'\n    notfounderror = NumericNotFoundError\n\n    def __init__(self):\n        include_dirs = []\n        try:\n            module = __import__(self.modulename)\n            prefix = []\n            for name in module.__file__.split(os.sep):\n                if name == \'lib\':\n                    break\n                prefix.append(name)\n\n                                    try:\n                include_dirs.append(getattr(module, \'get_include\')())\n            except AttributeError:\n                pass\n\n            include_dirs.append(distutils.sysconfig.get_python_inc(\n                                        prefix=os.sep.join(prefix)))\n        except ImportError:\n            pass\n        py_incl_dir = distutils.sysconfig.get_python_inc()\n        include_dirs.append(py_incl_dir)\n        py_pincl_dir = distutils.sysconfig.get_python_inc(plat_specific=True)\n        if py_pincl_dir not in include_dirs:\n            include_dirs.append(py_pincl_dir)\n        for d in default_include_dirs:\n            d = os.path.join(d, os.path.basename(py_incl_dir))\n            if d not in include_dirs:\n                include_dirs.append(d)\n        system_info.__init__(self,\n                             default_lib_dirs=[],\n                             default_include_dirs=include_dirs)\n\n    def calc_info(self):\n        try:\n            module = __import__(self.modulename)\n        except ImportError:\n            return\n        info = {}\n        macros = []\n        for v in [\'__version__\', \'version\']:\n            vrs = getattr(module, v, None)\n            if vrs is None:\n                continue\n            macros = [(self.modulename.upper() + \'_VERSION\',\n                      \'"\\\\"%s\\\\""\' % (vrs)),\n                      (self.modulename.upper(), None)]\n            break\n        dict_append(info, define_macros=macros)\n        include_dirs = self.get_include_dirs()\n        inc_dir = None\n        for d in include_dirs:\n            if self.combine_paths(d,\n                                  os.path.join(self.modulename,\n                                               \'arrayobject.h\')):\n                inc_dir = d\n                break\n        if inc_dir is not None:\n            dict_append(info, include_dirs=[inc_dir])\n        if info:\n            self.set_info(**info)\n        return\n\n\nclass numarray_info(_numpy_info):\n    section = \'numarray\'\n    modulename = \'numarray\'\n\n\nclass Numeric_info(_numpy_info):\n    section = \'Numeric\'\n    modulename = \'Numeric\'\n\n\nclass numpy_info(_numpy_info):\n    section = \'numpy\'\n    modulename = \'numpy\'\n\n\nclass numerix_info(system_info):\n    section = \'numerix\'\n\n    def calc_info(self):\n        which = None, None\n        if os.getenv("NUMERIX"):\n            which = os.getenv("NUMERIX"), "environment var"\n                if which[0] is None:\n            which = "numpy", "defaulted"\n            try:\n                import numpy\n                which = "numpy", "defaulted"\n            except ImportError:\n                msg1 = str(get_exception())\n                try:\n                    import Numeric\n                    which = "numeric", "defaulted"\n                except ImportError:\n                    msg2 = str(get_exception())\n                    try:\n                        import numarray\n                        which = "numarray", "defaulted"\n                    except ImportError:\n                        msg3 = str(get_exception())\n                        log.info(msg1)\n                        log.info(msg2)\n                        log.info(msg3)\n        which = which[0].strip().lower(), which[1]\n        if which[0] not in ["numeric", "numarray", "numpy"]:\n            raise ValueError("numerix selector must be either \'Numeric\' "\n                             "or \'numarray\' or \'numpy\' but the value obtained"\n                             " from the %s was \'%s\'." % (which[1], which[0]))\n        os.environ[\'NUMERIX\'] = which[0]\n        self.set_info(**get_info(which[0]))\n\n\nclass f2py_info(system_info):\n    def calc_info(self):\n        try:\n            import numpy.f2py as f2py\n        except ImportError:\n            return\n        f2py_dir = os.path.join(os.path.dirname(f2py.__file__), \'src\')\n        self.set_info(sources=[os.path.join(f2py_dir, \'fortranobject.c\')],\n                      include_dirs=[f2py_dir])\n        return\n\n\nclass boost_python_info(system_info):\n    section = \'boost_python\'\n    dir_env_var = \'BOOST\'\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend([d] + self.combine_paths(d, [\'boost*\']))\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        src_dirs = self.get_src_dirs()\n        src_dir = \'\'\n        for d in src_dirs:\n            if os.path.isfile(os.path.join(d, \'libs\', \'python\', \'src\',\n                                           \'module.cpp\')):\n                src_dir = d\n                break\n        if not src_dir:\n            return\n        py_incl_dirs = [distutils.sysconfig.get_python_inc()]\n        py_pincl_dir = distutils.sysconfig.get_python_inc(plat_specific=True)\n        if py_pincl_dir not in py_incl_dirs:\n            py_incl_dirs.append(py_pincl_dir)\n        srcs_dir = os.path.join(src_dir, \'libs\', \'python\', \'src\')\n        bpl_srcs = glob(os.path.join(srcs_dir, \'*.cpp\'))\n        bpl_srcs += glob(os.path.join(srcs_dir, \'*\', \'*.cpp\'))\n        info = {\'libraries\': [(\'boost_python_src\',\n                               {\'include_dirs\': [src_dir] + py_incl_dirs,\n                                \'sources\':bpl_srcs}\n                              )],\n                \'include_dirs\': [src_dir],\n                }\n        if info:\n            self.set_info(**info)\n        return\n\n\nclass agg2_info(system_info):\n    section = \'agg2\'\n    dir_env_var = \'AGG2\'\n\n    def get_paths(self, section, key):\n        pre_dirs = system_info.get_paths(self, section, key)\n        dirs = []\n        for d in pre_dirs:\n            dirs.extend([d] + self.combine_paths(d, [\'agg2*\']))\n        return [d for d in dirs if os.path.isdir(d)]\n\n    def calc_info(self):\n        src_dirs = self.get_src_dirs()\n        src_dir = \'\'\n        for d in src_dirs:\n            if os.path.isfile(os.path.join(d, \'src\', \'agg_affine_matrix.cpp\')):\n                src_dir = d\n                break\n        if not src_dir:\n            return\n        if sys.platform == \'win32\':\n            agg2_srcs = glob(os.path.join(src_dir, \'src\', \'platform\',\n                                          \'win32\', \'agg_win32_bmp.cpp\'))\n        else:\n            agg2_srcs = glob(os.path.join(src_dir, \'src\', \'*.cpp\'))\n            agg2_srcs += [os.path.join(src_dir, \'src\', \'platform\',\n                                       \'X11\',\n                                       \'agg_platform_support.cpp\')]\n\n        info = {\'libraries\':\n                [(\'agg2_src\',\n                  {\'sources\': agg2_srcs,\n                   \'include_dirs\': [os.path.join(src_dir, \'include\')],\n                  }\n                 )],\n                \'include_dirs\': [os.path.join(src_dir, \'include\')],\n                }\n        if info:\n            self.set_info(**info)\n        return\n\n\nclass _pkg_config_info(system_info):\n    section = None\n    config_env_var = \'PKG_CONFIG\'\n    default_config_exe = \'pkg-config\'\n    append_config_exe = \'\'\n    version_macro_name = None\n    release_macro_name = None\n    version_flag = \'--modversion\'\n    cflags_flag = \'--cflags\'\n\n    def get_config_exe(self):\n        if self.config_env_var in os.environ:\n            return os.environ[self.config_env_var]\n        return self.default_config_exe\n\n    def get_config_output(self, config_exe, option):\n        cmd = config_exe + \' \' + self.append_config_exe + \' \' + option\n        s, o = exec_command(cmd, use_tee=0)\n        if not s:\n            return o\n\n    def calc_info(self):\n        config_exe = find_executable(self.get_config_exe())\n        if not config_exe:\n            log.warn(\'File not found: %s. Cannot determine %s info.\' \\\n                  % (config_exe, self.section))\n            return\n        info = {}\n        macros = []\n        libraries = []\n        library_dirs = []\n        include_dirs = []\n        extra_link_args = []\n        extra_compile_args = []\n        version = self.get_config_output(config_exe, self.version_flag)\n        if version:\n            macros.append((self.__class__.__name__.split(\'.\')[-1].upper(),\n                           \'"\\\\"%s\\\\""\' % (version)))\n            if self.version_macro_name:\n                macros.append((self.version_macro_name + \'_%s\'\n                               % (version.replace(\'.\', \'_\')), None))\n        if self.release_macro_name:\n            release = self.get_config_output(config_exe, \'--release\')\n            if release:\n                macros.append((self.release_macro_name + \'_%s\'\n                               % (release.replace(\'.\', \'_\')), None))\n        opts = self.get_config_output(config_exe, \'--libs\')\n        if opts:\n            for opt in opts.split():\n                if opt[:2] == \'-l\':\n                    libraries.append(opt[2:])\n                elif opt[:2] == \'-L\':\n                    library_dirs.append(opt[2:])\n                else:\n                    extra_link_args.append(opt)\n        opts = self.get_config_output(config_exe, self.cflags_flag)\n        if opts:\n            for opt in opts.split():\n                if opt[:2] == \'-I\':\n                    include_dirs.append(opt[2:])\n                elif opt[:2] == \'-D\':\n                    if \'=\' in opt:\n                        n, v = opt[2:].split(\'=\')\n                        macros.append((n, v))\n                    else:\n                        macros.append((opt[2:], None))\n                else:\n                    extra_compile_args.append(opt)\n        if macros:\n            dict_append(info, define_macros=macros)\n        if libraries:\n            dict_append(info, libraries=libraries)\n        if library_dirs:\n            dict_append(info, library_dirs=library_dirs)\n        if include_dirs:\n            dict_append(info, include_dirs=include_dirs)\n        if extra_link_args:\n            dict_append(info, extra_link_args=extra_link_args)\n        if extra_compile_args:\n            dict_append(info, extra_compile_args=extra_compile_args)\n        if info:\n            self.set_info(**info)\n        return\n\n\nclass wx_info(_pkg_config_info):\n    section = \'wx\'\n    config_env_var = \'WX_CONFIG\'\n    default_config_exe = \'wx-config\'\n    append_config_exe = \'\'\n    version_macro_name = \'WX_VERSION\'\n    release_macro_name = \'WX_RELEASE\'\n    version_flag = \'--version\'\n    cflags_flag = \'--cxxflags\'\n\n\nclass gdk_pixbuf_xlib_2_info(_pkg_config_info):\n    section = \'gdk_pixbuf_xlib_2\'\n    append_config_exe = \'gdk-pixbuf-xlib-2.0\'\n    version_macro_name = \'GDK_PIXBUF_XLIB_VERSION\'\n\n\nclass gdk_pixbuf_2_info(_pkg_config_info):\n    section = \'gdk_pixbuf_2\'\n    append_config_exe = \'gdk-pixbuf-2.0\'\n    version_macro_name = \'GDK_PIXBUF_VERSION\'\n\n\nclass gdk_x11_2_info(_pkg_config_info):\n    section = \'gdk_x11_2\'\n    append_config_exe = \'gdk-x11-2.0\'\n    version_macro_name = \'GDK_X11_VERSION\'\n\n\nclass gdk_2_info(_pkg_config_info):\n    section = \'gdk_2\'\n    append_config_exe = \'gdk-2.0\'\n    version_macro_name = \'GDK_VERSION\'\n\n\nclass gdk_info(_pkg_config_info):\n    section = \'gdk\'\n    append_config_exe = \'gdk\'\n    version_macro_name = \'GDK_VERSION\'\n\n\nclass gtkp_x11_2_info(_pkg_config_info):\n    section = \'gtkp_x11_2\'\n    append_config_exe = \'gtk+-x11-2.0\'\n    version_macro_name = \'GTK_X11_VERSION\'\n\n\nclass gtkp_2_info(_pkg_config_info):\n    section = \'gtkp_2\'\n    append_config_exe = \'gtk+-2.0\'\n    version_macro_name = \'GTK_VERSION\'\n\n\nclass xft_info(_pkg_config_info):\n    section = \'xft\'\n    append_config_exe = \'xft\'\n    version_macro_name = \'XFT_VERSION\'\n\n\nclass freetype2_info(_pkg_config_info):\n    section = \'freetype2\'\n    append_config_exe = \'freetype2\'\n    version_macro_name = \'FREETYPE2_VERSION\'\n\n\nclass amd_info(system_info):\n    section = \'amd\'\n    dir_env_var = \'AMD\'\n    _lib_names = [\'amd\']\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n\n        amd_libs = self.get_libs(\'amd_libs\', self._lib_names)\n        info = self.check_libs(lib_dirs, amd_libs, [])\n        if info is None:\n            return\n\n        include_dirs = self.get_include_dirs()\n\n        inc_dir = None\n        for d in include_dirs:\n            p = self.combine_paths(d, \'amd.h\')\n            if p:\n                inc_dir = os.path.dirname(p[0])\n                break\n        if inc_dir is not None:\n            dict_append(info, include_dirs=[inc_dir],\n                        define_macros=[(\'SCIPY_AMD_H\', None)],\n                        swig_opts=[\'-I\' + inc_dir])\n\n        self.set_info(**info)\n        return\n\n\nclass umfpack_info(system_info):\n    section = \'umfpack\'\n    dir_env_var = \'UMFPACK\'\n    notfounderror = UmfpackNotFoundError\n    _lib_names = [\'umfpack\']\n\n    def calc_info(self):\n        lib_dirs = self.get_lib_dirs()\n\n        umfpack_libs = self.get_libs(\'umfpack_libs\', self._lib_names)\n        info = self.check_libs(lib_dirs, umfpack_libs, [])\n        if info is None:\n            return\n\n        include_dirs = self.get_include_dirs()\n\n        inc_dir = None\n        for d in include_dirs:\n            p = self.combine_paths(d, [\'\', \'umfpack\'], \'umfpack.h\')\n            if p:\n                inc_dir = os.path.dirname(p[0])\n                break\n        if inc_dir is not None:\n            dict_append(info, include_dirs=[inc_dir],\n                        define_macros=[(\'SCIPY_UMFPACK_H\', None)],\n                        swig_opts=[\'-I\' + inc_dir])\n\n        amd = get_info(\'amd\')\n        dict_append(info, **get_info(\'amd\'))\n\n        self.set_info(**info)\n        return\n\n\n\n\ndef combine_paths(*args, **kws):\n    \n    r = []\n    for a in args:\n        if not a:\n            continue\n        if is_string(a):\n            a = [a]\n        r.append(a)\n    args = r\n    if not args:\n        return []\n    if len(args) == 1:\n        result = reduce(lambda a, b: a + b, map(glob, args[0]), [])\n    elif len(args) == 2:\n        result = []\n        for a0 in args[0]:\n            for a1 in args[1]:\n                result.extend(glob(os.path.join(a0, a1)))\n    else:\n        result = combine_paths(*(combine_paths(args[0], args[1]) + args[2:]))\n    verbosity = kws.get(\'verbosity\', 1)\n    log.debug(\'(paths: %s)\', \',\'.join(result))\n    return result\n\nlanguage_map = {\'c\': 0, \'c++\': 1, \'f77\': 2, \'f90\': 3}\ninv_language_map = {0: \'c\', 1: \'c++\', 2: \'f77\', 3: \'f90\'}\n\n\ndef dict_append(d, **kws):\n    languages = []\n    for k, v in kws.items():\n        if k == \'language\':\n            languages.append(v)\n            continue\n        if k in d:\n            if k in [\'library_dirs\', \'include_dirs\', \n                     \'extra_compile_args\', \'extra_link_args\',\n                     \'runtime_library_dirs\', \'define_macros\']:\n                [d[k].append(vv) for vv in v if vv not in d[k]]\n            else:\n                d[k].extend(v)\n        else:\n            d[k] = v\n    if languages:\n        l = inv_language_map[max([language_map.get(l, 0) for l in languages])]\n        d[\'language\'] = l\n    return\n\n\ndef parseCmdLine(argv=(None,)):\n    import optparse\n    parser = optparse.OptionParser("usage: %prog [-v] [info objs]")\n    parser.add_option(\'-v\', \'--verbose\', action=\'store_true\', dest=\'verbose\',\n                      default=False,\n                      help=\'be verbose and print more messages\')\n\n    opts, args = parser.parse_args(args=argv[1:])\n    return opts, args\n\n\ndef show_all(argv=None):\n    import inspect\n    if argv is None:\n        argv = sys.argv\n    opts, args = parseCmdLine(argv)\n    if opts.verbose:\n        log.set_threshold(log.DEBUG)\n    else:\n        log.set_threshold(log.INFO)\n    show_only = []\n    for n in args:\n        if n[-5:] != \'_info\':\n            n = n + \'_info\'\n        show_only.append(n)\n    show_all = not show_only\n    _gdict_ = globals().copy()\n    for name, c in _gdict_.items():\n        if not inspect.isclass(c):\n            continue\n        if not issubclass(c, system_info) or c is system_info:\n            continue\n        if not show_all:\n            if name not in show_only:\n                continue\n            del show_only[show_only.index(name)]\n        conf = c()\n        conf.verbosity = 2\n        r = conf.get_info()\n    if show_only:\n        log.info(\'Info classes not defined: %s\', \',\'.join(show_only))\n\nif __name__ == "__main__":\n    show_all()\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport sys\nfrom tempfile import TemporaryFile\n\nfrom numpy.distutils import exec_command\n\nif sys.version_info[0] >= 3:\n    from io import StringIO\nelse:\n    from StringIO import StringIO\n\nclass redirect_stdout(object):\n    \n    def __init__(self, stdout=None):\n        self._stdout = stdout or sys.stdout\n\n    def __enter__(self):\n        self.old_stdout = sys.stdout\n        sys.stdout = self._stdout\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self._stdout.flush()\n        sys.stdout = self.old_stdout\n                self._stdout.close()\n\nclass redirect_stderr(object):\n    \n    def __init__(self, stderr=None):\n        self._stderr = stderr or sys.stderr\n\n    def __enter__(self):\n        self.old_stderr = sys.stderr\n        sys.stderr = self._stderr\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self._stderr.flush()\n        sys.stderr = self.old_stderr\n                self._stderr.close()\n\nclass emulate_nonposix(object):\n    \n    def __init__(self, osname=\'non-posix\'):\n        self._new_name = osname\n\n    def __enter__(self):\n        self._old_name = os.name\n        os.name = self._new_name\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        os.name = self._old_name\n\n\ndef test_exec_command_stdout():\n                    \n        \n        with redirect_stdout(StringIO()):\n        with redirect_stderr(TemporaryFile()):\n            exec_command.exec_command("cd \'.\'")\n\n    if os.name == \'posix\':\n                with emulate_nonposix():\n            with redirect_stdout(StringIO()):\n                with redirect_stderr(TemporaryFile()):\n                    exec_command.exec_command("cd \'.\'")\n\ndef test_exec_command_stderr():\n        with redirect_stdout(TemporaryFile(mode=\'w+\')):\n        with redirect_stderr(StringIO()):\n            exec_command.exec_command("cd \'.\'")\n\n    if os.name == \'posix\':\n                with emulate_nonposix():\n            with redirect_stdout(TemporaryFile()):\n                with redirect_stderr(StringIO()):\n                    exec_command.exec_command("cd \'.\'")\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.testing import TestCase, assert_, run_module_suite\n\nimport numpy.distutils.fcompiler\n\ng77_version_strings = [\n    (\'GNU Fortran 0.5.25 20010319 (prerelease)\', \'0.5.25\'),\n    (\'GNU Fortran (GCC 3.2) 3.2 20020814 (release)\', \'3.2\'),\n    (\'GNU Fortran (GCC) 3.3.3 20040110 (prerelease) (Debian)\', \'3.3.3\'),\n    (\'GNU Fortran (GCC) 3.3.3 (Debian 20040401)\', \'3.3.3\'),\n    (\'GNU Fortran (GCC 3.2.2 20030222 (Red Hat Linux 3.2.2-5)) 3.2.2\'\n       \' 20030222 (Red Hat Linux 3.2.2-5)\', \'3.2.2\'),\n]\n\ngfortran_version_strings = [\n    (\'GNU Fortran 95 (GCC 4.0.3 20051023 (prerelease) (Debian 4.0.2-3))\',\n     \'4.0.3\'),\n    (\'GNU Fortran 95 (GCC) 4.1.0\', \'4.1.0\'),\n    (\'GNU Fortran 95 (GCC) 4.2.0 20060218 (experimental)\', \'4.2.0\'),\n    (\'GNU Fortran (GCC) 4.3.0 20070316 (experimental)\', \'4.3.0\'),\n    (\'GNU Fortran (rubenvb-4.8.0) 4.8.0\', \'4.8.0\'),\n    (\'4.8.0\', \'4.8.0\'),\n    (\'4.0.3-7\', \'4.0.3\'),\n    ("gfortran: warning: couldn\'t understand kern.osversion \'14.1.0\\n4.9.1",\n     \'4.9.1\'),\n    ("gfortran: warning: couldn\'t understand kern.osversion \'14.1.0\\n"\n     "gfortran: warning: yet another warning\\n4.9.1",\n     \'4.9.1\')\n]\n\nclass TestG77Versions(TestCase):\n    def test_g77_version(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'gnu\')\n        for vs, version in g77_version_strings:\n            v = fc.version_match(vs)\n            assert_(v == version, (vs, v))\n\n    def test_not_g77(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'gnu\')\n        for vs, _ in gfortran_version_strings:\n            v = fc.version_match(vs)\n            assert_(v is None, (vs, v))\n\nclass TestGFortranVersions(TestCase):\n    def test_gfortran_version(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'gnu95\')\n        for vs, version in gfortran_version_strings:\n            v = fc.version_match(vs)\n            assert_(v == version, (vs, v))\n\n    def test_not_gfortran(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'gnu95\')\n        for vs, _ in g77_version_strings:\n            v = fc.version_match(vs)\n            assert_(v is None, (vs, v))\n\n\nif __name__ == \'__main__\':\n    run_module_suite()\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy.distutils.fcompiler\nfrom numpy.testing import TestCase, run_module_suite, assert_\n\n\nintel_32bit_version_strings = [\n    ("Intel(R) Fortran Intel(R) 32-bit Compiler Professional for applications"\n     "running on Intel(R) 32, Version 11.1", \'11.1\'),\n]\n\nintel_64bit_version_strings = [\n    ("Intel(R) Fortran IA-64 Compiler Professional for applications"\n     "running on IA-64, Version 11.0", \'11.0\'),\n    ("Intel(R) Fortran Intel(R) 64 Compiler Professional for applications"\n     "running on Intel(R) 64, Version 11.1", \'11.1\')\n]\n\nclass TestIntelFCompilerVersions(TestCase):\n    def test_32bit_version(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'intel\')\n        for vs, version in intel_32bit_version_strings:\n            v = fc.version_match(vs)\n            assert_(v == version)\n\n\nclass TestIntelEM64TFCompilerVersions(TestCase):\n    def test_64bit_version(self):\n        fc = numpy.distutils.fcompiler.new_fcompiler(compiler=\'intelem\')\n        for vs, version in intel_64bit_version_strings:\n            v = fc.version_match(vs)\n            assert_(v == version)\n\n\nif __name__ == \'__main__\':\n    run_module_suite()\nfrom __future__ import division, absolute_import, print_function\n\nfrom os.path import join, sep, dirname\n\nfrom numpy.distutils.misc_util import (\n    appendpath, minrelpath, gpaths, get_shared_lib_extension\n)\nfrom numpy.testing import (\n    TestCase, run_module_suite, assert_, assert_equal\n)\n\najoin = lambda *paths: join(*((sep,)+paths))\n\nclass TestAppendpath(TestCase):\n\n    def test_1(self):\n        assert_equal(appendpath(\'prefix\', \'name\'), join(\'prefix\', \'name\'))\n        assert_equal(appendpath(\'/prefix\', \'name\'), ajoin(\'prefix\', \'name\'))\n        assert_equal(appendpath(\'/prefix\', \'/name\'), ajoin(\'prefix\', \'name\'))\n        assert_equal(appendpath(\'prefix\', \'/name\'), join(\'prefix\', \'name\'))\n\n    def test_2(self):\n        assert_equal(appendpath(\'prefix/sub\', \'name\'),\n                     join(\'prefix\', \'sub\', \'name\'))\n        assert_equal(appendpath(\'prefix/sub\', \'sup/name\'),\n                     join(\'prefix\', \'sub\', \'sup\', \'name\'))\n        assert_equal(appendpath(\'/prefix/sub\', \'/prefix/name\'),\n                     ajoin(\'prefix\', \'sub\', \'name\'))\n\n    def test_3(self):\n        assert_equal(appendpath(\'/prefix/sub\', \'/prefix/sup/name\'),\n                     ajoin(\'prefix\', \'sub\', \'sup\', \'name\'))\n        assert_equal(appendpath(\'/prefix/sub/sub2\', \'/prefix/sup/sup2/name\'),\n                     ajoin(\'prefix\', \'sub\', \'sub2\', \'sup\', \'sup2\', \'name\'))\n        assert_equal(appendpath(\'/prefix/sub/sub2\', \'/prefix/sub/sup/name\'),\n                     ajoin(\'prefix\', \'sub\', \'sub2\', \'sup\', \'name\'))\n\nclass TestMinrelpath(TestCase):\n\n    def test_1(self):\n        n = lambda path: path.replace(\'/\', sep)\n        assert_equal(minrelpath(n(\'aa/bb\')), n(\'aa/bb\'))\n        assert_equal(minrelpath(\'..\'), \'..\')\n        assert_equal(minrelpath(n(\'aa/..\')), \'\')\n        assert_equal(minrelpath(n(\'aa/../bb\')), \'bb\')\n        assert_equal(minrelpath(n(\'aa/bb/..\')), \'aa\')\n        assert_equal(minrelpath(n(\'aa/bb/../..\')), \'\')\n        assert_equal(minrelpath(n(\'aa/bb/../cc/../dd\')), n(\'aa/dd\'))\n        assert_equal(minrelpath(n(\'.././..\')), n(\'../..\'))\n        assert_equal(minrelpath(n(\'aa/bb/.././../dd\')), n(\'dd\'))\n\nclass TestGpaths(TestCase):\n\n    def test_gpaths(self):\n        local_path = minrelpath(join(dirname(__file__), \'..\'))\n        ls = gpaths(\'command/*.py\', local_path)\n        assert_(join(local_path, \'command\', \'build_src.py\') in ls, repr(ls))\n        f = gpaths(\'system_info.py\', local_path)\n        assert_(join(local_path, \'system_info.py\') == f[0], repr(f))\n\nclass TestSharedExtension(TestCase):\n\n    def test_get_shared_lib_extension(self):\n        import sys\n        ext = get_shared_lib_extension(is_python_ext=False)\n        if sys.platform.startswith(\'linux\'):\n            assert_equal(ext, \'.so\')\n        elif sys.platform.startswith(\'gnukfreebsd\'):\n            assert_equal(ext, \'.so\')\n        elif sys.platform.startswith(\'darwin\'):\n            assert_equal(ext, \'.dylib\')\n        elif sys.platform.startswith(\'win\'):\n            assert_equal(ext, \'.dll\')\n                assert_(get_shared_lib_extension(is_python_ext=True))\n\nif __name__ == "__main__":\n    run_module_suite()\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nfrom tempfile import mkstemp\n\nfrom numpy.distutils.npy_pkg_config import read_config, parse_flags\nfrom numpy.testing import TestCase, run_module_suite\n\nsimple = \nsimple_d = {\'cflags\': \'-I/usr/include\', \'libflags\': \'-L/usr/lib\',\n        \'version\': \'0.1\', \'name\': \'foo\'}\n\nsimple_variable = \nsimple_variable_d = {\'cflags\': \'-I/foo/bar/include\', \'libflags\': \'-L/foo/bar/lib\',\n        \'version\': \'0.1\', \'name\': \'foo\'}\n\nclass TestLibraryInfo(TestCase):\n    def test_simple(self):\n        fd, filename = mkstemp(\'foo.ini\')\n        try:\n            pkg = os.path.splitext(filename)[0]\n            try:\n                os.write(fd, simple.encode(\'ascii\'))\n            finally:\n                os.close(fd)\n\n            out = read_config(pkg)\n            self.assertTrue(out.cflags() == simple_d[\'cflags\'])\n            self.assertTrue(out.libs() == simple_d[\'libflags\'])\n            self.assertTrue(out.name == simple_d[\'name\'])\n            self.assertTrue(out.version == simple_d[\'version\'])\n        finally:\n            os.remove(filename)\n\n    def test_simple_variable(self):\n        fd, filename = mkstemp(\'foo.ini\')\n        try:\n            pkg = os.path.splitext(filename)[0]\n            try:\n                os.write(fd, simple_variable.encode(\'ascii\'))\n            finally:\n                os.close(fd)\n\n            out = read_config(pkg)\n            self.assertTrue(out.cflags() == simple_variable_d[\'cflags\'])\n            self.assertTrue(out.libs() == simple_variable_d[\'libflags\'])\n            self.assertTrue(out.name == simple_variable_d[\'name\'])\n            self.assertTrue(out.version == simple_variable_d[\'version\'])\n\n            out.vars[\'prefix\'] = \'/Users/david\'\n            self.assertTrue(out.cflags() == \'-I/Users/david/include\')\n        finally:\n            os.remove(filename)\n\nclass TestParseFlags(TestCase):\n    def test_simple_cflags(self):\n        d = parse_flags("-I/usr/include")\n        self.assertTrue(d[\'include_dirs\'] == [\'/usr/include\'])\n\n        d = parse_flags("-I/usr/include -DFOO")\n        self.assertTrue(d[\'include_dirs\'] == [\'/usr/include\'])\n        self.assertTrue(d[\'macros\'] == [\'FOO\'])\n\n        d = parse_flags("-I /usr/include -DFOO")\n        self.assertTrue(d[\'include_dirs\'] == [\'/usr/include\'])\n        self.assertTrue(d[\'macros\'] == [\'FOO\'])\n\n    def test_simple_lflags(self):\n        d = parse_flags("-L/usr/lib -lfoo -L/usr/lib -lbar")\n        self.assertTrue(d[\'library_dirs\'] == [\'/usr/lib\', \'/usr/lib\'])\n        self.assertTrue(d[\'libraries\'] == [\'foo\', \'bar\'])\n\n        d = parse_flags("-L /usr/lib -lfoo -L/usr/lib -lbar")\n        self.assertTrue(d[\'library_dirs\'] == [\'/usr/lib\', \'/usr/lib\'])\n        self.assertTrue(d[\'libraries\'] == [\'foo\', \'bar\'])\n\n\nif __name__ == \'__main__\':\n    run_module_suite()\nfrom __future__ import division, absolute_import, print_function\n\nimport numpy as np\nfrom numpy.testing import (\n        TestCase, run_module_suite, assert_, assert_raises, assert_equal,\n        assert_warns)\nfrom numpy import random\nfrom numpy.compat import asbytes\nimport sys\n\nclass TestSeed(TestCase):\n    def test_scalar(self):\n        s = np.random.RandomState(0)\n        assert_equal(s.randint(1000), 684)\n        s = np.random.RandomState(4294967295)\n        assert_equal(s.randint(1000), 419)\n\n    def test_array(self):\n        s = np.random.RandomState(range(10))\n        assert_equal(s.randint(1000), 468)\n        s = np.random.RandomState(np.arange(10))\n        assert_equal(s.randint(1000), 468)\n        s = np.random.RandomState([0])\n        assert_equal(s.randint(1000), 973)\n        s = np.random.RandomState([4294967295])\n        assert_equal(s.randint(1000), 265)\n\n    def test_invalid_scalar(self):\n                assert_raises(TypeError, np.random.RandomState, -0.5)\n        assert_raises(ValueError, np.random.RandomState, -1)\n\n    def test_invalid_array(self):\n                assert_raises(TypeError, np.random.RandomState, [-0.5])\n        assert_raises(ValueError, np.random.RandomState, [-1])\n        assert_raises(ValueError, np.random.RandomState, [4294967296])\n        assert_raises(ValueError, np.random.RandomState, [1, 2, 4294967296])\n        assert_raises(ValueError, np.random.RandomState, [1, -2, 4294967296])\n\nclass TestBinomial(TestCase):\n    def test_n_zero(self):\n                                zeros = np.zeros(2, dtype=\'int\')\n        for p in [0, .5, 1]:\n            assert_(random.binomial(0, p) == 0)\n            np.testing.assert_array_equal(random.binomial(zeros, p), zeros)\n\n    def test_p_is_nan(self):\n                assert_raises(ValueError, random.binomial, 1, np.nan)\n\n\nclass TestMultinomial(TestCase):\n    def test_basic(self):\n        random.multinomial(100, [0.2, 0.8])\n\n    def test_zero_probability(self):\n        random.multinomial(100, [0.2, 0.8, 0.0, 0.0, 0.0])\n\n    def test_int_negative_interval(self):\n        assert_(-5 <= random.randint(-5, -1) < -1)\n        x = random.randint(-5, -1, 5)\n        assert_(np.all(-5 <= x))\n        assert_(np.all(x < -1))\n\n    def test_size(self):\n                p = [0.5, 0.5]\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.multinomial(1, p, [2, 2]).shape, (2, 2, 2))\n        assert_equal(np.random.multinomial(1, p, (2, 2)).shape, (2, 2, 2))\n        assert_equal(np.random.multinomial(1, p, np.array((2, 2))).shape,\n                     (2, 2, 2))\n\n        assert_raises(TypeError, np.random.multinomial, 1, p,\n                      np.float(1))\n\n\nclass TestSetState(TestCase):\n    def setUp(self):\n        self.seed = 1234567890\n        self.prng = random.RandomState(self.seed)\n        self.state = self.prng.get_state()\n\n    def test_basic(self):\n        old = self.prng.tomaxint(16)\n        self.prng.set_state(self.state)\n        new = self.prng.tomaxint(16)\n        assert_(np.all(old == new))\n\n    def test_gaussian_reset(self):\n                old = self.prng.standard_normal(size=3)\n        self.prng.set_state(self.state)\n        new = self.prng.standard_normal(size=3)\n        assert_(np.all(old == new))\n\n    def test_gaussian_reset_in_media_res(self):\n                \n        self.prng.standard_normal()\n        state = self.prng.get_state()\n        old = self.prng.standard_normal(size=3)\n        self.prng.set_state(state)\n        new = self.prng.standard_normal(size=3)\n        assert_(np.all(old == new))\n\n    def test_backwards_compatibility(self):\n                        old_state = self.state[:-2]\n        x1 = self.prng.standard_normal(size=16)\n        self.prng.set_state(old_state)\n        x2 = self.prng.standard_normal(size=16)\n        self.prng.set_state(self.state)\n        x3 = self.prng.standard_normal(size=16)\n        assert_(np.all(x1 == x2))\n        assert_(np.all(x1 == x3))\n\n    def test_negative_binomial(self):\n                        self.prng.negative_binomial(0.5, 0.5)\n\nclass TestRandomDist(TestCase):\n        \n    def setUp(self):\n        self.seed = 1234567890\n\n    def test_rand(self):\n        np.random.seed(self.seed)\n        actual = np.random.rand(3, 2)\n        desired = np.array([[0.61879477158567997, 0.59162362775974664],\n                            [0.88868358904449662, 0.89165480011560816],\n                            [0.4575674820298663, 0.7781880808593471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_randn(self):\n        np.random.seed(self.seed)\n        actual = np.random.randn(3, 2)\n        desired = np.array([[1.34016345771863121, 1.73759122771936081],\n                           [1.498988344300628, -0.2286433324536169],\n                           [2.031033998682787, 2.17032494605655257]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_randint(self):\n        np.random.seed(self.seed)\n        actual = np.random.randint(-99, 99, size=(3, 2))\n        desired = np.array([[31, 3],\n                            [-52, 41],\n                            [-48, -66]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_random_integers(self):\n        np.random.seed(self.seed)\n        actual = np.random.random_integers(-99, 99, size=(3, 2))\n        desired = np.array([[31, 3],\n                            [-52, 41],\n                            [-48, -66]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_random_sample(self):\n        np.random.seed(self.seed)\n        actual = np.random.random_sample((3, 2))\n        desired = np.array([[0.61879477158567997, 0.59162362775974664],\n                            [0.88868358904449662, 0.89165480011560816],\n                            [0.4575674820298663, 0.7781880808593471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_choice_uniform_replace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 4)\n        desired = np.array([2, 3, 2, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_nonuniform_replace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 4, p=[0.4, 0.4, 0.1, 0.1])\n        desired = np.array([1, 1, 2, 2])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_uniform_noreplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 3, replace=False)\n        desired = np.array([0, 1, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_nonuniform_noreplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice(4, 3, replace=False,\n                                  p=[0.1, 0.3, 0.5, 0.1])\n        desired = np.array([2, 3, 1])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_noninteger(self):\n        np.random.seed(self.seed)\n        actual = np.random.choice([\'a\', \'b\', \'c\', \'d\'], 4)\n        desired = np.array([\'c\', \'d\', \'c\', \'d\'])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_choice_exceptions(self):\n        sample = np.random.choice\n        assert_raises(ValueError, sample, -1, 3)\n        assert_raises(ValueError, sample, 3., 3)\n        assert_raises(ValueError, sample, [[1, 2], [3, 4]], 3)\n        assert_raises(ValueError, sample, [], 3)\n        assert_raises(ValueError, sample, [1, 2, 3, 4], 3,\n                                          p=[[0.25, 0.25], [0.25, 0.25]])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[0.4, 0.4, 0.2])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[1.1, -0.1])\n        assert_raises(ValueError, sample, [1, 2], 3, p=[0.4, 0.4])\n        assert_raises(ValueError, sample, [1, 2, 3], 4, replace=False)\n        assert_raises(ValueError, sample, [1, 2, 3], 2, replace=False,\n                                          p=[1, 0, 0])\n\n    def test_choice_return_shape(self):\n        p = [0.1, 0.9]\n                assert_(np.isscalar(np.random.choice(2, replace=True)))\n        assert_(np.isscalar(np.random.choice(2, replace=False)))\n        assert_(np.isscalar(np.random.choice(2, replace=True, p=p)))\n        assert_(np.isscalar(np.random.choice(2, replace=False, p=p)))\n        assert_(np.isscalar(np.random.choice([1, 2], replace=True)))\n        assert_(np.random.choice([None], replace=True) is None)\n        a = np.array([1, 2])\n        arr = np.empty(1, dtype=object)\n        arr[0] = a\n        assert_(np.random.choice(arr, replace=True) is a)\n\n                s = tuple()\n        assert_(not np.isscalar(np.random.choice(2, s, replace=True)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=False)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=True, p=p)))\n        assert_(not np.isscalar(np.random.choice(2, s, replace=False, p=p)))\n        assert_(not np.isscalar(np.random.choice([1, 2], s, replace=True)))\n        assert_(np.random.choice([None], s, replace=True).ndim == 0)\n        a = np.array([1, 2])\n        arr = np.empty(1, dtype=object)\n        arr[0] = a\n        assert_(np.random.choice(arr, s, replace=True).item() is a)\n\n                s = (2, 3)\n        p = [0.1, 0.1, 0.1, 0.1, 0.4, 0.2]\n        assert_(np.random.choice(6, s, replace=True).shape, s)\n        assert_(np.random.choice(6, s, replace=False).shape, s)\n        assert_(np.random.choice(6, s, replace=True, p=p).shape, s)\n        assert_(np.random.choice(6, s, replace=False, p=p).shape, s)\n        assert_(np.random.choice(np.arange(6), s, replace=True).shape, s)\n\n    def test_bytes(self):\n        np.random.seed(self.seed)\n        actual = np.random.bytes(10)\n        desired = asbytes(\'\\x82Ui\\x9e\\xff\\x97+Wf\\xa5\')\n        np.testing.assert_equal(actual, desired)\n\n    def test_shuffle(self):\n                for conv in [lambda x: x,\n                     np.asarray,\n                     lambda x: [(i, i) for i in x],\n                     lambda x: np.asarray([(i, i) for i in x])]:\n            np.random.seed(self.seed)\n            alist = conv([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n            np.random.shuffle(alist)\n            actual = alist\n            desired = conv([0, 1, 9, 6, 2, 4, 5, 8, 7, 3])\n            np.testing.assert_array_equal(actual, desired)\n\n    def test_shuffle_flexible(self):\n                arr = [(0, 1), (2, 3)]\n        dt = np.dtype([(\'a\', np.int32, 1), (\'b\', np.int32, 1)])\n        nparr = np.array(arr, dtype=dt)\n        a, b = nparr[0].copy(), nparr[1].copy()\n        for i in range(50):\n            np.random.shuffle(nparr)\n            assert_(a in nparr)\n            assert_(b in nparr)\n\n    def test_shuffle_masked(self):\n                a = np.ma.masked_values(np.reshape(range(20), (5,4)) % 3 - 1, -1)\n        b = np.ma.masked_values(np.arange(20) % 3 - 1, -1)\n        ma = np.ma.count_masked(a)\n        mb = np.ma.count_masked(b)\n        for i in range(50):\n            np.random.shuffle(a)\n            self.assertEqual(ma, np.ma.count_masked(a))\n            np.random.shuffle(b)\n            self.assertEqual(mb, np.ma.count_masked(b))\n\n    def test_beta(self):\n        np.random.seed(self.seed)\n        actual = np.random.beta(.1, .9, size=(3, 2))\n        desired = np.array(\n                [[1.45341850513746058e-02, 5.31297615662868145e-04],\n                 [1.85366619058432324e-06, 4.19214516800110563e-03],\n                 [1.58405155108498093e-04, 1.26252891949397652e-04]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_binomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.binomial(100.123, .456, size=(3, 2))\n        desired = np.array([[37, 43],\n                         [42, 48],\n                         [46, 45]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_chisquare(self):\n        np.random.seed(self.seed)\n        actual = np.random.chisquare(50, size=(3, 2))\n        desired = np.array([[63.87858175501090585, 68.68407748911370447],\n                            [65.77116116901505904, 47.09686762438974483],\n                            [72.3828403199695174, 74.18408615260374006]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=13)\n\n    def test_dirichlet(self):\n        np.random.seed(self.seed)\n        alpha = np.array([51.72840233779265162, 39.74494232180943953])\n        actual = np.random.mtrand.dirichlet(alpha, size=(3, 2))\n        desired = np.array([[[0.54539444573611562, 0.45460555426388438],\n                             [0.62345816822039413, 0.37654183177960598]],\n                            [[0.55206000085785778, 0.44793999914214233],\n                             [0.58964023305154301, 0.41035976694845688]],\n                            [[0.59266909280647828, 0.40733090719352177],\n                             [0.56974431743975207, 0.43025568256024799]]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_dirichlet_size(self):\n                p = np.array([51.72840233779265162, 39.74494232180943953])\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, np.uint32(1)).shape, (1, 2))\n        assert_equal(np.random.dirichlet(p, [2, 2]).shape, (2, 2, 2))\n        assert_equal(np.random.dirichlet(p, (2, 2)).shape, (2, 2, 2))\n        assert_equal(np.random.dirichlet(p, np.array((2, 2))).shape, (2, 2, 2))\n\n        assert_raises(TypeError, np.random.dirichlet, p, np.float(1))\n\n    def test_exponential(self):\n        np.random.seed(self.seed)\n        actual = np.random.exponential(1.1234, size=(3, 2))\n        desired = np.array([[1.08342649775011624, 1.00607889924557314],\n                            [2.46628830085216721, 2.49668106809923884],\n                            [0.68717433461363442, 1.69175666993575979]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_f(self):\n        np.random.seed(self.seed)\n        actual = np.random.f(12, 77, size=(3, 2))\n        desired = np.array([[1.21975394418575878, 1.75135759791559775],\n                            [1.44803115017146489, 1.22108959480396262],\n                            [1.02176975757740629, 1.34431827623300415]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_gamma(self):\n        np.random.seed(self.seed)\n        actual = np.random.gamma(5, 3, size=(3, 2))\n        desired = np.array([[24.60509188649287182, 28.54993563207210627],\n                            [26.13476110204064184, 12.56988482927716078],\n                            [31.71863275789960568, 33.30143302795922011]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_geometric(self):\n        np.random.seed(self.seed)\n        actual = np.random.geometric(.123456789, size=(3, 2))\n        desired = np.array([[8, 7],\n                            [17, 17],\n                            [5, 12]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_gumbel(self):\n        np.random.seed(self.seed)\n        actual = np.random.gumbel(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[0.19591898743416816, 0.34405539668096674],\n                            [-1.4492522252274278, -1.47374816298446865],\n                            [1.10651090478803416, -0.69535848626236174]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_hypergeometric(self):\n        np.random.seed(self.seed)\n        actual = np.random.hypergeometric(10.1, 5.5, 14, size=(3, 2))\n        desired = np.array([[10, 10],\n                            [10, 10],\n                            [9, 9]])\n        np.testing.assert_array_equal(actual, desired)\n\n                actual = np.random.hypergeometric(5, 0, 3, size=4)\n        desired = np.array([3, 3, 3, 3])\n        np.testing.assert_array_equal(actual, desired)\n\n        actual = np.random.hypergeometric(15, 0, 12, size=4)\n        desired = np.array([12, 12, 12, 12])\n        np.testing.assert_array_equal(actual, desired)\n\n                actual = np.random.hypergeometric(0, 5, 3, size=4)\n        desired = np.array([0, 0, 0, 0])\n        np.testing.assert_array_equal(actual, desired)\n\n        actual = np.random.hypergeometric(0, 15, 12, size=4)\n        desired = np.array([0, 0, 0, 0])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_laplace(self):\n        np.random.seed(self.seed)\n        actual = np.random.laplace(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[0.66599721112760157, 0.52829452552221945],\n                            [3.12791959514407125, 3.18202813572992005],\n                            [-0.05391065675859356, 1.74901336242837324]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_logistic(self):\n        np.random.seed(self.seed)\n        actual = np.random.logistic(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[1.09232835305011444, 0.8648196662399954],\n                            [4.27818590694950185, 4.33897006346929714],\n                            [-0.21682183359214885, 2.63373365386060332]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_lognormal(self):\n        np.random.seed(self.seed)\n        actual = np.random.lognormal(mean=.123456789, sigma=2.0, size=(3, 2))\n        desired = np.array([[16.50698631688883822, 36.54846706092654784],\n                            [22.67886599981281748, 0.71617561058995771],\n                            [65.72798501792723869, 86.84341601437161273]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=13)\n\n    def test_logseries(self):\n        np.random.seed(self.seed)\n        actual = np.random.logseries(p=.923456789, size=(3, 2))\n        desired = np.array([[2, 2],\n                            [6, 17],\n                            [3, 6]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_multinomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.multinomial(20, [1/6.]*6, size=(3, 2))\n        desired = np.array([[[4, 3, 5, 4, 2, 2],\n                             [5, 2, 8, 2, 2, 1]],\n                            [[3, 4, 3, 6, 0, 4],\n                             [2, 1, 4, 3, 6, 4]],\n                            [[4, 4, 2, 5, 2, 3],\n                             [4, 3, 4, 2, 3, 4]]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_multivariate_normal(self):\n        np.random.seed(self.seed)\n        mean = (.123456789, 10)\n                cov = [[1, 0], [1, 0]]\n        size = (3, 2)\n        actual = np.random.multivariate_normal(mean, cov, size)\n        desired = np.array([[[-1.47027513018564449, 10.],\n                             [-1.65915081534845532, 10.]],\n                            [[-2.29186329304599745, 10.],\n                             [-1.77505606019580053, 10.]],\n                            [[-0.54970369430044119, 10.],\n                             [0.29768848031692957, 10.]]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n                actual = np.random.multivariate_normal(mean, cov)\n        desired = np.array([-0.79441224511977482, 10.])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n                mean = [0, 0]\n        cov = [[1, 1 + 1e-10], [1 + 1e-10, 1]]\n        assert_warns(RuntimeWarning, np.random.multivariate_normal, mean, cov)\n\n    def test_negative_binomial(self):\n        np.random.seed(self.seed)\n        actual = np.random.negative_binomial(n=100, p=.12345, size=(3, 2))\n        desired = np.array([[848, 841],\n                            [892, 611],\n                            [779, 647]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_noncentral_chisquare(self):\n        np.random.seed(self.seed)\n        actual = np.random.noncentral_chisquare(df=5, nonc=5, size=(3, 2))\n        desired = np.array([[23.91905354498517511, 13.35324692733826346],\n                            [31.22452661329736401, 16.60047399466177254],\n                            [5.03461598262724586, 17.94973089023519464]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n        actual = np.random.noncentral_chisquare(df=.5, nonc=.2, size=(3, 2))\n        desired = np.array([[ 1.47145377828516666,  0.15052899268012659],\n                            [ 0.00943803056963588,  1.02647251615666169],\n                            [ 0.332334982684171  ,  0.15451287602753125]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_noncentral_f(self):\n        np.random.seed(self.seed)\n        actual = np.random.noncentral_f(dfnum=5, dfden=2, nonc=1,\n                                        size=(3, 2))\n        desired = np.array([[1.40598099674926669, 0.34207973179285761],\n                            [3.57715069265772545, 7.92632662577829805],\n                            [0.43741599463544162, 1.1774208752428319]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_normal(self):\n        np.random.seed(self.seed)\n        actual = np.random.normal(loc=.123456789, scale=2.0, size=(3, 2))\n        desired = np.array([[2.80378370443726244, 3.59863924443872163],\n                            [3.121433477601256, -0.33382987590723379],\n                            [4.18552478636557357, 4.46410668111310471]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_pareto(self):\n        np.random.seed(self.seed)\n        actual = np.random.pareto(a=.123456789, size=(3, 2))\n        desired = np.array(\n                [[2.46852460439034849e+03, 1.41286880810518346e+03],\n                 [5.28287797029485181e+07, 6.57720981047328785e+07],\n                 [1.40840323350391515e+02, 1.98390255135251704e+05]])\n                                                        np.testing.assert_array_almost_equal_nulp(actual, desired, nulp=30)\n\n    def test_poisson(self):\n        np.random.seed(self.seed)\n        actual = np.random.poisson(lam=.123456789, size=(3, 2))\n        desired = np.array([[0, 0],\n                         [1, 0],\n                         [0, 0]])\n        np.testing.assert_array_equal(actual, desired)\n\n    def test_poisson_exceptions(self):\n        lambig = np.iinfo(\'l\').max\n        lamneg = -1\n        assert_raises(ValueError, np.random.poisson, lamneg)\n        assert_raises(ValueError, np.random.poisson, [lamneg]*10)\n        assert_raises(ValueError, np.random.poisson, lambig)\n        assert_raises(ValueError, np.random.poisson, [lambig]*10)\n\n    def test_power(self):\n        np.random.seed(self.seed)\n        actual = np.random.power(a=.123456789, size=(3, 2))\n        desired = np.array([[0.02048932883240791, 0.01424192241128213],\n                            [0.38446073748535298, 0.39499689943484395],\n                            [0.00177699707563439, 0.13115505880863756]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_rayleigh(self):\n        np.random.seed(self.seed)\n        actual = np.random.rayleigh(scale=10, size=(3, 2))\n        desired = np.array([[13.8882496494248393, 13.383318339044731],\n                            [20.95413364294492098, 21.08285015800712614],\n                            [11.06066537006854311, 17.35468505778271009]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_standard_cauchy(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_cauchy(size=(3, 2))\n        desired = np.array([[0.77127660196445336, -6.55601161955910605],\n                            [0.93582023391158309, -2.07479293013759447],\n                            [-4.74601644297011926, 0.18338989290760804]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_exponential(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_exponential(size=(3, 2))\n        desired = np.array([[0.96441739162374596, 0.89556604882105506],\n                            [2.1953785836319808, 2.22243285392490542],\n                            [0.6116915921431676, 1.50592546727413201]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_gamma(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_gamma(shape=3, size=(3, 2))\n        desired = np.array([[5.50841531318455058, 6.62953470301903103],\n                            [5.93988484943779227, 2.31044849402133989],\n                            [7.54838614231317084, 8.012756093271868]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_standard_normal(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_normal(size=(3, 2))\n        desired = np.array([[1.34016345771863121, 1.73759122771936081],\n                            [1.498988344300628, -0.2286433324536169],\n                            [2.031033998682787, 2.17032494605655257]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_standard_t(self):\n        np.random.seed(self.seed)\n        actual = np.random.standard_t(df=10, size=(3, 2))\n        desired = np.array([[0.97140611862659965, -0.08830486548450577],\n                            [1.36311143689505321, -0.55317463909867071],\n                            [-0.18473749069684214, 0.61181537341755321]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_triangular(self):\n        np.random.seed(self.seed)\n        actual = np.random.triangular(left=5.12, mode=10.23, right=20.34,\n                                      size=(3, 2))\n        desired = np.array([[12.68117178949215784, 12.4129206149193152],\n                            [16.20131377335158263, 16.25692138747600524],\n                            [11.20400690911820263, 14.4978144835829923]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_uniform(self):\n        np.random.seed(self.seed)\n        actual = np.random.uniform(low=1.23, high=10.54, size=(3, 2))\n        desired = np.array([[6.99097932346268003, 6.73801597444323974],\n                            [9.50364421400426274, 9.53130618907631089],\n                            [5.48995325769805476, 8.47493103280052118]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_uniform_range_bounds(self):\n        fmin = np.finfo(\'float\').min\n        fmax = np.finfo(\'float\').max\n\n        func = np.random.uniform\n        np.testing.assert_raises(OverflowError, func, -np.inf, 0)\n        np.testing.assert_raises(OverflowError, func,  0,      np.inf)\n        np.testing.assert_raises(OverflowError, func,  fmin,   fmax)\n\n                np.random.uniform(low=fmin, high=fmax / 1e17)\n\n    def test_vonmises(self):\n        np.random.seed(self.seed)\n        actual = np.random.vonmises(mu=1.23, kappa=1.54, size=(3, 2))\n        desired = np.array([[2.28567572673902042, 2.89163838442285037],\n                            [0.38198375564286025, 2.57638023113890746],\n                            [1.19153771588353052, 1.83509849681825354]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_vonmises_small(self):\n                np.random.seed(self.seed)\n        r = np.random.vonmises(mu=0., kappa=1.1e-8, size=10**6)\n        np.testing.assert_(np.isfinite(r).all())\n\n    def test_wald(self):\n        np.random.seed(self.seed)\n        actual = np.random.wald(mean=1.23, scale=1.54, size=(3, 2))\n        desired = np.array([[3.82935265715889983, 5.13125249184285526],\n                            [0.35045403618358717, 1.50832396872003538],\n                            [0.24124319895843183, 0.22031101461955038]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=14)\n\n    def test_weibull(self):\n        np.random.seed(self.seed)\n        actual = np.random.weibull(a=1.23, size=(3, 2))\n        desired = np.array([[0.97097342648766727, 0.91422896443565516],\n                            [1.89517770034962929, 1.91414357960479564],\n                            [0.67057783752390987, 1.39494046635066793]])\n        np.testing.assert_array_almost_equal(actual, desired, decimal=15)\n\n    def test_zipf(self):\n        np.random.seed(self.seed)\n        actual = np.random.zipf(a=1.23, size=(3, 2))\n        desired = np.array([[66, 29],\n                            [1, 1],\n                            [3, 13]])\n        np.testing.assert_array_equal(actual, desired)\n\n\nclass TestThread(object):\n        def setUp(self):\n        self.seeds = range(4)\n\n    def check_function(self, function, sz):\n        from threading import Thread\n\n        out1 = np.empty((len(self.seeds),) + sz)\n        out2 = np.empty((len(self.seeds),) + sz)\n\n                t = [Thread(target=function, args=(np.random.RandomState(s), o))\n             for s, o in zip(self.seeds, out1)]\n        [x.start() for x in t]\n        [x.join() for x in t]\n\n                for s, o in zip(self.seeds, out2):\n            function(np.random.RandomState(s), o)\n\n                if (np.intp().dtype.itemsize == 4 and sys.platform == "win32"):\n            np.testing.assert_array_almost_equal(out1, out2)\n        else:\n            np.testing.assert_array_equal(out1, out2)\n\n    def test_normal(self):\n        def gen_random(state, out):\n            out[...] = state.normal(size=10000)\n        self.check_function(gen_random, sz=(10000,))\n\n    def test_exp(self):\n        def gen_random(state, out):\n            out[...] = state.exponential(scale=np.ones((100, 1000)))\n        self.check_function(gen_random, sz=(100, 1000))\n\n    def test_multinomial(self):\n        def gen_random(state, out):\n            out[...] = state.multinomial(10, [1/6.]*6, size=10000)\n        self.check_function(gen_random, sz=(10000,6))\n\n\nif __name__ == "__main__":\n    run_module_suite()\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nfrom numpy.testing import (TestCase, run_module_suite, assert_,\n                           assert_array_equal, assert_raises)\nfrom numpy import random\nfrom numpy.compat import long\nimport numpy as np\n\n\nclass TestRegression(TestCase):\n\n    def test_VonMises_range(self):\n                        for mu in np.linspace(-7., 7., 5):\n            r = random.mtrand.vonmises(mu, 1, 50)\n            assert_(np.all(r > -np.pi) and np.all(r <= np.pi))\n\n    def test_hypergeometric_range(self):\n                assert_(np.all(np.random.hypergeometric(3, 18, 11, size=10) < 4))\n        assert_(np.all(np.random.hypergeometric(18, 3, 11, size=10) > 0))\n\n                args = [\n            (2**20 - 2, 2**20 - 2, 2**20 - 2),          ]\n        is_64bits = sys.maxsize > 2**32\n        if is_64bits and sys.platform != \'win32\':\n            args.append((2**40 - 2, 2**40 - 2, 2**40 - 2))         for arg in args:\n            assert_(np.random.hypergeometric(*arg) > 0)\n\n    def test_logseries_convergence(self):\n                N = 1000\n        np.random.seed(0)\n        rvsn = np.random.logseries(0.8, size=N)\n                                freq = np.sum(rvsn == 1) / float(N)\n        msg = "Frequency was %f, should be > 0.45" % freq\n        assert_(freq > 0.45, msg)\n                freq = np.sum(rvsn == 2) / float(N)\n        msg = "Frequency was %f, should be < 0.23" % freq\n        assert_(freq < 0.23, msg)\n\n    def test_permutation_longs(self):\n        np.random.seed(1234)\n        a = np.random.permutation(12)\n        np.random.seed(1234)\n        b = np.random.permutation(long(12))\n        assert_array_equal(a, b)\n\n    def test_randint_range(self):\n                lmax = np.iinfo(\'l\').max\n        lmin = np.iinfo(\'l\').min\n        try:\n            random.randint(lmin, lmax)\n        except:\n            raise AssertionError\n\n    def test_shuffle_mixed_dimension(self):\n                for t in [[1, 2, 3, None],\n                  [(1, 1), (2, 2), (3, 3), None],\n                  [1, (2, 2), (3, 3), None],\n                  [(1, 1), 2, 3, None]]:\n            np.random.seed(12345)\n            shuffled = list(t)\n            random.shuffle(shuffled)\n            assert_array_equal(shuffled, [t[0], t[3], t[1], t[2]])\n\n    def test_call_within_randomstate(self):\n                m = np.random.RandomState()\n        res = np.array([0, 8, 7, 2, 1, 9, 4, 7, 0, 3])\n        for i in range(3):\n            np.random.seed(i)\n            m.seed(4321)\n                        assert_array_equal(m.choice(10, size=10, p=np.ones(10)/10.), res)\n\n    def test_multivariate_normal_size_types(self):\n                                np.random.multivariate_normal([0], [[0]], size=1)\n        np.random.multivariate_normal([0], [[0]], size=np.int_(1))\n        np.random.multivariate_normal([0], [[0]], size=np.int64(1))\n\n    def test_beta_small_parameters(self):\n                        np.random.seed(1234567890)\n        x = np.random.beta(0.0001, 0.0001, size=100)\n        assert_(not np.any(np.isnan(x)), \'Nans in np.random.beta\')\n\n    def test_choice_sum_of_probs_tolerance(self):\n                                np.random.seed(1234)\n        a = [1, 2, 3]\n        counts = [4, 4, 2]\n        for dt in np.float16, np.float32, np.float64:\n            probs = np.array(counts, dtype=dt) / sum(counts)\n            c = np.random.choice(a, p=probs)\n            assert_(c in a)\n            assert_raises(ValueError, np.random.choice, a, p=probs*0.9)\n\nif __name__ == "__main__":\n    run_module_suite()\nfrom __future__ import division, print_function\n\nimport os\nimport shutil\nfrom tempfile import mkstemp, mkdtemp\n\nfrom numpy.distutils import ccompiler\nfrom numpy.testing import TestCase, run_module_suite, assert_, assert_equal\nfrom numpy.testing.decorators import skipif\nfrom numpy.distutils.system_info import system_info, ConfigParser\nfrom numpy.distutils.system_info import default_lib_dirs, default_include_dirs\n\n\ndef get_class(name, notfound_action=1):\n    \n    cl = {\'temp1\': TestTemp1,\n          \'temp2\': TestTemp2\n          }.get(name.lower(), test_system_info)\n    return cl()\n\nsimple_site = \nsite_cfg = simple_site\n\nfakelib_c_text = \n\n\nclass test_system_info(system_info):\n\n    def __init__(self,\n                 default_lib_dirs=default_lib_dirs,\n                 default_include_dirs=default_include_dirs,\n                 verbosity=1,\n                 ):\n        self.__class__.info = {}\n        self.local_prefixes = []\n        defaults = {}\n        defaults[\'library_dirs\'] = \'\'\n        defaults[\'include_dirs\'] = \'\'\n        defaults[\'runtime_library_dirs\'] = \'\'\n        defaults[\'rpath\'] = \'\'\n        defaults[\'src_dirs\'] = \'\'\n        defaults[\'search_static_first\'] = "0"\n        defaults[\'extra_compile_args\'] = \'\'\n        defaults[\'extra_link_args\'] = \'\'\n        self.cp = ConfigParser(defaults)\n                \n    def _check_libs(self, lib_dirs, libs, opt_libs, exts):\n        \n        info = {\'libraries\': libs, \'library_dirs\': lib_dirs}\n        return info\n\n\nclass TestTemp1(test_system_info):\n    section = \'temp1\'\n\n\nclass TestTemp2(test_system_info):\n    section = \'temp2\'\n\n\nclass TestSystemInfoReading(TestCase):\n\n    def setUp(self):\n        \n                self._dir1 = mkdtemp()\n        self._src1 = os.path.join(self._dir1, \'foo.c\')\n        self._lib1 = os.path.join(self._dir1, \'libfoo.so\')\n        self._dir2 = mkdtemp()\n        self._src2 = os.path.join(self._dir2, \'bar.c\')\n        self._lib2 = os.path.join(self._dir2, \'libbar.so\')\n                global simple_site, site_cfg\n        site_cfg = simple_site.format(**{\n            \'dir1\': self._dir1,\n            \'lib1\': self._lib1,\n            \'dir2\': self._dir2,\n            \'lib2\': self._lib2,\n            \'pathsep\': os.pathsep\n        })\n                fd, self._sitecfg = mkstemp()\n        os.close(fd)\n        with open(self._sitecfg, \'w\') as fd:\n            fd.write(site_cfg)\n                with open(self._src1, \'w\') as fd:\n            fd.write(fakelib_c_text)\n        with open(self._src2, \'w\') as fd:\n            fd.write(fakelib_c_text)\n        \n        def site_and_parse(c, site_cfg):\n            c.files = [site_cfg]\n            c.parse_config_files()\n            return c\n        self.c_default = site_and_parse(get_class(\'default\'), self._sitecfg)\n        self.c_temp1 = site_and_parse(get_class(\'temp1\'), self._sitecfg)\n        self.c_temp2 = site_and_parse(get_class(\'temp2\'), self._sitecfg)\n\n    def tearDown(self):\n                try:\n            shutil.rmtree(self._dir1)\n        except:\n            pass\n        try:\n            shutil.rmtree(self._dir2)\n        except:\n            pass\n        try:\n            os.remove(self._sitecfg)\n        except:\n            pass\n\n    def test_all(self):\n                tsi = self.c_default\n        assert_equal(tsi.get_lib_dirs(), [self._dir1, self._dir2])\n        assert_equal(tsi.get_libraries(), [self._lib1, self._lib2])\n        assert_equal(tsi.get_runtime_lib_dirs(), [self._dir1])\n        extra = tsi.calc_extra_info()\n        assert_equal(extra[\'extra_compile_args\'], [\'-I/fake/directory\'])\n\n    def test_temp1(self):\n                tsi = self.c_temp1\n        assert_equal(tsi.get_lib_dirs(), [self._dir1])\n        assert_equal(tsi.get_libraries(), [self._lib1])\n        assert_equal(tsi.get_runtime_lib_dirs(), [self._dir1])\n\n    def test_temp2(self):\n                tsi = self.c_temp2\n        assert_equal(tsi.get_lib_dirs(), [self._dir2])\n        assert_equal(tsi.get_libraries(), [self._lib2])\n                assert_equal(tsi.get_runtime_lib_dirs(key=\'rpath\'), [self._dir2])\n        extra = tsi.calc_extra_info()\n        assert_equal(extra[\'extra_link_args\'], [\'-Wl,-rpath=\' + self._lib2])\n\n    def test_compile1(self):\n                c = ccompiler.new_compiler()\n        try:\n                        previousDir = os.getcwd()\n            os.chdir(self._dir1)\n            c.compile([os.path.basename(self._src1)], output_dir=self._dir1)\n                        assert_(os.path.isfile(self._src1.replace(\'.c\', \'.o\')) or\n                    os.path.isfile(self._src1.replace(\'.c\', \'.obj\')))\n            os.chdir(previousDir)\n        except OSError:\n            pass\n\n    @skipif(\'msvc\' in repr(ccompiler.new_compiler()))\n    def test_compile2(self):\n                tsi = self.c_temp2\n        c = ccompiler.new_compiler()\n        extra_link_args = tsi.calc_extra_info()[\'extra_link_args\']\n        try:\n                        previousDir = os.getcwd()\n            os.chdir(self._dir2)\n            c.compile([os.path.basename(self._src2)], output_dir=self._dir2,\n                      extra_postargs=extra_link_args)\n                        assert_(os.path.isfile(self._src2.replace(\'.c\', \'.o\')))\n            os.chdir(previousDir)\n        except OSError:\n            pass\n\nif __name__ == \'__main__\':\n    run_module_suite()\n\nfrom __future__ import division, absolute_import, print_function\n\nimport operator\n\nimport numpy as np\nfrom numpy import ndarray, float_\nimport numpy.core.umath as umath\nfrom numpy.testing import (\n    TestCase, assert_, assert_allclose, assert_array_almost_equal_nulp,\n    assert_raises, build_err_msg, run_module_suite,\n    )\nimport numpy.testing.utils as utils\nfrom .core import mask_or, getmask, masked_array, nomask, masked, filled\n\n__all__masked = [\n    \'almost\', \'approx\', \'assert_almost_equal\', \'assert_array_almost_equal\',\n    \'assert_array_approx_equal\', \'assert_array_compare\',\n    \'assert_array_equal\', \'assert_array_less\', \'assert_close\',\n    \'assert_equal\', \'assert_equal_records\', \'assert_mask_equal\',\n    \'assert_not_equal\', \'fail_if_array_equal\',\n    ]\n\n__some__from_testing = [\n    \'TestCase\', \'assert_\', \'assert_allclose\',\n    \'assert_array_almost_equal_nulp\', \'assert_raises\', \'run_module_suite\',\n    ]\n\n__all__ = __all__masked + __some__from_testing\n\n\ndef approx(a, b, fill_value=True, rtol=1e-5, atol=1e-8):\n    \n    m = mask_or(getmask(a), getmask(b))\n    d1 = filled(a)\n    d2 = filled(b)\n    if d1.dtype.char == "O" or d2.dtype.char == "O":\n        return np.equal(d1, d2).ravel()\n    x = filled(masked_array(d1, copy=False, mask=m), fill_value).astype(float_)\n    y = filled(masked_array(d2, copy=False, mask=m), 1).astype(float_)\n    d = np.less_equal(umath.absolute(x - y), atol + rtol * umath.absolute(y))\n    return d.ravel()\n\n\ndef almost(a, b, decimal=6, fill_value=True):\n    \n    m = mask_or(getmask(a), getmask(b))\n    d1 = filled(a)\n    d2 = filled(b)\n    if d1.dtype.char == "O" or d2.dtype.char == "O":\n        return np.equal(d1, d2).ravel()\n    x = filled(masked_array(d1, copy=False, mask=m), fill_value).astype(float_)\n    y = filled(masked_array(d2, copy=False, mask=m), 1).astype(float_)\n    d = np.around(np.abs(x - y), decimal) <= 10.0 ** (-decimal)\n    return d.ravel()\n\n\ndef _assert_equal_on_sequences(actual, desired, err_msg=\'\'):\n    \n    assert_equal(len(actual), len(desired), err_msg)\n    for k in range(len(desired)):\n        assert_equal(actual[k], desired[k], \'item=%r\\n%s\' % (k, err_msg))\n    return\n\n\ndef assert_equal_records(a, b):\n    \n    assert_equal(a.dtype, b.dtype)\n    for f in a.dtype.names:\n        (af, bf) = (operator.getitem(a, f), operator.getitem(b, f))\n        if not (af is masked) and not (bf is masked):\n            assert_equal(operator.getitem(a, f), operator.getitem(b, f))\n    return\n\n\ndef assert_equal(actual, desired, err_msg=\'\'):\n    \n        if isinstance(desired, dict):\n        if not isinstance(actual, dict):\n            raise AssertionError(repr(type(actual)))\n        assert_equal(len(actual), len(desired), err_msg)\n        for k, i in desired.items():\n            if k not in actual:\n                raise AssertionError("%s not in %s" % (k, actual))\n            assert_equal(actual[k], desired[k], \'key=%r\\n%s\' % (k, err_msg))\n        return\n        if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):\n        return _assert_equal_on_sequences(actual, desired, err_msg=\'\')\n    if not (isinstance(actual, ndarray) or isinstance(desired, ndarray)):\n        msg = build_err_msg([actual, desired], err_msg,)\n        if not desired == actual:\n            raise AssertionError(msg)\n        return\n        if ((actual is masked) and not (desired is masked)) or \\\n            ((desired is masked) and not (actual is masked)):\n        msg = build_err_msg([actual, desired],\n                            err_msg, header=\'\', names=(\'x\', \'y\'))\n        raise ValueError(msg)\n    actual = np.array(actual, copy=False, subok=True)\n    desired = np.array(desired, copy=False, subok=True)\n    (actual_dtype, desired_dtype) = (actual.dtype, desired.dtype)\n    if actual_dtype.char == "S" and desired_dtype.char == "S":\n        return _assert_equal_on_sequences(actual.tolist(),\n                                          desired.tolist(),\n                                          err_msg=\'\')\n    return assert_array_equal(actual, desired, err_msg)\n\n\ndef fail_if_equal(actual, desired, err_msg=\'\',):\n    \n    if isinstance(desired, dict):\n        if not isinstance(actual, dict):\n            raise AssertionError(repr(type(actual)))\n        fail_if_equal(len(actual), len(desired), err_msg)\n        for k, i in desired.items():\n            if k not in actual:\n                raise AssertionError(repr(k))\n            fail_if_equal(actual[k], desired[k], \'key=%r\\n%s\' % (k, err_msg))\n        return\n    if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):\n        fail_if_equal(len(actual), len(desired), err_msg)\n        for k in range(len(desired)):\n            fail_if_equal(actual[k], desired[k], \'item=%r\\n%s\' % (k, err_msg))\n        return\n    if isinstance(actual, np.ndarray) or isinstance(desired, np.ndarray):\n        return fail_if_array_equal(actual, desired, err_msg)\n    msg = build_err_msg([actual, desired], err_msg)\n    if not desired != actual:\n        raise AssertionError(msg)\n\n\nassert_not_equal = fail_if_equal\n\n\ndef assert_almost_equal(actual, desired, decimal=7, err_msg=\'\', verbose=True):\n    \n    if isinstance(actual, np.ndarray) or isinstance(desired, np.ndarray):\n        return assert_array_almost_equal(actual, desired, decimal=decimal,\n                                         err_msg=err_msg, verbose=verbose)\n    msg = build_err_msg([actual, desired],\n                        err_msg=err_msg, verbose=verbose)\n    if not round(abs(desired - actual), decimal) == 0:\n        raise AssertionError(msg)\n\n\nassert_close = assert_almost_equal\n\n\ndef assert_array_compare(comparison, x, y, err_msg=\'\', verbose=True, header=\'\',\n                         fill_value=True):\n    \n        m = mask_or(getmask(x), getmask(y))\n    x = masked_array(x, copy=False, mask=m, keep_mask=False, subok=False)\n    y = masked_array(y, copy=False, mask=m, keep_mask=False, subok=False)\n    if ((x is masked) and not (y is masked)) or \\\n            ((y is masked) and not (x is masked)):\n        msg = build_err_msg([x, y], err_msg=err_msg, verbose=verbose,\n                            header=header, names=(\'x\', \'y\'))\n        raise ValueError(msg)\n        return utils.assert_array_compare(comparison,\n                                      x.filled(fill_value),\n                                      y.filled(fill_value),\n                                      err_msg=err_msg,\n                                      verbose=verbose, header=header)\n\n\ndef assert_array_equal(x, y, err_msg=\'\', verbose=True):\n    \n    assert_array_compare(operator.__eq__, x, y,\n                         err_msg=err_msg, verbose=verbose,\n                         header=\'Arrays are not equal\')\n\n\ndef fail_if_array_equal(x, y, err_msg=\'\', verbose=True):\n    \n    def compare(x, y):\n        return (not np.alltrue(approx(x, y)))\n    assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n                         header=\'Arrays are not equal\')\n\n\ndef assert_array_approx_equal(x, y, decimal=6, err_msg=\'\', verbose=True):\n    \n    def compare(x, y):\n        "Returns the result of the loose comparison between x and y)."\n        return approx(x, y, rtol=10. ** -decimal)\n    assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n                         header=\'Arrays are not almost equal\')\n\n\ndef assert_array_almost_equal(x, y, decimal=6, err_msg=\'\', verbose=True):\n    \n    def compare(x, y):\n        "Returns the result of the loose comparison between x and y)."\n        return almost(x, y, decimal)\n    assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n                         header=\'Arrays are not almost equal\')\n\n\ndef assert_array_less(x, y, err_msg=\'\', verbose=True):\n    \n    assert_array_compare(operator.__lt__, x, y,\n                         err_msg=err_msg, verbose=verbose,\n                         header=\'Arrays are not less-ordered\')\n\n\ndef assert_mask_equal(m1, m2, err_msg=\'\'):\n    \n    if m1 is nomask:\n        assert_(m2 is nomask)\n    if m2 is nomask:\n        assert_(m1 is nomask)\n    assert_array_equal(m1, m2, err_msg=err_msg)\nfrom __future__ import division, absolute_import, print_function\n\nimport timeit\nfrom functools import reduce\n\nimport numpy as np\nfrom numpy import float_\nimport numpy.core.fromnumeric as fromnumeric\n\nfrom numpy.testing.utils import build_err_msg\n\nnp.seterr(all=\'ignore\')\n\npi = np.pi\n\n\nclass ModuleTester(object):\n    def __init__(self, module):\n        self.module = module\n        self.allequal = module.allequal\n        self.arange = module.arange\n        self.array = module.array\n        self.concatenate = module.concatenate\n        self.count = module.count\n        self.equal = module.equal\n        self.filled = module.filled\n        self.getmask = module.getmask\n        self.getmaskarray = module.getmaskarray\n        self.id = id\n        self.inner = module.inner\n        self.make_mask = module.make_mask\n        self.masked = module.masked\n        self.masked_array = module.masked_array\n        self.masked_values = module.masked_values\n        self.mask_or = module.mask_or\n        self.nomask = module.nomask\n        self.ones = module.ones\n        self.outer = module.outer\n        self.repeat = module.repeat\n        self.resize = module.resize\n        self.sort = module.sort\n        self.take = module.take\n        self.transpose = module.transpose\n        self.zeros = module.zeros\n        self.MaskType = module.MaskType\n        try:\n            self.umath = module.umath\n        except AttributeError:\n            self.umath = module.core.umath\n        self.testnames = []\n\n    def assert_array_compare(self, comparison, x, y, err_msg=\'\', header=\'\',\n                         fill_value=True):\n        \n        xf = self.filled(x)\n        yf = self.filled(y)\n        m = self.mask_or(self.getmask(x), self.getmask(y))\n\n        x = self.filled(self.masked_array(xf, mask=m), fill_value)\n        y = self.filled(self.masked_array(yf, mask=m), fill_value)\n        if (x.dtype.char != "O"):\n            x = x.astype(float_)\n            if isinstance(x, np.ndarray) and x.size > 1:\n                x[np.isnan(x)] = 0\n            elif np.isnan(x):\n                x = 0\n        if (y.dtype.char != "O"):\n            y = y.astype(float_)\n            if isinstance(y, np.ndarray) and y.size > 1:\n                y[np.isnan(y)] = 0\n            elif np.isnan(y):\n                y = 0\n        try:\n            cond = (x.shape == () or y.shape == ()) or x.shape == y.shape\n            if not cond:\n                msg = build_err_msg([x, y],\n                                    err_msg\n                                    + \'\\n(shapes %s, %s mismatch)\' % (x.shape,\n                                                                      y.shape),\n                                    header=header,\n                                    names=(\'x\', \'y\'))\n                assert cond, msg\n            val = comparison(x, y)\n            if m is not self.nomask and fill_value:\n                val = self.masked_array(val, mask=m)\n            if isinstance(val, bool):\n                cond = val\n                reduced = [0]\n            else:\n                reduced = val.ravel()\n                cond = reduced.all()\n                reduced = reduced.tolist()\n            if not cond:\n                match = 100-100.0*reduced.count(1)/len(reduced)\n                msg = build_err_msg([x, y],\n                                    err_msg\n                                    + \'\\n(mismatch %s%%)\' % (match,),\n                                    header=header,\n                                    names=(\'x\', \'y\'))\n                assert cond, msg\n        except ValueError:\n            msg = build_err_msg([x, y], err_msg, header=header, names=(\'x\', \'y\'))\n            raise ValueError(msg)\n\n    def assert_array_equal(self, x, y, err_msg=\'\'):\n        \n        self.assert_array_compare(self.equal, x, y, err_msg=err_msg,\n                                  header=\'Arrays are not equal\')\n\n    def test_0(self):\n        \n        x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n        m = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n        xm = self.masked_array(x, mask=m)\n        xm[0]\n\n    def test_1(self):\n        \n        x = np.array([1., 1., 1., -2., pi/2.0, 4., 5., -10., 10., 1., 2., 3.])\n        y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])\n        m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n        m2 = [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n        xm = self.masked_array(x, mask=m1)\n        ym = self.masked_array(y, mask=m2)\n        xf = np.where(m1, 1.e+20, x)\n        xm.set_fill_value(1.e+20)\n\n        assert((xm-ym).filled(0).any())\n        s = x.shape\n        assert(xm.size == reduce(lambda x, y:x*y, s))\n        assert(self.count(xm) == len(m1) - reduce(lambda x, y:x+y, m1))\n\n        for s in [(4, 3), (6, 2)]:\n            x.shape = s\n            y.shape = s\n            xm.shape = s\n            ym.shape = s\n            xf.shape = s\n            assert(self.count(xm) == len(m1) - reduce(lambda x, y:x+y, m1))\n\n    def test_2(self):\n        \n        x1 = np.array([1, 2, 4, 3])\n        x2 = self.array(x1, mask=[1, 0, 0, 0])\n        x3 = self.array(x1, mask=[0, 1, 0, 1])\n        x4 = self.array(x1)\n                str(x2)\n        repr(x2)\n                assert type(x2[1]) is type(x1[1])\n        assert x1[1] == x2[1]\n        x1[2] = 9\n        x2[2] = 9\n        self.assert_array_equal(x1, x2)\n        x1[1:3] = 99\n        x2[1:3] = 99\n        x2[1] = self.masked\n        x2[1:3] = self.masked\n        x2[:] = x1\n        x2[1] = self.masked\n        x3[:] = self.masked_array([1, 2, 3, 4], [0, 1, 1, 0])\n        x4[:] = self.masked_array([1, 2, 3, 4], [0, 1, 1, 0])\n        x1 = np.arange(5)*1.0\n        x2 = self.masked_values(x1, 3.0)\n        x1 = self.array([1, \'hello\', 2, 3], object)\n        x2 = np.array([1, \'hello\', 2, 3], object)\n                x1[1]\n        x2[1]\n        assert x1[1:1].shape == (0,)\n                n = [0, 0, 1, 0, 0]\n        m = self.make_mask(n)\n        m2 = self.make_mask(m)\n        assert(m is m2)\n        m3 = self.make_mask(m, copy=1)\n        assert(m is not m3)\n\n    def test_3(self):\n        \n        x4 = self.arange(4)\n        x4[2] = self.masked\n        y4 = self.resize(x4, (8,))\n        assert self.allequal(self.concatenate([x4, x4]), y4)\n        assert self.allequal(self.getmask(y4), [0, 0, 1, 0, 0, 0, 1, 0])\n        y5 = self.repeat(x4, (2, 2, 2, 2), axis=0)\n        self.assert_array_equal(y5, [0, 0, 1, 1, 2, 2, 3, 3])\n        y6 = self.repeat(x4, 2, axis=0)\n        assert self.allequal(y5, y6)\n        y7 = x4.repeat((2, 2, 2, 2), axis=0)\n        assert self.allequal(y5, y7)\n        y8 = x4.repeat(2, 0)\n        assert self.allequal(y5, y8)\n\n    def test_4(self):\n        \n        x = self.arange(24)\n        y = np.arange(24)\n        x[5:6] = self.masked\n        x = x.reshape(2, 3, 4)\n        y = y.reshape(2, 3, 4)\n        assert self.allequal(np.transpose(y, (2, 0, 1)), self.transpose(x, (2, 0, 1)))\n        assert self.allequal(np.take(y, (2, 0, 1), 1), self.take(x, (2, 0, 1), 1))\n        assert self.allequal(np.inner(self.filled(x, 0), self.filled(y, 0)),\n                            self.inner(x, y))\n        assert self.allequal(np.outer(self.filled(x, 0), self.filled(y, 0)),\n                            self.outer(x, y))\n        y = self.array([\'abc\', 1, \'def\', 2, 3], object)\n        y[2] = self.masked\n        t = self.take(y, [0, 3, 4])\n        assert t[0] == \'abc\'\n        assert t[1] == 2\n        assert t[2] == 3\n\n    def test_5(self):\n        \n        x = self.arange(10)\n        y = self.arange(10)\n        xm = self.arange(10)\n        xm[2] = self.masked\n        x += 1\n        assert self.allequal(x, y+1)\n        xm += 1\n        assert self.allequal(xm, y+1)\n\n        x = self.arange(10)\n        xm = self.arange(10)\n        xm[2] = self.masked\n        x -= 1\n        assert self.allequal(x, y-1)\n        xm -= 1\n        assert self.allequal(xm, y-1)\n\n        x = self.arange(10)*1.0\n        xm = self.arange(10)*1.0\n        xm[2] = self.masked\n        x *= 2.0\n        assert self.allequal(x, y*2)\n        xm *= 2.0\n        assert self.allequal(xm, y*2)\n\n        x = self.arange(10)*2\n        xm = self.arange(10)*2\n        xm[2] = self.masked\n        x /= 2\n        assert self.allequal(x, y)\n        xm /= 2\n        assert self.allequal(xm, y)\n\n        x = self.arange(10)*1.0\n        xm = self.arange(10)*1.0\n        xm[2] = self.masked\n        x /= 2.0\n        assert self.allequal(x, y/2.0)\n        xm /= self.arange(10)\n        self.assert_array_equal(xm, self.ones((10,)))\n\n        x = self.arange(10).astype(float_)\n        xm = self.arange(10)\n        xm[2] = self.masked\n        x += 1.\n        assert self.allequal(x, y + 1.)\n\n    def test_6(self):\n        \n        x = self.arange(10, dtype=float_)\n        y = self.arange(10)\n        xm = self.arange(10, dtype=float_)\n        xm[2] = self.masked\n        m = xm.mask\n        a = self.arange(10, dtype=float_)\n        a[-1] = self.masked\n        x += a\n        xm += a\n        assert self.allequal(x, y+a)\n        assert self.allequal(xm, y+a)\n        assert self.allequal(xm.mask, self.mask_or(m, a.mask))\n\n        x = self.arange(10, dtype=float_)\n        xm = self.arange(10, dtype=float_)\n        xm[2] = self.masked\n        m = xm.mask\n        a = self.arange(10, dtype=float_)\n        a[-1] = self.masked\n        x -= a\n        xm -= a\n        assert self.allequal(x, y-a)\n        assert self.allequal(xm, y-a)\n        assert self.allequal(xm.mask, self.mask_or(m, a.mask))\n\n        x = self.arange(10, dtype=float_)\n        xm = self.arange(10, dtype=float_)\n        xm[2] = self.masked\n        m = xm.mask\n        a = self.arange(10, dtype=float_)\n        a[-1] = self.masked\n        x *= a\n        xm *= a\n        assert self.allequal(x, y*a)\n        assert self.allequal(xm, y*a)\n        assert self.allequal(xm.mask, self.mask_or(m, a.mask))\n\n        x = self.arange(10, dtype=float_)\n        xm = self.arange(10, dtype=float_)\n        xm[2] = self.masked\n        m = xm.mask\n        a = self.arange(10, dtype=float_)\n        a[-1] = self.masked\n        x /= a\n        xm /= a\n\n    def test_7(self):\n        "Tests ufunc"\n        d = (self.array([1.0, 0, -1, pi/2]*2, mask=[0, 1]+[0]*6),\n             self.array([1.0, 0, -1, pi/2]*2, mask=[1, 0]+[0]*6),)\n        for f in [\'sqrt\', \'log\', \'log10\', \'exp\', \'conjugate\',\n                  ]:\n            try:\n                uf = getattr(self.umath, f)\n            except AttributeError:\n                uf = getattr(fromnumeric, f)\n            mf = getattr(self.module, f)\n            args = d[:uf.nin]\n            ur = uf(*args)\n            mr = mf(*args)\n            self.assert_array_equal(ur.filled(0), mr.filled(0), f)\n            self.assert_array_equal(ur._mask, mr._mask)\n\n    def test_99(self):\n                ott = self.array([0., 1., 2., 3.], mask=[1, 0, 0, 0])\n        self.assert_array_equal(2.0, self.average(ott, axis=0))\n        self.assert_array_equal(2.0, self.average(ott, weights=[1., 1., 2., 1.]))\n        result, wts = self.average(ott, weights=[1., 1., 2., 1.], returned=1)\n        self.assert_array_equal(2.0, result)\n        assert(wts == 4.0)\n        ott[:] = self.masked\n        assert(self.average(ott, axis=0) is self.masked)\n        ott = self.array([0., 1., 2., 3.], mask=[1, 0, 0, 0])\n        ott = ott.reshape(2, 2)\n        ott[:, 1] = self.masked\n        self.assert_array_equal(self.average(ott, axis=0), [2.0, 0.0])\n        assert(self.average(ott, axis=1)[0] is self.masked)\n        self.assert_array_equal([2., 0.], self.average(ott, axis=0))\n        result, wts = self.average(ott, axis=0, returned=1)\n        self.assert_array_equal(wts, [1., 0.])\n        w1 = [0, 1, 1, 1, 1, 0]\n        w2 = [[0, 1, 1, 1, 1, 0], [1, 0, 0, 0, 0, 1]]\n        x = self.arange(6)\n        self.assert_array_equal(self.average(x, axis=0), 2.5)\n        self.assert_array_equal(self.average(x, axis=0, weights=w1), 2.5)\n        y = self.array([self.arange(6), 2.0*self.arange(6)])\n        self.assert_array_equal(self.average(y, None), np.add.reduce(np.arange(6))*3./12.)\n        self.assert_array_equal(self.average(y, axis=0), np.arange(6) * 3./2.)\n        self.assert_array_equal(self.average(y, axis=1), [self.average(x, axis=0), self.average(x, axis=0) * 2.0])\n        self.assert_array_equal(self.average(y, None, weights=w2), 20./6.)\n        self.assert_array_equal(self.average(y, axis=0, weights=w2), [0., 1., 2., 3., 4., 10.])\n        self.assert_array_equal(self.average(y, axis=1), [self.average(x, axis=0), self.average(x, axis=0) * 2.0])\n        m1 = self.zeros(6)\n        m2 = [0, 0, 1, 1, 0, 0]\n        m3 = [[0, 0, 1, 1, 0, 0], [0, 1, 1, 1, 1, 0]]\n        m4 = self.ones(6)\n        m5 = [0, 1, 1, 1, 1, 1]\n        self.assert_array_equal(self.average(self.masked_array(x, m1), axis=0), 2.5)\n        self.assert_array_equal(self.average(self.masked_array(x, m2), axis=0), 2.5)\n        self.assert_array_equal(self.average(self.masked_array(x, m5), axis=0), 0.0)\n        self.assert_array_equal(self.count(self.average(self.masked_array(x, m4), axis=0)), 0)\n        z = self.masked_array(y, m3)\n        self.assert_array_equal(self.average(z, None), 20./6.)\n        self.assert_array_equal(self.average(z, axis=0), [0., 1., 99., 99., 4.0, 7.5])\n        self.assert_array_equal(self.average(z, axis=1), [2.5, 5.0])\n        self.assert_array_equal(self.average(z, axis=0, weights=w2), [0., 1., 99., 99., 4.0, 10.0])\n\n    def test_A(self):\n        x = self.arange(24)\n        x[5:6] = self.masked\n        x = x.reshape(2, 3, 4)\n\n\nif __name__ == \'__main__\':\n    setup_base = ("from __main__ import ModuleTester \\n"\n                  "import numpy\\n"\n                  "tester = ModuleTester(module)\\n")\n    setup_cur = "import numpy.ma.core as module\\n" + setup_base\n    (nrepeat, nloop) = (10, 10)\n\n    if 1:\n        for i in range(1, 8):\n            func = \'tester.test_%i()\' % i\n            cur = timeit.Timer(func, setup_cur).repeat(nrepeat, nloop*10)\n            cur = np.sort(cur)\n            print("            print(eval("ModuleTester.test_%i.__doc__" % i))\n            print("core_current : %.3f - %.3f" % (cur[0], cur[1]))\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.core.numeric import (\n    asanyarray, arange, zeros, greater_equal, multiply, ones, asarray,\n    where, int8, int16, int32, int64, empty, promote_types, diagonal,\n    )\nfrom numpy.core import iinfo\n\n\n__all__ = [\n    \'diag\', \'diagflat\', \'eye\', \'fliplr\', \'flipud\', \'rot90\', \'tri\', \'triu\',\n    \'tril\', \'vander\', \'histogram2d\', \'mask_indices\', \'tril_indices\',\n    \'tril_indices_from\', \'triu_indices\', \'triu_indices_from\', ]\n\n\ni1 = iinfo(int8)\ni2 = iinfo(int16)\ni4 = iinfo(int32)\n\n\ndef _min_int(low, high):\n    \n    if high <= i1.max and low >= i1.min:\n        return int8\n    if high <= i2.max and low >= i2.min:\n        return int16\n    if high <= i4.max and low >= i4.min:\n        return int32\n    return int64\n\n\ndef fliplr(m):\n    \n    m = asanyarray(m)\n    if m.ndim < 2:\n        raise ValueError("Input must be >= 2-d.")\n    return m[:, ::-1]\n\n\ndef flipud(m):\n    \n    m = asanyarray(m)\n    if m.ndim < 1:\n        raise ValueError("Input must be >= 1-d.")\n    return m[::-1, ...]\n\n\ndef rot90(m, k=1):\n    \n    m = asanyarray(m)\n    if m.ndim < 2:\n        raise ValueError("Input must >= 2-d.")\n    k = k % 4\n    if k == 0:\n        return m\n    elif k == 1:\n        return fliplr(m).swapaxes(0, 1)\n    elif k == 2:\n        return fliplr(flipud(m))\n    else:\n                return fliplr(m.swapaxes(0, 1))\n\n\ndef eye(N, M=None, k=0, dtype=float):\n    \n    if M is None:\n        M = N\n    m = zeros((N, M), dtype=dtype)\n    if k >= M:\n        return m\n    if k >= 0:\n        i = k\n    else:\n        i = (-k) * M\n    m[:M-k].flat[i::M+1] = 1\n    return m\n\n\ndef diag(v, k=0):\n    \n    v = asanyarray(v)\n    s = v.shape\n    if len(s) == 1:\n        n = s[0]+abs(k)\n        res = zeros((n, n), v.dtype)\n        if k >= 0:\n            i = k\n        else:\n            i = (-k) * n\n        res[:n-k].flat[i::n+1] = v\n        return res\n    elif len(s) == 2:\n        return diagonal(v, k)\n    else:\n        raise ValueError("Input must be 1- or 2-d.")\n\n\ndef diagflat(v, k=0):\n    \n    try:\n        wrap = v.__array_wrap__\n    except AttributeError:\n        wrap = None\n    v = asarray(v).ravel()\n    s = len(v)\n    n = s + abs(k)\n    res = zeros((n, n), v.dtype)\n    if (k >= 0):\n        i = arange(0, n-k)\n        fi = i+k+i*n\n    else:\n        i = arange(0, n+k)\n        fi = i+(i-k)*n\n    res.flat[fi] = v\n    if not wrap:\n        return res\n    return wrap(res)\n\n\ndef tri(N, M=None, k=0, dtype=float):\n    \n    if M is None:\n        M = N\n\n    m = greater_equal.outer(arange(N, dtype=_min_int(0, N)),\n                            arange(-k, M-k, dtype=_min_int(-k, M - k)))\n\n        m = m.astype(dtype, copy=False)\n\n    return m\n\n\ndef tril(m, k=0):\n    \n    m = asanyarray(m)\n    mask = tri(*m.shape[-2:], k=k, dtype=bool)\n\n    return where(mask, m, zeros(1, m.dtype))\n\n\ndef triu(m, k=0):\n    \n    m = asanyarray(m)\n    mask = tri(*m.shape[-2:], k=k-1, dtype=bool)\n\n    return where(mask, zeros(1, m.dtype), m)\n\n\ndef vander(x, N=None, increasing=False):\n    \n    x = asarray(x)\n    if x.ndim != 1:\n        raise ValueError("x must be a one-dimensional array or sequence.")\n    if N is None:\n        N = len(x)\n\n    v = empty((len(x), N), dtype=promote_types(x.dtype, int))\n    tmp = v[:, ::-1] if not increasing else v\n\n    if N > 0:\n        tmp[:, 0] = 1\n    if N > 1:\n        tmp[:, 1:] = x[:, None]\n        multiply.accumulate(tmp[:, 1:], out=tmp[:, 1:], axis=1)\n\n    return v\n\n\ndef histogram2d(x, y, bins=10, range=None, normed=False, weights=None):\n    \n    from numpy import histogramdd\n\n    try:\n        N = len(bins)\n    except TypeError:\n        N = 1\n\n    if N != 1 and N != 2:\n        xedges = yedges = asarray(bins, float)\n        bins = [xedges, yedges]\n    hist, edges = histogramdd([x, y], bins, range, normed, weights)\n    return hist, edges[0], edges[1]\n\n\ndef mask_indices(n, mask_func, k=0):\n    \n    m = ones((n, n), int)\n    a = mask_func(m, k)\n    return where(a != 0)\n\n\ndef tril_indices(n, k=0, m=None):\n    \n    return where(tri(n, m, k=k, dtype=bool))\n\n\ndef tril_indices_from(arr, k=0):\n    \n    if arr.ndim != 2:\n        raise ValueError("input array must be 2-d")\n    return tril_indices(arr.shape[-2], k=k, m=arr.shape[-1])\n\n\ndef triu_indices(n, k=0, m=None):\n    \n    return where(~tri(n, m, k=k-1, dtype=bool))\n\n\ndef triu_indices_from(arr, k=0):\n    \n    if arr.ndim != 2:\n        raise ValueError("input array must be 2-d")\n    return triu_indices(arr.shape[-2], k=k, m=arr.shape[-1])\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'iscomplexobj\', \'isrealobj\', \'imag\', \'iscomplex\',\n           \'isreal\', \'nan_to_num\', \'real\', \'real_if_close\',\n           \'typename\', \'asfarray\', \'mintypecode\', \'asscalar\',\n           \'common_type\']\n\nimport numpy.core.numeric as _nx\nfrom numpy.core.numeric import asarray, asanyarray, array, isnan, \\\n                obj2sctype, zeros\nfrom .ufunclike import isneginf, isposinf\n\n_typecodes_by_elsize = \'GDFgdfQqLlIiHhBb?\'\n\ndef mintypecode(typechars,typeset=\'GDFgdf\',default=\'d\'):\n    \n    typecodes = [(isinstance(t, str) and t) or asarray(t).dtype.char\n                 for t in typechars]\n    intersection = [t for t in typecodes if t in typeset]\n    if not intersection:\n        return default\n    if \'F\' in intersection and \'d\' in intersection:\n        return \'D\'\n    l = []\n    for t in intersection:\n        i = _typecodes_by_elsize.index(t)\n        l.append((i, t))\n    l.sort()\n    return l[0][1]\n\ndef asfarray(a, dtype=_nx.float_):\n    \n    dtype = _nx.obj2sctype(dtype)\n    if not issubclass(dtype, _nx.inexact):\n        dtype = _nx.float_\n    return asarray(a, dtype=dtype)\n\ndef real(val):\n    \n    return asanyarray(val).real\n\ndef imag(val):\n    \n    return asanyarray(val).imag\n\ndef iscomplex(x):\n    \n    ax = asanyarray(x)\n    if issubclass(ax.dtype.type, _nx.complexfloating):\n        return ax.imag != 0\n    res = zeros(ax.shape, bool)\n    return +res  \ndef isreal(x):\n    \n    return imag(x) == 0\n\ndef iscomplexobj(x):\n    \n    return issubclass(asarray(x).dtype.type, _nx.complexfloating)\n\ndef isrealobj(x):\n    \n    return not issubclass(asarray(x).dtype.type, _nx.complexfloating)\n\n\ndef _getmaxmin(t):\n    from numpy.core import getlimits\n    f = getlimits.finfo(t)\n    return f.max, f.min\n\ndef nan_to_num(x):\n    \n    x = _nx.array(x, subok=True)\n    xtype = x.dtype.type\n    if not issubclass(xtype, _nx.inexact):\n        return x\n\n    iscomplex = issubclass(xtype, _nx.complexfloating)\n    isscalar = (x.ndim == 0)\n\n    x = x[None] if isscalar else x\n    dest = (x.real, x.imag) if iscomplex else (x,)\n    maxf, minf = _getmaxmin(x.real.dtype)\n    for d in dest:\n        _nx.copyto(d, 0.0, where=isnan(d))\n        _nx.copyto(d, maxf, where=isposinf(d))\n        _nx.copyto(d, minf, where=isneginf(d))\n    return x[0] if isscalar else x\n\n\ndef real_if_close(a,tol=100):\n    \n    a = asanyarray(a)\n    if not issubclass(a.dtype.type, _nx.complexfloating):\n        return a\n    if tol > 1:\n        from numpy.core import getlimits\n        f = getlimits.finfo(a.dtype.type)\n        tol = f.eps * tol\n    if _nx.allclose(a.imag, 0, atol=tol):\n        a = a.real\n    return a\n\n\ndef asscalar(a):\n    \n    return a.item()\n\n\n_namefromtype = {\'S1\': \'character\',\n                 \'?\': \'bool\',\n                 \'b\': \'signed char\',\n                 \'B\': \'unsigned char\',\n                 \'h\': \'short\',\n                 \'H\': \'unsigned short\',\n                 \'i\': \'integer\',\n                 \'I\': \'unsigned integer\',\n                 \'l\': \'long integer\',\n                 \'L\': \'unsigned long integer\',\n                 \'q\': \'long long integer\',\n                 \'Q\': \'unsigned long long integer\',\n                 \'f\': \'single precision\',\n                 \'d\': \'double precision\',\n                 \'g\': \'long precision\',\n                 \'F\': \'complex single precision\',\n                 \'D\': \'complex double precision\',\n                 \'G\': \'complex long double precision\',\n                 \'S\': \'string\',\n                 \'U\': \'unicode\',\n                 \'V\': \'void\',\n                 \'O\': \'object\'\n                 }\n\ndef typename(char):\n    \n    return _namefromtype[char]\n\n\narray_type = [[_nx.half, _nx.single, _nx.double, _nx.longdouble],\n              [None, _nx.csingle, _nx.cdouble, _nx.clongdouble]]\narray_precision = {_nx.half: 0,\n                   _nx.single: 1,\n                   _nx.double: 2,\n                   _nx.longdouble: 3,\n                   _nx.csingle: 1,\n                   _nx.cdouble: 2,\n                   _nx.clongdouble: 3}\ndef common_type(*arrays):\n    \n    is_complex = False\n    precision = 0\n    for a in arrays:\n        t = a.dtype.type\n        if iscomplexobj(a):\n            is_complex = True\n        if issubclass(t, _nx.integer):\n            p = 2          else:\n            p = array_precision.get(t, None)\n            if p is None:\n                raise TypeError("can\'t get common type for non-numeric array")\n        precision = max(precision, p)\n    if is_complex:\n        return array_type[1][precision]\n    else:\n        return array_type[0][precision]\n\nfrom __future__ import division, absolute_import, print_function\n\ndocdict = {}\n\ndef get(name):\n    return docdict.get(name)\n\ndef add_newdoc(place, name, doc):\n    docdict[\'.\'.join((place, name))] = doc\n\n\nadd_newdoc(\'numpy.core.umath\', \'absolute\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'add\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arccos\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arccosh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arcsin\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arcsinh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arctan\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arctan2\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'_arg\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'arctanh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'bitwise_and\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'bitwise_or\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'bitwise_xor\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'ceil\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'trunc\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'conjugate\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'cos\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'cosh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'degrees\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'rad2deg\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'divide\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'equal\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'exp\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'exp2\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'expm1\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'fabs\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'floor\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'floor_divide\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'fmod\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'greater\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'greater_equal\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'hypot\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'invert\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'isfinite\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'isinf\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'isnan\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'left_shift\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'less\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'less_equal\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'log\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'log10\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'log2\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logaddexp\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logaddexp2\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'log1p\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logical_and\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logical_not\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logical_or\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'logical_xor\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'maximum\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'minimum\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'fmax\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'fmin\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'modf\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'multiply\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'negative\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'not_equal\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'_ones_like\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'power\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'radians\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'deg2rad\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'reciprocal\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'remainder\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'right_shift\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'rint\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'sign\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'signbit\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'copysign\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'nextafter\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'spacing\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'sin\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'sinh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'sqrt\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'cbrt\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'square\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'subtract\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'tan\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'tanh\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'true_divide\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'frexp\',\n    )\n\nadd_newdoc(\'numpy.core.umath\', \'ldexp\',\n    )\n\nfrom __future__ import division, absolute_import, print_function\n\n__all__ = [\'fix\', \'isneginf\', \'isposinf\']\n\nimport numpy.core.numeric as nx\n\ndef fix(x, y=None):\n    \n    x = nx.asanyarray(x)\n    y1 = nx.floor(x)\n    y2 = nx.ceil(x)\n    if y is None:\n        y = nx.asanyarray(y1)\n    y[...] = nx.where(x >= 0, y1, y2)\n    return y\n\ndef isposinf(x, y=None):\n    \n    if y is None:\n        x = nx.asarray(x)\n        y = nx.empty(x.shape, dtype=nx.bool_)\n    nx.logical_and(nx.isinf(x), ~nx.signbit(x), y)\n    return y\n\ndef isneginf(x, y=None):\n    \n    if y is None:\n        x = nx.asarray(x)\n        y = nx.empty(x.shape, dtype=nx.bool_)\n    nx.logical_and(nx.isinf(x), nx.signbit(x), y)\n    return y\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom __future__ import division, absolute_import, print_function\n\nimport os\n\nfrom distutils.errors import DistutilsExecError, CompileError\nfrom distutils.unixccompiler import *\nfrom numpy.distutils.ccompiler import replace_method\nfrom numpy.distutils.compat import get_exception\n\nif sys.version_info[0] < 3:\n    from . import log\nelse:\n    from numpy.distutils import log\n\ndef UnixCCompiler__compile(self, obj, src, ext, cc_args, extra_postargs, pp_opts):\n    \n        ccomp = self.compiler_so\n    if ccomp[0] == \'aCC\':\n                if \'-Ae\' in ccomp:\n            ccomp.remove(\'-Ae\')\n        if \'-Aa\' in ccomp:\n            ccomp.remove(\'-Aa\')\n                ccomp += [\'-AA\']\n        self.compiler_so = ccomp\n        if \'OPT\' in os.environ:\n        from distutils.sysconfig import get_config_vars\n        opt = " ".join(os.environ[\'OPT\'].split())\n        gcv_opt = " ".join(get_config_vars(\'OPT\')[0].split())\n        ccomp_s = " ".join(self.compiler_so)\n        if opt not in ccomp_s:\n            ccomp_s = ccomp_s.replace(gcv_opt, opt)\n            self.compiler_so = ccomp_s.split()\n        llink_s = " ".join(self.linker_so)\n        if opt not in llink_s:\n            self.linker_so = llink_s.split() + opt.split()\n\n    display = \'%s: %s\' % (os.path.basename(self.compiler_so[0]), src)\n    try:\n        self.spawn(self.compiler_so + cc_args + [src, \'-o\', obj] +\n                   extra_postargs, display = display)\n    except DistutilsExecError:\n        msg = str(get_exception())\n        raise CompileError(msg)\n\nreplace_method(UnixCCompiler, \'_compile\', UnixCCompiler__compile)\n\n\ndef UnixCCompiler_create_static_lib(self, objects, output_libname,\n                                    output_dir=None, debug=0, target_lang=None):\n    \n    objects, output_dir = self._fix_object_args(objects, output_dir)\n\n    output_filename = \\\n                    self.library_filename(output_libname, output_dir=output_dir)\n\n    if self._need_link(objects, output_filename):\n        try:\n                                                os.unlink(output_filename)\n        except (IOError, OSError):\n            pass\n        self.mkpath(os.path.dirname(output_filename))\n        tmp_objects = objects + self.objects\n        while tmp_objects:\n            objects = tmp_objects[:50]\n            tmp_objects = tmp_objects[50:]\n            display = \'%s: adding %d object files to %s\' % (\n                           os.path.basename(self.archiver[0]),\n                           len(objects), output_filename)\n            self.spawn(self.archiver + [output_filename] + objects,\n                       display = display)\n\n                                                if self.ranlib:\n            display = \'%s:@ %s\' % (os.path.basename(self.ranlib[0]),\n                                   output_filename)\n            try:\n                self.spawn(self.ranlib + [output_filename],\n                           display = display)\n            except DistutilsExecError:\n                msg = str(get_exception())\n                raise LibError(msg)\n    else:\n        log.debug("skipping %s (up-to-date)", output_filename)\n    return\n\nreplace_method(UnixCCompiler, \'create_static_lib\',\n               UnixCCompiler_create_static_lib)\n\nfrom __future__ import division, absolute_import, print_function\n\n__version__ = "$Revision: 1.3 $"[10:-1]\n\nf2py_version = \'See `f2py -v`\'\n\n\nfrom .auxfuncs import (\n    applyrules, dictappend, gentitle, hasnote, outmess\n)\n\n\nusemodule_rules = {\n    \'body\': ,\n    \'method\': \'\\t{\\"get_    \'need\': [\'F_MODFUNC\']\n}\n\n\n\ndef buildusevars(m, r):\n    ret = {}\n    outmess(\n        \'\\t\\tBuilding use variable hooks for module "%s" (feature only for F90/F95)...\\n\' % (m[\'name\']))\n    varsmap = {}\n    revmap = {}\n    if \'map\' in r:\n        for k in r[\'map\'].keys():\n            if r[\'map\'][k] in revmap:\n                outmess(\'\\t\\t\\tVariable "%s<=%s" is already mapped by "%s". Skipping.\\n\' % (\n                    r[\'map\'][k], k, revmap[r[\'map\'][k]]))\n            else:\n                revmap[r[\'map\'][k]] = k\n    if \'only\' in r and r[\'only\']:\n        for v in r[\'map\'].keys():\n            if r[\'map\'][v] in m[\'vars\']:\n\n                if revmap[r[\'map\'][v]] == v:\n                    varsmap[v] = r[\'map\'][v]\n                else:\n                    outmess(\'\\t\\t\\tIgnoring map "%s=>%s". See above.\\n\' %\n                            (v, r[\'map\'][v]))\n            else:\n                outmess(\n                    \'\\t\\t\\tNo definition for variable "%s=>%s". Skipping.\\n\' % (v, r[\'map\'][v]))\n    else:\n        for v in m[\'vars\'].keys():\n            if v in revmap:\n                varsmap[v] = revmap[v]\n            else:\n                varsmap[v] = v\n    for v in varsmap.keys():\n        ret = dictappend(ret, buildusevar(v, varsmap[v], m[\'vars\'], m[\'name\']))\n    return ret\n\n\ndef buildusevar(name, realname, vars, usemodulename):\n    outmess(\'\\t\\t\\tConstructing wrapper function for variable "%s=>%s"...\\n\' % (\n        name, realname))\n    ret = {}\n    vrd = {\'name\': name,\n           \'realname\': realname,\n           \'REALNAME\': realname.upper(),\n           \'usemodulename\': usemodulename,\n           \'USEMODULENAME\': usemodulename.upper(),\n           \'texname\': name.replace(\'_\', \'\\\\_\'),\n           \'begintitle\': gentitle(\'%s=>%s\' % (name, realname)),\n           \'endtitle\': gentitle(\'end of %s=>%s\' % (name, realname)),\n           \'apiname\': \'           }\n    nummap = {0: \'Ro\', 1: \'Ri\', 2: \'Rii\', 3: \'Riii\', 4: \'Riv\',\n              5: \'Rv\', 6: \'Rvi\', 7: \'Rvii\', 8: \'Rviii\', 9: \'Rix\'}\n    vrd[\'texnamename\'] = name\n    for i in nummap.keys():\n        vrd[\'texnamename\'] = vrd[\'texnamename\'].replace(repr(i), nummap[i])\n    if hasnote(vars[realname]):\n        vrd[\'note\'] = vars[realname][\'note\']\n    rd = dictappend({}, vrd)\n\n    print(name, realname, vars[realname])\n    ret = applyrules(usemodule_rules, rd)\n    return ret\n\nfrom __future__ import division, absolute_import, print_function\n\nfrom numpy.core import (\n    array, asarray, absolute, add, subtract, multiply, divide,\n    remainder, power, left_shift, right_shift, bitwise_and, bitwise_or,\n    bitwise_xor, invert, less, less_equal, not_equal, equal, greater,\n    greater_equal, shape, reshape, arange, sin, sqrt, transpose\n)\nfrom numpy.compat import long\n\n\nclass container(object):\n\n    def __init__(self, data, dtype=None, copy=True):\n        self.array = array(data, dtype, copy=copy)\n\n    def __repr__(self):\n        if len(self.shape) > 0:\n            return self.__class__.__name__ + repr(self.array)[len("array"):]\n        else:\n            return self.__class__.__name__ + "(" + repr(self.array) + ")"\n\n    def __array__(self, t=None):\n        if t:\n            return self.array.astype(t)\n        return self.array\n\n        def __len__(self):\n        return len(self.array)\n\n    def __getitem__(self, index):\n        return self._rc(self.array[index])\n\n    def __getslice__(self, i, j):\n        return self._rc(self.array[i:j])\n\n    def __setitem__(self, index, value):\n        self.array[index] = asarray(value, self.dtype)\n\n    def __setslice__(self, i, j, value):\n        self.array[i:j] = asarray(value, self.dtype)\n\n    def __abs__(self):\n        return self._rc(absolute(self.array))\n\n    def __neg__(self):\n        return self._rc(-self.array)\n\n    def __add__(self, other):\n        return self._rc(self.array + asarray(other))\n\n    __radd__ = __add__\n\n    def __iadd__(self, other):\n        add(self.array, other, self.array)\n        return self\n\n    def __sub__(self, other):\n        return self._rc(self.array - asarray(other))\n\n    def __rsub__(self, other):\n        return self._rc(asarray(other) - self.array)\n\n    def __isub__(self, other):\n        subtract(self.array, other, self.array)\n        return self\n\n    def __mul__(self, other):\n        return self._rc(multiply(self.array, asarray(other)))\n\n    __rmul__ = __mul__\n\n    def __imul__(self, other):\n        multiply(self.array, other, self.array)\n        return self\n\n    def __div__(self, other):\n        return self._rc(divide(self.array, asarray(other)))\n\n    def __rdiv__(self, other):\n        return self._rc(divide(asarray(other), self.array))\n\n    def __idiv__(self, other):\n        divide(self.array, other, self.array)\n        return self\n\n    def __mod__(self, other):\n        return self._rc(remainder(self.array, other))\n\n    def __rmod__(self, other):\n        return self._rc(remainder(other, self.array))\n\n    def __imod__(self, other):\n        remainder(self.array, other, self.array)\n        return self\n\n    def __divmod__(self, other):\n        return (self._rc(divide(self.array, other)),\n                self._rc(remainder(self.array, other)))\n\n    def __rdivmod__(self, other):\n        return (self._rc(divide(other, self.array)),\n                self._rc(remainder(other, self.array)))\n\n    def __pow__(self, other):\n        return self._rc(power(self.array, asarray(other)))\n\n    def __rpow__(self, other):\n        return self._rc(power(asarray(other), self.array))\n\n    def __ipow__(self, other):\n        power(self.array, other, self.array)\n        return self\n\n    def __lshift__(self, other):\n        return self._rc(left_shift(self.array, other))\n\n    def __rshift__(self, other):\n        return self._rc(right_shift(self.array, other))\n\n    def __rlshift__(self, other):\n        return self._rc(left_shift(other, self.array))\n\n    def __rrshift__(self, other):\n        return self._rc(right_shift(other, self.array))\n\n    def __ilshift__(self, other):\n        left_shift(self.array, other, self.array)\n        return self\n\n    def __irshift__(self, other):\n        right_shift(self.array, other, self.array)\n        return self\n\n    def __and__(self, other):\n        return self._rc(bitwise_and(self.array, other))\n\n    def __rand__(self, other):\n        return self._rc(bitwise_and(other, self.array))\n\n    def __iand__(self, other):\n        bitwise_and(self.array, other, self.array)\n        return self\n\n    def __xor__(self, other):\n        return self._rc(bitwise_xor(self.array, other))\n\n    def __rxor__(self, other):\n        return self._rc(bitwise_xor(other, self.array))\n\n    def __ixor__(self, other):\n        bitwise_xor(self.array, other, self.array)\n        return self\n\n    def __or__(self, other):\n        return self._rc(bitwise_or(self.array, other))\n\n    def __ror__(self, other):\n        return self._rc(bitwise_or(other, self.array))\n\n    def __ior__(self, other):\n        bitwise_or(self.array, other, self.array)\n        return self\n\n    def __pos__(self):\n        return self._rc(self.array)\n\n    def __invert__(self):\n        return self._rc(invert(self.array))\n\n    def _scalarfunc(self, func):\n        if len(self.shape) == 0:\n            return func(self[0])\n        else:\n            raise TypeError(\n                "only rank-0 arrays can be converted to Python scalars.")\n\n    def __complex__(self):\n        return self._scalarfunc(complex)\n\n    def __float__(self):\n        return self._scalarfunc(float)\n\n    def __int__(self):\n        return self._scalarfunc(int)\n\n    def __long__(self):\n        return self._scalarfunc(long)\n\n    def __hex__(self):\n        return self._scalarfunc(hex)\n\n    def __oct__(self):\n        return self._scalarfunc(oct)\n\n    def __lt__(self, other):\n        return self._rc(less(self.array, other))\n\n    def __le__(self, other):\n        return self._rc(less_equal(self.array, other))\n\n    def __eq__(self, other):\n        return self._rc(equal(self.array, other))\n\n    def __ne__(self, other):\n        return self._rc(not_equal(self.array, other))\n\n    def __gt__(self, other):\n        return self._rc(greater(self.array, other))\n\n    def __ge__(self, other):\n        return self._rc(greater_equal(self.array, other))\n\n    def copy(self):\n        return self._rc(self.array.copy())\n\n    def tostring(self):\n        return self.array.tostring()\n\n    def byteswap(self):\n        return self._rc(self.array.byteswap())\n\n    def astype(self, typecode):\n        return self._rc(self.array.astype(typecode))\n\n    def _rc(self, a):\n        if len(shape(a)) == 0:\n            return a\n        else:\n            return self.__class__(a)\n\n    def __array_wrap__(self, *args):\n        return self.__class__(args[0])\n\n    def __setattr__(self, attr, value):\n        if attr == \'array\':\n            object.__setattr__(self, attr, value)\n            return\n        try:\n            self.array.__setattr__(attr, value)\n        except AttributeError:\n            object.__setattr__(self, attr, value)\n\n        def __getattr__(self, attr):\n        if (attr == \'array\'):\n            return object.__getattribute__(self, attr)\n        return self.array.__getattribute__(attr)\n\nif __name__ == \'__main__\':\n    temp = reshape(arange(10000), (100, 100))\n\n    ua = container(temp)\n        print(dir(ua))\n    print(shape(ua), ua.shape)  \n    ua_small = ua[:3, :5]\n    print(ua_small)\n        ua_small[0, 0] = 10\n    print(ua_small[0, 0], ua[0, 0])\n    print(sin(ua_small) / 3. * 6. + sqrt(ua_small ** 2))\n    print(less(ua_small, 103), type(less(ua_small, 103)))\n    print(type(ua_small * reshape(arange(15), shape(ua_small))))\n    print(reshape(ua_small, (5, 3)))\n    print(transpose(ua_small))\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport sys\nimport types\nimport re\nimport warnings\n\nfrom numpy.core.numerictypes import issubclass_, issubsctype, issubdtype\nfrom numpy.core import ndarray, ufunc, asarray\n\nfrom numpy.compat import getargspec, formatargspec\n\n__all__ = [\n    \'issubclass_\', \'issubsctype\', \'issubdtype\', \'deprecate\',\n    \'deprecate_with_doc\', \'get_include\', \'info\', \'source\', \'who\',\n    \'lookfor\', \'byte_bounds\', \'safe_eval\'\n    ]\n\ndef get_include():\n    \n    import numpy\n    if numpy.show_config is None:\n                d = os.path.join(os.path.dirname(numpy.__file__), \'core\', \'include\')\n    else:\n                import numpy.core as core\n        d = os.path.join(os.path.dirname(core.__file__), \'include\')\n    return d\n\n\ndef _set_function_name(func, name):\n    func.__name__ = name\n    return func\n\n\nclass _Deprecate(object):\n    \n\n    def __init__(self, old_name=None, new_name=None, message=None):\n        self.old_name = old_name\n        self.new_name = new_name\n        self.message = message\n\n    def __call__(self, func, *args, **kwargs):\n        \n        old_name = self.old_name\n        new_name = self.new_name\n        message = self.message\n\n        import warnings\n        if old_name is None:\n            try:\n                old_name = func.__name__\n            except AttributeError:\n                old_name = func.__name__\n        if new_name is None:\n            depdoc = "`%s` is deprecated!" % old_name\n        else:\n            depdoc = "`%s` is deprecated, use `%s` instead!" % \\\n                     (old_name, new_name)\n\n        if message is not None:\n            depdoc += "\\n" + message\n\n        def newfunc(*args,**kwds):\n            \n            warnings.warn(depdoc, DeprecationWarning)\n            return func(*args, **kwds)\n\n        newfunc = _set_function_name(newfunc, old_name)\n        doc = func.__doc__\n        if doc is None:\n            doc = depdoc\n        else:\n            doc = \'\\n\\n\'.join([depdoc, doc])\n        newfunc.__doc__ = doc\n        try:\n            d = func.__dict__\n        except AttributeError:\n            pass\n        else:\n            newfunc.__dict__.update(d)\n        return newfunc\n\ndef deprecate(*args, **kwargs):\n    \n            \n    if args:\n        fn = args[0]\n        args = args[1:]\n\n                        if \'newname\' in kwargs:\n            kwargs[\'new_name\'] = kwargs.pop(\'newname\')\n        if \'oldname\' in kwargs:\n            kwargs[\'old_name\'] = kwargs.pop(\'oldname\')\n\n        return _Deprecate(*args, **kwargs)(fn)\n    else:\n        return _Deprecate(*args, **kwargs)\n\ndeprecate_with_doc = lambda msg: _Deprecate(message=msg)\n\n\n\ndef byte_bounds(a):\n    \n    ai = a.__array_interface__\n    a_data = ai[\'data\'][0]\n    astrides = ai[\'strides\']\n    ashape = ai[\'shape\']\n    bytes_a = asarray(a).dtype.itemsize\n\n    a_low = a_high = a_data\n    if astrides is None:\n                a_high += a.size * bytes_a\n    else:\n        for shape, stride in zip(ashape, astrides):\n            if stride < 0:\n                a_low += (shape-1)*stride\n            else:\n                a_high += (shape-1)*stride\n        a_high += bytes_a\n    return a_low, a_high\n\n\n\n\ndef who(vardict=None):\n    \n    if vardict is None:\n        frame = sys._getframe().f_back\n        vardict = frame.f_globals\n    sta = []\n    cache = {}\n    for name in vardict.keys():\n        if isinstance(vardict[name], ndarray):\n            var = vardict[name]\n            idv = id(var)\n            if idv in cache.keys():\n                namestr = name + " (%s)" % cache[idv]\n                original = 0\n            else:\n                cache[idv] = name\n                namestr = name\n                original = 1\n            shapestr = " x ".join(map(str, var.shape))\n            bytestr = str(var.nbytes)\n            sta.append([namestr, shapestr, bytestr, var.dtype.name,\n                        original])\n\n    maxname = 0\n    maxshape = 0\n    maxbyte = 0\n    totalbytes = 0\n    for k in range(len(sta)):\n        val = sta[k]\n        if maxname < len(val[0]):\n            maxname = len(val[0])\n        if maxshape < len(val[1]):\n            maxshape = len(val[1])\n        if maxbyte < len(val[2]):\n            maxbyte = len(val[2])\n        if val[4]:\n            totalbytes += int(val[2])\n\n    if len(sta) > 0:\n        sp1 = max(10, maxname)\n        sp2 = max(10, maxshape)\n        sp3 = max(10, maxbyte)\n        prval = "Name %s Shape %s Bytes %s Type" % (sp1*\' \', sp2*\' \', sp3*\' \')\n        print(prval + "\\n" + "="*(len(prval)+5) + "\\n")\n\n    for k in range(len(sta)):\n        val = sta[k]\n        print("%s %s %s %s %s %s %s" % (val[0], \' \'*(sp1-len(val[0])+4),\n                                        val[1], \' \'*(sp2-len(val[1])+5),\n                                        val[2], \' \'*(sp3-len(val[2])+5),\n                                        val[3]))\n    print("\\nUpper bound on total bytes  =       %d" % totalbytes)\n    return\n\n\n\n\ndef _split_line(name, arguments, width):\n    firstwidth = len(name)\n    k = firstwidth\n    newstr = name\n    sepstr = ", "\n    arglist = arguments.split(sepstr)\n    for argument in arglist:\n        if k == firstwidth:\n            addstr = ""\n        else:\n            addstr = sepstr\n        k = k + len(argument) + len(addstr)\n        if k > width:\n            k = firstwidth + 1 + len(argument)\n            newstr = newstr + ",\\n" + " "*(firstwidth+2) + argument\n        else:\n            newstr = newstr + addstr + argument\n    return newstr\n\n_namedict = None\n_dictlist = None\n\ndef _makenamedict(module=\'numpy\'):\n    module = __import__(module, globals(), locals(), [])\n    thedict = {module.__name__:module.__dict__}\n    dictlist = [module.__name__]\n    totraverse = [module.__dict__]\n    while True:\n        if len(totraverse) == 0:\n            break\n        thisdict = totraverse.pop(0)\n        for x in thisdict.keys():\n            if isinstance(thisdict[x], types.ModuleType):\n                modname = thisdict[x].__name__\n                if modname not in dictlist:\n                    moddict = thisdict[x].__dict__\n                    dictlist.append(modname)\n                    totraverse.append(moddict)\n                    thedict[modname] = moddict\n    return thedict, dictlist\n\n\ndef _info(obj, output=sys.stdout):\n    \n    extra = ""\n    tic = ""\n    bp = lambda x: x\n    cls = getattr(obj, \'__class__\', type(obj))\n    nm = getattr(cls, \'__name__\', cls)\n    strides = obj.strides\n    endian = obj.dtype.byteorder\n\n    print("class: ", nm, file=output)\n    print("shape: ", obj.shape, file=output)\n    print("strides: ", strides, file=output)\n    print("itemsize: ", obj.itemsize, file=output)\n    print("aligned: ", bp(obj.flags.aligned), file=output)\n    print("contiguous: ", bp(obj.flags.contiguous), file=output)\n    print("fortran: ", obj.flags.fortran, file=output)\n    print(\n        "data pointer: %s%s" % (hex(obj.ctypes._as_parameter_.value), extra),\n        file=output\n        )\n    print("byteorder: ", end=\' \', file=output)\n    if endian in [\'|\', \'=\']:\n        print("%s%s%s" % (tic, sys.byteorder, tic), file=output)\n        byteswap = False\n    elif endian == \'>\':\n        print("%sbig%s" % (tic, tic), file=output)\n        byteswap = sys.byteorder != "big"\n    else:\n        print("%slittle%s" % (tic, tic), file=output)\n        byteswap = sys.byteorder != "little"\n    print("byteswap: ", bp(byteswap), file=output)\n    print("type: %s" % obj.dtype, file=output)\n\n\ndef info(object=None, maxwidth=76, output=sys.stdout, toplevel=\'numpy\'):\n    \n    global _namedict, _dictlist\n        import pydoc\n    import inspect\n\n    if (hasattr(object, \'_ppimport_importer\') or\n           hasattr(object, \'_ppimport_module\')):\n        object = object._ppimport_module\n    elif hasattr(object, \'_ppimport_attr\'):\n        object = object._ppimport_attr\n\n    if object is None:\n        info(info)\n    elif isinstance(object, ndarray):\n        _info(object, output=output)\n    elif isinstance(object, str):\n        if _namedict is None:\n            _namedict, _dictlist = _makenamedict(toplevel)\n        numfound = 0\n        objlist = []\n        for namestr in _dictlist:\n            try:\n                obj = _namedict[namestr][object]\n                if id(obj) in objlist:\n                    print("\\n     "\n                          "*** Repeat reference found in %s *** " % namestr,\n                          file=output\n                          )\n                else:\n                    objlist.append(id(obj))\n                    print("     *** Found in %s ***" % namestr, file=output)\n                    info(obj)\n                    print("-"*maxwidth, file=output)\n                numfound += 1\n            except KeyError:\n                pass\n        if numfound == 0:\n            print("Help for %s not found." % object, file=output)\n        else:\n            print("\\n     "\n                  "*** Total of %d references found. ***" % numfound,\n                  file=output\n                  )\n\n    elif inspect.isfunction(object):\n        name = object.__name__\n        arguments = formatargspec(*getargspec(object))\n\n        if len(name+arguments) > maxwidth:\n            argstr = _split_line(name, arguments, maxwidth)\n        else:\n            argstr = name + arguments\n\n        print(" " + argstr + "\\n", file=output)\n        print(inspect.getdoc(object), file=output)\n\n    elif inspect.isclass(object):\n        name = object.__name__\n        arguments = "()"\n        try:\n            if hasattr(object, \'__init__\'):\n                arguments = formatargspec(\n                        *getargspec(object.__init__.__func__)\n                        )\n                arglist = arguments.split(\', \')\n                if len(arglist) > 1:\n                    arglist[1] = "("+arglist[1]\n                    arguments = ", ".join(arglist[1:])\n        except:\n            pass\n\n        if len(name+arguments) > maxwidth:\n            argstr = _split_line(name, arguments, maxwidth)\n        else:\n            argstr = name + arguments\n\n        print(" " + argstr + "\\n", file=output)\n        doc1 = inspect.getdoc(object)\n        if doc1 is None:\n            if hasattr(object, \'__init__\'):\n                print(inspect.getdoc(object.__init__), file=output)\n        else:\n            print(inspect.getdoc(object), file=output)\n\n        methods = pydoc.allmethods(object)\n        if methods != []:\n            print("\\n\\nMethods:\\n", file=output)\n            for meth in methods:\n                if meth[0] == \'_\':\n                    continue\n                thisobj = getattr(object, meth, None)\n                if thisobj is not None:\n                    methstr, other = pydoc.splitdoc(\n                            inspect.getdoc(thisobj) or "None"\n                            )\n                print("  %s  --  %s" % (meth, methstr), file=output)\n\n    elif (sys.version_info[0] < 3\n            and isinstance(object, types.InstanceType)):\n                        print("Instance of class: ", object.__class__.__name__, file=output)\n        print(file=output)\n        if hasattr(object, \'__call__\'):\n            arguments = formatargspec(\n                    *getargspec(object.__call__.__func__)\n                    )\n            arglist = arguments.split(\', \')\n            if len(arglist) > 1:\n                arglist[1] = "("+arglist[1]\n                arguments = ", ".join(arglist[1:])\n            else:\n                arguments = "()"\n\n            if hasattr(object, \'name\'):\n                name = "%s" % object.name\n            else:\n                name = "<name>"\n            if len(name+arguments) > maxwidth:\n                argstr = _split_line(name, arguments, maxwidth)\n            else:\n                argstr = name + arguments\n\n            print(" " + argstr + "\\n", file=output)\n            doc = inspect.getdoc(object.__call__)\n            if doc is not None:\n                print(inspect.getdoc(object.__call__), file=output)\n            print(inspect.getdoc(object), file=output)\n\n        else:\n            print(inspect.getdoc(object), file=output)\n\n    elif inspect.ismethod(object):\n        name = object.__name__\n        arguments = formatargspec(\n                *getargspec(object.__func__)\n                )\n        arglist = arguments.split(\', \')\n        if len(arglist) > 1:\n            arglist[1] = "("+arglist[1]\n            arguments = ", ".join(arglist[1:])\n        else:\n            arguments = "()"\n\n        if len(name+arguments) > maxwidth:\n            argstr = _split_line(name, arguments, maxwidth)\n        else:\n            argstr = name + arguments\n\n        print(" " + argstr + "\\n", file=output)\n        print(inspect.getdoc(object), file=output)\n\n    elif hasattr(object, \'__doc__\'):\n        print(inspect.getdoc(object), file=output)\n\n\ndef source(object, output=sys.stdout):\n    \n        import inspect\n    try:\n        print("In file: %s\\n" % inspect.getsourcefile(object), file=output)\n        print(inspect.getsource(object), file=output)\n    except:\n        print("Not available for this object.", file=output)\n\n\n_lookfor_caches = {}\n\n_function_signature_re = re.compile(r"[a-z0-9_]+\\(.*[,=].*\\)", re.I)\n\ndef lookfor(what, module=None, import_modules=True, regenerate=False,\n            output=None):\n    \n    import pydoc\n\n        cache = _lookfor_generate_cache(module, import_modules, regenerate)\n\n            found = []\n    whats = str(what).lower().split()\n    if not whats:\n        return\n\n    for name, (docstring, kind, index) in cache.items():\n        if kind in (\'module\', \'object\'):\n                        continue\n        ok = True\n        doc = docstring.lower()\n        for w in whats:\n            if w not in doc:\n                ok = False\n                break\n        if ok:\n            found.append(name)\n\n            \n    kind_relevance = {\'func\': 1000, \'class\': 1000,\n                      \'module\': -1000, \'object\': -1000}\n\n    def relevance(name, docstr, kind, index):\n        r = 0\n                first_doc = "\\n".join(docstr.lower().strip().split("\\n")[:3])\n        r += sum([200 for w in whats if w in first_doc])\n                r += sum([30 for w in whats if w in name])\n                r += -len(name) * 5\n                r += kind_relevance.get(kind, -1000)\n                r += -name.count(\'.\') * 10\n        r += max(-index / 100, -100)\n        return r\n\n    def relevance_value(a):\n        return relevance(a, *cache[a])\n    found.sort(key=relevance_value)\n\n        s = "Search results for \'%s\'" % (\' \'.join(whats))\n    help_text = [s, "-"*len(s)]\n    for name in found[::-1]:\n        doc, kind, ix = cache[name]\n\n        doclines = [line.strip() for line in doc.strip().split("\\n")\n                    if line.strip()]\n\n                try:\n            first_doc = doclines[0].strip()\n            if _function_signature_re.search(first_doc):\n                first_doc = doclines[1].strip()\n        except IndexError:\n            first_doc = ""\n        help_text.append("%s\\n    %s" % (name, first_doc))\n\n    if not found:\n        help_text.append("Nothing found.")\n\n        if output is not None:\n        output.write("\\n".join(help_text))\n    elif len(help_text) > 10:\n        pager = pydoc.getpager()\n        pager("\\n".join(help_text))\n    else:\n        print("\\n".join(help_text))\n\ndef _lookfor_generate_cache(module, import_modules, regenerate):\n    \n    global _lookfor_caches\n        import inspect\n\n    if sys.version_info[0] >= 3:\n                from io import StringIO\n    else:\n        from StringIO import StringIO\n\n    if module is None:\n        module = "numpy"\n\n    if isinstance(module, str):\n        try:\n            __import__(module)\n        except ImportError:\n            return {}\n        module = sys.modules[module]\n    elif isinstance(module, list) or isinstance(module, tuple):\n        cache = {}\n        for mod in module:\n            cache.update(_lookfor_generate_cache(mod, import_modules,\n                                                 regenerate))\n        return cache\n\n    if id(module) in _lookfor_caches and not regenerate:\n        return _lookfor_caches[id(module)]\n\n        cache = {}\n    _lookfor_caches[id(module)] = cache\n    seen = {}\n    index = 0\n    stack = [(module.__name__, module)]\n    while stack:\n        name, item = stack.pop(0)\n        if id(item) in seen:\n            continue\n        seen[id(item)] = True\n\n        index += 1\n        kind = "object"\n\n        if inspect.ismodule(item):\n            kind = "module"\n            try:\n                _all = item.__all__\n            except AttributeError:\n                _all = None\n\n                        if import_modules and hasattr(item, \'__path__\'):\n                for pth in item.__path__:\n                    for mod_path in os.listdir(pth):\n                        this_py = os.path.join(pth, mod_path)\n                        init_py = os.path.join(pth, mod_path, \'__init__.py\')\n                        if (os.path.isfile(this_py) and\n                                mod_path.endswith(\'.py\')):\n                            to_import = mod_path[:-3]\n                        elif os.path.isfile(init_py):\n                            to_import = mod_path\n                        else:\n                            continue\n                        if to_import == \'__init__\':\n                            continue\n\n                        try:\n                                                        base_exc = BaseException\n                        except NameError:\n                                                        base_exc = Exception\n\n                        try:\n                            old_stdout = sys.stdout\n                            old_stderr = sys.stderr\n                            try:\n                                sys.stdout = StringIO()\n                                sys.stderr = StringIO()\n                                __import__("%s.%s" % (name, to_import))\n                            finally:\n                                sys.stdout = old_stdout\n                                sys.stderr = old_stderr\n                        except base_exc:\n                            continue\n\n            for n, v in _getmembers(item):\n                try:\n                    item_name = getattr(v, \'__name__\', "%s.%s" % (name, n))\n                    mod_name = getattr(v, \'__module__\', None)\n                except NameError:\n                                                            item_name = "%s.%s" % (name, n)\n                    mod_name = None\n                if \'.\' not in item_name and mod_name:\n                    item_name = "%s.%s" % (mod_name, item_name)\n\n                if not item_name.startswith(name + \'.\'):\n                                        if isinstance(v, ufunc):\n                                                pass\n                    else:\n                        continue\n                elif not (inspect.ismodule(v) or _all is None or n in _all):\n                    continue\n                stack.append(("%s.%s" % (name, n), v))\n        elif inspect.isclass(item):\n            kind = "class"\n            for n, v in _getmembers(item):\n                stack.append(("%s.%s" % (name, n), v))\n        elif hasattr(item, "__call__"):\n            kind = "func"\n\n        try:\n            doc = inspect.getdoc(item)\n        except NameError:\n                        doc = None\n        if doc is not None:\n            cache[name] = (doc, kind, index)\n\n    return cache\n\ndef _getmembers(item):\n    import inspect\n    try:\n        members = inspect.getmembers(item)\n    except Exception:\n        members = [(x, getattr(item, x)) for x in dir(item)\n                   if hasattr(item, x)]\n    return members\n\n\n\n\nclass SafeEval(object):\n    \n    def __init__(self):\n                warnings.warn("SafeEval is deprecated in 1.10 and will be removed.",\n                      DeprecationWarning)\n\n    def visit(self, node):\n        cls = node.__class__\n        meth = getattr(self, \'visit\' + cls.__name__, self.default)\n        return meth(node)\n\n    def default(self, node):\n        raise SyntaxError("Unsupported source construct: %s"\n                          % node.__class__)\n\n    def visitExpression(self, node):\n        return self.visit(node.body)\n\n    def visitNum(self, node):\n        return node.n\n\n    def visitStr(self, node):\n        return node.s\n\n    def visitBytes(self, node):\n        return node.s\n\n    def visitDict(self, node,**kw):\n        return dict([(self.visit(k), self.visit(v))\n                     for k, v in zip(node.keys, node.values)])\n\n    def visitTuple(self, node):\n        return tuple([self.visit(i) for i in node.elts])\n\n    def visitList(self, node):\n        return [self.visit(i) for i in node.elts]\n\n    def visitUnaryOp(self, node):\n        import ast\n        if isinstance(node.op, ast.UAdd):\n            return +self.visit(node.operand)\n        elif isinstance(node.op, ast.USub):\n            return -self.visit(node.operand)\n        else:\n            raise SyntaxError("Unknown unary op: %r" % node.op)\n\n    def visitName(self, node):\n        if node.id == \'False\':\n            return False\n        elif node.id == \'True\':\n            return True\n        elif node.id == \'None\':\n            return None\n        else:\n            raise SyntaxError("Unknown name: %s" % node.id)\n\n    def visitNameConstant(self, node):\n        return node.value\n\n\ndef safe_eval(source):\n    \n        import ast\n\n    return ast.literal_eval(source)\nfrom __future__ import division, absolute_import, print_function\n\nimport os\n\nfrom numpy.distutils.fcompiler.gnu import GnuFCompiler\n\ncompilers = [\'VastFCompiler\']\n\nclass VastFCompiler(GnuFCompiler):\n    compiler_type = \'vast\'\n    compiler_aliases = ()\n    description = \'Pacific-Sierra Research Fortran 90 Compiler\'\n    version_pattern = r\'\\s*Pacific-Sierra Research vf90 \'\\\n                      \'(Personal|Professional)\\s+(?P<version>[^\\s]*)\'\n\n            object_switch = \' && function _mvfile { mv -v `basename $1` $1 ; } && _mvfile \'\n\n    executables = {\n        \'version_cmd\'  : ["vf90", "-v"],\n        \'compiler_f77\' : ["g77"],\n        \'compiler_fix\' : ["f90", "-Wv,-ya"],\n        \'compiler_f90\' : ["f90"],\n        \'linker_so\'    : ["<F90>"],\n        \'archiver\'     : ["ar", "-cr"],\n        \'ranlib\'       : ["ranlib"]\n        }\n    module_dir_switch = None      module_include_switch = None \n    def find_executables(self):\n        pass\n\n    def get_version_cmd(self):\n        f90 = self.compiler_f90[0]\n        d, b = os.path.split(f90)\n        vf90 = os.path.join(d, \'v\'+b)\n        return vf90\n\n    def get_flags_arch(self):\n        vast_version = self.get_version()\n        gnu = GnuFCompiler()\n        gnu.customize(None)\n        self.version = gnu.get_version()\n        opt = GnuFCompiler.get_flags_arch(self)\n        self.version = vast_version\n        return opt\n\nif __name__ == \'__main__\':\n    from distutils import log\n    log.set_verbosity(2)\n    from numpy.distutils.fcompiler import new_fcompiler\n    compiler = new_fcompiler(compiler=\'vast\')\n    compiler.customize()\n    print(compiler.get_version())\n\nfrom __future__ import division, absolute_import, print_function\n\nversion = \'1.00\'\nrelease = False\n\nif not release:\n    from . import core\n    from . import extras\n    revision = [core.__revision__.split(\':\')[-1][:-1].strip(),\n                extras.__revision__.split(\':\')[-1][:-1].strip(),]\n    version += \'.dev%04i\' % max([int(rev) for rev in revision])\nfrom __future__ import division, absolute_import, print_function\n\nimport os\nimport re\n\nimport waflib.Configure\nimport waflib.Tools.c_config\nfrom waflib import Logs, Utils\n\nfrom .common \\\n    import \\\n        LONG_DOUBLE_REPRESENTATION_SRC, pyod, \\\n        long_double_representation\n\nDEFKEYS = waflib.Tools.c_config.DEFKEYS\nDEFINE_COMMENTS = "define_commentz"\n\ndef to_header(dct):\n    if \'header_name\' in dct:\n        dct = Utils.to_list(dct[\'header_name\'])\n        return \'\'.join([\'    return \'\'\n\ndef sanitize_string(s):\n    key_up = s.upper()\n    return re.sub(\'[^A-Z0-9_]\', \'_\', key_up)\n\ndef validate_arguments(self, kw):\n    if not \'env\' in kw:\n        kw[\'env\'] = self.env.derive()\n    if not "compile_mode" in kw:\n        kw["compile_mode"] = "c"\n    if not \'compile_filename\' in kw:\n        kw[\'compile_filename\'] = \'test.c\' + \\\n                ((kw[\'compile_mode\'] == \'cxx\') and \'pp\' or \'\')\n    if not \'features\' in kw:\n        kw[\'features\'] = [kw[\'compile_mode\']]\n    if not \'execute\' in kw:\n        kw[\'execute\'] = False\n    if not \'okmsg\' in kw:\n        kw[\'okmsg\'] = \'yes\'\n    if not \'errmsg\' in kw:\n        kw[\'errmsg\'] = \'no !\'\n\n    if \'define_name\' in kw:\n        comment = kw.get(\'define_comment\', None)\n        self.undefine_with_comment(kw[\'define_name\'], comment)\n\ndef try_compile(self, kw):\n    self.start_msg(kw["msg"])\n    ret = None\n    try:\n        ret = self.run_c_code(**kw)\n    except self.errors.ConfigurationError as e:\n        self.end_msg(kw[\'errmsg\'], \'YELLOW\')\n        if Logs.verbose > 1:\n            raise\n        else:\n            self.fatal(\'The configuration failed\')\n    else:\n        kw[\'success\'] = ret\n        self.end_msg(self.ret_msg(kw[\'okmsg\'], kw))\n\n@waflib.Configure.conf\ndef check_header(self, header_name, **kw):\n    code =  % to_header({"header_name": header_name})\n\n    kw["code"] = code\n    kw["define_comment"] = "/* Define to 1 if you have the <%s> header file. */" % header_name\n    kw["define_name"] = "HAVE_%s" % sanitize_string(header_name)\n    if not "features" in kw:\n        kw["features"] = ["c"]\n    kw["msg"] = "Checking for header %r" % header_name\n\n    validate_arguments(self, kw)\n    try_compile(self, kw)\n    ret = kw["success"]\n    if ret == 0:\n        kw["define_value"] = 1\n    else:\n        kw["define_value"] = 0\n\n    self.post_check(**kw)\n    if not kw.get(\'execute\', False):\n        return ret == 0\n    return ret\n\n@waflib.Configure.conf\ndef check_declaration(self, symbol, **kw):\n    code = r % (symbol, symbol)\n\n    kw["code"] = to_header(kw) + code\n    kw["msg"] = "Checking for macro %r" % symbol\n    kw["errmsg"] = "not found"\n    kw["okmsg"] = "yes"\n\n    validate_arguments(self, kw)\n    try_compile(self, kw)\n    ret = kw["success"]\n\n    kw["define_name"] = "HAVE_DECL_%s" % sanitize_string(symbol)\n    kw["define_comment"] = "/* Set to 1 if %s is defined. */" % symbol\n    self.post_check(**kw)\n    if not kw.get(\'execute\', False):\n        return ret == 0\n    return ret\n\n@waflib.Configure.conf\ndef check_type(self, type_name, **kw):\n    code = r % {"type_name": type_name}\n\n    kw["code"] = to_header(kw) + code\n    kw["msg"] = "Checking for type %r" % type_name\n    kw["errmsg"] = "not found"\n    kw["okmsg"] = "yes"\n\n    validate_arguments(self, kw)\n    try_compile(self, kw)\n    ret = kw["success"]\n    if ret == 0:\n        kw["define_value"] = 1\n    else:\n        kw["define_value"] = 0\n\n    kw["define_name"] = "HAVE_%s" % sanitize_string(type_name)\n    kw["define_comment"] = "/* Define to 1 if the system has the type `%s\'. */" % type_name\n    self.post_check(**kw)\n    if not kw.get(\'execute\', False):\n        return ret == 0\n    return ret\n\ndef do_binary_search(conf, type_name, kw):\n    code =  % {"type": type_name}\n    kw["code"] = to_header(kw) + code\n\n    try:\n        conf.run_c_code(**kw)\n    except conf.errors.ConfigurationError as e:\n        conf.end_msg("failed !")\n        if waflib.Logs.verbose > 1:\n            raise\n        else:\n            conf.fatal("The configuration failed !")\n\n    body = r\n                    low = 0\n    mid = 0\n    while True:\n        try:\n            kw["code"] = to_header(kw) + body % {"type": type_name, "size": mid}\n            validate_arguments(conf, kw)\n            conf.run_c_code(**kw)\n            break\n        except conf.errors.ConfigurationError:\n                        low = mid + 1\n            mid = 2 * mid + 1\n\n    high = mid\n    ret = None\n        while low != high:\n        mid = (high - low) / 2 + low\n        try:\n            kw["code"] = to_header(kw) + body % {"type": type_name, "size": mid}\n            validate_arguments(conf, kw)\n            ret = conf.run_c_code(**kw)\n            high = mid\n        except conf.errors.ConfigurationError:\n            low = mid + 1\n\n    return low\n\n@waflib.Configure.conf\ndef check_type_size(conf, type_name, expected_sizes=None, **kw):\n    kw["define_name"] = "SIZEOF_%s" % sanitize_string(type_name)\n    kw["define_comment"] = "/* The size of `%s\', as computed by sizeof. */" % type_name\n    kw["msg"] = "Checking sizeof(%s)" % type_name\n\n    validate_arguments(conf, kw)\n    conf.start_msg(kw["msg"])\n\n    if expected_sizes is not None:\n        try:\n            val = int(expected_sizes)\n        except TypeError:\n            values = expected_sizes\n        else:\n            values = [val]\n\n        size = None\n        for value in values:\n            code =  % {"type": type_name, "size": value}\n            kw["code"] = to_header(kw) + code\n            try:\n                conf.run_c_code(**kw)\n                size = value\n                break\n            except conf.errors.ConfigurationError:\n                pass\n        if size is None:\n            size = do_binary_search(conf, type_name, kw)\n    else:\n        size = do_binary_search(conf, type_name, kw)\n\n    kw["define_value"] = size\n    kw["success"] = 0\n    conf.end_msg(size)\n    conf.post_check(**kw)\n    return size\n\n@waflib.Configure.conf\ndef check_functions_at_once(self, funcs, **kw):\n    header = []\n    header = [\'    header.append(\'extern "C" {\')\n    header.append(\'    for f in funcs:\n        header.append("\\tchar %s();" % f)\n                                        header.append("        header.append("        header.append("    header.append(\'    header.append(\'};\')\n    header.append(\'    funcs_decl = "\\n".join(header)\n\n    tmp = []\n    for f in funcs:\n        tmp.append("\\t%s();" % f)\n    tmp = "\\n".join(tmp)\n\n    code = r % {"tmp": tmp, "include": to_header(kw), "funcs_decl": funcs_decl}\n    kw["code"] = code\n    if not "features" in kw:\n        kw["features"] = ["c", "cprogram"]\n\n    msg = ", ".join(funcs)\n    if len(msg) > 30:\n        _funcs = list(funcs)\n        msg = []\n        while len(", ".join(msg)) < 30 and _funcs:\n            msg.append(_funcs.pop(0))\n        msg = ", ".join(msg) + ",..."\n    if "lib" in kw:\n        kw["msg"] = "Checking for functions %s in library %r" % (msg, kw["lib"])\n    else:\n        kw["msg"] = "Checking for functions %s" % msg\n\n    validate_arguments(self, kw)\n    try_compile(self, kw)\n    ret = kw["success"]\n\n            if ret == 0:\n        for f in funcs:\n            self.define_with_comment("HAVE_%s" % sanitize_string(f), 1,\n                                "/* Define to 1 if you have the `%s\' function. */" % f)\n\n    self.post_check(**kw)\n    if not kw.get(\'execute\', False):\n        return ret == 0\n    return ret\n\n@waflib.Configure.conf\ndef check_inline(conf, **kw):\n    validate_arguments(conf, kw)\n\n    code = \n\n    conf.start_msg("Checking for inline support")\n    inline = None\n    for k in [\'inline\', \'__inline__\', \'__inline\']:\n        try:\n            kw["code"] = code % {"inline": k}\n            ret = conf.run_c_code(**kw)\n            inline = k\n            break\n        except conf.errors.ConfigurationError:\n            pass\n\n    if inline is None:\n        conf.end_msg("failed", \'YELLOW\')\n        if Logs.verbose > 1:\n            raise\n        else:\n            conf.fatal(\'The configuration failed\')\n    else:\n        kw[\'success\'] = ret\n        conf.end_msg(inline)\n        return inline\n\n@waflib.Configure.conf\ndef check_ldouble_representation(conf, **kw):\n    msg = {\n        \'INTEL_EXTENDED_12_BYTES_LE\': "Intel extended, little endian",\n        \'INTEL_EXTENDED_16_BYTES_LE\': "Intel extended, little endian",\n        \'IEEE_QUAD_BE\': "IEEE Quad precision, big endian",\n        \'IEEE_QUAD_LE\': "IEEE Quad precision, little endian",\n        \'IEEE_DOUBLE_LE\': "IEEE Double precision, little endian",\n        \'IEEE_DOUBLE_BE\': "IEEE Double precision, big endian"\n    }\n\n    code = LONG_DOUBLE_REPRESENTATION_SRC % {\'type\': \'long double\'}\n    validate_arguments(conf, kw)\n\n    conf.start_msg("Checking for long double representation... ")\n    try:\n        kw["code"] = code\n        ret = conf.run_c_code(**kw)\n    except conf.errors.ConfigurationError as e:\n        conf.end_msg(kw[\'errmsg\'], \'YELLOW\')\n        if Logs.verbose > 1:\n            raise\n        else:\n            conf.fatal(\'The configuration failed\')\n    else:\n        task_gen = conf.test_bld.groups[0][0]\n        obj_filename = task_gen.tasks[0].outputs[0].abspath()\n        tp = long_double_representation(pyod(obj_filename))\n        kw[\'success\'] = ret\n        conf.end_msg(msg[tp])\n        kw["define_name"] = "HAVE_LDOUBLE_%s" % tp\n        kw["define_comment"] = "/* Define for arch-specific long double representation */"\n    ret = kw["success"]\n\n    conf.post_check(**kw)\n    if not kw.get(\'execute\', False):\n        return ret == 0\n    return ret\n\n@waflib.Configure.conf\ndef post_check(self, *k, **kw):\n    "set the variables after a test was run successfully"\n\n    is_success = False\n    if kw[\'execute\']:\n        if kw[\'success\'] is not None:\n            if kw.get(\'define_ret\', False):\n                is_success = kw[\'success\']\n            else:\n                is_success = (kw[\'success\'] == 0)\n    else:\n        is_success = (kw[\'success\'] == 0)\n\n    def define_or_stuff():\n        nm = kw[\'define_name\']\n        cmt = kw.get(\'define_comment\', None)\n        value = kw.get("define_value", is_success)\n        if kw[\'execute\'] and kw.get(\'define_ret\', None) and isinstance(is_success, str):\n            self.define_with_comment(kw[\'define_name\'], value, cmt, quote=kw.get(\'quote\', 1))\n        else:\n            self.define_cond(kw[\'define_name\'], value, cmt)\n\n    if \'define_name\' in kw:\n        define_or_stuff()\n\n    if is_success and \'uselib_store\' in kw:\n        from waflib.Tools import ccroot\n\n                _vars = set([])\n        for x in kw[\'features\']:\n            if x in ccroot.USELIB_VARS:\n                _vars |= ccroot.USELIB_VARS[x]\n\n        for k in _vars:\n            lk = k.lower()\n            if k == \'INCLUDES\': lk = \'includes\'\n            if k == \'DEFKEYS\': lk = \'defines\'\n            if lk in kw:\n                val = kw[lk]\n                                if isinstance(val, str):\n                    val = val.rstrip(os.path.sep)\n                self.env.append_unique(k + \'_\' + kw[\'uselib_store\'], val)\n    return is_success\n\n@waflib.Configure.conf\ndef define_with_comment(conf, define, value, comment=None, quote=True):\n    if comment is None:\n        return conf.define(define, value, quote)\n\n    assert define and isinstance(define, str)\n\n    comment_tbl = conf.env[DEFINE_COMMENTS] or {}\n    comment_tbl[define] = comment\n    conf.env[DEFINE_COMMENTS] = comment_tbl\n\n    return conf.define(define, value, quote)\n\n@waflib.Configure.conf\ndef undefine_with_comment(conf, define, comment=None):\n    if comment is None:\n        return conf.undefine(define)\n\n    comment_tbl = conf.env[DEFINE_COMMENTS] or {}\n    comment_tbl[define] = comment\n    conf.env[DEFINE_COMMENTS] = comment_tbl\n\n    conf.undefine(define)\n\n@waflib.Configure.conf\ndef get_comment(self, key):\n    assert key and isinstance(key, str)\n\n    if key in self.env[DEFINE_COMMENTS]:\n        return self.env[DEFINE_COMMENTS][key]\n    return None\n\n@waflib.Configure.conf\ndef define_cond(self, name, value, comment):\n    \n    if value:\n        self.define_with_comment(name, value, comment)\n    else:\n        self.undefine(name)\n\n@waflib.Configure.conf\ndef get_config_header(self, defines=True, headers=False, define_prefix=None):\n    \n    tpl = self.env["CONFIG_HEADER_TEMPLATE"] or "%(content)s"\n\n    lst = []\n    if headers:\n        for x in self.env[INCKEYS]:\n            lst.append(\'\n    if defines:\n        for x in self.env[DEFKEYS]:\n            cmt = self.get_comment(x)\n            if cmt is not None:\n                lst.append(cmt)\n            if self.is_defined(x):\n                val = self.get_define(x)\n                lst.append(\'            else:\n                lst.append(\'/*     return tpl % {"content": "\\n".join(lst)}\n'